MedNLI	O
Is	O
Not	O
Immune	O
:	O
Natural	O
Language	O
Inference	O
Artifacts	O
in	O
the	O
Clinical	O
Domain	O

Crowdworker	O
-	O
constructed	O
natural	O
language	O
inference	O
(	O
NLI	O
)	O
datasets	O
have	O
been	O
found	O
to	O
contain	O
statistical	O
artifacts	O
associated	O
with	O
the	O
annotation	O
process	O
that	O
allow	O
hypothesis	O
-	O
only	O
classifiers	O
to	O
achieve	O
better	O
-	O
than	O
-	O
random	O
performance	O
(	O
Poliak	O
et	O
al	O
.	O
,	O
2018;Gururangan	O
et	O
al	O
.	O
,	O
2018;Tsuchiya	O
,	O
2018	O
)	O
.	O
We	O
investigate	O
whether	O
MedNLI	O
,	O
a	O
physician	O
-	O
annotated	O
dataset	O
with	O
premises	O
extracted	O
from	O
clinical	O
notes	O
,	O
contains	O
such	O
artifacts	O
(	O
Romanov	O
and	O
Shivade	O
,	O
2018	O
)	O
.	O
We	O
find	O
that	O
entailed	O
hypotheses	O
contain	O
generic	O
versions	O
of	O
specific	O
concepts	O
in	O
the	O
premise	O
,	O
as	O
well	O
as	O
modifiers	O
related	O
to	O
responsiveness	O
,	O
duration	O
,	O
and	O
probability	O
.	O
Neutral	O
hypotheses	O
feature	O
conditions	O
and	O
behaviors	O
that	O
co	O
-	O
occur	O
with	O
,	O
or	O
cause	O
,	O
the	O
condition(s	O
)	O
in	O
the	O
premise	O
.	O
Contradiction	O
hypotheses	O
feature	O
explicit	O
negation	O
of	O
the	O
premise	O
and	O
implicit	O
negation	O
via	O
assertion	O
of	O
good	O
health	O
.	O
Adversarial	O
filtering	O
demonstrates	O
that	O
performance	O
degrades	O
when	O
evaluated	O
on	O
the	O
difficult	O
subset	O
.	O
We	O
provide	O
partition	O
information	O
and	O
recommendations	O
for	O
alternative	O
dataset	O
construction	O
strategies	O
for	O
knowledge	O
-	O
intensive	O
domains	O
.	O

Introduction	O

In	O
the	O
clinical	O
domain	O
,	O
the	O
ability	O
to	O
conduct	O
natural	O
language	O
inference	O
(	O
NLI	O
)	O
on	O
unstructured	O
,	O
domainspecific	O
texts	O
such	O
as	O
patient	O
notes	O
,	O
pathology	O
reports	O
,	O
and	O
scientific	O
papers	O
,	O
plays	O
a	O
critical	O
role	O
in	O
the	O
development	O
of	O
predictive	O
models	O
and	O
clinical	O
decision	O
support	O
(	O
CDS	O
)	O
systems	O
.	O

Considerable	O
progress	O
in	O
domain	O
-	O
agnostic	O
NLI	O
has	O
been	O
facilitated	O
by	O
the	O
development	O
of	O
largescale	O
,	O
crowdworker	O
-	O
constructed	O
datasets	O
,	O
including	O
the	O
Stanford	O
Natural	O
Language	O
Inference	O
corpus	O
(	O
SNLI	O
)	O
,	O
and	O
the	O
Multi	O
-	O
Genre	O
Natural	O
Language	O
Inference	O
(	O
MultiNLI	O
)	O
corpus	O
(	O
Bowman	O
et	O
al	O
.	O
,	O
2015;Williams	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
MedNLI	O
is	O
a	O
similarlymotivated	O
,	O
healthcare	O
-	O
specific	O
dataset	O
created	O
by	O
a	O
small	O
team	O
of	O
physician	O
-	O
annotators	O
in	O
lieu	O
of	O
crowdworkers	O
,	O
due	O
to	O
the	O
extensive	O
domain	O
expertise	O
required	O
(	O
Romanov	O
and	O
Shivade	O
,	O
2018	O
)	O
.	O
Poliak	O
et	O
al	O
.	O
(	O
2018	O
)	O
,	O
Gururangan	O
et	O
al	O
.	O
(	O
2018	O
)	O
,	O
Tsuchiya	O
(	O
2018	O
)	O
,	O
andMcCoy	O
et	O
al	O
.	O
(	O
2019	O
)	O
empirically	O
demonstrate	O
that	O
SNLI	O
and	O
MultiNLI	O
contain	O
lexical	O
and	O
syntactic	O
annotation	O
artifacts	O
that	O
are	O
disproportionately	O
associated	O
with	O
specific	O
classes	O
,	O
allowing	O
a	O
hypothesis	O
-	O
only	O
classifier	O
to	O
significantly	O
outperform	O
a	O
majority	O
-	O
class	O
baseline	O
model	O
.	O
The	O
presence	O
of	O
such	O
artifacts	O
is	O
hypothesized	O
to	O
be	O
partially	O
attributable	O
to	O
the	O
priming	O
effect	O
of	O
the	O
example	O
hypotheses	O
provided	O
to	O
crowdworkers	O
at	O
annotation	O
-	O
time	O
.	O
Romanov	O
and	O
Shivade	O
(	O
2018	O
)	O
note	O
that	O
a	O
hypothesis	O
-	O
only	O
baseline	O
is	O
able	O
to	O
outperform	O
a	O
majority	O
class	O
baseline	O
in	O
MedNLI	O
,	O
but	O
they	O
do	O
not	O
identify	O
specific	O
artifacts	O
.	O

We	O
confirm	O
the	O
presence	O
of	O
annotation	O
artifacts	O
in	O
MedNLI	O
and	O
proceed	O
to	O
identify	O
their	O
lexical	O
and	O
semantic	O
characteristics	O
.	O
We	O
then	O
conduct	O
adversarial	O
filtering	O
to	O
partition	O
MedNLI	O
into	O
easy	O
and	O
difficult	O
subsets	O
(	O
Sakaguchi	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
We	O
find	O
that	O
performance	O
of	O
off	O
-	O
the	O
-	O
shelf	O
fastText	O
-	O
based	O
hypothesis	O
-	O
only	O
and	O
hypothesis	O
-	O
plus	O
-	O
premise	O
classifiers	O
is	O
lower	O
on	O
the	O
difficult	O
subset	O
than	O
on	O
the	O
full	O
and	O
easy	O
subsets	O
(	O
Joulin	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
We	O
provide	O
partition	O
information	O
for	O
downstream	O
use	O
,	O
and	O
conclude	O
by	O
advocating	O
alternative	O
dataset	O
construction	O
strategies	O
for	O
knowledge	O
-	O
intensive	O
domains	O
.	O
1	O

The	O
MedNLI	O
Dataset	O

MedNLI	O
is	O
domain	O
-	O
specific	O
evaluation	O
dataset	O
inspired	O
by	O
general	O
-	O
purpose	O
NLI	O
datasets	O
,	O
including	O
SNLI	O
and	O
MultiNLI	O
(	O
Romanov	O
and	O
Shivade	O
,	O
2018;Bowman	O
et	O
al	O
.	O
,	O
2015;Williams	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
Much	O
like	O
its	O
predecessors	O
,	O
MedNLI	O
consists	O
of	O
premisehypothesis	O
pairs	O
,	O
in	O
which	O
the	O
premises	O
are	O
drawn	O
1021	O
from	O
the	O
Past	O
Medical	O
History	O
sections	O
of	O
a	O
randomly	O
selected	O
subset	O
of	O
de	O
-	O
identified	O
clinical	O
notes	O
contained	O
in	O
MIMIC	O
-	O
III	O
(	O
Johnson	O
et	O
al	O
.	O
,	O
2016;Goldberger	O
et	O
al	O
.	O
,	O
2000	O
(	O
June	O
13	O
)	O
.	O
MIMIC	O
-	O
III	O
was	O
created	O
from	O
the	O
records	O
of	O
adult	O
and	O
neonatal	O
intensive	O
care	O
unit	O
(	O
ICU	O
)	O
patients	O
.	O
As	O
such	O
,	O
complex	O
and	O
clinically	O
severe	O
cases	O
are	O
disproportionately	O
represented	O
,	O
relative	O
to	O
their	O
frequency	O
of	O
occurrence	O
in	O
the	O
general	O
population	O
.	O

Physician	O
-	O
annotators	O
were	O
asked	O
to	O
write	O
a	O
definitely	O
true	O
,	O
maybe	O
true	O
,	O
and	O
definitely	O
false	O
set	O
of	O
hypotheses	O
for	O
each	O
premise	O
,	O
corresponding	O
to	O
entailment	O
,	O
neutral	O
and	O
contradiction	O
labels	O
,	O
respectively	O
.	O
The	O
resulting	O
dataset	O
has	O
cardinality	O
:	O
n	O
train	O
=	O
11232	O
;	O
n	O
dev	O
=	O
1395	O
;	O
n	O
test	O
=	O
1422	O
.	O

MedNLI	O
Contains	O
Artifacts	O

To	O
determine	O
whether	O
MedNLI	O
contains	O
annotation	O
artifacts	O
that	O
may	O
artificially	O
inflate	O
the	O
performance	O
of	O
models	O
trained	O
on	O
this	O
dataset	O
,	O
we	O
train	O
a	O
simple	O
,	O
premise	O
-	O
unaware	O
,	O
fastText	O
classifier	O
to	O
predict	O
the	O
label	O
of	O
each	O
premise	O
-	O
hypothesis	O
pair	O
,	O
and	O
compare	O
the	O
performance	O
of	O
this	O
classifier	O
to	O
a	O
majority	O
-	O
class	O
baseline	O
,	O
in	O
which	O
all	O
training	O
examples	O
are	O
mapped	O
to	O
the	O
most	O
commonly	O
occurring	O
class	O
label	O
(	O
Joulin	O
et	O
al	O
.	O
,	O
2016;Poliak	O
et	O
al	O
.	O
,	O
2018;Gururangan	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
Note	O
that	O
since	O
annotators	O
were	O
asked	O
to	O
create	O
an	O
entailed	O
,	O
contradictory	O
,	O
and	O
neutral	O
hypothesis	O
for	O
each	O
premise	O
,	O
MedNLI	O
is	O
class	O
-	O
balanced	O
.	O
Thus	O
,	O
in	O
this	O
setting	O
,	O
a	O
majority	O
class	O
baseline	O
is	O
equivalent	O
to	O
choosing	O
a	O
label	O
uniformly	O
at	O
random	O
for	O
each	O
training	O
example	O
.	O

The	O
micro	O
F1	O
-	O
score	O
achieved	O
by	O
the	O
fastText	O
classifier	O
significantly	O
exceeds	O
that	O
of	O
the	O
majority	O
class	O
baseline	O
,	O
confirming	O
the	O
findings	O
of	O
Romanov	O
and	O
Shivade	O
(	O
2018	O
)	O
,	O
who	O
report	O
a	O
micro	O
-	O
F1	O
score	O
of	O
61.9	O
but	O
do	O
not	O
identify	O
or	O
analyze	O
artifacts	O
:	O

Characteristics	O
of	O
Clinical	O
Artifacts	O

In	O
this	O
section	O
,	O
we	O
conduct	O
class	O
-	O
specific	O
lexical	O
analysis	O
to	O
identify	O
the	O
clinical	O
and	O
domainagnostic	O
characteristics	O
of	O
annotation	O
artifacts	O
associated	O
with	O
each	O
set	O
of	O
hypotheses	O
in	O
MedNLI	O
.	O

Preprocessing	O

We	O
cast	O
each	O
hypothesis	O
string	O
in	O
the	O
MedNLI	O
training	O
dataset	O
to	O
lowercase	O
.	O
We	O
then	O
use	O
a	O
scispaCy	O
model	O
pre	O
-	O
trained	O
on	O
the	O
en_core_sci_lg	O
corpus	O
for	O
tokenization	O
and	O
clinical	O
named	O
entity	O
recognition	O
(	O
CNER	O
)	O
(	O
Neumann	O
et	O
al	O
.	O
,	O
2019a	O
)	O
.	O
One	O
challenge	O
associated	O
with	O
clinical	O
text	O
,	O
and	O
scientific	O
text	O
more	O
generally	O
,	O
is	O
that	O
semantically	O
meaningful	O
entities	O
often	O
consist	O
of	O
spans	O
rather	O
than	O
single	O
tokens	O
.	O
To	O
mitigate	O
this	O
issue	O
during	O
lexical	O
analysis	O
,	O
we	O
map	O
each	O
multi	O
-	O
token	O
entity	O
to	O
a	O
single	O
-	O
token	O
representation	O
,	O
where	O
sub	O
-	O
tokens	O
are	O
separated	O
by	O
underscores	O
.	O

Lexical	O
Artifacts	O

Following	O
Gururangan	O
et	O
al	O
.	O
(	O
2018	O
)	O
,	O
to	O
identify	O
tokens	O
that	O
occur	O
disproportionately	O
in	O
hypotheses	O
associated	O
with	O
a	O
specific	O
class	O
,	O
we	O
compute	O
tokenclass	O
pointwise	O
mutual	O
information	O
(	O
PMI	O
)	O
with	O
add-50	O
smoothing	O
applied	O
to	O
raw	O
counts	O
,	O
and	O
a	O
filter	O
to	O
exclude	O
tokens	O
appearing	O
less	O
than	O
five	O
times	O
in	O
the	O
overall	O
training	O
dataset	O
.	O

Physician	O
-	O
Annotator	O
Heuristics	O

In	O
this	O
section	O
,	O
we	O
re	O
-	O
introduce	O
premises	O
to	O
our	O
analysis	O
to	O
evaluate	O
a	O
set	O
of	O
hypotheses	O
regarding	O
latent	O
,	O
class	O
-	O
specific	O
annotator	O
heuristics	O
.	O
If	O
annotators	O
do	O
employ	O
class	O
-	O
specific	O
heuristics	O
,	O
we	O
should	O
expect	O
the	O
semantic	O
contents	O
,	O
ϕ	O
,	O
of	O
a	O
given	O
hypothesis	O
,	O
h	O
∈	O
H	O
,	O
to	O
be	O
influenced	O
not	O
only	O
by	O
the	O
semantic	O
contents	O
of	O
its	O
associated	O
premise	O
,	O
p	O
∈	O
P	O
,	O
but	O
also	O
by	O
the	O
target	O
class	O
,	O
c	O
∈	O
C.	O

To	O
investigate	O
,	O
we	O
identify	O
a	O
set	O
of	O
heuristics	O
parameterized	O
by	O
ϕ(p	O
)	O
and	O
c	O
,	O
and	O
characterized	O
by	O
the	O
presence	O
of	O
a	O
set	O
of	O
heuristic	O
-	O
specific	O
Medical	O
Subject	O
Headings	O
(	O
MeSH	O
)	O
linked	O
entities	O
in	O
the	O
premise	O
and	O
hypothesis	O
of	O
each	O
heuristic	O
-	O
satisfying	O
example	O
.	O
These	O
heuristics	O
are	O
described	O
below	O
;	O
specific	O
MeSH	O
features	O
are	O
detailed	O
in	O
the	O
Appendix	O
.	O

Hypernym	O
Heuristic	O
This	O
heuristic	O
applies	O
when	O
the	O
premise	O
contains	O
clinical	O
condition(s	O
)	O
,	O
medication(s	O
)	O
,	O
finding(s	O
)	O
,	O
procedure(s	O
)	O
or	O
event(s	O
)	O
,	O
the	O
target	O
class	O
is	O
entailment	O
,	O
and	O
the	O
generated	O
hypothesis	O
contains	O
term(s	O
)	O
that	O
can	O
be	O
interpreted	O
as	O
super	O
-	O
types	O
for	O
a	O
subset	O
of	O
elements	O
in	O
the	O
premise	O
(	O
e.g.	O
,	O
clindamycin	O
<	O
:	O
antibiotic	O
)	O
.	O

Probable	O
Cause	O
Heuristic	O
This	O
heuristic	O
applies	O
when	O
the	O
premise	O
contains	O
clinical	O
condition(s	O
)	O
,	O
the	O
target	O
class	O
is	O
neutral	O
,	O
and	O
the	O
generated	O
hypothesis	O
provides	O
a	O
plausible	O
,	O
often	O
subjective	O
or	O
behavioral	O
,	O
causal	O
explanation	O
for	O
the	O
condition	O
,	O
finding	O
,	O
or	O
event	O
described	O
in	O
the	O
premise	O
(	O
e.g.	O
,	O
associating	O
altered	O
mental	O
status	O
with	O
drug	O
overdose	O
)	O
.	O

Everything	O
Is	O
Fine	O
Heuristic	O
This	O
heuristic	O
applies	O
when	O
the	O
premise	O
contains	O
condition(s	O
)	O
or	O
finding(s	O
)	O
,	O
the	O
target	O
class	O
is	O
contradiction	O
,	O
and	O
the	O
generated	O
hypothesis	O
negates	O
the	O
premise	O
or	O
asserts	O
unremarkable	O
finding(s	O
)	O
.	O
This	O
can	O
take	O
two	O
forms	O
:	O
repetition	O
of	O
premise	O
content	O
plus	O
negation	O
,	O
or	O
inclusion	O
of	O
modifiers	O
that	O
convey	O
good	O
health	O
.	O

Analysis	O
We	O
conduct	O
a	O
χ	O
2	O
test	O
for	O
each	O
heuristic	O
to	O
determine	O
whether	O
we	O
are	O
able	O
to	O
reject	O
the	O
null	O
hypothesis	O
that	O
pattern	O
-	O
satisfying	O
premisehypothesis	O
pairs	O
are	O
uniformly	O
distributed	O
over	O
classes	O
.	O
The	O
results	O
support	O
our	O
hypotheses	O
regarding	O
each	O
of	O
the	O
three	O
heuristics	O
.	O
Notably	O
,	O
the	O
percentage	O
of	O
heuristic	O
-	O
satisfying	O
pairs	O
accounted	O
for	O
by	O
the	O
top	O
class	O
is	O
lowest	O
for	O
the	O
HYPERNYM	O
hypothesis	O
,	O
which	O
we	O
attribute	O
to	O
the	O
high	O
degree	O
of	O
semantic	O
overlap	O
between	O
entailed	O
and	O
neutral	O
hypotheses	O
.	O

Adversarial	O
Filtering	O

To	O
mitigate	O
the	O
effect	O
of	O
clinical	O
annotation	O
artifacts	O
,	O
we	O
employ	O
AFLite	O
,	O
an	O
adversarial	O
filtering	O
algorithm	O
introduced	O
by	O
Sakaguchi	O
et	O
AFLite	O
requires	O
distributed	O
representations	O
of	O
the	O
full	O
dataset	O
as	O
input	O
,	O
and	O
proceeds	O
in	O
an	O
iterative	O
fashion	O
.	O
At	O
each	O
iteration	O
,	O
an	O
ensemble	O
of	O
n	O
linear	O
classifiers	O
are	O
trained	O
and	O
evaluated	O
on	O
different	O
random	O
subsets	O
of	O
the	O
data	O
.	O
A	O
score	O
is	O
then	O
computed	O
for	O
each	O
premise	O
-	O
hypothesis	O
instance	O
,	O
reflecting	O
the	O
number	O
of	O
times	O
the	O
instance	O
is	O
correctly	O
labeled	O
by	O
a	O
classifier	O
,	O
divided	O
by	O
the	O
number	O
of	O
times	O
the	O
instance	O
appears	O
in	O
any	O
classifier	O
's	O
evaluation	O
set	O
.	O
The	O
top	O
-	O
k	O
instances	O
with	O
scores	O
above	O
a	O
threshold	O
,	O
τ	O
,	O
are	O
filtered	O
out	O
and	O
added	O
to	O
the	O
easy	O
partition	O
;	O
the	O
remaining	O
instances	O
are	O
retained	O
.	O
This	O
process	O
continues	O
until	O
the	O
size	O
of	O
the	O
filtered	O
subset	O
is	O
<	O
k	O
,	O
or	O
the	O
number	O
of	O
retained	O
instances	O
is	O
<	O
m	O
;	O
retained	O
instances	O
constitute	O
the	O
difficult	O
partition	O
.	O

To	O
represent	O
the	O
full	O
dataset	O
,	O
we	O
use	O
fastText	O
MIMIC	O
-	O
III	O
embeddings	O
,	O
which	O
have	O
been	O
pretrained	O
on	O
deidentified	O
patient	O
notes	O
from	O
MIMIC	O
-	O
III	O
(	O
Romanov	O
and	O
Shivade	O
,	O
2018;Johnson	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
We	O
represent	O
each	O
example	O
as	O
the	O
average	O
of	O
its	O
component	O
token	O
vectors	O
.	O
We	O
proportionally	O
adjust	O
a	O
subset	O
of	O
the	O
hyperparameters	O
used	O
by	O
Sakaguchi	O
et	O
al	O
.	O
(	O
2020	O
)	O
to	O
account	O
for	O
the	O
fact	O
that	O
MedNLI	O
contains	O
far	O
fewer	O
examples	O
than	O
WINOGRANDE	O
2	O
:	O
specifically	O
,	O
we	O
set	O
the	O
training	O
size	O
for	O
each	O
ensemble	O
,	O
m	O
,	O
to	O
5620	O
,	O
which	O
represents	O
≈	O
2	O
5	O
of	O
the	O
MedNLI	O
combined	O
dataset	O
.	O
The	O
remaining	O
hyperparameters	O
are	O
unchanged	O
:	O
the	O
ensemble	O
consists	O
of	O
n	O
=	O
64	O
logistic	O
regression	O
models	O
,	O
the	O
filtering	O
cutoff	O
,	O
k	O
=	O
500	O
,	O
and	O
the	O
filtering	O
threshold	O
τ	O
=	O
0.75	O
.	O

We	O
apply	O
AFLite	O
to	O
two	O
different	O
versions	O
of	O
MedNLI	O
:	O
(	O
1	O
)	O
X	O
h	O
,	O
m	O
:	O
hypothesis	O
-	O
only	O
,	O
multi	O
-	O
token	O
entities	O
merged	O
,	O
and	O
(	O
2	O
)	O
X	O
ph	O
,	O
m	O
:	O
premise	O
and	O
hypothesis	O
concatenated	O
,	O
multi	O
-	O
token	O
entities	O
merged	O
.	O
AFLIte	O
maps	O
each	O
version	O
to	O
an	O
easy	O
and	O
difficult	O
partition	O
,	O
which	O
can	O
in	O
turn	O
be	O
split	O
into	O
training	O
,	O
dev	O
,	O
and	O
test	O
subsets	O
.	O
We	O
report	O
results	O
for	O
the	O
fastText	O
classifier	O
trained	O
on	O
the	O
original	O
,	O
hypothesis	O
-	O
only	O
(	O
hypothesis	O
+	O
premise	O
)	O
MedNLI	O
training	O
set	O
,	O
and	O
evaluated	O
on	O
the	O
full	O
,	O
easy	O
and	O
difficult	O
dev	O
and	O
test	O
subsets	O
of	O
X	O
h	O
,	O
m	O
(	O
X	O
ph	O
,	O
m	O
)	O
,	O
and	O
observe	O
that	O
performance	O
decreases	O
on	O
the	O
difficult	O
partition	O
:	O

Discussion	O

MedNLI	O
is	O
Not	O
Immune	O
from	O
Artifacts	O

In	O
this	O
paper	O
,	O
we	O
demonstrate	O
that	O
MedNLI	O
suffers	O
from	O
the	O
same	O
challenge	O
associated	O
with	O
annotation	O
artifacts	O
that	O
its	O
domain	O
-	O
agnostic	O
predecessors	O
have	O
encountered	O
:	O
namely	O
,	O
NLI	O
models	O
trained	O
on	O
{	O
Med	O
,	O
S	O
,	O
Multi}NLI	O
can	O
perform	O
well	O
even	O
without	O
access	O
to	O
the	O
training	O
examples	O
'	O
premises	O
,	O
indicating	O
that	O
they	O
often	O
exploit	O
shallow	O
heuristics	O
,	O
with	O
negative	O
implications	O
for	O
out	O
-	O
of	O
-	O
sample	O
generalization	O
.	O
Interestingly	O
,	O
many	O
of	O
the	O
high	O
-	O
level	O
lexical	O
characteristics	O
identified	O
in	O
MedNLI	O
can	O
be	O
considered	O
domain	O
-	O
specific	O
variants	O
of	O
the	O
more	O
generic	O
,	O
classspecific	O
patterns	O
identified	O
in	O
SNLI	O
.	O
This	O
observation	O
suggests	O
that	O
a	O
set	O
of	O
abstract	O
design	O
patterns	O
for	O
inference	O
example	O
generation	O
exists	O
across	O
domains	O
,	O
and	O
may	O
be	O
reinforced	O
by	O
the	O
prompts	O
provided	O
to	O
annotators	O
.	O
Creative	O
or	O
randomized	O
priming	O
,	O
such	O
as	O
Sakaguchi	O
et	O
al	O
.	O
(	O
2020	O
)	O
's	O
use	O
of	O
anchor	O
words	O
from	O
WikiHow	O
articles	O
,	O
may	O
help	O
to	O
decrease	O
reliance	O
on	O
such	O
design	O
patterns	O
,	O
but	O
it	O
appears	O
unlikely	O
that	O
they	O
can	O
be	O
systematically	O
sidestepped	O
without	O
introducing	O
new	O
,	O
"	O
corrective	O
"	O
artifacts	O
.	O

A	O
Prescription	O
for	O
Dataset	O
Construction	O

To	O
mitigate	O
the	O
risk	O
of	O
performance	O
overestimation	O
associated	O
with	O
annotation	O
artifacts	O
,	O
Zellers	O
et	O
al	O
.	O
(	O
2019	O
)	O
advocate	O
adversarial	O
dataset	O
construction	O
,	O
such	O
that	O
benchmarks	O
will	O
co	O
-	O
evolve	O
with	O
language	O
models	O
.	O
This	O
may	O
be	O
difficult	O
to	O
scale	O
in	O
knowledge	O
-	O
intensive	O
domains	O
,	O
as	O
expert	O
validation	O
of	O
adversarially	O
generated	O
benchmarks	O
is	O
typically	O
required	O
.	O
Additionally	O
,	O
in	O
high	O
-	O
stakes	O
domains	O
such	O
as	O
medicine	O
,	O
information	O
-	O
rich	O
inferences	O
should	O
be	O
preferred	O
over	O
correct	O
but	O
trivial	O
inferences	O
that	O
time	O
-	O
constrained	O
expert	O
annotators	O
may	O
be	O
rationally	O
incentivized	O
to	O
produce	O
,	O
because	O
entropy	O
-	O
reducing	O
inferences	O
are	O
more	O
useful	O
for	O
downstream	O
tasks	O
.	O

We	O
advocate	O
the	O
adoption	O
of	O
a	O
mechanism	O
design	O
perspective	O
,	O
so	O
as	O
to	O
develop	O
modified	O
annotation	O
tasks	O
that	O
reduce	O
the	O
cognitive	O
load	O
placed	O
on	O
expert	O
annotators	O
while	O
incentivizing	O
the	O
production	O
of	O
domain	O
-	O
specific	O
NLI	O
datasets	O
with	O
high	O
downstream	O
utility	O
(	O
Ho	O
et	O
al	O
.	O
,	O
2015;Liu	O
and	O
Chen	O
,	O
2017	O
)	O
.	O
An	O
additional	O
option	O
is	O
to	O
narrow	O
the	O
generative	O
scope	O
by	O
defining	O
a	O
set	O
of	O
inferences	O
deemed	O
to	O
be	O
useful	O
for	O
a	O
specific	O
task	O
.	O
Annotators	O
can	O
then	O
map	O
(	O
premise	O
,	O
relation	O
)	O
tuples	O
to	O
relation	O
-	O
satisfying	O
,	O
potentially	O
fuzzy	O
subsets	O
of	O
this	O
pool	O
of	O
useful	O
inferences	O
,	O
or	O
return	O
partial	O
functions	O
when	O
more	O
information	O
is	O
needed	O
.	O

Ethical	O
Considerations	O

When	O
working	O
with	O
clinical	O
data	O
,	O
two	O
key	O
ethical	O
objectives	O
include	O
:	O
(	O
1	O
)	O
the	O
preservation	O
of	O
pa	O
-	O
tient	O
privacy	O
,	O
and	O
(	O
2	O
)	O
the	O
development	O
of	O
language	O
and	O
predictive	O
models	O
that	O
benefit	O
patients	O
and	O
providers	O
to	O
the	O
extent	O
possible	O
,	O
without	O
causing	O
undue	O
harm	O
.	O
With	O
respect	O
to	O
the	O
former	O
,	O
MedNLI	O
's	O
premises	O
are	O
sampled	O
from	O
de	O
-	O
identified	O
clinical	O
notes	O
contained	O
in	O
MIMIC	O
-	O
III	O
(	O
Goldberger	O
et	O
al	O
.	O
,	O
2000	O
(	O
June	O
13;Johnson	O
et	O
al	O
.	O
,	O
2016	O
)	O
,	O
and	O
the	O
hypotheses	O
generated	O
by	O
annotators	O
do	O
not	O
refer	O
to	O
specific	O
patients	O
,	O
providers	O
,	O
or	O
locations	O
by	O
name	O
.	O
MedNLI	O
requires	O
users	O
to	O
complete	O
Health	O
Insurance	O
Portability	O
and	O
Accountability	O
Act	O
(	O
HIPAA	O
)	O
training	O
and	O
sign	O
a	O
data	O
use	O
agreement	O
prior	O
to	O
being	O
granted	O
access	O
,	O
which	O
we	O
have	O
complied	O
with	O
.	O

Per	O
MedNLI	O
's	O
data	O
use	O
agreement	O
requirements	O
,	O
we	O
do	O
not	O
attempt	O
to	O
identify	O
any	O
patient	O
,	O
provider	O
,	O
or	O
institution	O
mentioned	O
in	O
the	O
de	O
-	O
identified	O
corpus	O
.	O
Additionally	O
,	O
while	O
we	O
provide	O
AFLite	O
easy	O
and	O
difficult	O
partition	O
information	O
for	O
community	O
use	O
in	O
the	O
form	O
of	O
split	O
-	O
example	O
ids	O
and	O
a	O
checksum	O
,	O
we	O
do	O
not	O
share	O
the	O
premise	O
or	O
hypothesis	O
text	O
associated	O
with	O
any	O
example	O
.	O
Interested	O
readers	O
are	O
encouraged	O
to	O
complete	O
the	O
necessary	O
training	O
and	O
obtain	O
credentials	O
so	O
that	O
they	O
can	O
access	O
the	O
complete	O
dataset	O
(	O
Romanov	O
and	O
Shivade	O
,	O
2018;Goldberger	O
et	O
al	O
.	O
,	O
2000	O
(	O
June	O
13	O
)	O
.	O

With	O
respect	O
to	O
benefiting	O
patients	O
,	O
the	O
discussion	O
of	O
natural	O
language	O
artifacts	O
we	O
have	O
presented	O
is	O
intended	O
to	O
encourage	O
clinical	O
researchers	O
who	O
rely	O
on	O
(	O
or	O
construct	O
)	O
expert	O
-	O
annotated	O
clinical	O
corpora	O
to	O
train	O
domain	O
-	O
specific	O
language	O
models	O
,	O
or	O
consume	O
such	O
models	O
to	O
perform	O
downstream	O
tasks	O
,	O
to	O
be	O
aware	O
of	O
the	O
presence	O
of	O
annotation	O
artifacts	O
,	O
and	O
adjust	O
their	O
assessments	O
of	O
model	O
performance	O
accordingly	O
.	O
It	O
is	O
our	O
hope	O
that	O
these	O
findings	O
can	O
be	O
used	O
to	O
inform	O
error	O
analysis	O
and	O
improve	O
predictive	O
models	O
that	O
inform	O
patient	O
care	O
.	O

A	O
Appendix	O

A.1	O
Hypothesis	O
-	O
only	O
Baseline	O
Analysis	O

To	O
conduct	O
the	O
analysis	O
presented	O
in	O
Section	O
3	O
,	O
we	O
take	O
the	O
MedNLI	O
training	O
dataset	O
as	O
input	O
,	O
and	O
exclude	O
the	O
premise	O
text	O
for	O
each	O
training	O
example	O
.	O
We	O
cast	O
the	O
text	O
of	O
each	O
training	O
hypothesis	O
to	O
lowercase	O
,	O
but	O
do	O
not	O
perform	O
any	O
additional	O
preprocessing	O
.	O
We	O
use	O
an	O
off	O
-	O
the	O
-	O
shelf	O
fastText	O
classifier	O
,	O
with	O
all	O
model	O
hyperparameters	O
set	O
to	O
their	O
default	O
values	O
with	O
the	O
exception	O
of	O
wordNgrams	O
,	O
which	O
we	O
set	O
equal	O
to	O
2	O
to	O
allow	O
the	O
model	O
to	O
use	O
bigrams	O
in	O
addition	O
to	O
unigrams	O
(	O
Joulin	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
We	O
evaluate	O
the	O
trained	O
classifier	O
on	O
the	O
hypotheses	O
contained	O
in	O
the	O
MedNLI	O
dev	O
and	O
test	O
datasets	O
,	O
and	O
report	O
results	O
for	O
each	O
split	O
.	O

A.2	O
Lexical	O
Artifact	O
Analysis	O

To	O
perform	O
the	O
analysis	O
presented	O
in	O
Section	O
4	O
,	O
we	O
cast	O
each	O
hypothesis	O
string	O
in	O
the	O
MedNLI	O
training	O
dataset	O
to	O
lowercase	O
.	O
We	O
then	O
use	O
a	O
scispaCy	O
model	O
pre	O
-	O
trained	O
on	O
the	O
en_core_sci_lg	O
corpus	O
for	O
tokenization	O
and	O
clinical	O
named	O
entity	O
recognition	O
(	O
CNER	O
)	O
(	O
Neumann	O
et	O
al	O
.	O
,	O
2019a	O
)	O
.	O
Next	O
,	O
we	O
merge	O
multi	O
-	O
token	O
entities	O
,	O
using	O
underscores	O
as	O
delimiters	O
-	O
e.g.	O
,	O
"	O
brain	O
injury	O
"	O
→	O
"	O
brain_injury	O
"	O
.	O

When	O
computing	O
token	O
-	O
class	O
pointwise	O
mutual	O
information	O
(	O
PMI	O
)	O
,	O
we	O
exclude	O
tokens	O
that	O
appear	O
less	O
than	O
five	O
times	O
in	O
the	O
overall	O
training	O
dataset	O
's	O
hypotheses	O
.	O
Then	O
,	O
following	O
Gururangan	O
et	O
al	O
.	O
(	O
2018	O
)	O
,	O
who	O
apply	O
add-100	O
smoothing	O
to	O
raw	O
counts	O
to	O
highlight	O
particularly	O
discriminative	O
token	O
-	O
class	O
co	O
-	O
occurrence	O
patterns	O
,	O
we	O
apply	O
add-50	O
smoothing	O
to	O
raw	O
counts	O
.	O
Our	O
approach	O
is	O
similarly	O
motivated	O
;	O
our	O
choice	O
of	O
50	O
reflects	O
the	O
smaller	O
state	O
space	O
associated	O
with	O
a	O
focus	O
on	O
the	O
clinical	O
domain	O
.	O

A.3	O
Semantic	O
Analysis	O
of	O
Heuristics	O

To	O
perform	O
the	O
statistical	O
analysis	O
presented	O
in	O
Section	O
5	O
,	O
we	O
take	O
the	O
premise	O
-	O
hypothesis	O
pairs	O
from	O
the	O
MedNLI	O
training	O
,	O
dev	O
,	O
and	O
test	O
splits	O
,	O
and	O
combine	O
them	O
to	O
produce	O
a	O
single	O
corpus	O
.	O
We	O
use	O
a	O
scispaCy	O
model	O
pre	O
-	O
trained	O
on	O
the	O
en_core_sci_lg	O
corpus	O
for	O
tokenization	O
and	O
entity	O
linking	O
(	O
Neumann	O
et	O
al	O
.	O
,	O
2019b	O
)	O
,	O
and	O
link	O
against	O
the	O
Medical	O
Subject	O
Headings	O
(	O
MeSH	O
)	O
knowledge	O
base	O
.	O
We	O
take	O
the	O
top	O
-	O
ranked	O
knowledge	O
base	O
entry	O
for	O
each	O
linked	O
entity	O
.	O
Linking	O
against	O
MeSH	O
provides	O
a	O
unique	O
concept	O
i	O
d	O
,	O
canonical	O
name	O
,	O
alias(es	O
)	O
,	O
a	O
definition	O
,	O
and	O
one	O
or	O
more	O
MeSH	O
tree	O
numbers	O
for	O
each	O
recovered	O
entity	O
.	O
Tree	O
numbers	O
convey	O
semantic	O
type	O
information	O
by	O
embedding	O
each	O
concept	O
into	O
the	O
broader	O
MeSH	O
hierarchy	O
3	O
.	O
We	O
operationalize	O
each	O
of	O
our	O
heuristics	O
with	O
a	O
set	O
of	O
MeSH	O
-	O
informed	O
semantic	O
properties	O
,	O
which	O
are	O
defined	O
as	O
follows	O
:	O

1	O
.	O
Hypernym	O
Heuristic	O
:	O
a	O
premise	O
-	O
hypothesis	O
pair	O
satisfies	O
this	O
heuristic	O
if	O
specific	O
clinical	O
concept(s	O
)	O
appearing	O
in	O
the	O
premise	O
appear	O
in	O
a	O
more	O
general	O
form	O
in	O
the	O
hypothesis	O
.	O
Formally	O
:	O
{	O
(	O
p	O
,	O
h)|ϕ(p	O
)	O
ϕ(h	O
)	O
}	O
.	O
MeSH	O
tree	O
numbers	O
are	O
organized	O
hierarchically	O
,	O
and	O
increase	O
in	O
length	O
with	O
specificity	O
.	O
Thus	O
,	O
when	O
a	O
premise	O
entity	O
and	O
hypothesis	O
entity	O
are	O
leftaligned	O
,	O
the	O
hypothesis	O
entity	O
is	O
a	O
hypernym	O
for	O
the	O
premise	O
entity	O
if	O
the	O
hypothesis	O
entity	O
is	O
a	O
substring	O
of	O
the	O
premise	O
entity	O
.	O
To	O
provide	O
a	O
concrete	O
example	O
:	O
diabetes	O
mellitus	O
is	O
an	O
endocrine	O
system	O
disease	O
;	O
the	O
associated	O
MeSH	O
tree	O
numbers	O
are	O
C19.246	O
and	O
C19	O
,	O
respectively	O
.	O

2	O
.	O
Probable	O
Cause	O
Heuristic	O
:	O
a	O
premisehypothesis	O
pair	O
satisfies	O
this	O
heuristic	O
if	O
:	O
(	O
1	O
)	O
the	O
premise	O
contains	O
one	O
or	O
more	O
MeSH	O
entities	O
belonging	O
to	O
high	O
-	O
level	O
categories	O
C	O
(	O
diseases	O
)	O
,	O
D	O
(	O
chemicals	O
and	O
drugs	O
)	O
,	O
E	O
(	O
analytical	O
,	O
diagnostic	O
and	O
therapeutic	O
techniques	O
,	O
and	O
equipment	O
)	O
or	O
F	O
(	O
psychiatry	O
and	O
psychology	O
)	O
;	O
and	O
(	O
2	O
)	O
the	O
hypothesis	O
contains	O
one	O
or	O
more	O
MeSH	O
entities	O
that	O
can	O
be	O
interpreted	O
as	O
providing	O
a	O
plausible	O
causal	O
or	O
behavioral	O
explanation	O
for	O
the	O
condition	O
,	O
finding	O
,	O
or	O
event	O
described	O
in	O
the	O
premise	O
(	O
e.g.	O
,	O
smoking	O
,	O
substance	O
-	O
related	O
disorders	O
,	O
mental	O
disorders	O
,	O
alcoholism	O
,	O
homelessness	O
,	O
obesity	O
)	O
.	O

3	O
.	O
Everything	O
Is	O
Fine	O
Heuristic	O
:	O
a	O
premisehypothesis	O
pair	O
satisfies	O
this	O
heuristic	O
if	O
the	O
hypothesis	O
contains	O
one	O
or	O
more	O
of	O
the	O
same	O
MeSH	O
entities	O
as	O
the	O
premise	O
(	O
excluding	O
the	O
patient	O
entity	O
,	O
which	O
appears	O
in	O
almost	O
all	O
notes	O
)	O
and	O
also	O
contains	O
:	O
(	O
1	O
)	O
a	O
negation	O
word	O
or	O
phrase	O
(	O
e.g.	O
,	O
does	O
not	O
have	O
,	O
no	O
finding	O
,	O
no	O
,	O
denies	O
)	O
;	O
or	O
(	O
2	O
)	O
a	O
word	O
or	O
phrase	O
that	O
affirms	O
the	O
patient	O
's	O
health	O
(	O
e.g.	O
,	O
normal	O
,	O
healthy	O
,	O
discharged	O
)	O
.	O

For	O
each	O
heuristic	O
,	O
we	O
subset	O
the	O
complete	O
dataset	O
to	O
find	O
pattern	O
-	O
satisfying	O
premise	O
-	O
heuristic	O
pairs	O
.	O
We	O
use	O
this	O
subset	O
when	O
performing	O
the	O
χ	O
2	O
tests	O
.	O

Acknowledgments	O

We	O
thank	O
the	O
four	O
anonymous	O
reviewers	O
whose	O
feedback	O
and	O
suggestions	O
helped	O
improve	O
this	O
manuscript	O
.	O
The	O
first	O
author	O
was	O
supported	O
by	O
the	O
National	O
Institute	O
of	O
Standards	O
and	O
Technology	O
's	O
(	O
NIST	O
)	O
Professional	O
Research	O
Experience	O
Program	O
(	O
PREP	O
)	O
.	O
This	O
research	O
was	O
also	O
supported	O
by	O
the	O
DARPA	O
KAIROS	O
program	O
.	O
The	O
views	O
and	O
conclusions	O
contained	O
in	O
this	O
publication	O
are	O
those	O
of	O
the	O
authors	O
and	O
should	O
not	O
be	O
interpreted	O
as	O
representing	O
official	O
policies	O
or	O
endorsements	O
of	O
NIST	O
,	O
DARPA	O
,	O
or	O
the	O
U.S.	O
Government	O
.	O

A.4	O
Adversarial	O
Filtering	O

When	O
implementing	O
AFLite	O
,	O
we	O
follow	O
Sakaguchi	O
et	O
al	O
.	O
(	O
2020	O
)	O
.	O
We	O
use	O
a	O
smaller	O
training	O
set	O
size	O
of	O
m	O
=	O
5620	O
,	O
but	O
keep	O
the	O
remaining	O
hyperparameters	O
unchanged	O
,	O
such	O
that	O
the	O
ensemble	O
consists	O
of	O
n	O
=	O
64	O
logistic	O
regression	O
models	O
,	O
the	O
filtering	O
cutoff	O
,	O
k	O
=	O
500	O
,	O
and	O
the	O
filtering	O
threshold	O
τ	O
=	O
0.75	O
.	O

Question	O
Generation	O
for	O
Adaptive	O
Education	O

Intelligent	O
and	O
adaptive	O
online	O
education	O
systems	O
aim	O
to	O
make	O
high	O
-	O
quality	O
education	O
available	O
for	O
a	O
diverse	O
range	O
of	O
students	O
.	O
However	O
,	O
existing	O
systems	O
usually	O
depend	O
on	O
a	O
pool	O
of	O
hand	O
-	O
made	O
questions	O
,	O
limiting	O
how	O
finegrained	O
and	O
open	O
-	O
ended	O
they	O
can	O
be	O
in	O
adapting	O
to	O
individual	O
students	O
.	O
We	O
explore	O
targeted	O
question	O
generation	O
as	O
a	O
controllable	O
sequence	O
generation	O
task	O
.	O
We	O
first	O
show	O
how	O
to	O
fine	O
-	O
tune	O
pre	O
-	O
trained	O
language	O
models	O
for	O
deep	O
knowledge	O
tracing	O
(	O
LM	O
-	O
KT	O
)	O
.	O
This	O
model	O
accurately	O
predicts	O
the	O
probability	O
of	O
a	O
student	O
answering	O
a	O
question	O
correctly	O
,	O
and	O
generalizes	O
to	O
questions	O
not	O
seen	O
in	O
training	O
.	O
We	O
then	O
use	O
LM	O
-	O
KT	O
to	O
specify	O
the	O
objective	O
and	O
data	O
for	O
training	O
a	O
model	O
to	O
generate	O
questions	O
conditioned	O
on	O
the	O
student	O
and	O
target	O
difficulty	O
.	O
Our	O
results	O
show	O
we	O
succeed	O
at	O
generating	O
novel	O
,	O
wellcalibrated	O
language	O
translation	O
questions	O
for	O
second	O
language	O
learners	O
from	O
a	O
real	O
online	O
education	O
platform	O
.	O

Introduction	O

Online	O
education	O
platforms	O
can	O
increase	O
the	O
accessibility	O
of	O
educational	O
resources	O
around	O
the	O
world	O
.	O
However	O
,	O
achieving	O
equitable	O
outcomes	O
across	O
diverse	O
learning	O
needs	O
benefits	O
from	O
systems	O
that	O
are	O
adaptive	O
and	O
individualized	O
to	O
each	O
student	O
(	O
Doroudi	O
and	O
Brunskill	O
,	O
2019	O
)	O
.	O
Traditionally	O
,	O
adaptive	O
education	O
methods	O
involve	O
planning	O
over	O
a	O
pool	O
of	O
pre	O
-	O
made	O
questions	O
(	O
Atkinson	O
,	O
1972;Hunziker	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
These	O
are	O
naturally	O
limited	O
by	O
the	O
diversity	O
and	O
coverage	O
of	O
the	O
pool	O
,	O
as	O
well	O
as	O
the	O
scaling	O
capacity	O
of	O
curriculum	O
planning	O
algorithms	O
.	O
Recent	O
approaches	O
,	O
such	O
as	O
procedural	O
generation	O
for	O
personalized	O
programming	O
games	O
(	O
Valls	O
-	O
Vargas	O
et	O
al	O
.	O
,	O
2017	O
)	O
,	O
are	O
limited	O
to	O
well	O
-	O
specified	O
small	O
domains	O
.	O
We	O
address	O
these	O
limitations	O
by	O
leveraging	O
recent	O
success	O
in	O
deep	O
generative	O
models	O
,	O
in	O
particular	O
language	O
models	O
(	O
LMs	O
)	O
.	O

Many	O
educational	O
activities	O
involve	O
sequential	O
data	O
,	O
such	O
as	O
language	O
translation	O
,	O
reading	O
compre-	O

<	O
Y	O
>	O

Figure	O
1	O
:	O
Example	O
input	O
and	O
outputs	O
for	O
our	O
LM	O
-	O
based	O
knowledge	O
tracing	O
model	O
(	O
middle	O
)	O
and	O
question	O
generation	O
model	O
(	O
bottom	O
)	O
for	O
an	O
online	O
reverse	O
language	O
translation	O
task	O
(	O
top	O
)	O
.	O
A	O
question	O
in	O
this	O
task	O
consists	O
of	O
a	O
target	O
phrase	O
for	O
the	O
student	O
,	O
in	O
this	O
case	O
a	O
Spanish	O
learner	O
,	O
to	O
translate	O
(	O
e.g.	O
"	O
the	O
woman	O
"	O
)	O
.	O

hension	O
,	O
algebra	O
,	O
and	O
deductive	O
logic	O
.	O
Meanwhile	O
,	O
pre	O
-	O
trained	O
LMs	O
can	O
effectively	O
handle	O
sequences	O
from	O
a	O
wide	O
range	O
of	O
modalities	O
(	O
Madani	O
et	O
al	O
.	O
,	O
2020;Polu	O
and	O
Sutskever	O
,	O
2020	O
)	O
.	O
In	O
this	O
work	O
,	O
we	O
focus	O
on	O
natural	O
language	O
sequences	O
,	O
where	O
recent	O
progress	O
in	O
language	O
modeling	O
has	O
shown	O
great	O
success	O
at	O
capturing	O
abstract	O
properties	O
of	O
language	O
(	O
Hewitt	O
and	O
Manning	O
,	O
2019;Liu	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Specifically	O
,	O
we	O
show	O
how	O
pre	O
-	O
trained	O
LMs	O
can	O
be	O
easily	O
leveraged	O
to	O
adaptively	O
generate	O
questions	O
for	O
a	O
given	O
student	O
and	O
target	O
difficulty	O
in	O
a	O
reverse	O
translation	O
task	O
,	O
using	O
difficulty	O
at	O
answering	O
questions	O
as	O
a	O
proxy	O
for	O
more	O
complex	O
future	O
learning	O
objectives	O
.	O

We	O
introduce	O
an	O
LM	O
-	O
based	O
knowledge	O
tracing	O
model	O
(	O
LM	O
-	O
KT	O
)	O
to	O
predict	O
students	O
'	O
difficulty	O
on	O
novel	O
questions	O
(	O
e.g.	O
target	O
phrases	O
to	O
translate	O
)	O
.	O
We	O
show	O
that	O
LM	O
-	O
KT	O
is	O
well	O
-	O
calibrated	O
,	O
allowing	O
us	O
to	O
pose	O
the	O
learning	O
problem	O
for	O
the	O
question	O
generator	O
:	O
given	O
a	O
student	O
state	O
,	O
generate	O
a	O
question	O
that	O
will	O
achieve	O
a	O
target	O
difficulty	O
,	O
according	O
to	O
LM	O
-	O
KT	O
.	O
We	O
evaluate	O
both	O
LM	O
-	O
KT	O
and	O
question	O
generation	O
models	O
on	O
real	O
users	O
and	O
responses	O
from	O
Duolingo	O
1	O
,	O
a	O
popular	O
online	O
second	O
-	O
language	O
learning	O
platform	O
.	O

Background	O
&	O
Related	O
Works	O

There	O
exists	O
a	O
rich	O
body	O
of	O
work	O
on	O
precisely	O
modeling	O
student	O
"	O
ability	O
"	O
and	O
learning	O
.	O
For	O
example	O
,	O
Item	O
Response	O
Theory	O
(	O
IRT	O
)	O
seeks	O
to	O
model	O
individual	O
student	O
ability	O
based	O
on	O
their	O
responses	O
to	O
different	O
questions	O
,	O
creating	O
a	O
strong	O
factorization	O
between	O
students	O
and	O
test	O
items	O
(	O
Lord	O
,	O
1980;Hambelton	O
and	O
Jodoin	O
,	O
2003	O
)	O
.	O
Meanwhile	O
,	O
Computer	O
Adaptive	O
Testing	O
(	O
CAT	O
)	O
techniques	O
are	O
used	O
to	O
determine	O
a	O
fixed	O
student	O
ability	O
as	O
quickly	O
as	O
possible	O
by	O
selecting	O
test	O
items	O
based	O
on	O
information	O
utility	O
(	O
Weiss	O
and	O
Kingsbury	O
,	O
1984;Thissen	O
and	O
Mislevy	O
,	O
2000;Settles	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
However	O
,	O
these	O
methods	O
,	O
which	O
have	O
been	O
used	O
to	O
develop	O
efficient	O
standardized	O
tests	O
,	O
do	O
not	O
necessarily	O
optimize	O
a	O
student	O
's	O
learning	O
experience	O
(	O
Mu	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
We	O
instead	O
focus	O
on	O
tracking	O
each	O
student	O
's	O
evolving	O
knowledge	O
,	O
choosing	O
questions	O
to	O
target	O
difficulty	O
.	O

Knowledge	O
Tracing	O
(	O
KT	O
)	O
seeks	O
to	O
model	O
a	O
student	O
's	O
knowledge	O
state	O
from	O
their	O
answer	O
history	O
in	O
order	O
to	O
help	O
individualize	O
exercise	O
sequences	O
(	O
Corbett	O
and	O
Anderson	O
,	O
1995	O
)	O
.	O
This	O
draws	O
inspiration	O
from	O
traditional	O
education	O
curriculum	O
practices	O
,	O
such	O
as	O
distributed	O
spacing	O
of	O
vocabulary	O
(	O
Bloom	O
and	O
Shuell	O
,	O
1981	O
)	O
and	O
mixed	O
review	O
in	O
mathematics	O
(	O
Rohrer	O
,	O
2009	O
)	O
.	O
To	O
address	O
simplifying	O
assumptions	O
in	O
earlier	O
KT	O
approaches	O
,	O
such	O
as	O
discrete	O
knowledge	O
representations	O
,	O
Piech	O
et	O
al	O
.	O
(	O
2015	O
)	O
introduced	O
Deep	O
Knowledge	O
Tracing	O
(	O
DKT	O
)	O
,	O
which	O
uses	O
RNNs	O
to	O
enable	O
more	O
complex	O
knowledge	O
representations	O
for	O
students	O
.	O
Recently	O
,	O
SAINT+	O
(	O
Shin	O
et	O
al	O
.	O
,	O
2020	O
)	O
showed	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
the	O
popular	O
EdNet	O
KT	O
task	O
using	O
a	O
Transformer	O
model	O
to	O
capture	O
temporal	O
information	O
across	O
activities	O
,	O
motivating	O
our	O
use	O
of	O
Transformer	O
LMs	O
.	O

Controllable	O
Text	O
Generation	O
aims	O
to	O
steer	O

LMs	O
towards	O
desired	O
attributes	O
.	O
Examples	O
include	O
using	O
reinforcement	O
learning	O
to	O
control	O
quality	O
metrics	O
(	O
Ranzato	O
et	O
al	O
.	O
,	O
2016	O
)	O
,	O
adjusting	O
sampling	O
weights	O
to	O
control	O
for	O
poetry	O
style	O
(	O
Ghazvininejad	O
et	O
al	O
.	O
,	O
2017	O
)	O
,	O
and	O
learning	O
to	O
condition	O
on	O
valence	O
or	O
domain	O
-	O
specific	O
codes	O
(	O
Keskar	O
et	O
al	O
.	O
,	O
2019;Peng	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
To	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
we	O
are	O

Method	O

Given	O
any	O
autoregressive	O
language	O
model	O
(	O
e.g.	O
GPT-2	O
(	O
Radford	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
we	O
can	O
fine	O
-	O
tune	O
a	O
LM	O
-	O
KT	O
model	O
(	O
p	O
θ	O
KT	O
)	O
to	O
predict	O
whether	O
an	O
individual	O
student	O
will	O
correctly	O
answer	O
the	O
next	O
question	O
.	O
If	O
this	O
model	O
has	O
well	O
-	O
calibrated	O
uncertainty	O
,	O
we	O
can	O
use	O
its	O
predicted	O
probability	O
of	O
a	O
correct	O
answer	O
as	O
a	O
proxy	O
for	O
the	O
difficulty	O
of	O
a	O
question	O
to	O
a	O
student	O
.	O
We	O
then	O
train	O
a	O
question	O
generation	O
model	O
(	O
p	O
θ	O
QG	O
)	O
to	O
generate	O
a	O
new	O
question	O
conditioned	O
on	O
a	O
student	O
and	O
desired	O
target	O
difficulty	O
.	O

Question	O
Representation	O
Unlike	O
standard	O
DKT	O
,	O
which	O
treats	O
questions	O
as	O
IDs	O
or	O
simple	O
handcrafted	O
features	O
,	O
we	O
represent	O
questions	O
fully	O
in	O
text	O
(	O
e.g.	O
"	O
she	O
eats	O
"	O
in	O
Figure	O
1	O
)	O
.	O
This	O
is	O
a	O
key	O
contribution	O
of	O
our	O
work	O
,	O
required	O
by	O
our	O
eventual	O
goal	O
of	O
generating	O
questions	O
in	O
text	O
,	O
and	O
allows	O
the	O
model	O
to	O
leverage	O
similarity	O
across	O
linguistic	O
features	O
.	O
We	O
thus	O
represent	O
a	O
question	O
q	O
as	O
a	O
sequence	O
of	O
words	O
,	O
with	O
prefix	O
and	O
suffix	O
tokens	O
:	O

q	O
i	O
=	O
<	O
Q	O
>	O
w	O
i	O
1	O
w	O
i	O
2	O
w	O
i	O
3	O
...	O
w	O
i	O
n	O
<	O
A	O
>	O
Student	O
State	O

We	O
represent	O
a	O
student	O
as	O
a	O
temporally	O
-	O
evolving	O
sequence	O
of	O
questions	O
and	O
their	O
responses	O
.	O
As	O
in	O
much	O
previous	O
KT	O
work	O
,	O
we	O
represent	O
the	O
student	O
response	O
as	O
simply	O
correct	O
/	O
incorrect	O
,	O
with	O
special	O
tokens	O
<	O
Y	O
>	O
and	O
<	O
N	O
>	O
.	O
A	O
student	O
's	O
current	O
state	O
is	O
thus	O
represented	O
as	O
a	O
sequence	O
of	O
all	O
past	O
question	O
and	O
response	O
pairs	O
:	O

s	O
j	O
=	O
q	O
j	O
1	O
a	O
j	O
1	O
q	O
j	O
2	O
a	O
j	O
2	O
.	O

..	O
q	O
j	O
m	O
a	O
j	O
m	O
,	O
a	O
i	O
∈	O
{	O
<	O
Y>,<N	O
>	O
}	O
LM	O
-	O
KT	O
Given	O
the	O
sequential	O
nature	O
of	O
student	O
learning	O
over	O
time	O
,	O
we	O
can	O
easily	O
frame	O
knowledge	O
tracing	O
as	O
an	O
autoregressive	O
language	O
modeling	O
task	O
.	O
Given	O
a	O
dataset	O
D	O
of	O
students	O
s	O
1	O
,	O
s	O
2	O
,	O
...	O
,	O
s	O
|D|	O
,	O
we	O
employ	O
the	O
standard	O
training	O
objective	O
of	O
finding	O
the	O
parameters	O
θ	O
KT	O
that	O
minimizes	O

L	O
KT	O
=	O
−	O
|D|	O
i=1	O
|x	O
(	O
i	O
)	O
|	O
t=1	O
logp	O
θ	O
KT	O
(	O
x	O
(	O
i	O
)	O
t	O
|x	O
(	O
i	O
)	O
<	O
t	O
)	O
(	O
1	O
)	O

where	O

x	O
(	O
j	O
)	O
=	O
(	O
x	O
(	O
j	O
)	O
1	O
,	O
....	O
,	O
x	O
(	O
j	O
)	O

|x|	O
)	O
is	O
the	O
entire	O
sequence	O
tokens	O
corresponding	O
to	O
student	O
s	O
j	O
,	O
consisting	O
of	O
all	O
their	O
past	O
questions	O
and	O
answers	O
.	O
Using	O
the	O
softmax	O
output	O
of	O
the	O
LM	O
-	O
KT	O
model	O
(	O
p	O
θ	O
KT	O
)	O
,	O
we	O
estimate	O
a	O
student	O
's	O
(	O
inverse	O
)	O
difficulty	O
in	O
answering	O
a	O
specific	O
question	O
as	O
d	O
qs	O
=	O
p	O
θ	O
KT	O
(	O
<	O
Y>|s	O
,	O
q	O
)	O
.	O
We	O
find	O
that	O
p	O
θ	O
KT	O
is	O
well	O
-	O
calibrated	O
(	O
Section	O
4.2	O
)	O
,	O
yielding	O
a	O
good	O
proxy	O
for	O
the	O
true	O
question	O
difficulty	O
.	O

Question	O
Generation	O
We	O
frame	O
question	O
generation	O
as	O
finetuning	O
a	O
new	O
autoregressive	O
LM	O
.	O
Given	O
random	O
samples	O
of	O
students	O
and	O
questions	O
from	O
a	O
held	O
-	O
out	O
set	O
not	O
used	O
to	O
train	O
LM	O
-	O
KT	O
,	O
we	O
can	O
construct	O
a	O
new	O
dataset	O
D	O
consisting	O
of	O
s	O
i	O
d	O
i	O
<	O
G	O
>	O
q	O
i	O
sequences	O
,	O
where	O
<	O
G	O
>	O
is	O
a	O
special	O
generation	O
token	O
and	O
d	O
i	O
=	O
p	O
θ	O
KT	O
(	O
<	O
Y>|s	O
i	O
,	O
q	O
i	O
)	O
is	O
the	O
continuous	O
difficulty	O
value	O
assigned	O
by	O
LM	O
-	O
KT	O
.	O
We	O
learn	O
a	O
linear	O
layer	O
to	O
map	O
the	O
continuous	O
input	O
difficulty	O
into	O
a	O
difficulty	O
control	O
vector	O
c	O
d	O
of	O
dimension	O
matching	O
the	O
LM	O
word	O
-	O
embeddings	O
,	O
which	O
we	O
append	O
to	O
the	O
token	O
embeddings	O
.	O
Unlike	O
LM	O
-	O
KT	O
,	O
we	O
train	O
our	O
question	O
generation	O
model	O
p	O
θ	O
QG	O
to	O
minimize	O
the	O
loss	O
only	O
on	O
the	O
question	O
text	O
,	O
which	O
only	O
appears	O
after	O
the	O
<	O
G	O
>	O
token	O
.	O
If	O
t	O
g	O
is	O
the	O
token	O
index	O
of	O
<	O
G	O
>	O
,	O
then	O
our	O
modified	O
loss	O
is	O
:	O

L	O
QG	O
=	O
−	O
|D	O
|	O
i=1	O
|x	O
(	O
i	O
)	O
|	O
t	O
=	O
tg+1	O
logp	O
θ	O
QG	O
(	O
x	O
(	O
i	O
)	O
t	O
|x	O
(	O
i	O
)	O
<	O
t	O
)	O
(	O
2	O
)	O

where	O
sequence	O
x	O
(	O
j	O
)	O
contains	O
the	O
full	O
s	O
j	O
d	O
j	O
<	O
G	O
>	O
q	O
j	O
sequence	O
.	O
At	O
test	O
time	O
,	O
we	O
generate	O
tokens	O
w	O
1	O
...	O
w	O
n	O
conditioned	O
on	O
the	O
s	O
j	O
d	O
j	O
<	O
G	O
>	O
prefix	O
.	O

Experiments	O

Our	O
method	O
generalizes	O
to	O
any	O
education	O
activity	O
that	O
can	O
be	O
represented	O
with	O
text	O
sequences	O
.	O
Due	O
to	O
the	O
availability	O
of	O
real	O
student	O
learning	O
data	O
,	O
we	O
focus	O
on	O
a	O
reverse	O
language	O
translation	O
task	O
,	O
where	O
a	O
student	O
translates	O
phrases	O
from	O
their	O
native	O
language	O
(	O
e.g.	O
English	O
,	O
"	O
she	O
eats	O
"	O
)	O
to	O
the	O
second	O
language	O
they	O
are	O
learning	O
(	O
e.g.	O
Spanish	O
,	O
"	O
ella	O
come	O
"	O
)	O
.	O

Experimental	O
Details	O

We	O
use	O
the	O
2018	O
Duolingo	O
Shared	O
Task	O
on	O
Second	O
Language	O
Acquisition	O
Modeling	O
(	O
Settles	O
et	O
al	O
.	O
,	O
2018	O
)	O
dataset	O
,	O
which	O
contains	O
questions	O
and	O
responses	O
for	O
Duolingo	O
users	O
over	O
the	O
first	O
30	O
days	O
of	O
learning	O
a	O
second	O
language	O
.	O
While	O
the	O
original	O
task	O
's	O
goal	O
was	O
to	O
identify	O
token	O
-	O
level	O
mistakes	O
,	O
we	O
collapse	O
these	O
errors	O
into	O
binary	O
(	O
correct	O
/	O
incorrect	O
)	O
per	O
-	O
question	O
labels	O
.	O
We	O
use	O
the	O
provided	O
train	O
/	O
dev	O
/	O
test	O
splits	O
for	O
users	O
learning	O
Spanish	O
and	O
French	O
.	O
We	O
create	O
separate	O
held	O
-	O
out	O
sets	O
from	O
the	O
test	O
set	O
to	O
evaluate	O
the	O
LM	O
-	O
KT	O
and	O
question	O
generation	O
models	O
.	O
For	O
both	O
models	O
,	O
we	O
finetune	O
separate	O
GPT-2	O
(	O
Radford	O
et	O
al	O
.	O
,	O
2019	O
)	O

Results	O
:	O
Student	O
Modeling	O

We	O
evaluate	O
LM	O
-	O
KT	O
two	O
ways	O
:	O
first	O
,	O
its	O
ability	O
to	O
predict	O
if	O
an	O
individual	O
student	O
will	O
answer	O
a	O
novel	O
question	O
correctly	O
on	O
a	O
held	O
-	O
out	O
test	O
set	O
of	O
real	O
Duolingo	O
student	O
responses	O
.	O
Second	O
,	O
how	O
wellcalibrated	O
these	O
predictions	O
are	O
,	O
which	O
is	O
crucial	O
to	O
our	O
later	O
use	O
of	O
LM	O
-	O
KT	O
for	O
question	O
generation	O
.	O
Table	O
1	O
compares	O
AUC	O
-	O
ROC	O
on	O
a	O
held	O
-	O
out	O
test	O
set	O
for	O
our	O
LM	O
-	O
KT	O
model	O
with	O
standard	O
DKT	O
,	O
which	O
uses	O
question	O
IDs	O
instead	O
of	O
text	O
,	O
and	O
a	O
baseline	O
that	O
ignores	O
the	O
student	O
state	O
,	O
only	O
using	O
the	O
question	O
text	O
representation	O
.	O
This	O
question	O
only	O
baseline	O
would	O
perform	O
well	O
if	O
the	O
Duolingo	O
dataset	O
largely	O
consisted	O
of	O
universally	O
"	O
easy	O
"	O
and	O
"	O
difficult	O
"	O
questions	O
,	O
independent	O
of	O
individual	O
student	O
.	O
Our	O
results	O
show	O
that	O
incorporating	O
the	O
student	O
state	O
is	O
crucial	O
for	O
accurately	O
predicting	O
Duolingo	O
user	O
responses	O
,	O
and	O
including	O
question	O
text	O
also	O
leads	O
to	O
a	O
significant	O
improvement	O
.	O
LM	O
-	O
KT	O
outperforms	O
Standard	O
DKT	O
especially	O
on	O
novel	O
questions	O
-	O
a	O
necessary	O
generalization	O
ability	O
for	O
generation	O
.	O

Finally	O
,	O
we	O
measure	O
the	O
calibration	O
of	O
our	O
LM	O
-	O
KT	O
models	O
for	O
both	O
Spanish	O
and	O
French	O
(	O
from	O
En	O
-	O
glish	O
)	O
learners	O
,	O
which	O
is	O
the	O
crucial	O
property	O
for	O
our	O
downstream	O
generation	O
task	O
.	O
We	O
bin	O
our	O
test	O
data	O
by	O
predicted	O
question	O
difficulty	O
,	O
and	O
plot	O
the	O
fraction	O
of	O
true	O
correct	O
answers	O
in	O
each	O
bin	O
.	O
Figure	O
2	O
shows	O
that	O
LM	O
-	O
KT	O
is	O
well	O
-	O
calibrated	O
,	O
for	O
both	O
Spanish	O
and	O
French	O
,	O
meaning	O
the	O
predicted	O
difficulty	O
matches	O
the	O
empirically	O
observed	O
proportion	O
of	O
correct	O
answers	O
.	O

Results	O
:	O
Question	O
Generation	O

We	O
evaluate	O
four	O
different	O
aspects	O
of	O
our	O
question	O
generation	O
model	O
:	O
(	O
i	O
)	O
successful	O
control	O
for	O
difficulty	O
,	O
(	O
ii	O
)	O
novelty	O
,	O
(	O
iii	O
)	O
fluency	O
,	O
and	O
(	O
iv	O
)	O
latency	O
.	O

Difficulty	O
Control	O
To	O
explore	O
whether	O
our	O
question	O
generation	O
model	O
indeed	O
depends	O
on	O
target	O
difficulty	O
and	O
the	O
individual	O
student	O
,	O
we	O
first	O
measure	O
the	O
model	O
's	O
perplexity	O
on	O
a	O
held	O
-	O
out	O
test	O
set	O
of	O
Duolingo	O
questions	O
,	O
compared	O
to	O
permutation	O
baselines	O
.	O
Table	O
2	O
(	O
top	O
)	O
shows	O
that	O
perplexity	O
is	O
lower	O
for	O
true	O
student	O
/	O
target	O
difficulty	O
inputs	O
than	O
when	O
either	O
or	O
both	O
of	O
these	O
are	O
permuted	O
.	O
The	O
target	O
difficulty	O
values	O
in	O
this	O
analysis	O
were	O
defined	O
by	O
the	O
LM	O
-	O
DKT	O
model	O
.	O
We	O
can	O
remove	O
this	O
dependence	O
by	O
using	O
the	O
actual	O
student	O
responses	O
from	O
Duolingo	O
:	O
we	O
set	O
the	O
target	O
difficulty	O
to	O
1	O
if	O
the	O
student	O
was	O
correct	O
and	O
0	O
otherwise	O
.	O
Table	O
2	O
(	O
bottom	O
)	O
shows	O
our	O
model	O
prefers	O
questions	O
paired	O
with	O
these	O
"	O
true	O
correctness	O
"	O
targets	O
than	O
paired	O
with	O
random	O
ones	O
.	O

To	O
evaluate	O
how	O
well	O
our	O
generation	O
model	O
achieves	O
target	O
difficulties	O
,	O
we	O
take	O
15	O
unseen	O
students	O
and	O
generate	O
30	O
questions	O
for	O
each	O
of	O
9	O
input	O
difficulties	O
(	O
0.1	O
-	O
0.9	O
)	O
.	O
We	O
then	O
use	O
LM	O
-	O
KT	O
(	O
a	O
wellcalibrated	O
proxy	O
for	O
true	O
difficulty	O
)	O
to	O
measure	O
the	O
difficulty	O
of	O
these	O
generated	O
questions	O
for	O
each	O
student	O
.	O
Figure	O
3	O
shows	O
that	O
we	O
are	O
able	O
to	O
achieve	O
fine	O
-	O
grained	O
control	O
over	O
target	O
difficulty	O
for	O
both	O
Spanish	O
and	O
French	O
students	O
,	O
with	O
an	O
average	O
Root	O
-	O
Mean	O
Squared	O
Error	O
(	O
RMSE	O
)	O
of	O
.052	O
across	O
all	O
students	O
and	O
target	O
difficulties	O
.	O
Adding	O
a	O
sampling	O
penalty	O
(	O
Keskar	O
et	O
al	O
.	O
,	O
2019	O
)	O
increases	O
the	O
variance	O
in	O
difficulty	O
(	O
RMSE	O
.062	O
)	O
in	O
exchange	O
for	O
more	O
novel	O
and	O
diverse	O
questions	O
,	O
as	O
discussed	O
next	O
.	O

Novelty	O
and	O
Fluency	O
By	O
leveraging	O
a	O
pretrained	O
language	O
model	O
's	O
ability	O
to	O
manipulate	O
structure	O
,	O
we	O
can	O
generate	O
novel	O
questions	O
not	O
present	O
in	O
the	O
entire	O
Duolingo	O
question	O
set	O
(	O
See	O
Table	O
3	O
)	O
.	O
Across	O
4,050	O
questions	O
generated	O
for	O
Spanish	O
learners	O
,	O
we	O
found	O
that	O
with	O
a	O
repetition	O
penalty	O
(	O
Keskar	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
around	O
43	O
%	O
of	O
all	O
questions	O
,	O
and	O
66	O
%	O
of	O
high	O
difficulty	O
(	O
d	O
=	O
0.1	O
)	O
required	O
to	O
rank	O
all	O
questions	O
in	O
the	O
pool	O
,	O
varying	O
its	O
size	O
(	O
Figure	O
4	O
)	O
.	O
On	O
one	O
NVIDIA	O
Titan	O
XP	O
GPU	O
,	O
we	O
find	O
that	O
,	O
averaged	O
across	O
all	O
target	O
difficulties	O
,	O
our	O
question	O
generation	O
model	O
takes	O
half	O
the	O
time	O
to	O
achieve	O
the	O
same	O
quality	O
as	O
pool	O
selection	O
.	O
The	O
gap	O
increases	O
when	O
trying	O
to	O
sample	O
harder	O
questions	O
(	O
d	O
<	O
0.5	O
)	O
-even	O
a	O
pool	O
size	O
of	O
1000	O
does	O
not	O
have	O
sufficient	O
difficult	O
questions	O
,	O
likely	O
due	O
to	O
a	O
skew	O
in	O
the	O
Duolingo	O
question	O
set	O
.	O
Additional	O
controls	O
,	O
such	O
as	O
for	O
style	O
or	O
topic	O
,	O
can	O
easily	O
be	O
combined	O
with	O
our	O
generation	O
method	O
,	O
but	O
would	O
make	O
pool	O
selection	O
exponentially	O
more	O
complex	O
.	O
Pool	O
Sampling	O
(	O
all	O
targets	O
)	O
Pool	O
Sampling	O
(	O
difficult	O
targets	O
only	O
)	O
Generation	O
(	O
all	O
targets	O
)	O
Generation	O
(	O
difficult	O
targets	O
only	O
)	O

Figure	O
4	O
:	O
Pool	O
selection	O
(	O
for	O
one	O
student	O
)	O
suffers	O
worse	O
question	O
quality	O
vs.	O
latency	O
trade	O
-	O
off	O
than	O
question	O
generation	O
,	O
especially	O
for	O
sampling	O
difficult	O
questions	O
.	O

Conclusion	O

Our	O
work	O
is	O
a	O
first	O
step	O
toward	O
showing	O
that	O
sequence	O
-	O
based	O
models	O
combined	O
with	O
domain	O
knowledge	O
,	O
such	O
as	O
pre	O
-	O
trained	O
LMs	O
,	O
can	O
be	O
leveraged	O
for	O
adaptive	O
learning	O
tasks	O
.	O
We	O
show	O
how	O
to	O
use	O
modern	O
LMs	O
to	O
generate	O
novel	O
reversetranslation	O
questions	O
that	O
achieve	O
a	O
target	O
difficulty	O
,	O
allowing	O
adaptive	O
education	O
methods	O
to	O
expand	O
beyond	O
limited	O
question	O
pools	O
.	O
Limitations	O
of	O
our	O
approach	O
include	O
the	O
compute	O
constraints	O
of	O
large	O
LMs	O
and	O
training	O
data	O
availability	O
.	O
More	O
detailed	O
student	O
data	O
will	O
be	O
crucial	O
to	O
future	O
model	O
development	O
.	O
For	O
instance	O
,	O
while	O
most	O
publicly	O
available	O
education	O
datasets	O
do	O
not	O
include	O
the	O
full	O
student	O
responses	O
(	O
e.g.	O
full	O
translation	O
response	O
in	O
Duolingo	O
)	O
,	O
such	O
information	O
could	O
significantly	O
improve	O
the	O
performance	O
of	O
our	O
LM	O
-	O
KT	O
model	O
.	O
Other	O
future	O
directions	O
include	O
exploring	O
non	O
-	O
language	O
domains	O
,	O
such	O
as	O
math	O
or	O
logic	O
exercises	O
,	O
and	O
controlling	O
for	O
auxiliary	O
objectives	O
such	O
as	O
question	O
topic	O
.	O

Finally	O
,	O
designing	O
appropriate	O
user	O
studies	O
to	O
evaluate	O
our	O
method	O
is	O
a	O
complex	O
yet	O
critical	O
next	O
step	O
to	O
determine	O
its	O
suitability	O
in	O
a	O
real	O
-	O
world	O
education	O
setting	O
.	O
Our	O
techniques	O
allows	O
control	O
for	O
individual	O
student	O
difficulty	O
,	O
but	O
it	O
leaves	O
open	O
the	O
question	O
of	O
optimal	O
curriculum	O
design	O
using	O
difficulty	O
-	O
directed	O
question	O
generation	O
.	O

Broader	O
Impact	O

Online	O
education	O
platforms	O
can	O
increase	O
the	O
accessibility	O
of	O
high	O
quality	O
educational	O
resources	O
for	O
students	O
around	O
the	O
world	O
.	O
Adaptive	O
techniques	O
that	O
allow	O
for	O
more	O
individualized	O
learning	O
strategies	O
can	O
help	O
such	O
technologies	O
be	O
more	O
inclusive	O
for	O
students	O
who	O
make	O
less	O
-	O
common	O
mistakes	O
or	O
have	O
different	O
prior	O
backgrounds	O
(	O
Lee	O
and	O
Brunskill	O
,	O
2012	O
)	O
.	O
However	O
,	O
our	O
method	O
is	O
subject	O
to	O
biases	O
found	O
in	O
the	O
training	O
data	O
,	O
and	O
careful	O
consideration	O
of	O
using	O
safe	O
and	O
appropriate	O
data	O
is	O
crucial	O
in	O
an	O
education	O
context	O
.	O
Moreover	O
,	O
our	O
specific	O
use	O
of	O
pre	O
-	O
trained	O
LMs	O
relies	O
on	O
the	O
significant	O
progress	O
of	O
NLP	O
tools	O
for	O
English	O
language	O
-further	O
research	O
and	O
development	O
of	O
these	O
tools	O
for	O
other	O
languages	O
can	O
help	O
ensure	O
our	O
method	O
benefits	O
a	O
larger	O
population	O
of	O
students	O
.	O

A	O
APPENDIX	O

A.1	O
Dataset	O
Details	O

The	O
2018	O
Duolingo	O
Shared	O
Task	O
on	O
Second	O
Language	O
Acquisition	O
Modeling	O
(	O
Settles	O
et	O
al	O
.	O
,	O
2018	O
)	O
dataset	O
contains	O
questions	O
and	O
responses	O
for	O
Duolingo	O
users	O
over	O
the	O
first	O
30	O
days	O
of	O
learning	O
a	O
second	O
language	O
.	O
The	O
dataset	O
contains	O
three	O
different	O
question	O
types	O
:	O
reverse	O
translate	O
(	O
free	O
response	O
translation	O
of	O
a	O
given	O
prompt	O
in	O
the	O
language	O
they	O
are	O
learning	O
)	O
,	O
reverse	O
tap	O
(	O
a	O
selection	O
-	O
based	O
equivalent	O
of	O
reverse	O
translate	O
)	O
,	O
and	O
listen	O
,	O
where	O
students	O
listen	O
to	O
a	O
vocal	O
utterance	O
.	O
We	O
focus	O
on	O
the	O
reverse	O
translate	O
question	O
type	O
for	O
English	O
-	O
speaking	O
students	O
learning	O
French	O
and	O
Spanish	O
.	O
The	O
dataset	O
size	O
for	O
French	O
learners	O
(	O
1.2k	O
users	O
)	O
is	O
roughly	O
half	O
the	O
size	O
of	O
that	O
for	O
Spanish	O
learners	O
(	O
2.6k	O
users	O
)	O
.	O

Because	O
the	O
original	O
dataset	O
was	O
intended	O
for	O
per	O
-	O
token	O
error	O
prediction	O
,	O
each	O
question	O
has	O
per	O
-	O
token	O
information	O
that	O
includes	O
whether	O
the	O
student	O
translated	O
the	O
token	O
correctly	O
,	O
as	O
well	O
as	O
Universal	O
Dependencies	O
tags	O
such	O
as	O
part	O
of	O
speech	O
and	O
morphology	O
labels	O
.	O
We	O
use	O
the	O
full	O
question	O
text	O
,	O
rather	O
than	O
individual	O
tokens	O
,	O
for	O
our	O
task	O
,	O
and	O
combine	O
the	O
labels	O
such	O
that	O
if	O
a	O
Duolingo	O
user	O
incorrectly	O
translated	O
one	O
or	O
more	O
tokens	O
in	O
a	O
question	O
,	O
the	O
entire	O
question	O
is	O
marked	O
incorrect	O
.	O
We	O
do	O
not	O
use	O
any	O
additional	O
features	O
.	O

We	O
use	O
the	O
publicly	O
provided	O
train	O
/	O
dev	O
/	O
test	O
splits	O
from	O
the	O
Shared	O
Task	O
,	O
which	O
are	O
temporally	O
ordered	O
in	O
sequence	O
.	O
We	O
therefore	O
construct	O
student	O
states	O
by	O
tracking	O
user	O
IDs	O
throughout	O
the	O
datasets	O
and	O
appending	O
each	O
new	O
question	O
and	O
response	O
to	O
the	O
current	O
student	O
state	O
.	O
When	O
evaluating	O
our	O
LM	O
-	O
KT	O
model	O
,	O
we	O
use	O
the	O
true	O
responses	O
of	O
preceding	O
questions	O
in	O
the	O
test	O
set	O
to	O
form	O
the	O
student	O
state	O
for	O
a	O
given	O
question	O
.	O
Overall	O
,	O
we	O
find	O
that	O
the	O
dataset	O
is	O
severely	O
imbalanced	O
(	O
as	O
in	O
the	O
original	O
task	O
)	O
-about	O
30	O
%	O
of	O
questions	O
are	O
answered	O
incorrectly	O
across	O
students	O
studying	O
both	O
French	O
and	O
Spanish	O
.	O

Finally	O
,	O
we	O
create	O
a	O
held	O
-	O
out	O
set	O
of	O
Duolingo	O
questions	O
for	O
both	O
French	O
and	O
Spanish	O
learners	O
to	O
create	O
the	O
training	O
data	O
for	O
our	O
question	O
generation	O
model	O
.	O
From	O
a	O
set	O
of	O
random	O
student	O
states	O
,	O
we	O
select	O
questions	O
from	O
this	O
set	O
and	O
use	O
a	O
trained	O
LM	O
-	O
KT	O
model	O
to	O
assign	O
the	O
difficulty	O
score	O
.	O
In	O
practice	O
,	O
this	O
held	O
-	O
out	O
set	O
can	O
come	O
from	O
any	O
source	O
,	O
not	O
just	O
Duolingo	O
data	O
.	O

A.2	O
Model	O
Training	O
Details	O

To	O
train	O
both	O
our	O
LM	O
-	O
KT	O
knowledge	O
tracing	O
model	O
and	O
our	O
question	O
generation	O
model	O
,	O
we	O
use	O
the	O
pre	O
-	O
trained	O
OpenAI	O
GPT-2	O
model	O
from	O
the	O
HuggingFace	O
Transformers	O
library	O
(	O
Wolf	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
For	O
question	O
generation	O
,	O
we	O
modify	O
the	O
library	O
to	O
add	O
a	O
linear	O
layer	O
and	O
the	O
modified	O
loss	O
function	O
for	O
question	O
generation	O
from	O
Section	O
3	O
.	O

We	O
use	O
1	O
NVIDIA	O
TitanXP	O
GPU	O
with	O
12	O
GB	O
of	O
memory	O
available	O
.	O
Because	O
the	O
maximum	O
input	O
sequence	O
length	O
of	O
the	O
GPT-2	O
model	O
we	O
use	O
is	O
1024	O
tokens	O
,	O
we	O
resize	O
all	O
inputs	O
to	O
the	O
last	O
1024	O
tokens	O
before	O
training	O
.	O
We	O
report	O
results	O
for	O
an	O
LM	O
-	O
KT	O
model	O
trained	O
for	O
13k	O
steps	O
with	O
the	O
default	O
batch	O
size	O
of	O
2	O
and	O
learning	O
rate	O
of	O
5e-5	O
,	O
and	O
a	O
Question	O
Generation	O
model	O
trained	O
for	O
25k	O
steps	O
with	O
the	O
same	O
batch	O
size	O
and	O
learning	O
rate	O
.	O
The	O
total	O
compute	O
time	O
to	O
train	O
both	O
models	O
was	O
2.5	O
hours	O
for	O
each	O
language	O
learning	O
task	O
.	O

A.3	O
Question	O
Generation	O
Details	O

For	O
both	O
French	O
and	O
Spanish	O
question	O
generation	O
models	O
,	O
we	O
select	O
15	O
students	O
unseen	O
during	O
training	O
and	O
generate	O
30	O
questions	O
across	O
9	O
difficulties	O
from	O
0.1	O
to	O
0.9	O
,	O
using	O
nucleus	O
sampling	O
(	O
Holtzman	O
et	O
al	O
.	O
,	O
2020	O
)	O
(	O
p	O
=	O
0.99	O
)	O
with	O
a	O
maximum	O
output	O
length	O
of	O
20	O
tokens	O
.	O
We	O
also	O
vary	O
a	O
repetition	O
penalty	O
(	O
Keskar	O
et	O
al	O
.	O
,	O
2019	O
)	O
that	O
penalizes	O
for	O
previous	O
tokens	O
(	O
including	O
those	O
in	O
the	O
student	O
state	O
)	O
.	O
Lastly	O
,	O
we	O
resize	O
all	O
prompts	O
(	O
student	O
state	O
and	O
target	O
difficulty	O
)	O
to	O
fit	O
into	O
the	O
GPT-2	O
Model	O
by	O
taking	O
the	O
most	O
recent	O
1024	O
tokens	O
,	O
as	O
in	O
training	O
.	O
This	O
is	O
a	O
limitation	O
of	O
our	O
work	O
,	O
as	O
the	O
full	O
student	O
history	O
is	O
not	O
able	O
to	O
be	O
considered	O
for	O
students	O
who	O
have	O
answered	O
a	O
large	O
set	O
of	O
questions	O
.	O

A.4	O
Additional	O
Question	O
Generation	O
Outputs	O

Our	O
question	O
generation	O
model	O
demonstrates	O
the	O
ability	O
to	O
generate	O
novel	O
questions	O
that	O
do	O
not	O
exist	O
in	O
the	O
entire	O
Duolingo	O
question	O
dataset	O
,	O
especially	O
when	O
a	O
sampling	O
penalty	O
is	O
applied	O
to	O
encourage	O
more	O
diverse	O
outputs	O
.	O
However	O
,	O
this	O
comes	O
at	O
a	O
cost	O
to	O
fluency	O
.	O
Below	O
we	O
include	O
a	O
set	O
of	O
outputs	O
generated	O
by	O
our	O
model	O
for	O
1	O
Spanish	O
student	O
and	O
1	O
French	O
student	O
from	O
the	O
Duolingo	O
dataset	O
,	O
with	O
a	O
target	O
difficulty	O
of	O
d	O
=	O
0.1	O
,	O
and	O
both	O
with	O
and	O
without	O
a	O
repetition	O
penalty	O
.	O
We	O
observe	O
that	O
while	O
applying	O
a	O
penalty	O
results	O
in	O
a	O
far	O
more	O
novel	O
questions	O
generated	O
,	O
several	O
of	O
these	O
are	O
also	O
non	O
-	O
fluent	O
,	O
using	O
a	O
combination	O
of	O
manual	O
judgement	O
and	O
the	O
Python	O
language	O
-	O
check	O
package	O
(	O
https://pypi.org/project/language-check/	O
)	O
.	O

An	O
Exploratory	O
Analysis	O
of	O
Multilingual	O
Word	O
-	O
Level	O
Quality	O
Estimation	O
with	O
Cross	O
-	O
Lingual	O
Transformers	O

Most	O
studies	O
on	O
word	O
-	O
level	O
Quality	O
Estimation	O
(	O
QE	O
)	O
of	O
machine	O
translation	O
focus	O
on	O
languagespecific	O
models	O
.	O
The	O
obvious	O
disadvantages	O
of	O
these	O
approaches	O
are	O
the	O
need	O
for	O
labelled	O
data	O
for	O
each	O
language	O
pair	O
and	O
the	O
high	O
cost	O
required	O
to	O
maintain	O
several	O
language	O
-	O
specific	O
models	O
.	O
To	O
overcome	O
these	O
problems	O
,	O
we	O
explore	O
different	O
approaches	O
to	O
multilingual	O
,	O
word	O
-	O
level	O
QE	O
.	O
We	O
show	O
that	O
multilingual	O
QE	O
models	O
perform	O
on	O
par	O
with	O
the	O
current	O
language	O
-	O
specific	O
models	O
.	O
In	O
the	O
cases	O
of	O
zeroshot	O
and	O
few	O
-	O
shot	O
QE	O
,	O
we	O
demonstrate	O
that	O
it	O
is	O
possible	O
to	O
accurately	O
predict	O
word	O
-	O
level	O
quality	O
for	O
any	O
given	O
new	O
language	O
pair	O
from	O
models	O
trained	O
on	O
other	O
language	O
pairs	O
.	O
Our	O
findings	O
suggest	O
that	O
the	O
word	O
-	O
level	O
QE	O
models	O
based	O
on	O
powerful	O
pre	O
-	O
trained	O
transformers	O
that	O
we	O
propose	O
in	O
this	O
paper	O
generalise	O
well	O
across	O
languages	O
,	O
making	O
them	O
more	O
useful	O
in	O
real	O
-	O
world	O
scenarios	O
.	O

Quality	O
Estimation	O
(	O
QE	O
)	O
is	O
the	O
task	O
of	O
assessing	O
the	O
quality	O
of	O
a	O
translation	O
without	O
having	O
access	O
to	O
a	O
reference	O
translation	O
(	O
Specia	O
et	O
al	O
.	O
,	O
2009	O
)	O
.	O
Translation	O
quality	O
can	O
be	O
estimated	O
at	O
different	O
levels	O
of	O
granularity	O
:	O
word	O
,	O
sentence	O
and	O
document	O
level	O
(	O
I	O
ve	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
So	O
far	O
the	O
most	O
popular	O
task	O
has	O
been	O
sentence	O
-	O
level	O
QE	O
,	O
in	O
which	O
QE	O
models	O
provide	O
a	O
score	O
for	O
each	O
pair	O
of	O
source	O
and	O
target	O
sentences	O
.	O
A	O
more	O
challenging	O
task	O
,	O
which	O
is	O
currently	O
receiving	O
a	O
lot	O
of	O
attention	O
from	O
the	O
research	O
community	O
,	O
is	O
word	O
-	O
level	O
quality	O
estimation	O
.	O
This	O
task	O
provides	O
more	O
fine	O
-	O
grained	O
information	O
about	O
the	O
quality	O
of	O
a	O
translation	O
,	O
indicating	O
which	O
words	O
from	O
the	O
source	O
have	O
been	O
incorrectly	O
translated	O
in	O
the	O
target	O
,	O
and	O
whether	O
the	O
words	O
inserted	O
between	O
these	O
words	O
are	O
correct	O
(	O
good	O
vs	O
bad	O
gaps	O
)	O
.	O
This	O
information	O
can	O
be	O
useful	O
for	O
post	O
-	O
editors	O
by	O
indicating	O
the	O
parts	O
of	O
a	O
sentence	O
on	O
which	O
they	O
have	O
to	O
focus	O
more	O
.	O

Word	O
-	O
level	O
QE	O
is	O
generally	O
framed	O
as	O
a	O
supervised	O
ML	O
problem	O
(	O
Kepler	O
et	O
al	O
.	O
,	O
2019;Lee	O
,	O
2020	O
)	O
trained	O
on	O
data	O
in	O
which	O
the	O
correctness	O
of	O
translation	O
is	O
labelled	O
at	O
word	O
-	O
level	O
(	O
i.e.	O
good	O
,	O
bad	O
,	O
gap	O
)	O
.	O

The	O
training	O
data	O
publicly	O
available	O
to	O
build	O
wordlevel	O
QE	O
models	O
is	O
limited	O
to	O
very	O
few	O
language	O
pairs	O
,	O
which	O
makes	O
it	O
difficult	O
to	O
build	O
QE	O
models	O
for	O
many	O
languages	O
.	O
From	O
an	O
application	O
perspective	O
,	O
even	O
for	O
the	O
languages	O
with	O
resources	O
,	O
it	O
is	O
difficult	O
to	O
maintain	O
separate	O
QE	O
models	O
for	O
each	O
language	O
since	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
neural	O
QE	O
models	O
are	O
large	O
in	O
size	O
(	O
Ranasinghe	O
et	O
al	O
.	O
,	O
2020b	O
)	O
.	O

In	O
our	O
paper	O
,	O
we	O
address	O
this	O
problem	O
by	O
developing	O
multilingual	O
word	O
-	O
level	O
QE	O
models	O
which	O
perform	O
competitively	O
in	O
different	O
domains	O
,	O
MT	O
types	O
and	O
language	O
pairs	O
.	O
In	O
addition	O
,	O
for	O
the	O
first	O
time	O
,	O
we	O
propose	O
word	O
-	O
level	O
QE	O
as	O
a	O
zero	O
-	O
shot	O
crosslingual	O
transfer	O
task	O
,	O
enabling	O
new	O
avenues	O
of	O
research	O
in	O
which	O
multilingual	O
models	O
can	O
be	O
trained	O
once	O
and	O
then	O
serve	O
a	O
multitude	O
of	O
languages	O
and	O
domains	O
.	O
The	O
main	O
contributions	O
of	O
this	O
paper	O
are	O
the	O
following	O
:	O
i	O
We	O
introduce	O
a	O
simple	O
architecture	O
to	O
perform	O
word	O
-	O
level	O
quality	O
estimation	O
that	O
predicts	O
the	O
quality	O
of	O
the	O
words	O
in	O
the	O
source	O
sentence	O
,	O
target	O
sentence	O
and	O
the	O
gaps	O
in	O
the	O
target	O
sentence	O
.	O

ii	O
We	O
explore	O
multilingual	O
,	O
word	O
-	O
level	O
quality	O
estimation	O
with	O
the	O
proposed	O
architecture	O
.	O
We	O
show	O
that	O
multilingual	O
models	O
are	O
competitive	O
with	O
bilingual	O
models	O
.	O

iii	O
We	O
inspect	O
few	O
-	O
shot	O
and	O
zero	O
-	O
shot	O
word	O
-	O
level	O
quality	O
estimation	O
with	O
the	O
bilingual	O
and	O
multilingual	O
models	O
.	O
We	O
report	O
how	O
the	O
sourcetarget	O
direction	O
,	O
domain	O
and	O
MT	O
type	O
affect	O
the	O
predictions	O
for	O
a	O
new	O
language	O
pair	O
.	O

iv	O
We	O
release	O
the	O
code	O
and	O
the	O
pre	O
-	O
trained	O
models	O
as	O
part	O
of	O
an	O
open	O
-	O
source	O
framework	O
1	O
.	O
(	O
Kepler	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
However	O
,	O
the	O
current	O
state	O
of	O
the	O
art	O
in	O
word	O
-	O
level	O
QE	O
is	O
based	O
on	O
transformers	O
like	O
BERT	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
XLM	O
-	O
R	O
(	O
Conneau	O
et	O
al	O
.	O
,	O
2020	O
)	O
where	O
a	O
simple	O
linear	O
layer	O
is	O
added	O
on	O
top	O
of	O
the	O
transformer	O
model	O
to	O
obtain	O
the	O
predictions	O
(	O
Lee	O
,	O
2020	O
)	O
.	O
All	O
of	O
these	O
approaches	O
consider	O
quality	O
estimation	O
as	O
a	O
language	O
-	O
specific	O
task	O
and	O
build	O
a	O
different	O
model	O
for	O
each	O
language	O
pair	O
.	O
This	O
approach	O
has	O
many	O
drawbacks	O
in	O
real	O
-	O
world	O
applications	O
,	O
some	O
of	O
which	O
are	O
discussed	O
in	O
Section	O
1	O
.	O

Multilinguality	O
Multilinguality	O
allows	O
training	O
a	O
single	O
model	O
to	O
perform	O
a	O
task	O
from	O
and/or	O
to	O
multiple	O
languages	O
.	O
Even	O
though	O
this	O
has	O
been	O
applied	O
to	O
many	O
tasks	O
Zampieri	O
,	O
2020	O
,	O
2021	O
)	O
including	O
NMT	O
(	O
Nguyen	O
and	O
Chiang	O
,	O
2017;Aharoni	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
multilingual	O
approaches	O
have	O
been	O
rarely	O
used	O
in	O
QE	O
.	O
Shah	O
and	O
Specia	O
(	O
2016	O
)	O
explore	O
QE	O
models	O
for	O
more	O
than	O
one	O
language	O
where	O
they	O
use	O
multitask	O
learning	O
with	O
annotators	O
or	O
languages	O
as	O
multiple	O
tasks	O
.	O
They	O
show	O
that	O
multilingual	O
models	O
led	O
to	O
marginal	O
improvements	O
over	O
bilingual	O
ones	O
with	O
a	O
traditional	O
black	O
-	O
box	O
,	O
feature	O
-	O
based	O
approach	O
.	O
In	O
a	O
recent	O
study	O
,	O
Ranasinghe	O
et	O
al	O
.	O
(	O
2020b	O
)	O
show	O
that	O
multilingual	O
QE	O
models	O
based	O
on	O
transformers	O
trained	O
on	O
high	O
-	O
resource	O
languages	O
can	O
be	O
used	O
for	O
zeroshot	O
,	O
sentence	O
-	O
level	O
QE	O
in	O
low	O
-	O
resource	O
languages	O
.	O

In	O
a	O
similar	O
architecture	O
,	O
but	O
with	O
multi	O
-	O
task	O
learning	O
,	O
report	O
that	O
multilingual	O
QE	O
models	O
outperform	O
bilingual	O
models	O
,	O
particularly	O
in	O
less	O
balanced	O
quality	O
label	O
distributions	O
and	O
lowresource	O
settings	O
.	O
However	O
,	O
these	O
two	O
papers	O
are	O
focused	O
on	O
sentence	O
-	O
level	O
QE	O
and	O
to	O
the	O
best	O
of	O
our	O
knowledge	O
,	O
no	O
prior	O
work	O
has	O
been	O
done	O
on	O
multilingual	O
,	O
word	O
-	O
level	O
QE	O
models	O
.	O

In	O
our	O
experiments	O
,	O
we	O
observed	O
that	O
multilingual	O
QE	O
models	O
deliver	O
excellent	O
results	O
on	O
the	O
language	O
pairs	O
they	O
were	O
trained	O
on	O
.	O
In	O
addition	O
,	O
the	O
multilingual	O
QE	O
models	O
perform	O
well	O
in	O
the	O
majority	O
of	O
the	O
zero	O
-	O
shot	O
scenarios	O
where	O
the	O
multilingual	O
QE	O
model	O
is	O
tested	O
on	O
an	O
unseen	O
language	O
pair	O
.	O
Furthermore	O
,	O
multilingual	O
models	O
perform	O
very	O
well	O
with	O
few	O
-	O
shot	O
learning	O
on	O
an	O
unseen	O
language	O
pair	O
when	O
compared	O
to	O
training	O
from	O
scratch	O
for	O
that	O
language	O
pair	O
,	O
proving	O
that	O
multilingual	O
QE	O
models	O
are	O
effective	O
even	O
with	O
a	O
limited	O
number	O
of	O
training	O
instances	O
.	O
While	O
we	O
centered	O
our	O
analysis	O
around	O
the	O
F1	O
-	O
score	O
of	O
the	O
target	O
words	O
,	O
these	O
findings	O
are	O
consistent	O
with	O
the	O
F1	O
-	O
score	O
of	O
the	O
target	O
gaps	O
and	O
the	O
F1	O
-	O
score	O
of	O
the	O
source	O
words	O
too	O
.	O
This	O
suggests	O
that	O
we	O
can	O
train	O
a	O
single	O
multilingual	O
QE	O
model	O
on	O
as	O
many	O
languages	O
as	O
possible	O
and	O
apply	O
it	O
on	O
other	O
language	O
pairs	O
as	O
well	O
.	O
These	O
findings	O
can	O
be	O
beneficial	O
to	O
perform	O
QE	O
in	O
low	O
-	O
resource	O
languages	O
for	O
which	O
the	O
training	O
data	O
is	O
scarce	O
and	O
when	O
maintaining	O
several	O
QE	O
models	O
for	O
different	O
language	O
pairs	O
is	O
arduous	O
.	O

In	O
this	O
paper	O
,	O
we	O
explored	O
multilingual	O
,	O
word	O
-	O
level	O
QE	O
with	O
transformers	O
.	O
We	O
introduced	O
a	O
new	O
architecture	O
based	O
on	O
transformers	O
to	O
perform	O
wordlevel	O
QE	O
.	O
The	O
implementation	O
of	O
the	O
architecture	O
,	O
which	O
is	O
based	O
on	O
Hugging	O
Face	O
(	O
Wolf	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
has	O
been	O
integrated	O
into	O
the	O
TransQuest	O
framework	O
(	O
Ranasinghe	O
et	O
al	O
.	O
,	O
2020b	O
)	O
which	O
won	O
the	O
WMT	O
2020	O
QE	O
task	O
)	O
on	O
sentencelevel	O
direct	O
assessment	O
(	O
Ranasinghe	O
et	O
al	O
.	O
,	O
2020a	O
)	O
2	O
.	O

We	O
also	O
evaluated	O
how	O
the	O
QE	O
models	O
behave	O
with	O
a	O
limited	O
number	O
of	O
training	O
instances	O
.	O
For	O
each	O
language	O
pair	O
,	O
we	O
initiated	O
the	O
weights	O
of	O
the	O
bilingual	O
model	O
with	O
those	O
of	O
the	O
relevant	O
All-1	O
QE	O
and	O
trained	O
it	O
on	O
100	O
,	O
200	O
,	O
300	O
and	O
up	O
to	O
1000	O
training	O
instances	O
.	O
We	O
compared	O
the	O
results	O
with	O
those	O
obtained	O
having	O
trained	O
the	O
QE	O
model	O
from	O
scratch	O
for	O
that	O
language	O
pair	O
.	O
The	O
results	O
in	O
Figure	O
2	O
show	O

Few	O
-	O
shot	O
QE	O

One	O
limitation	O
of	O
the	O
zero	O
-	O
shot	O
QE	O
is	O
its	O
inability	O
to	O
perform	O
when	O
the	O
language	O
direction	O
changes	O
.	O
In	O
the	O
scenario	O
where	O
we	O
performed	O
zero	O
-	O
shot	O
learning	O
from	O
De	O
-	O
En	O
to	O
other	O
language	O
pairs	O
,	O
results	O
degraded	O
considerably	O
from	O
the	O
bilingual	O
result	O
.	O
Similarly	O
,	O
the	O
performance	O
is	O
rather	O
poor	O
when	O
we	O
test	O
on	O
De	O
-	O
En	O
for	O
the	O
multilingual	O
zero	O
-	O
shot	O
experiment	O
as	O
the	O
direction	O
of	O
all	O
the	O
other	O
pairs	O
used	O
for	O
training	O
is	O
different	O
.	O
This	O
is	O
in	O
line	O
with	O
results	O
reported	O
by	O
Ranasinghe	O
et	O
al	O
.	O
(	O
2020b	O
)	O
for	O
sentence	O
level	O
.	O

We	O
also	O
experimented	O
with	O
zero	O
-	O
shot	O
QE	O
with	O
multilingual	O
QE	O
models	O
.	O
We	O
trained	O
the	O
QE	O
model	O
in	O
all	O
the	O
pairs	O
except	O
one	O
and	O
performed	O
predic	O
-	O
tion	O
on	O
the	O
test	O
set	O
of	O
the	O
language	O
pair	O
left	O
out	O
.	O
In	O
section	O
II	O
(	O
"	O
All-1	O
"	O
)	O
,	O
we	O
show	O
its	O
difference	O
to	O
the	O
multilingual	O
QE	O
model	O
.	O
This	O
also	O
provides	O
competitive	O
results	O
for	O
the	O
majority	O
of	O
the	O
languages	O
,	O
proving	O
it	O
is	O
possible	O
to	O
train	O
a	O
single	O
multilingual	O
QE	O
model	O
and	O
extend	O
it	O
to	O
a	O
multitude	O
of	O
languages	O
and	O
domains	O
.	O
This	O
approach	O
provides	O
better	O
results	O
than	O
performing	O
transfer	O
learning	O
from	O
a	O
bilingual	O
model	O
.	O

To	O
test	O
whether	O
a	O
QE	O
model	O
trained	O
on	O
a	O
particular	O
language	O
pair	O
can	O
be	O
generalised	O
to	O
other	O
language	O
pairs	O
,	O
different	O
domains	O
and	O
MT	O
types	O
,	O
we	O
performed	O
zero	O
-	O
shot	O
quality	O
estimation	O
.	O
We	O
used	O
the	O
QE	O
model	O
trained	O
on	O
a	O
particular	O
language	O
pair	O
and	O
evaluated	O
it	O
on	O
the	O
test	O
sets	O
of	O
the	O
other	O
language	O
pairs	O
.	O
Non	O
-	O
diagonal	O
values	O
of	O
section	O
I	O
in	O
Table	O
2	O
show	O
how	O
each	O
QE	O
model	O
performed	O
on	O
other	O
language	O
pairs	O
.	O
For	O
better	O
visualisation	O
,	O
the	O
nondiagonal	O
values	O
of	O
section	O
I	O
of	O
Table	O
2	O
show	O
by	O
how	O
much	O
the	O
score	O
changes	O
when	O
the	O
zero	O
-	O
shot	O
QE	O
model	O
is	O
used	O
instead	O
of	O
the	O
bilingual	O
QE	O
model	O
.	O
As	O
can	O
be	O
seen	O
,	O
the	O
scores	O
decrease	O
,	O
but	O
this	O
decrease	O
is	O
negligible	O
and	O
is	O
to	O
be	O
expected	O
.	O
For	O
most	O
pairs	O
,	O
the	O
QE	O
model	O
that	O
did	O
not	O
see	O
any	O
training	O
instances	O
of	O
that	O
particular	O
language	O
pair	O
outperforms	O
the	O
baselines	O
that	O
were	O
trained	O
extensively	O
on	O
that	O
particular	O
language	O
pair	O
.	O
Further	O
analysing	O
the	O
results	O
,	O
we	O
can	O
see	O
that	O
zero	O
-	O
shot	O
QE	O
performs	O
better	O
when	O
the	O
language	O
pair	O
shares	O
some	O
properties	O
such	O
as	O
domain	O
,	O
MT	O
type	O
or	O
language	O
direction	O
.	O
For	O
example	O
,	O
En	O
-	O
De	O
SMT	O
⇒	O
En	O
-	O
Cs	O
SMT	O
is	O
better	O
than	O
En	O
-	O
De	O
NMT	O
⇒	O
En	O
-	O
Cs	O
SMT	O
and	O
En	O
-	O
De	O
SMT	O
⇒	O
En	O
-	O
De	O
NMT	O
is	O
better	O
than	O
En	O
-	O
Cs	O
SMT	O
⇒	O
En	O
-	O
De	O
NMT	O
.	O

Zero	O
-	O
shot	O
QE	O

We	O
combined	O
instances	O
from	O
all	O
the	O
language	O
pairs	O
and	O
built	O
a	O
single	O
word	O
-	O
level	O
QE	O
model	O
.	O
Our	O
results	O
,	O
displayed	O
in	O
section	O
II	O
(	O
"	O
All	O
"	O
)	O
of	O
Table	O
2	O
,	O
show	O
that	O
multilingual	O
models	O
perform	O
on	O
par	O
with	O
bilingual	O
models	O
or	O
even	O
better	O
for	O
some	O
language	O
pairs	O
.	O
We	O
also	O
investigate	O
whether	O
combining	O
language	O
pairs	O
that	O
share	O
either	O
the	O
same	O
domain	O
or	O
MT	O
type	O
can	O
be	O
more	O
beneficial	O
,	O
since	O
it	O
is	O
possible	O
that	O
the	O
learning	O
process	O
is	O
better	O
when	O
language	O
pairs	O
share	O
certain	O
characteristics	O
.	O
However	O
as	O
shown	O
in	O
sections	O
III	O
and	O
IV	O
of	O
Table	O
2	O
,	O
for	O
the	O
majority	O
of	O
the	O
language	O
pairs	O
,	O
specialised	O
multilingual	O
models	O
built	O
on	O
certain	O
domains	O
or	O
MT	O
types	O
do	O
not	O
perform	O
better	O
than	O
multilingual	O
models	O
which	O
contain	O
all	O
the	O
data	O
.	O
Section	O
IV	O
shows	O
the	O
results	O
of	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
methods	O
and	O
the	O
best	O
system	O
submitted	O
for	O
the	O
language	O
pair	O
in	O
that	O
competition	O
.	O
NR	O
implies	O
that	O
a	O
particular	O
result	O
was	O
not	O
reported	O
by	O
the	O
organisers	O
.	O
Zero	O
-	O
shot	O
results	O
are	O
coloured	O
in	O
grey	O
and	O
the	O
value	O
shows	O
the	O
difference	O
between	O
the	O
best	O
result	O
in	O
that	O
section	O
for	O
that	O
language	O
pair	O
and	O
itself	O
.	O

Multilingual	O
QE	O

The	O
values	O
displayed	O
diagonally	O
across	O
section	O
I	O
of	O
Table	O
2	O
show	O
the	O
results	O
for	O
supervised	O
,	O
bilingual	O
,	O
word	O
-	O
level	O
QE	O
models	O
where	O
the	O
model	O
was	O
trained	O
on	O
the	O
training	O
set	O
of	O
a	O
particular	O
language	O
pair	O
and	O
tested	O
on	O
the	O
test	O
set	O
of	O
the	O
same	O
language	O
pair	O
.	O
As	O
can	O
be	O
seen	O
in	O
section	O
V	O
,	O
the	O
architecture	O
outperforms	O
the	O
baselines	O
in	O
all	O
the	O
language	O
pairs	O
and	O
also	O
outperforms	O
the	O
majority	O
of	O
the	O
best	O
systems	O
from	O
previous	O
competitions	O
.	O
In	O
addition	O
to	O
the	O
target	O
word	O
F1	O
-	O
score	O
,	O
our	O
architecture	O
outperforms	O
the	O
baselines	O
and	O
best	O
systems	O
in	O
target	O
gaps	O
F1	O
-	O
score	O
and	O
source	O
words	O
F1	O
-	O
score	O
too	O
as	O
shown	O
in	O
Tables	O
5	O
and	O
6	O
.	O
In	O
the	O
following	O
sections	O
we	O
explore	O
its	O
behaviour	O
in	O
different	O
multilingual	O
settings	O
.	O

For	O
evaluation	O
,	O
we	O
used	O
the	O
approach	O
proposed	O
in	O
the	O
WMT	O
shared	O
tasks	O
in	O
which	O
the	O
classification	O
performance	O
is	O
calculated	O
using	O
the	O
multiplication	O
of	O
F1	O
-	O
scores	O
for	O
the	O
'	O
OK	O
'	O
and	O
'	O
BAD	O
'	O
classes	O
against	O
the	O
true	O
labels	O
independently	O
:	O
words	O
in	O
the	O
target	O
(	O
'	O
OK	O
'	O
for	O
correct	O
words	O
,	O
'	O
BAD	O
'	O
for	O
incorrect	O
words	O
)	O
,	O
gaps	O
in	O
the	O
target	O
(	O
'	O
OK	O
'	O
for	O
genuine	O
gaps	O
,	O
'	O
BAD	O
'	O
for	O
gaps	O
indicating	O
missing	O
words	O
)	O
and	O
source	O
words	O
(	O
'	O
BAD	O
'	O
for	O
words	O
that	O
lead	O
to	O
errors	O
in	O
the	O
target	O
,	O
'	O
OK	O
'	O
for	O
other	O
words	O
)	O
.	O
In	O
recent	O
WMT	O
shared	O
tasks	O
,	O
the	O
most	O
popular	O
category	O
was	O
predicting	O
quality	O
for	O
words	O
in	O
the	O
target	O
.	O
Therefore	O
,	O
in	O
Section	O
5	O
we	O
only	O
report	O
the	O
F1	O
-	O
score	O
for	O
words	O
in	O
the	O
target	O
.	O
Other	O
results	O
are	O
presented	O
in	O
the	O
supplementary	O
material	O
.	O
Prior	O
to	O
WMT	O
2019	O
,	O
organisers	O
provided	O
separate	O
scores	O
for	O
gaps	O
and	O
words	O
in	O
the	O
target	O
,	O
while	O
after	O
WMT	O
2019	O
they	O
produce	O
a	O
single	O
result	O
for	O
target	O
gaps	O
and	O
words	O
.	O
We	O
follow	O
this	O
latter	O
approach	O
.	O

Our	O
architecture	O
relies	O
on	O
the	O
XLM	O
-	O
R	O
transformer	O
model	O
(	O
Conneau	O
et	O
al	O
.	O
,	O
2020	O
)	O
to	O
derive	O
the	O
representations	O
of	O
the	O
input	O
sentences	O
.	O
XLM	O
-	O
R	O
has	O
been	O
trained	O
on	O
a	O
large	O
-	O
scale	O
multilingual	O
dataset	O
in	O
104	O
languages	O
,	O
totalling	O
2.5	O
TB	O
,	O
extracted	O
from	O
the	O
CommonCrawl	O
datasets	O
.	O
It	O
is	O
trained	O
using	O
only	O
RoBERTa	O
's	O
(	O
Liu	O
et	O
al	O
.	O
,	O
2019	O
)	O
masked	O
language	O
modelling	O
(	O
MLM	O
)	O
objective	O
.	O
XML	O
-	O
R	O
was	O
used	O
by	O
the	O
winning	O
systems	O
in	O
the	O
recent	O
WMT	O
2020	O
shared	O
task	O
on	O
sentence	O
-	O
level	O
QE	O
(	O
Ranasinghe	O
et	O
al	O
.	O
,	O
2020a;Lee	O
,	O
2020	O
;	O
.	O
This	O
motivated	O
us	O
to	O
use	O
a	O
similar	O
approach	O
for	O
wordlevel	O
QE	O
.	O

Our	O
architecture	O
adds	O
a	O
new	O
token	O
to	O
the	O
XLM	O
-	O
R	O
tokeniser	O
called	O
<	O
GAP	O
>	O
which	O
is	O
inserted	O
between	O
the	O
words	O
in	O
the	O
target	O
.	O
We	O
then	O
concatenate	O
the	O
source	O
and	O
the	O
target	O
with	O
a	O
[	O
SEP	O
]	O
token	O
and	O
we	O
feed	O
them	O
into	O
XLM	O
-	O
R.	O
A	O
simple	O
linear	O
layer	O
is	O
added	O
on	O
top	O
of	O
word	O
and	O
<	O
GAP	O
>	O
embeddings	O
to	O
predict	O
whether	O
it	O
is	O
"	O
Good	O
"	O
or	O
"	O
Bad	O
"	O
as	O
shown	O
in	O
Figure	O
1	O
.	O
The	O
training	O
configurations	O
and	O
the	O
system	O
specifications	O
are	O
presented	O
in	O
the	O
supplementary	O
material	O
.	O
We	O
used	O
several	O
language	O
pairs	O
for	O
which	O
word	O
-	O
level	O
QE	O
annotations	O
were	O
available	O
:	O
English	O
-	O
Chinese	O
(	O
En	O
-	O
Zh	O
)	O
,	O
English	O
-	O
Czech	O
(	O
En	O
-	O
Cs	O
)	O
,	O
English	O
-	O
German	O
(	O
En	O
-	O
De	O
)	O
,	O
English	O
-	O
Russian	O
(	O
En	O
-	O
Ru	O
)	O
,	O
English	O
-	O
Latvian	O
(	O
En	O
-	O
Lv	O
)	O
and	O
German	O
-	O
English	O
(	O
De	O
-	O
En	O
)	O
.	O
The	O
texts	O
are	O
from	O
a	O
variety	O
of	O
domains	O
and	O
the	O
translations	O
were	O
produced	O
using	O
both	O
neural	O
and	O
statistical	O
machine	O
translation	O
systems	O
.	O
More	O
details	O
about	O
these	O
datasets	O
can	O
be	O
found	O
in	O
Table	O
1	O
and	O
in	O
Fonseca	O
et	O
al	O
.	O
,	O
2019	O
;	O
.	O

Translating	O
Headers	O
of	O
Tabular	O
Data	O
:	O
A	O
Pilot	O
Study	O
of	O
Schema	O
Translation	O

Schema	O
translation	O
is	O
the	O
task	O
of	O
automatically	O
translating	O
headers	O
of	O
tabular	O
data	O
from	O
one	O
language	O
to	O
another	O
.	O
High	O
-	O
quality	O
schema	O
translation	O
plays	O
an	O
important	O
role	O
in	O
crosslingual	O
table	O
searching	O
,	O
understanding	O
and	O
analysis	O
.	O
Despite	O
its	O
importance	O
,	O
schema	O
translation	O
is	O
not	O
well	O
studied	O
in	O
the	O
community	O
,	O
and	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
neural	O
machine	O
translation	O
models	O
can	O
not	O
work	O
well	O
on	O
this	O
task	O
because	O
of	O
two	O
intrinsic	O
differences	O
between	O
plain	O
text	O
and	O
tabular	O
data	O
:	O
morphological	O
difference	O
and	O
context	O
difference	O
.	O
To	O
facilitate	O
the	O
research	O
study	O
,	O
we	O
construct	O
the	O
first	O
parallel	O
dataset	O
for	O
schema	O
translation	O
,	O
which	O
consists	O
of	O
3,158	O
tables	O
with	O
11,979	O
headers	O
written	O
in	O
6	O
different	O
languages	O
,	O
including	O
English	O
,	O
Chinese	O
,	O
French	O
,	O
German	O
,	O
Spanish	O
,	O
and	O
Japanese	O
.	O
Also	O
,	O
we	O
propose	O
the	O
first	O
schema	O
translation	O
model	O
called	O
CAST	O
,	O
which	O
is	O
a	O
header	O
-	O
to	O
-	O
header	O
neural	O
machine	O
translation	O
model	O
augmented	O
with	O
schema	O
context	O
.	O
Specifically	O
,	O
we	O
model	O
a	O
target	O
header	O
and	O
its	O
context	O
as	O
a	O
directed	O
graph	O
to	O
represent	O
their	O
entity	O
types	O
and	O
relations	O
.	O
Then	O
CAST	O
encodes	O
the	O
graph	O
with	O
a	O
relational	O
-	O
aware	O
transformer	O
and	O
uses	O
another	O
transformer	O
to	O
decode	O
the	O
header	O
in	O
the	O
target	O
language	O
.	O
Experiments	O
on	O
our	O
dataset	O
demonstrate	O
that	O
CAST	O
significantly	O
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
neural	O
machine	O
translation	O
models	O
.	O
Our	O
dataset	O
will	O
be	O
released	O
at	O
https://github.com/microsoft/ContextualSP	O
.	O

Introduction	O

As	O
the	O
saying	O
goes	O
,	O
"	O
a	O
chart	O
is	O
worth	O
a	O
thousand	O
words	O
"	O
.	O
Nowadays	O
,	O
tremendous	O
amounts	O
of	O
tabular	O
data	O
written	O
in	O
various	O
languages	O
are	O
widely	O
used	O
in	O
Wikipedia	O
pages	O
,	O
research	O
papers	O
,	O
finance	O
reports	O
,	O
file	O
systems	O
,	O
and	O
databases	O
,	O
which	O
are	O
informative	O
.	O
Schema	O
translation	O
is	O
the	O
task	O
of	O
automatically	O
translating	O
headers	O
of	O
tabular	O
data	O
from	O
one	O
language	O
to	O
another	O
.	O
High	O
-	O
quality	O
schema	O
translation	O
plays	O
an	O
essential	O
role	O
in	O
cross	O
-	O
lingual	O
table	O
⇤	O
Work	O
done	O
during	O
an	O
internship	O
at	O
Microsoft	O
Research	O
.	O

No	O
.	O

Match	O
Hosted_by	O
Loc	O
.	O

Cost	O
(	O
$	O
)	O

Figure	O
1	O
:	O
An	O
illustrative	O
example	O
of	O
schema	O
translation	O
from	O
English	O
to	O
Chinese	O
.	O
1	O
-4	O
denotes	O
headers	O
with	O
abbreviation	O
,	O
polysemy	O
,	O
verb	O
-	O
object	O
phrase	O
and	O
special	O
symbol	O
,	O
respectively	O
.	O

searching	O
,	O
understanding	O
,	O
and	O
analysis	O
(	O
Zhang	O
and	O
Balog	O
,	O
2018;Deng	O
et	O
al	O
.	O
,	O
2019;Sherborne	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
Note	O
that	O
in	O
this	O
work	O
,	O
we	O
focus	O
on	O
translating	O
the	O
headers	O
instead	O
of	O
the	O
entire	O
table	O
content	O
,	O
since	O
for	O
each	O
entity	O
in	O
table	O
content	O
,	O
it	O
is	O
hard	O
to	O
decide	O
if	O
it	O
needs	O
to	O
be	O
translated	O
or	O
not	O
.	O
Over	O
translation	O
could	O
even	O
have	O
negative	O
effects	O
in	O
reality	O
.	O
Despite	O
its	O
importance	O
,	O
most	O
research	O
efforts	O
are	O
dedicated	O
to	O
plain	O
text	O
machine	O
translation	O
(	O
Sutskever	O
et	O
al	O
.	O
,	O
2014;Bahdanau	O
et	O
al	O
.	O
,	O
2015;Vaswani	O
et	O
al	O
.	O
,	O
2017;Yang	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
and	O
schema	O
translation	O
is	O
not	O
well	O
studied	O
in	O
the	O
community	O
,	O
to	O
the	O
best	O
of	O
our	O
knowledge	O
.	O
According	O
to	O
our	O
preliminary	O
study	O
,	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
neural	O
machine	O
translation	O
(	O
NMT	O
)	O
systems	O
can	O
not	O
work	O
well	O
on	O
schema	O
translation	O
because	O
of	O
two	O
intrinsic	O
differences	O
between	O
plain	O
text	O
and	O
tabular	O
data	O
:	O
morphological	O
difference	O
and	O
context	O
difference	O
.	O

Morphological	O
Difference	O
.	O
The	O
morphology	O
of	O
table	O
headers	O
differs	O
from	O
that	O
of	O
plain	O
text	O
in	O
the	O
following	O
four	O
aspects	O
.	O
First	O
,	O
headers	O
are	O
always	O
phrases	O
and	O
they	O
usually	O
contain	O
a	O
lot	O
of	O
domainspecific	O
abbreviations	O
(	O
e.g.	O
,	O
as	O
shown	O
in	O
Figure	O
1	O
,	O
"	O
No	O
.	O
"	O
is	O
the	O
abbreviation	O
of	O
"	O
Number	O
"	O
and	O
the	O
"	O
Loc	O
.	O
"	O
is	O
short	O
for	O
"	O
Location	O
"	O
)	O
and	O
special	O
symbols	O
(	O
e.g.	O
,	O
"	O
$	O
"	O
means	O
"	O
dollar	O
"	O
in	O
Figure	O
1	O
)	O
.	O
Second	O
,	O
verb	O
-	O
object	O
phrases	O
are	O
frequently	O
used	O
as	O
headers	O
which	O
indicate	O
a	O
subject	O
-	O
object	O
relationship	O
between	O
two	O
columns	O
.	O
For	O
example	O
,	O
"	O
Hosted	O
by	O
"	O
in	O
Figure	O
1	O
indicates	O
a	O
host	O
relationship	O
between	O
the	O
second	O
and	O
the	O
third	O
columns	O
.	O
Third	O
,	O
special	O
tokenizations	O
like	O
CamelCase	O
and	O
underscore	O
are	O
idiomatic	O
usages	O
in	O
headers	O
.	O
At	O
last	O
,	O
capitalized	O
words	O
are	O
particularly	O
preferred	O
in	O
order	O
to	O
capture	O
more	O
readers	O
'	O
attention	O
for	O
headers	O
.	O
These	O
special	O
word	O
-	O
forms	O
are	O
commonly	O
used	O
in	O
headers	O
but	O
rarely	O
seen	O
in	O
plain	O
text	O
.	O
Therefore	O
,	O
the	O
NMT	O
models	O
trained	O
with	O
a	O
massive	O
amount	O
of	O
plain	O
text	O
can	O
not	O
be	O
directly	O
applied	O
to	O
schema	O
translation	O
.	O

Context	O
Difference	O
.	O
Compared	O
with	O
plain	O
text	O
,	O
which	O
is	O
a	O
sequence	O
of	O
words	O
,	O
tables	O
have	O
welldefined	O
structures	O
,	O
and	O
understanding	O
a	O
table	O
's	O
structure	O
is	O
crucial	O
for	O
schema	O
translation	O
.	O
Specifically	O
,	O
a	O
table	O
consists	O
of	O
an	O
ordered	O
arrangement	O
of	O
rows	O
and	O
columns	O
.	O
Each	O
column	O
header	O
describes	O
the	O
concept	O
of	O
that	O
column	O
.	O
The	O
intersection	O
of	O
a	O
row	O
and	O
a	O
column	O
is	O
called	O
a	O
cell	O
.	O
Each	O
cell	O
contains	O
entities	O
of	O
the	O
column	O
header	O
it	O
belongs	O
to	O
.	O
This	O
structure	O
plays	O
an	O
important	O
role	O
in	O
schema	O
translation	O
,	O
especially	O
for	O
polysemy	O
words	O
and	O
abbreviation	O
words	O
.	O
For	O
example	O
,	O
in	O
Figure	O
1	O
,	O
the	O
header	O
"	O
Match	O
"	O
could	O
be	O
translated	O
to	O
"	O
kÙ	O
(	O
Matchstick	O
)	O
"	O
,	O
"	O
9	O
M	O
(	O
Mapping	O
)	O
"	O
,	O
and	O
"	O
'	O
[	O
(	O
Competition	O
)	O
"	O
,	O
but	O
its	O
sibling	O
column	O
header	O
"	O
Hosted_by	O
"	O
provides	O
important	O
clues	O
that	O
the	O
table	O
might	O
belong	O
to	O
the	O
domain	O
of	O
sport	O
.	O
Thus	O
,	O
translating	O
"	O
Match	O
"	O
to	O
"	O
'	O
[	O
(	O
Competition	O
)	O
"	O
is	O
more	O
appropriate	O
in	O
the	O
context	O
.	O
Moreover	O
,	O
a	O
column	O
header	O
's	O
cell	O
values	O
could	O
also	O
provide	O
hints	O
to	O
infer	O
the	O
meaning	O
of	O
the	O
header	O
.	O
For	O
example	O
,	O
successive	O
numerical	O
cell	O
values	O
indicate	O
that	O
"	O
No	O
.	O
"	O
might	O
be	O
an	O
identity	O
column	O
in	O
Figure	O
1	O
.	O
NMT	O
models	O
trained	O
with	O
plain	O
text	O
have	O
never	O
seen	O
the	O
structure	O
of	O
tables	O
,	O
and	O
consequently	O
,	O
they	O
perform	O
poorly	O
in	O
schema	O
translation	O
.	O

Although	O
the	O
context	O
information	O
of	O
tables	O
is	O
important	O
,	O
how	O
to	O
effectively	O
use	O
it	O
for	O
schema	O
translation	O
is	O
challenging	O
.	O
On	O
the	O
one	O
hand	O
,	O
the	O
NMT	O
model	O
needs	O
to	O
make	O
use	O
of	O
the	O
context	O
information	O
to	O
make	O
word	O
-	O
sense	O
disambiguation	O
for	O
polysemy	O
headers	O
and	O
abbreviation	O
headers	O
.	O
For	O
another	O
,	O
the	O
context	O
information	O
should	O
not	O
bring	O
additional	O
noise	O
when	O
translating	O
the	O
target	O
header	O
.	O

To	O
facilitate	O
the	O
research	O
study	O
,	O
we	O
construct	O
the	O
first	O
parallel	O
dataset	O
for	O
schema	O
translation	O
written	O
in	O
six	O
different	O
languages	O
.	O
It	O
consists	O
of	O
3,158	O
tables	O
with	O
11,979	O
headers	O
written	O
in	O
six	O
differ	O
-	O
ent	O
languages	O
,	O
including	O
English	O
,	O
Chinese	O
,	O
French	O
,	O
German	O
,	O
Spanish	O
,	O
and	O
Japanese	O
.	O

Furthermore	O
,	O
to	O
address	O
the	O
challenges	O
in	O
schema	O
translation	O
,	O
we	O
propose	O
a	O
Context	O
Aware	O
Schema	O
Translation	O
(	O
CAST	O
)	O
model	O
,	O
which	O
is	O
a	O
header	O
-	O
to	O
-	O
header	O
neural	O
machine	O
translation	O
model	O
augmented	O
with	O
table	O
context	O
.	O
Specifically	O
,	O
we	O
model	O
a	O
target	O
header	O
and	O
its	O
context	O
as	O
a	O
directed	O
graph	O
to	O
represent	O
their	O
entity	O
types	O
and	O
structural	O
relations	O
.	O
Then	O
CAST	O
encodes	O
the	O
graph	O
with	O
a	O
relational	O
-	O
aware	O
transformer	O
and	O
uses	O
another	O
transformer	O
to	O
decode	O
the	O
header	O
in	O
the	O
target	O
language	O
.	O
The	O
advantages	O
of	O
our	O
approach	O
come	O
from	O
two	O
folds	O
:	O
(	O
1	O
)	O
The	O
structure	O
relationships	O
make	O
the	O
transformer	O
encoder	O
capture	O
the	O
structural	O
information	O
and	O
learn	O
a	O
contextualized	O
representation	O
for	O
the	O
target	O
header	O
;	O
(	O
2	O
)	O
The	O
entity	O
types	O
differentiate	O
the	O
target	O
header	O
from	O
its	O
context	O
and	O
thus	O
help	O
denoise	O
the	O
target	O
header	O
translation	O
.	O

Experiments	O
on	O
our	O
dataset	O
demonstrate	O
that	O
CAST	O
significantly	O
outperforms	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
neural	O
machine	O
translation	O
models	O
.	O
Our	O
contributions	O
are	O
summarized	O
as	O
follows	O
.	O

•	O
We	O
propose	O
the	O
task	O
of	O
schema	O
translation	O
,	O
and	O
discuss	O
its	O
differences	O
with	O
a	O
plain	O
text	O
translation	O
.	O
To	O
facilitate	O
the	O
research	O
study	O
,	O
we	O
construct	O
the	O
first	O
parallel	O
schema	O
translation	O
dataset	O
.	O

•	O
We	O
propose	O
a	O
header	O
-	O
to	O
-	O
header	O
context	O
-	O
aware	O
schema	O
translation	O
model	O
,	O
called	O
CAST	O
,	O
for	O
the	O
new	O
schema	O
translation	O
task	O
.	O
Specifically	O
,	O
we	O
use	O
the	O
transformer	O
self	O
-	O
attention	O
mechanism	O
to	O
encode	O
the	O
schema	O
over	O
predefined	O
entity	O
types	O
and	O
structural	O
relationships	O
,	O
making	O
it	O
aware	O
of	O
the	O
schema	O
context	O
.	O

•	O
Experiments	O
on	O
our	O
proposed	O
dataset	O
demonstrate	O
that	O
our	O
approach	O
significantly	O
outperforms	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
neural	O
machine	O
translation	O
models	O
in	O
schema	O
translation	O
.	O

Schema	O
Translation	O
Dataset	O

To	O
address	O
the	O
need	O
for	O
a	O
dataset	O
for	O
the	O
new	O
schema	O
translation	O
task	O
,	O
we	O
construct	O
the	O
first	O
parallel	O
schema	O
translation	O
dataset	O
.	O
It	O
consists	O
of	O
3,158	O
tables	O
with	O
11,979	O
headers	O
written	O
in	O
six	O
different	O
languages	O
,	O
including	O
English	O
,	O
Chinese	O
,	O
French	O
,	O
German	O
,	O
Spanish	O
,	O
and	O
Japanese	O
.	O
In	O
this	O
section	O
,	O
we	O
will	O
first	O
introduce	O
our	O
construction	O
methodology	O
and	O
then	O
analyze	O
the	O
characteristics	O
of	O
our	O
dataset	O
.	O

58	O

Dataset	O
Construction	O

We	O
construct	O
the	O
dataset	O
in	O
two	O
steps	O
:	O
collecting	O
3,158	O
English	O
tables	O
and	O
then	O
manually	O
translating	O
the	O
schema	O
of	O
English	O
tables	O
to	O
other	O
languages	O
.	O
(	O
Pasupat	O
and	O
Liang	O
,	O
2015	O
)	O
,	O
in	O
which	O
they	O
randomly	O
select	O
2,108	O
multidomain	O
data	O
tables	O
in	O
English	O
from	O
Wikipedia	O
with	O
at	O
least	O
eight	O
rows	O
and	O
five	O
columns	O
.	O
Secondly	O
,	O
we	O
manually	O
collect	O
176	O
English	O
tables	O
from	O
the	O
search	O
engine	O
covering	O
multiple	O
domains	O
like	O
retail	O
,	O
education	O
,	O
and	O
government	O
.	O
At	O
last	O
,	O
we	O
select	O
all	O
the	O
tables	O
that	O
appear	O
in	O
the	O
training	O
set	O
and	O
development	O
set	O
from	O
the	O
Spider	O
dataset	O
(	O
Yu	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
which	O
contains	O
200	O
databases	O
covering	O
138	O
different	O
domains	O
.	O
Finally	O
,	O
we	O
obtained	O
3,158	O
tables	O
with	O
11,979	O
headers	O
in	O
total	O
.	O

Context	O
Aware	O
Schema	O
Annotation	O
.	O
To	O
reduce	O
the	O
translation	O
effort	O
,	O
we	O
first	O
use	O
Google	O
translator	O
1	O
to	O
automatically	O
translate	O
the	O
English	O
headers	O
to	O
five	O
target	O
languages	O
,	O
header	O
by	O
header	O
.	O
Then	O
based	O
on	O
the	O
Google	O
translations	O
,	O
we	O
recruit	O
three	O
professional	O
translators	O
for	O
each	O
language	O
to	O
manually	O
check	O
and	O
modify	O
the	O
translations	O
if	O
inappropriate	O
.	O

In	O
this	O
process	O
,	O
we	O
found	O
that	O
Google	O
translator	O
is	O
not	O
good	O
enough	O
in	O
schema	O
translation	O
since	O
industry	O
jargon	O
and	O
abbreviations	O
are	O
commonly	O
used	O
in	O
column	O
headers	O
.	O
Table	O
1	O
shows	O
some	O
example	O
headers	O
and	O
their	O
paraphrases	O
under	O
different	O
domains	O
in	O
our	O
dataset	O
.	O
However	O
,	O
domain	O
information	O
is	O
implicit	O
,	O
and	O
the	O
meaning	O
of	O
the	O
header	O
needs	O
to	O
be	O
inferred	O
carefully	O
from	O
the	O
entire	O
table	O
context	O
.	O
To	O
get	O
more	O
precise	O
translations	O
,	O
we	O
provide	O
three	O
kinds	O
of	O
additional	O
information	O
as	O
a	O
schema	O
context	O
:	O
(	O
1	O
)	O
a	O
whole	O
table	O
with	O
structural	O
information	O
,	O
including	O
its	O
table	O
name	O
,	O
column	O
headers	O
and	O
cell	O
values	O
;	O
(	O
2	O
)	O
an	O
original	O
web	O
-	O
page	O
URL	O
for	O
the	O
table	O
from	O
the	O
Wikipedia	O
website	O
;	O
(	O
3	O
)	O
some	O
natural	O
language	O
question	O
/	O
answer	O
pairs	O
about	O
the	O
table	O
2	O
.	O
Our	O
translators	O
are	O
asked	O
to	O
first	O
understand	O
the	O
context	O
of	O
the	O
given	O
schema	O
before	O
validating	O
the	O
translations	O
.	O
We	O
find	O
that	O
the	O
modification	O
rate	O
is	O
40	O
%	O
,	O
which	O
indicates	O
that	O
the	O
provided	O
context	O
is	O
very	O
useful	O
.	O
Finally	O
,	O
we	O
further	O
verify	O
the	O
annotated	O
data	O
by	O
asking	O
a	O
different	O
translator	O
to	O
check	O
if	O
the	O
headers	O
are	O
correctly	O
translated	O
.	O

Data	O
Statistics	O
and	O
Analysis	O

As	O
we	O
know	O
,	O
the	O
translation	O
cost	O
is	O
expensive	O
,	O
and	O
we	O
provide	O
parallel	O
corpus	O
in	O
six	O
languages	O
,	O
which	O
limits	O
the	O
volume	O
of	O
translated	O
headers	O
.	O
On	O
the	O
basis	O
of	O
our	O
statistics	O
,	O
the	O
average	O
validating	O
speed	O
is	O
100	O
headers	O
/	O
hour	O
and	O
we	O
spend	O
159.34	O
⇤	O
5	O
hours	O
in	O
total	O
.	O
This	O
speed	O
is	O
much	O
slower	O
than	O
the	O
plain	O
text	O
translation	O
since	O
our	O
translators	O
need	O
to	O
read	O
large	O
amounts	O
of	O
different	O
domain	O
-	O
specific	O
contexts	O
to	O
help	O
disambiguation	O
.	O
To	O
this	O
end	O
,	O
we	O
make	O
our	O
best	O
effort	O
and	O
translate	O
11,979	O
headers	O
,	O
spending	O
6,625	O
USD	O
in	O
total	O
.	O
According	O
to	O
our	O
translators	O
'	O
feedback	O
,	O
the	O
context	O
is	O
quite	O
helpful	O
in	O
understanding	O
the	O
meaning	O
of	O
headers	O
.	O
We	O
will	O
also	O
release	O
these	O
contexts	O
together	O
with	O
our	O
schema	O
translation	O
dataset	O
to	O
facilitate	O
further	O
study	O
.	O

Dataset	O
Analysis	O
.	O
To	O
have	O
a	O
more	O
quantitative	O
analysis	O
of	O
our	O
dataset	O
,	O
we	O
count	O
the	O
ratio	O
of	O
headers	O
containing	O
four	O
lexical	O
features	O
,	O
including	O
abbreviation	O
,	O
symbol	O
characters	O
,	O
verb	O
-	O
object	O
phrase	O
and	O
capitalized	O
character	O
.	O
As	O
we	O
can	O
see	O
in	O
table	O
2	O
,	O
these	O
lexical	O
features	O
commonly	O
occur	O
in	O
headers	O
,	O
making	O
them	O
quite	O
different	O
from	O
plain	O
text	O
.	O

To	O
help	O
better	O
understand	O
the	O
domains	O
of	O
the	O
collected	O
tables	O
,	O
we	O
firstly	O
use	O
a	O
44	O
-	O
category	O
ontology	O
presented	O
in	O
Wikipedia	O
:	O
WikiProject	O
Council	O
/	O
Directory	O
as	O
our	O
domain	O
category	O
.	O
Then	O
we	O
randomly	O
sample	O
500	O
tables	O
in	O
the	O
training	O
set	O
and	O
manually	O
label	O
the	O
domains	O
.	O
According	O
to	O
our	O
statistics	O
,	O
our	O
dataset	O
covers	O
all	O
44	O
domains	O
.	O
In	O
detail	O
,	O
the	O
Sports	O
,	O
Countries	O
,	O
Economics	O
,	O
and	O
Music	O
topics	O
together	O
comprise	O
44.6	O
%	O
of	O
our	O
dataset	O
,	O
but	O
the	O
other	O
55.4	O
%	O
is	O
composed	O
of	O
broader	O
topics	O
such	O
as	O
Business	O
,	O
Education	O
,	O
Science	O
,	O
and	O
Government	O
.	O

Methodology	O

In	O
this	O
section	O
,	O
we	O
describe	O
our	O
schema	O
translation	O
approach	O
in	O
detail	O
.	O
We	O
first	O
introduce	O
the	O
requirement	O
and	O
our	O
definition	O
for	O
the	O
schema	O
translation	O
task	O
and	O
then	O
introduce	O
the	O
model	O
architecture	O
.	O

Task	O
Requirement	O

In	O
schema	O
translation	O
,	O
both	O
the	O
meaning	O
of	O
the	O
headers	O
and	O
the	O
structural	O
information	O
like	O
order	O
and	O
numbers	O
must	O
be	O
completely	O
transferred	O
to	O
the	O
target	O
language	O
.	O
Obviously	O
,	O
this	O
requirement	O
can	O
not	O
be	O
met	O
by	O
translating	O
schema	O
as	O
a	O
whole	O
with	O
the	O
traditional	O
sequence	O
-	O
to	O
-	O
sequence	O
NMT	O
models	O
because	O
it	O
can	O
not	O
achieve	O
precisely	O
token	O
level	O
alignment	O
.	O
For	O
example	O
,	O
when	O
concatenating	O
all	O
headers	O
with	O
a	O
separator	O
"	O
|	O
"	O
,	O
the	O
separator	O
can	O
be	O
easily	O
lost	O
during	O
translation	O
.	O
To	O
meet	O
this	O
requirement	O
,	O
we	O
employ	O
a	O
header	O
-	O
to	O
-	O
header	O
translation	O
manner	O
in	O
this	O
work	O
,	O
which	O
translates	O
one	O
header	O
at	O
a	O
time	O
.	O

Task	O
Definition	O

We	O
define	O
a	O
column	O
header	O
as	O
H	O
i	O
=	O
hh	O
1	O
,	O
.	O
.	O
.	O
,	O
h	O
n	O
i	O
,	O
where	O
h	O
j	O
is	O
the	O
jth	O
token	O
of	O
the	O
header	O
in	O
the	O
source	O
language	O
.	O

Let	O
C	O
i	O
=	O
(	O
S	O
i	O
,	O
V	O
i	O
)	O
denote	O
the	O
context	O
of	O
H	O
i	O
.	O

It	O
is	O
made	O
up	O
of	O
a	O
set	O
of	O
selected	O
cell	O
values	O
V	O
i	O
=	O
{	O
v	O
1	O
,	O
.	O
.	O
.	O
,	O
v	O
t	O
}	O
of	O
H	O
i	O
and	O
the	O
rest	O
of	O
headers	O

S	O
i	O
=	O
[	O
H	O
1	O
,	O
.	O
.	O
.	O
,	O
H	O
i	O
1	O
,	O
H	O
i+1	O
,	O
.	O
.	O
.	O
,	O
H	O
m	O
]	O

in	O
the	O
schema	O
.	O
The	O
translation	O
of	O
H	O
i	O
is	O
denoted	O
as	O
Y	O
i	O
=	O
hy	O
1	O
,	O
.	O
.	O
.	O
,	O
y	O
m	O
i	O
,	O
where	O
y	O
j	O
is	O
the	O
jth	O
token	O
of	O
the	O
header	O
in	O
the	O
target	O
language	O
.	O
Taking	O
a	O
header	O
H	O
and	O
its	O
corresponding	O
context	O
C	O
as	O
input	O
,	O
the	O
model	O
outputs	O
the	O
header	O
Y	O
in	O
the	O
target	O
language	O
.	O

Model	O

Basically	O
,	O
our	O
model	O
adopts	O
a	O
Transformer	O
encoderdecoder	O
architecture	O
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017	O
)	O
,	O
which	O
takes	O
the	O
source	O
language	O
header	O
with	O
its	O
corresponding	O
context	O
as	O
inputs	O
and	O
generates	O
the	O
translation	O
for	O
the	O
target	O
language	O
header	O
as	O
outputs	O
.	O
Specifically	O
,	O
we	O
model	O
the	O
target	O
header	O
and	O
its	O
context	O
as	O
a	O
directed	O
graph	O
and	O
use	O
the	O
transformer	O
self	O
-	O
attention	O
to	O
encode	O
them	O
over	O
two	O
predefined	O
structural	O
relationships	O
and	O
three	O
entity	O
types	O
.	O
Figure	O
2	O
depicts	O
the	O
overall	O
architecture	O
of	O
our	O
model	O
via	O
an	O
illustrative	O
example	O
.	O

Relation	O
-	O
Aware	O
Self	O
-	O
Attention	O
.	O
First	O
,	O
we	O
introduce	O
self	O
-	O
attention	O
and	O
then	O
its	O
extension	O
,	O
relationaware	O
self	O
-	O
attention	O
.	O
Consider	O
a	O
sequence	O
of	O
inputs	O

X	O
=	O
{	O
x	O
i	O
}	O
n	O
i=1	O

where	O
x	O
i	O
2	O
R	O
dx	O
.	O
Self	O
-	O
attention	O
introduced	O
by	O
Vaswani	O
et	O
al	O
.	O
(	O
2017	O
)	O
transforms	O
each	O
x	O
i	O
into	O
z	O
i	O
2	O
R	O
dx	O
as	O
follows	O
:	O

e	O
ij	O
=	O
x	O
i	O
W	O
Q	O
(	O
x	O
j	O
W	O
K	O
)	O
T	O
p	O
d	O
z	O
↵	O
ij	O
=	O
softmax	O
j	O
{	O
e	O
ij	O
}	O
(	O
1	O
)	O
z	O
i	O
=	O
n	O
X	O
j=1	O
↵	O
ij	O
(	O
x	O
j	O
W	O
V	O
)	O

where	O
dz	O
)	O
.	O
Shaw	O
et	O
al	O
.	O
(	O
2018	O
)	O
proposes	O
an	O
extension	O
to	O
selfattention	O
to	O
consider	O
the	O
pairwise	O
relationships	O
between	O
input	O
tokens	O
by	O
changing	O
Equation	O
(	O
1	O
)	O
as	O
follows	O
:	O

W	O
Q	O
,	O
W	O
K	O
,	O
W	O
V	O
2	O
R	O
dx	O
⇥	O
(	O

e	O
ij	O
=	O
x	O
i	O
W	O
Q	O
(	O
x	O
j	O
W	O
K	O
+	O
r	O
K	O
ij	O
)	O
)	O
T	O
p	O
d	O
z	O
z	O
i	O
=	O
n	O
X	O
j=1	O
↵	O
ij	O
(	O
x	O
j	O
W	O
V	O
+	O
r	O
V	O
ij	O
)	O
(	O
2	O
)	O

Here	O
the	O
r	O
ij	O
terms	O
encode	O
the	O
known	O
relationships	O
between	O
the	O
two	O
tokens	O
x	O
i	O
and	O
x	O
j	O
in	O
the	O
input	O
sequence	O
.	O
In	O
this	O
way	O
,	O
this	O
self	O
-	O
attention	O
is	O
biased	O
toward	O
some	O
pre	O
-	O
defined	O
relationships	O
using	O
the	O
relation	O
vector	O
r	O
ij	O
in	O
each	O
layer	O
when	O
learning	O
the	O
contextualized	O
embedding	O
.	O
Specifically	O
,	O
they	O
use	O
it	O
to	O
represent	O
the	O
relative	O
position	O
information	O
between	O
sequence	O
elements	O
.	O
More	O
details	O
could	O
be	O
found	O
in	O
their	O
work	O
(	O
Shaw	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
Figure	O
2	O
:	O
An	O
overview	O
of	O
CAST	O
with	O
an	O
illustrative	O
example	O
of	O
English	O
-	O
to	O
-	O
Chinese	O
schema	O
translation	O
.	O
Firstly	O
,	O
the	O
target	O
header	O
"	O
Chinese	O
"	O
and	O
its	O
context	O
are	O
modeled	O
as	O
a	O
directed	O
graph	O
.	O
Then	O
a	O
stack	O
of	O
relation	O
-	O
aware	O
transformers	O
encodes	O
the	O
input	O
sequence	O
X	O
to	O
X	O
0	O
with	O
a	O
relational	O
matrix	O
R	O
induced	O
from	O
the	O
graph	O
.	O

Inspired	O
by	O
Shaw	O
et	O
al	O
.	O
(	O
2018	O
)	O
,	O
we	O
model	O
the	O
target	O
header	O
and	O
its	O
context	O
as	O
a	O
labeled	O
directed	O
graph	O
and	O
use	O
the	O
same	O
formulation	O
of	O
relationaware	O
self	O
-	O
attention	O
as	O
Shaw	O
et	O
al	O
.	O
(	O
2018	O
)	O
.	O
Here	O

X	O
=	O
{	O
x	O
i	O
}	O
n	O

i=1	O
are	O
initial	O
embeddings	O
of	O
our	O
input	O
sequence	O
,	O
and	O
the	O
relational	O
matrix	O
R	O
is	O
induced	O
from	O
the	O
input	O
graph	O
,	O
where	O
r	O
ij	O
is	O
a	O
learned	O
embedding	O
according	O
to	O
the	O
type	O
of	O
edge	O
that	O
x	O
i	O
and	O
x	O
j	O
hold	O
in	O
the	O
directed	O
input	O
graph	O
.	O
The	O
following	O
section	O
will	O
describe	O
the	O
set	O
of	O
relations	O
our	O
model	O
uses	O
to	O
encode	O
a	O
target	O
header	O
concatenated	O
with	O
its	O
context	O
.	O

Input	O
Graph	O
.	O
We	O
model	O
a	O
target	O
header	O
and	O
its	O
context	O
as	O
a	O
directed	O
graph	O
to	O
represent	O
their	O
entity	O
types	O
and	O
structural	O
relations	O
.	O
Firstly	O
,	O
we	O
induce	O
two	O
kinds	O
of	O
edges	O
to	O
denote	O
the	O
structural	O
relationships	O
between	O
the	O
target	O
header	O
and	O
its	O
context	O
:	O
sibling	O
header	O
(	O
i.e.	O
,	O
an	O
edge	O
point	O
from	O
tokens	O
in	O
S	O
to	O
tokens	O
in	O
the	O
target	O
header	O
.	O
)	O
,	O
and	O
belonging	O
value	O
(	O
i.e.	O
,	O
an	O
edge	O
point	O
from	O
tokens	O
in	O
V	O
to	O
tokens	O
in	O
the	O
target	O
header	O
.	O
)	O
.	O
In	O
this	O
sense	O
,	O
it	O
could	O
incorporate	O
the	O
structural	O
information	O
into	O
the	O
contextualized	O
representation	O
of	O
the	O
target	O
header	O
.	O

Then	O
,	O
we	O
define	O
three	O
sorts	O
of	O
entity	O
types	O
to	O
distinguish	O
the	O
target	O
header	O
from	O
its	O
context	O
.	O
Specifically	O
,	O
for	O
a	O
token	O
in	O
the	O
target	O
header	O
,	O
we	O
assign	O
a	O
special	O
edge	O
Target	O
point	O
to	O
itself	O
,	O
denoting	O
the	O
entity	O
type	O
.	O
For	O
tokens	O
in	O
S	O
and	O
V	O
,	O
we	O
assign	O
them	O
different	O
edges	O
point	O
to	O
themselves	O
,	O
e.g.	O
,	O
Header	O
,	O
and	O
Value	O
respectively	O
.	O
Figure	O
2	O
illustrates	O
an	O
example	O
graph	O
(	O
with	O
actual	O
edges	O
and	O
labels	O
)	O
and	O
its	O
induced	O
relational	O
matrix	O
R.	O
Initial	O
Token	O
Embedding	O
.	O
We	O
obtain	O
the	O
initial	O
token	O
embedding	O
by	O
a	O
pre	O
-	O
trained	O
transformer	O
encoder	O
before	O
feeding	O
it	O
to	O
the	O
ration	O
-	O
aware	O
transformer	O
.	O
To	O
obtain	O
the	O
input	O
sequence	O
,	O
each	O
element	O
in	O
S	O
and	O
V	O
are	O
firstly	O
concatenated	O
with	O
a	O
vertical	O
bar	O
"	O
|	O
"	O
.	O
Then	O
,	O
the	O
target	O
header	O
H	O
,	O
the	O
rest	O
of	O
the	O
headers	O
S	O
,	O
and	O
the	O
selected	O
cell	O
values	O
V	O
are	O
concatenated	O
by	O
a	O
separator	O
symbol	O
"	O
[	O
sep	O
]	O
"	O
.	O
At	O
last	O
,	O
following	O
,	O
an	O
additional	O
source	O
language	O
token	O
"	O
hsrci	O
"	O
is	O
added	O
at	O
the	O
front	O
to	O
help	O
the	O
pretrained	O
model	O
identify	O
the	O
source	O
language	O
.	O
The	O
encoder	O
then	O
transforms	O
the	O
final	O
input	O
sequence	O
into	O
a	O
sequence	O
of	O
embedding	O

X	O
=	O
[	O
x	O
1	O
,	O
.	O
.	O
.	O
,	O
x	O
l	O
]	O
.	O

Then	O
we	O
feed	O
them	O
to	O
the	O
relational	O
aware	O
layers	O
and	O
get	O
the	O
final	O
contextualized	O
sequence	O
of	O
embedding	O
X	O

0	O
=	O
[	O
x	O
0	O
1	O
,	O
.	O
.	O
.	O
,	O
x	O
0	O
l	O
]	O
.	O

Decoder	O
.	O
The	O
goal	O
of	O
the	O
decoder	O
is	O
to	O
autoregressively	O
generate	O
the	O
translated	O
column	O
header	O
Y	O
=	O
hy	O
1	O
,	O
.	O
.	O
.	O
,	O
y	O
m	O
i.	O
Specifically	O
,	O
taking	O
X	O
0	O
and	O
the	O
representation	O
of	O
previously	O
output	O
token	O
as	O
input	O
,	O
the	O
decoder	O
predicts	O
the	O
translation	O
token	O
by	O
token	O
until	O
an	O
ending	O
signal	O
hendi	O
is	O
generated	O
.	O
Similar	O
to	O
the	O
encoder	O
,	O
a	O
special	O
token	O
htgti	O
which	O
indicates	O
the	O
target	O
language	O
is	O
added	O
at	O
the	O
front	O
to	O
guide	O
the	O
prediction	O
of	O
the	O
target	O
language	O
.	O

Experiments	O

In	O
this	O
section	O
,	O
we	O
conduct	O
experiments	O
on	O
our	O
proposed	O
schema	O
translation	O
dataset	O
to	O
evaluate	O
the	O
effectiveness	O
of	O
our	O
approach	O
.	O
Furthermore	O
,	O
we	O
ablate	O
different	O
ways	O
of	O
context	O
modeling	O
in	O
our	O
approach	O
to	O
understand	O
their	O
contributions	O
.	O
At	O
last	O
,	O
we	O
conduct	O
a	O
qualitative	O
analysis	O
and	O
show	O
example	O
cases	O
and	O
their	O
predicting	O
results	O
.	O

Experiment	O
Setup	O

Baseline	O
.	O
We	O
choose	O
two	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
NMT	O
models	O
,	O
including	O
M2M-100	O
and	O
MBart-50M2	O
M	O
(	O
Tang	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
as	O
our	O
baselines	O
.	O
Specifically	O
,	O
both	O
of	O
the	O
baseline	O
models	O
employ	O
the	O
Transformer	O
sequence	O
-	O
to	O
-	O
sequence	O
architecture	O
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017	O
)	O
to	O
capture	O
features	O
from	O
source	O
language	O
input	O
and	O
generate	O
the	O
translation	O
.	O
The	O
M2M-100	O
is	O
directly	O
trained	O
on	O
large	O
-	O
scaled	O
translation	O
data	O
while	O
MBart-50M2	O
M	O
is	O
firstly	O
pre	O
-	O
trained	O
with	O
a	O
"	O
Multilingual	O
Denoising	O
Pretraining	O
"	O
objective	O
and	O
then	O
fine	O
-	O
tuned	O
in	O
machine	O
-	O
translation	O
task	O
.	O
We	O
evaluate	O
the	O
baseline	O
models	O
with	O
the	O
following	O
settings	O
:	O

•	O
Base	O
:	O
The	O
original	O
NMT	O
models	O
without	O
finetuning	O
on	O
the	O
schema	O
dataset	O
.	O
•	O
H2H	O
:	O
The	O
NMT	O
models	O
that	O
are	O
fine	O
-	O
tuned	O
on	O
our	O
schema	O
translation	O
dataset	O
in	O
a	O
headerto	O
-	O
header	O
manner	O
.	O
•	O
H2H+CXT	O
:	O
The	O
NMT	O
models	O
are	O
fine	O
-	O
tuned	O
by	O
concatenating	O
a	O
target	O
header	O
and	O
its	O
context	O
as	O
input	O
and	O
translating	O
the	O
target	O
header	O
.	O
•	O
H2H+CXT+ExtL	O
:	O
The	O
NMT	O
models	O
with	O
two	O
extra	O
Transformers	O
layers	O
at	O
the	O
end	O
of	O
the	O
encoder	O
,	O
and	O
are	O
fine	O
-	O
tuned	O
with	O
the	O
same	O
setting	O
as	O
H2H+CXT	O
.	O

Besides	O
NMT	O
models	O
,	O
we	O
also	O
trained	O
a	O
phrasebased	O
statistical	O
machine	O
translation	O
(	O
PB	O
-	O
SMT	O
)	O
schema	O
translation	O
model	O
with	O
Moses	O
3	O
(	O
Koehn	O
et	O
al	O
.	O
,	O
2007	O
)	O
,	O
with	O
the	O
same	O
data	O
split	O
.	O

Evaluation	O
Metrics	O
.	O
We	O
evaluate	O
the	O
performances	O
of	O
different	O
models	O
with	O
the	O
4	O
-	O
gram	O
BLEU	O
(	O
Papineni	O
et	O
al	O
.	O
,	O
2002	O
)	O
score	O
of	O
the	O
translations	O
.	O
Following	O
the	O
evaluation	O
step	O
in	O
M2M-100	O
,	O
before	O
computing	O
BLEU	O
,	O
we	O
de	O
-	O
tokenize	O
the	O
data	O
and	O
apply	O
standard	O
tokenizers	O
for	O
each	O
language	O
.	O
We	O
use	O
SacreBLEU	O
tokenizer	O
for	O
Chinese	O
,	O
Kytea	O
4	O
for	O
Japanese	O
,	O
and	O
Moses	O
tokenizer	O
5	O
for	O
the	O
rest	O
of	O
the	O
languages	O
.	O
Besides	O
BLEU	O
,	O
we	O
also	O
conduct	O
a	O
human	O
evaluation	O
for	O
a	O
more	O
precise	O
analysis	O
.	O

Hyperparameters	O
.	O
We	O
fine	O
-	O
tune	O
all	O
of	O
our	O
NMT	O
models	O
for	O
4	O
epochs	O
with	O
a	O
batch	O
size	O
of	O
4	O
and	O
a	O
warmup	O
rate	O
of	O
0.2	O
.	O
To	O
avoid	O
over	O
-	O
fitting	O
,	O
we	O
set	O
the	O
early	O
stopping	O
patience	O
on	O
the	O
validation	O
set	O
as	O
2	O
.	O
In	O
the	O
context	O
construction	O
,	O
we	O
randomly	O
select	O
5	O
cell	O
values	O
for	O
each	O
target	O
column	O
.	O
The	O
Adam	O
optimizer	O
(	O
Kingma	O
and	O
Ba	O
,	O
2015	O
)	O
with	O
ß1	O
=	O
0.9	O
,	O
ß2	O
=	O
0.99	O
and	O
✏	O
=	O
1e-8	O
is	O
adopted	O
.	O
We	O
set	O
the	O
number	O
of	O
relation	O
-	O
aware	O
layers	O
as	O
2	O
,	O
and	O
we	O
set	O
the	O
learning	O
rate	O
of	O
the	O
decoder	O
and	O
the	O
relational	O
aware	O
layers	O
as	O
3e-5	O
,	O
and	O
decrease	O
the	O
learning	O
rate	O
of	O
the	O
Transformer	O
encoder	O
to	O
4	O
times	O
and	O
8	O
times	O
smaller	O
for	O
M2M-100	O
and	O
MBart-50M2	O
M	O
respectively	O
.	O

Experimental	O
Results	O

We	O
conduct	O
experiments	O
of	O
translating	O
schema	O
from	O
English	O
(	O
En	O
)	O
to	O
five	O
different	O
languages	O
,	O
including	O
Chinese	O
(	O
Zh	O
)	O
,	O
French	O
(	O
Fr	O
)	O
,	O
German	O
(	O
De	O
)	O
,	O
Spanish	O
(	O
Es	O
)	O
,	O
and	O
Japanese	O
(	O
Ja	O
)	O
.	O
The	O
performances	O
of	O
different	O
translation	O
models	O
are	O
listed	O
in	O
Table	O
4	O
.	O

Overall	O
Performance	O
.	O
The	O
overall	O
performances	O
of	O
two	O
NMT	O
models	O
across	O
five	O
target	O
languages	O
show	O
similar	O
trends	O
.	O
Firstly	O
,	O
compared	O
with	O
Base	O
,	O
which	O
is	O
trained	O
only	O
on	O
plain	O
text	O
,	O
H2H	O
gains	O
significant	O
improvement	O
.	O
For	O
example	O
,	O
H2H	O
based	O
on	O
M2M-100	O
outperforms	O
Base	O
by	O
17.7	O
,	O
24.7	O
,	O
26.7	O
,	O
15.5	O
,	O
and	O
16.6	O
BLEU	O
in	O
translating	O
schema	O
from	O
En	O
to	O
Zh	O
,	O
Es	O
,	O
Fr	O
,	O
De	O
,	O
and	O
Ja	O
,	O
respectively	O
.	O
It	O
demonstrates	O
a	O
big	O
difference	O
between	O
plain	O
text	O
and	O
tabular	O
data	O
,	O
and	O
fine	O
-	O
tuning	O
on	O
schema	O
translation	O
data	O
could	O
alleviate	O
the	O
difference	O
to	O
some	O
extent	O
.	O

Next	O
,	O
we	O
find	O
that	O
,	O
in	O
most	O
situations	O
,	O
the	O
performance	O
of	O
H2H	O
can	O
be	O
further	O
boosted	O
by	O
concatenating	O
the	O
constructed	O
context	O
from	O
the	O
table	O
.	O
Taking	O
H2H+CXT	O
based	O
on	O
M2M-100	O
as	O
an	O
example	O
,	O
comparing	O
with	O
H2H	O
,	O
H2H+CXT	O
obtains	O
2.1	O
,	O
0.6	O
,	O
and	O
1.6	O
points	O
of	O
improvement	O
in	O
En	O
-	O
Zh	O
,	O
En	O
-	O
De	O
,	O
and	O
En	O
-	O
Ja	O
settings	O
,	O
respectively	O
.	O
In	O
terms	O
of	O
H2H+CXT	O
based	O
on	O
MBart-50M2	O
M	O
,	O
the	O
concatenation	O
of	O
context	O
also	O
boosts	O
the	O
BLEU	O
score	O
for	O
translating	O
schema	O
from	O
En	O
to	O
Zh	O
and	O
Es	O
by	O
1.5	O
and	O
1.2	O
.	O
The	O
observations	O
demonstrate	O
the	O
benefits	O
of	O
making	O
good	O
use	O
of	O
the	O
constructed	O
context	O
.	O

However	O
,	O
we	O
also	O
notice	O
that	O
concatenating	O
the	O
context	O
does	O
not	O
help	O
improve	O
the	O
performance	O
of	O
H2H+CXT	O
based	O
on	O
MBart-50M2	O
M	O
and	O
M2M100	O
in	O
the	O
setting	O
of	O
En	O
-	O
De	O
and	O
En	O
-	O
Ja	O
,	O
and	O
the	O
setting	O
of	O
En	O
-	O
Es	O
and	O
En	O
-	O
Fr	O
,	O
respectively	O
.	O
We	O
hypothesize	O
that	O
the	O
decrease	O
of	O
BLEU	O
score	O
comes	O
from	O
the	O
noise	O
brought	O
by	O
the	O
context	O
.	O

There	O
are	O
no	O
significant	O
differences	O
between	O
the	O
performance	O
of	O
H2H+CXT	O
and	O
H2H+CXT+ExtL	O
which	O
has	O
two	O
extra	O
Transformers	O
layers	O
since	O
the	O
pre	O
-	O
trained	O
NMT	O
models	O
have	O
already	O
had	O
12	O
Transformers	O
layers	O
.	O

For	O
example	O
,	O
the	O
H2H+CXT+ExtL	O
model	O
based	O
on	O
M2M100	O
obtains	O
47	O
.	O
1	O
,	O
48.6	O
,	O
53.0	O
,	O
46.6	O
,	O
and	O
40.4	O
BLEU	O
points	O
on	O
En	O
-	O
Zh	O
,	O
En	O
-	O
Es	O
,	O
En	O
-	O
Fr	O
,	O
En	O
-	O
De	O
,	O
and	O
En	O
-	O
Ja	O
,	O
respectively	O
.	O

Finally	O
,	O
equipped	O
with	O
the	O
relation	O
-	O
aware	O
module	O
,	O
CAST	O
can	O
make	O
the	O
best	O
use	O
of	O
the	O
context	O
and	O
obtain	O
significant	O
improvement	O
over	O
H2H	O
across	O
all	O
settings	O
.	O
For	O
models	O
based	O
on	O
M2M-100	O
,	O
CAST	O
outperforms	O
H2H	O
by	O
2.6	O
,	O
1.4	O
,	O
0.3	O
,	O
1.8	O
,	O
and	O
1.9	O
BLEU	O
in	O
En	O
-	O
Zh	O
,	O
En	O
-	O
Es	O
,	O
En	O
-	O
Fr	O
,	O
En	O
-	O
De	O
,	O
and	O
En	O
-	O
Ja	O
,	O
respectively	O
.	O
When	O
it	O
comes	O
to	O
models	O
based	O
on	O
MBart-50M2	O
M	O
,	O
CAST	O
obtains	O
1.6	O
,	O
2.7	O
,	O
1.9	O
,	O
0.9	O
,	O
0.2	O
improvements	O
of	O
BLEU	O
points	O
over	O
H2H	O
in	O
translating	O
schema	O
from	O
En	O
to	O
5	O
target	O
languages	O
.	O
It	O
is	O
also	O
noticeable	O
that	O
CAST	O
can	O
help	O
denoise	O
the	O
concatenated	O
context	O
for	O
H2H+CXT	O
.	O
For	O
instance	O
,	O
CAST	O
based	O
on	O
M2M-100	O
achieves	O
1.5	O
and	O
1.2	O
improvements	O
of	O
BLEU	O
points	O
over	O
H2H+CXT	O
for	O
schema	O
translation	O
from	O
En	O
to	O
Es	O
and	O
Fr	O
respectively	O
.	O
This	O
improvement	O
shows	O
CAST	O
can	O
better	O
model	O
the	O
target	O
header	O
and	O
its	O
context	O
.	O
We	O
also	O
run	O
a	O
Wilcoxon	O
signed	O
-	O
rank	O
tests	O
between	O
CAST	O
and	O
H2H+CXT	O
and	O
the	O
results	O
show	O
the	O
improvement	O
are	O
significant	O
with	O
p	O
<	O
0.05	O
in	O
3	O
out	O
of	O
5	O
languages	O
.	O
For	O
the	O
rest	O
of	O
the	O
languages	O
CAST	O
achieves	O
comparable	O
results	O
.	O

Human	O
Evaluation	O
.	O
Since	O
the	O
machine	O
evaluation	O
metrics	O
can	O
not	O
absolutely	O
make	O
sure	O
whether	O
the	O
predicted	O
result	O
is	O
correct	O
or	O
not	O
,	O
we	O
conduct	O
a	O
human	O
evaluation	O
on	O
the	O
test	O
set	O
for	O
a	O
more	O
precise	O
evaluation	O
.	O
Specifically	O
,	O
we	O
invite	O
two	O
experts	O
to	O
evaluate	O
each	O
language	O
pair	O
.	O
For	O
each	O
case	O
,	O
they	O
compare	O
the	O
machine	O
translation	O
and	O
the	O
human	O
annotation	O
.	O
The	O
label	O
is	O
set	O
as	O
1	O
if	O
they	O
think	O
the	O
translation	O
is	O
equivalent	O
to	O
the	O
annotation	O
,	O
otherwise	O
0	O
.	O
We	O
report	O
the	O
human	O
evaluation	O
results	O
for	O
the	O
Base	O
,	O
H2H	O
,	O
H2H+CXT	O
,	O
and	O
CAST	O
based	O
on	O
M2M-100	O
on	O
the	O
En	O
-	O
Zh	O
setting	O
in	O
Table	O
5	O
.	O
According	O
to	O
human	O
evaluation	O
,	O
H2H	O
achieves	O
14.84	O
%	O
improvement	O
over	O
Base	O
,	O
and	O
the	O
performance	O
is	O
further	O
boosted	O
by	O
3.11	O
%	O
when	O
the	O
context	O
is	O
added	O
.	O
Finally	O
,	O
enhanced	O
by	O
the	O
relationaware	O
structure	O
,	O
CAST	O
obtains	O
2.3	O
%	O
improvement	O
over	O
H2H+CXT	O
,	O
which	O
demonstrates	O
the	O
effectiveness	O
of	O
our	O
approach	O
.	O

Ablation	O
Study	O

We	O
conduct	O
ablation	O
studies	O
on	O
CAST	O
to	O
analyze	O
the	O
contributions	O
of	O
our	O
predefined	O
entity	O
types	O
and	O
structural	O
relationships	O
for	O
context	O
modeling	O
.	O
First	O
,	O
we	O
evaluate	O
the	O
variant	O
of	O
CAST	O
without	O
entity	O
types	O
.	O
Next	O
,	O
we	O
evaluate	O
the	O
performance	O
of	O
CAST	O
,	O
without	O
structural	O
relations	O
.	O
Finally	O
,	O
we	O
erase	O
all	O
kinds	O
of	O
relations	O
in	O
CAST	O
which	O
is	O
identical	O
to	O
H2H+CXT	O
.	O
We	O
report	O
the	O
performance	O
of	O
models	O
based	O
on	O
M2M-100	O
in	O
the	O
setting	O
of	O
En	O
-	O
De	O
and	O
En	O
-	O
Fr	O
in	O
Table	O
6	O
.	O

Firstly	O
,	O
it	O
is	O
clear	O
that	O
erasing	O
entity	O
types	O
decreases	O
the	O
performance	O
of	O
the	O
schema	O
translation	O
Table	O
7	O
:	O
Qualitative	O
analysis	O
for	O
models	O
'	O
performance	O
in	O
schema	O
translation	O
from	O
En	O
to	O
Zh	O
on	O
three	O
kinds	O
of	O
headers	O
.	O
For	O
each	O
predicting	O
result	O
,	O
we	O
add	O
extra	O
explanations	O
for	O
their	O
meanings	O
in	O
the	O
brackets	O
.	O
Results	O
with	O
underline	O
denote	O
the	O
correct	O
translation	O
for	O
the	O
header	O
.	O
models	O
.	O
Comparing	O
CAST	O
(	O
w/o	O
entity	O
type	O
)	O
with	O
CAST	O
,	O
for	O
instance	O
,	O
We	O
can	O
see	O
a	O
0.5	O
and	O
0.5	O
decrease	O
of	O
BLEU	O
for	O
En	O
-	O
De	O
and	O
En	O
-	O
Fr	O
respectively	O
.	O
Secondly	O
,	O
the	O
comparison	O
between	O
CAST	O
(	O
w/o	O
structural	O
relation	O
)	O
and	O
CAST	O
shows	O
that	O
the	O
structure	O
relations	O
also	O
play	O
an	O
important	O
role	O
in	O
bettering	O
the	O
performance	O
of	O
context	O
modeling	O
.	O
As	O
seen	O
in	O
the	O
En	O
-	O
Fr	O
translation	O
setting	O
,	O
CAST(w	O
/	O
o	O
structural	O
relation	O
)	O
obtains	O
a	O
1.0	O
lower	O
BLEU	O
score	O
over	O
CAST	O
.	O
Finally	O
,	O
when	O
erasing	O
both	O
kinds	O
of	O
edges	O
and	O
the	O
models	O
give	O
the	O
lowest	O
performance	O
.	O

Qualitative	O
Analysis	O

In	O
this	O
section	O
,	O
we	O
conduct	O
a	O
qualitative	O
analysis	O
on	O
the	O
effectiveness	O
of	O
CAST	O
based	O
on	O
M2M-100	O
for	O
three	O
types	O
of	O
headers	O
:	O
headers	O
with	O
special	O
tokenization	O
,	O
abbreviation	O
headers	O
,	O
and	O
polysemy	O
headers	O
.	O
We	O
list	O
some	O
of	O
the	O
example	O
translations	O
in	O
Table	O
7	O
.	O

By	O
comparing	O
the	O
translations	O
for	O
headers	O
with	O
special	O
tokenization	O
,	O
we	O
can	O
see	O
that	O
all	O
fine	O
-	O
tuned	O
models	O
,	O
including	O
H2H	O
,	O
H2H+CXT	O
,	O
and	O
CAST	O
can	O
accurately	O
translate	O
headers	O
in	O
CamelCase	O
or	O
underscore	O
tokenizations	O
,	O
while	O
Base	O
fails	O
to	O
skip	O
the	O
underscore	O
and	O
can	O
not	O
translate	O
"	O
Debt	O
"	O
in	O
the	O
middle	O
of	O
"	O
AccessedDebtService	O
"	O
.	O

For	O
the	O
abbreviation	O
headers	O
,	O
when	O
translating	O
"	O
OS	O
"	O
(	O
the	O
abbreviation	O
of	O
operation	O
system	O
)	O
and	O
"	O
Jan	O
"	O
(	O
the	O
abbreviation	O
of	O
January	O
)	O
,	O
both	O
Base	O
and	O
H2H	O
fail	O
to	O
get	O
the	O
correct	O
result	O
.	O
However	O
,	O
being	O
aware	O
of	O
the	O
context	O
of	O
"	O
Jan	O
"	O
(	O
e.g.	O
,	O
Feb	O
,	O
Mar	O
and	O
Apr	O
,	O
etc	O
.	O
)	O
and	O
"	O
OS	O
"	O
(	O
e.g.	O
,	O
Computer	O
,	O
System	O
,	O
and	O
Core	O
,	O
etc	O
.	O
)	O
,	O
H2H+CXT	O
and	O
CAST	O
can	O
better	O
understand	O
and	O
translate	O
the	O
abbreviations	O
.	O

When	O
it	O
comes	O
to	O
the	O
polysemy	O
headers	O
,	O
with	O
the	O
help	O
of	O
context	O
like	O
"	O
Height	O
"	O
,	O
"	O
Width	O
"	O
and	O
"	O
Depth	O
"	O
,	O
H2H+CXT	O
and	O
CAST	O
can	O
disambiguate	O
polysemy	O
header	O
"	O
Area	O
"	O
from	O
region	O
or	O
zone	O
to	O
acreage	O
.	O
For	O
header	O
"	O
Volume	O
"	O
,	O
However	O
,	O
H2H+CXT	O
copies	O
the	O
source	O
language	O
column	O
,	O
which	O
is	O
not	O
a	O
valid	O
translation	O
,	O
because	O
the	O
translator	O
is	O
disturbed	O
by	O
the	O
context	O
.	O
On	O
the	O
other	O
hand	O
,	O
with	O
the	O
help	O
of	O
the	O
relational	O
-	O
aware	O
transformer	O
encoder	O
,	O
CAST	O
generates	O
a	O
proper	O
translation	O
for	O
"	O
Volume	O
"	O
as	O
the	O
capacity	O
of	O
the	O
engine	O
.	O
Affected	O
by	O
the	O
context	O
,	O
H2H+CXT	O
only	O
translates	O
part	O
of	O
the	O
information	O
from	O
header	O
'	O
Film.1	O
'	O
and	O
'	O
Rank	O
of	O
the	O
year	O
'	O
,	O
while	O
M2M-100	O
,	O
H2H	O
,	O
and	O
CAST	O
give	O
an	O
appropriate	O
translation	O
.	O

Related	O
Work	O

With	O
the	O
developments	O
of	O
Neural	O
Machine	O
Translation	O
(	O
NMT	O
)	O
systems	O
(	O
Sutskever	O
et	O
al	O
.	O
,	O
2014;Bahdanau	O
et	O
al	O
.	O
,	O
2015	O
)	O
,	O
tremendous	O
success	O
has	O
been	O
achieved	O
by	O
existing	O
studies	O
on	O
machine	O
translation	O
tasks	O
.	O
For	O
instance	O
,	O
Vaswani	O
et	O
al	O
.	O
(	O
2017	O
)	O
greatly	O
improved	O
bilingual	O
machine	O
translation	O
systems	O
with	O
the	O
Transformer	O
architectures	O
,	O
(	O
Edunov	O
et	O
al	O
.	O
,	O
2018	O
)	O
achieved	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
the	O
WMT	O
'	O
14	O
English	O
-	O
German	O
tasks	O
with	O
back	O
-	O
translations	O
augmentation	O
,	O
Weng	O
et	O
al	O
.	O
(	O
2020	O
)	O
and	O
Yang	O
et	O
al	O
.	O
(	O
2020	O
)	O
explored	O
ways	O
to	O
boost	O
the	O
performance	O
of	O
NMT	O
systems	O
with	O
pre	O
-	O
trained	O
language	O
models	O
.	O
Recent	O
works	O
saw	O
the	O
potential	O
to	O
improve	O
NMT	O
models	O
in	O
many	O
-	O
to	O
-	O
many	O
settings	O
and	O
proposed	O
models	O
that	O
can	O
perform	O
machine	O
translation	O
on	O
various	O
language	O
pairs	O
.	O
While	O
the	O
above	O
-	O
mentioned	O
studies	O
focus	O
on	O
sentence	O
-	O
level	O
translation	O
in	O
plain	O
text	O
,	O
they	O
are	O
not	O
suitable	O
for	O
schema	O
translation	O
.	O

A	O
line	O
of	O
machine	O
translation	O
research	O
closely	O
related	O
to	O
our	O
task	O
is	O
the	O
phrase	O
-	O
to	O
-	O
phrase	O
translation	O
,	O
which	O
considers	O
phrases	O
in	O
multi	O
-	O
word	O
expressions	O
as	O
their	O
translation	O
unit	O
.	O
Traditional	O
phrase	O
-	O
based	O
SMT	O
models	O
(	O
Koehn	O
et	O
al	O
.	O
,	O
2007;Haddow	O
et	O
al	O
.	O
,	O
2015	O
)	O
get	O
phrase	O
table	O
translation	O
probabilities	O
by	O
counting	O
phrase	O
occurrences	O
and	O
use	O
local	O
context	O
through	O
a	O
smoothed	O
n	O
-	O
gram	O
language	O
model	O
.	O
Recently	O
,	O
some	O
works	O
explore	O
ways	O
to	O
adapt	O
NMT	O
models	O
for	O
phrase	O
translation	O
.	O
For	O
example	O
,	O
Wang	O
et	O
al	O
.	O
(	O
2017	O
)	O
combined	O
the	O
phrase	O
-	O
based	O
statistical	O
machine	O
translation	O
(	O
SMT	O
)	O
model	O
into	O
NMT	O
and	O
shown	O
significant	O
improvements	O
on	O
Chineseto	O
-	O
English	O
translation	O
data	O
,	O
explored	O
the	O
use	O
of	O
phrase	O
structures	O
for	O
NMT	O
systems	O
by	O
modeling	O
phrases	O
in	O
target	O
language	O
sequences	O
,	O
and	O
Feng	O
et	O
al	O
.	O
(	O
2018	O
)	O
used	O
a	O
phrase	O
attention	O
mechanism	O
to	O
enhance	O
the	O
decoder	O
in	O
relevant	O
source	O
segment	O
recognition	O
.	O
The	O
main	O
differences	O
between	O
these	O
studies	O
and	O
our	O
work	O
are	O
:	O
(	O
1	O
)	O
we	O
do	O
not	O
rely	O
on	O
external	O
phrase	O
dictionaries	O
or	O
phrase	O
tables	O
;	O
and	O
(	O
2	O
)	O
we	O
study	O
how	O
to	O
make	O
use	O
of	O
the	O
schema	O
context	O
for	O
word	O
-	O
sense	O
disambiguation	O
in	O
the	O
schema	O
translation	O
scenario	O
.	O

Context	O
-	O
aware	O
schema	O
encoding	O
has	O
received	O
considerable	O
attention	O
in	O
both	O
recent	O
semantic	O
parsing	O
literature	O
(	O
Hwang	O
et	O
al	O
.	O
,	O
2019;Gong	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
Table	O
-	O
to	O
-	O
Text	O
literature	O
(	O
Gong	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
In	O
general	O
,	O
there	O
are	O
two	O
sorts	O
of	O
techniques	O
:	O
1	O
)	O
.	O
add	O
additional	O
entity	O
type	O
embedding	O
and	O
special	O
separator	O
token	O
from	O
the	O
input	O
sequence	O
to	O
distinguish	O
the	O
table	O
structure	O
(	O
i.e.	O
,	O
Type	O
-	O
SQL	O
and	O
IRNET	O
)	O
;	O
2	O
)	O
.	O
encode	O
the	O
schema	O
as	O
a	O
directed	O
graph	O
.	O
For	O
example	O
,	O
Bogin	O
et	O
al	O
.	O
(	O
2019	O
)	O
use	O
a	O
Graph	O
Neural	O
Network	O
(	O
Scarselli	O
et	O
al	O
.	O
,	O
2008	O
)	O
,	O
and	O
;	O
Shaw	O
et	O
al	O
.	O
(	O
2019	O
)	O
use	O
a	O
transformer	O
self	O
-	O
attention	O
mechanism	O
to	O
encode	O
the	O
schema	O
over	O
predefined	O
schema	O
relationships	O
.	O
Unlike	O
these	O
works	O
,	O
we	O
explore	O
the	O
suitability	O
of	O
schema	O
encoding	O
techniques	O
for	O
the	O
newly	O
proposed	O
schema	O
translation	O
task	O
.	O

Conclusion	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
new	O
challenging	O
translation	O
task	O
called	O
schema	O
translation	O
,	O
and	O
construct	O
the	O
first	O
parallel	O
dataset	O
for	O
this	O
task	O
.	O
To	O
address	O
the	O
challenges	O
for	O
this	O
new	O
task	O
,	O
we	O
propose	O
CAST	O
,	O
which	O
uses	O
a	O
relational	O
-	O
aware	O
transformer	O
to	O
encode	O
a	O
header	O
and	O
its	O
context	O
over	O
predefined	O
relationships	O
,	O
making	O
it	O
aware	O
of	O
the	O
table	O
context	O
.	O

Ethical	O
Considerations	O

The	O
schema	O
translation	O
dataset	O
presented	O
in	O
this	O
work	O
is	O
a	O
free	O
and	O
open	O
resource	O
for	O
the	O
community	O
to	O
study	O
the	O
newly	O
proposed	O
translation	O
task	O
.	O
English	O
tables	O
collected	O
are	O
from	O
three	O
sources	O
.	O
First	O
,	O
we	O
collect	O
all	O
tables	O
from	O
the	O
WikiTableQuestions	O
dataset	O
(	O
Pasupat	O
and	O
Liang	O
,	O
2015	O
)	O
,	O
which	O
is	O
a	O
free	O
and	O
open	O
dataset	O
for	O
the	O
research	O
of	O
question	O
answering	O
task	O
on	O
semi	O
-	O
structured	O
HTML	O
ta	O
-	O
bles	O
.	O
Since	O
all	O
of	O
the	O
tables	O
are	O
collected	O
from	O
open	O
-	O
access	O
Wikipedia	O
pages	O
,	O
there	O
is	O
no	O
privacy	O
issue	O
.	O
Second	O
,	O
we	O
collect	O
176	O
English	O
tables	O
from	O
the	O
search	O
engines	O
which	O
are	O
also	O
publicly	O
available	O
and	O
do	O
not	O
contain	O
personal	O
data	O
.	O
To	O
Further	O
enlarge	O
our	O
dataset	O
,	O
we	O
select	O
all	O
tables	O
from	O
the	O
training	O
set	O
and	O
development	O
set	O
of	O
the	O
Spider	O
dataset	O
(	O
Yu	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
which	O
is	O
also	O
a	O
free	O
and	O
open	O
dataset	O
for	O
research	O
use	O
.	O
Since	O
the	O
tables	O
from	O
the	O
Spider	O
dataset	O
are	O
mainly	O
collected	O
from	O
openaccess	O
online	O
csv	O
files	O
,	O
college	O
database	O
courses	O
and	O
SQL	O
websites	O
,	O
there	O
is	O
no	O
privacy	O
issue	O
either	O
.	O
For	O
the	O
translation	O
step	O
,	O
we	O
hire	O
professional	O
translators	O
to	O
translate	O
the	O
collected	O
English	O
tables	O
to	O
five	O
target	O
languages	O
and	O
the	O
details	O
can	O
be	O
found	O
in	O
Section	O
2	O
.	O

All	O
the	O
experiments	O
with	O
NMT	O
models	O
in	O
this	O
paper	O
can	O
be	O
run	O
on	O
a	O
single	O
Tesla	O
V100	O
GPU	O
.	O
On	O
average	O
,	O
the	O
training	O
process	O
of	O
models	O
in	O
different	O
languages	O
can	O
be	O
finished	O
in	O
four	O
hours	O
.	O
We	O
implement	O
our	O
model	O
with	O
the	O
Transformer	O
6	O
tools	O
in	O
Pytorch	O
7	O
,	O
and	O
the	O
data	O
will	O
be	O
released	O
with	O
the	O
paper	O
.	O

Multimodal	O
Quality	O
Estimation	O
for	O
Machine	O
Translation	O

We	O
propose	O
approaches	O
to	O
Quality	O
Estimation	O
(	O
QE	O
)	O
for	O
Machine	O
Translation	O
that	O
explore	O
both	O
text	O
and	O
visual	O
modalities	O
for	O
Multimodal	O
QE	O
.	O
We	O
compare	O
various	O
multimodality	O
integration	O
and	O
fusion	O
strategies	O
.	O
For	O
both	O
sentence	O
-	O
level	O
and	O
document	O
-	O
level	O
predictions	O
,	O
we	O
show	O
that	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
neural	O
and	O
feature	O
-	O
based	O
QE	O
frameworks	O
obtain	O
better	O
results	O
when	O
using	O
the	O
additional	O
modality	O
.	O

Quality	O
Estimation	O
(	O
QE	O
)	O
for	O
Machine	O
Translation	O
(	O
MT	O
)	O
(	O
Blatz	O
et	O
al	O
.	O
,	O
2004;Specia	O
et	O
al	O
.	O
,	O
2009	O
)	O
aims	O
to	O
predict	O
the	O
quality	O
of	O
a	O
machine	O
-	O
translated	O
text	O
without	O
using	O
reference	O
translations	O
.	O
It	O
estimates	O
a	O
label	O
(	O
a	O
category	O
,	O
such	O
as	O
'	O
good	O
'	O
or	O
'	O
bad	O
'	O
,	O
or	O
a	O
numerical	O
score	O
)	O
for	O
a	O
translation	O
,	O
given	O
text	O
in	O
a	O
source	O
language	O
and	O
its	O
machine	O
translation	O
in	O
a	O
target	O
language	O
(	O
Specia	O
et	O
al	O
.	O
,	O
2018b	O
)	O
.	O
QE	O
can	O
operate	O
at	O
different	O
linguistic	O
levels	O
,	O
including	O
sentence	O
and	O
document	O
levels	O
.	O
Sentence	O
-	O
level	O
QE	O
estimates	O
the	O
translation	O
quality	O
of	O
a	O
whole	O
sentence	O
,	O
while	O
document	O
-	O
level	O
QE	O
predicts	O
the	O
translation	O
quality	O
of	O
an	O
entire	O
document	O
,	O
even	O
though	O
in	O
practice	O
in	O
literature	O
the	O
documents	O
have	O
been	O
limited	O
to	O
a	O
small	O
set	O
of	O
3	O
-	O
5	O
sentences	O
(	O
Specia	O
et	O
al	O
.	O
,	O
2018b	O
)	O
.	O

Table	O
1	O
:	O
Example	O
of	O
incorrectly	O
machine	O
-	O
translated	O
text	O
:	O
the	O
word	O
shorts	O
is	O
used	O
to	O
indicate	O
short	O
trousers	O
,	O
but	O
gets	O
translated	O
in	O
French	O
as	O
court	O
,	O
the	O
adjective	O
short	O
.	O
Here	O
multimodality	O
could	O
help	O
to	O
detect	O
the	O
error	O
(	O
extracted	O
from	O
the	O
Amazon	O
Reviews	O
Dataset	O
of	O
McAuley	O
et	O
al	O
.	O
,	O
2015	O
)	O
.	O
creasingly	O
accompanied	O
with	O
visual	O
elements	O
such	O
as	O
images	O
or	O
videos	O
,	O
especially	O
in	O
social	O
media	O
but	O
also	O
in	O
domains	O
such	O
as	O
e	O
-	O
commerce	O
.	O
Multimodality	O
has	O
not	O
yet	O
been	O
applied	O
to	O
QE	O
.	O
Table	O
1	O
shows	O
an	O
example	O
from	O
our	O
e	O
-	O
commerce	O
dataset	O
in	O
which	O
multimodality	O
could	O
help	O
to	O
improve	O
QE	O
.	O
Here	O
,	O
the	O
English	O
noun	O
shorts	O
is	O
translated	O
by	O
the	O
adjective	O
court	O
(	O
for	O
the	O
adjective	O
short	O
)	O
in	O
French	O
,	O
which	O
is	O
a	O
possible	O
translation	O
out	O
of	O
context	O
.	O
However	O
,	O
as	O
the	O
corresponding	O
product	O
image	O
shows	O
,	O
this	O
product	O
is	O
an	O
item	O
of	O
clothing	O
,	O
and	O
thus	O
the	O
machine	O
translation	O
is	O
incorrect	O
.	O
External	O
information	O
can	O
hence	O
help	O
identify	O
mismatches	O
between	O
translations	O
which	O
are	O
difficult	O
to	O
find	O
within	O
the	O
text	O
.	O
Progress	O
in	O
QE	O
is	O
mostly	O
benchmarked	O
as	O
part	O
of	O
the	O
Conference	O
on	O
Machine	O
Translation	O
(	O
WMT	O
)	O
Shared	O
Task	O
on	O
QE	O
.	O
This	O
paper	O
is	O
based	O
on	O
data	O
from	O
the	O
WMT'18	O
edition	O
's	O
Task	O
4	O
-documentlevel	O
QE	O
.	O
This	O
Task	O
4	O
aims	O
to	O
predict	O
a	O
translation	O
quality	O
score	O
for	O
short	O
documents	O
based	O
on	O
the	O
number	O
and	O
the	O
severity	O
of	O
translation	O
errors	O
at	O
the	O
word	O
level	O
(	O
Specia	O
et	O
al	O
.	O
,	O
2018a	O
)	O
.	O
This	O
data	O
was	O
chosen	O
as	O
it	O
is	O
the	O
only	O
one	O
for	O
which	O
meta	O
information	O
(	O
images	O
in	O
this	O
case	O
)	O
is	O
available	O
.	O
We	O
extend	O
this	O
dataset	O
by	O
computing	O
scores	O
for	O
each	O
sentence	O
for	O
a	O
sentence	O
-	O
level	O
prediction	O
task	O
.	O
We	O
consider	O
both	O
feature	O
-	O
based	O
and	O
neural	O
state	O
-	O
of	O
-	O
theart	O
models	O
for	O
QE	O
.	O
Having	O
these	O
as	O
our	O
starting	O
points	O
,	O
we	O
propose	O
different	O
ways	O
to	O
integrate	O
the	O
visual	O
modality	O
.	O

The	O
main	O
contributions	O
of	O
this	O
paper	O
are	O
as	O
follows	O
:	O
(	O
i	O
)	O
we	O
introduce	O
the	O
task	O
of	O
Multimodal	O
QE	O
(	O
MQE	O
)	O
for	O
MT	O
as	O
an	O
attempt	O
to	O
improve	O
QE	O
by	O
using	O
external	O
sources	O
of	O
information	O
,	O
namely	O
images	O
;	O
(	O
ii	O
)	O
we	O
propose	O
several	O
ways	O
of	O
incorporating	O
visual	O
information	O
in	O
neural	O
-	O
based	O
and	O
featurebased	O
QE	O
architectures	O
;	O
and	O
(	O
iii	O
)	O
we	O
achieve	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
for	O
such	O
architectures	O
in	O
document	O
and	O
sentence	O
-	O
level	O
QE	O
.	O

QE	O
Frameworks	O
and	O
Models	O

We	O
explore	O
feature	O
-	O
based	O
and	O
neural	O
-	O
based	O
models	O
from	O
two	O
open	O
-	O
source	O
frameworks	O
:	O
QuEst++	O
:	O
QuEst++	O
(	O
Specia	O
et	O
al	O
.	O
,	O
2015	O
)	O
is	O
a	O
feature	O
-	O
based	O
QE	O
framework	O
composed	O
of	O
two	O
modules	O
:	O
a	O
feature	O
extractor	O
module	O
,	O
to	O
extract	O
the	O
relevant	O
QE	O
features	O
from	O
both	O
the	O
source	O
sentences	O
and	O
their	O
translations	O
,	O
and	O
a	O
machine	O
learning	O
module	O
.	O
We	O
only	O
use	O
this	O
framework	O
for	O
our	O
experiments	O
on	O
document	O
-	O
level	O
QE	O
,	O
since	O
it	O
does	O
not	O
perform	O
well	O
enough	O
for	O
sentence	O
-	O
level	O
prediction	O
.	O
We	O
use	O
the	O
same	O
model	O
(	O
Support	O
Vector	O
Regression	O
)	O
,	O
hyperparameters	O
and	O
feature	O
settings	O
as	O
the	O
baseline	O
model	O
for	O
the	O
document	O
-	O
level	O
QE	O
task	O
at	O
WMT'18	O
.	O

deepQuest	O
:	O
deepQuest	O
(	O
I	O
ve	O
et	O
al	O
.	O
,	O
2018	O
)	O
is	O
a	O
neural	O
-	O
based	O
framework	O
that	O
provides	O
state	O
-	O
of	O
-	O
theart	O
models	O
for	O
multi	O
-	O
level	O
QE	O
.	O
We	O
use	O
the	O
BiRNN	O
model	O
,	O
a	O
light	O
-	O
weight	O
architecture	O
which	O
can	O
be	O
trained	O
at	O
either	O
sentence	O
or	O
document	O
level	O
.	O

The	O
BiRNN	O
model	O
uses	O
an	O
encoder	O
-	O
decoder	O
architecture	O
:	O
it	O
takes	O
on	O
its	O
input	O
both	O
the	O
source	O
sentence	O
and	O
its	O
translation	O
which	O
are	O
encoded	O
separately	O
by	O
two	O
independent	O
bi	O
-	O
directional	O
Recurrent	O
Neural	O
Networks	O
(	O
RNNs	O
)	O
.	O
The	O
two	O
resulting	O
sentence	O
representations	O
are	O
then	O
concatenated	O
as	O
a	O
weighted	O
sum	O
of	O
their	O
word	O
vectors	O
,	O
generated	O
by	O
an	O
attention	O
mechanism	O
.	O
For	O
sentence	O
-	O
level	O
predictions	O
,	O
the	O
weighted	O
representation	O
of	O
the	O
two	O
input	O
sentences	O
is	O
passed	O
through	O
a	O
dense	O
layer	O
with	O
sigmoid	O
activation	O
to	O
generate	O
the	O
quality	O
estimates	O
.	O
For	O
document	O
-	O
level	O
predictions	O
,	O
the	O
final	O
representation	O
of	O
a	O
document	O
is	O
generated	O
by	O
a	O
second	O
attention	O
mechanism	O
,	O
as	O
the	O
weighted	O
sum	O
of	O
the	O
weighted	O
sentence	O
-	O
level	O
representations	O
of	O
all	O
the	O
sentences	O
within	O
the	O
document	O
.	O
The	O
resulting	O
document	O
-	O
level	O
representation	O
is	O
then	O
passed	O
through	O
a	O
dense	O
layer	O
with	O
sigmoid	O
activation	O
to	O
generate	O
the	O
quality	O
estimates	O
.	O

Additionally	O
,	O
we	O
propose	O
and	O
experiment	O
with	O
BERT	O
-	O
BiRNN	O
,	O
a	O
variant	O
of	O
the	O
BiRNN	O
model	O
.	O
Rather	O
than	O
training	O
the	O
token	O
embeddings	O
with	O
the	O
task	O
at	O
hand	O
,	O
we	O
use	O
large	O
-	O
scale	O
pre	O
-	O
trained	O
token	O
-	O
level	O
representations	O
from	O
the	O
multilingual	O
cased	O
base	O
BERT	O
model	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
During	O
training	O
,	O
the	O
BERT	O
model	O
is	O
fine	O
-	O
tuned	O
by	O
unfreezing	O
the	O
weights	O
of	O
the	O
last	O
four	O
hidden	O
layers	O
along	O
with	O
the	O
token	O
embedding	O
layer	O
.	O
This	O
performs	O
comparably	O
to	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
predictorestimator	O
neural	O
model	O
in	O
Kepler	O
et	O
al	O
.	O
(	O
2019	O
)	O
.	O

WMT'18	O
QE	O
Task	O
4	O
data	O
:	O
This	O
dataset	O
was	O
created	O
for	O
the	O
document	O
-	O
level	O
track	O
.	O
It	O
contains	O
a	O
sample	O
of	O
products	O
from	O
the	O
Amazon	O
Reviews	O
Dataset	O
(	O
McAuley	O
et	O
al	O
.	O
,	O
2015	O
)	O
taken	O
from	O
the	O
Sports	O
&	O
Outdoors	O
category	O
.	O
'	O
Documents	O
'	O
consist	O
of	O
the	O
English	O
product	O
title	O
and	O
its	O
description	O
,	O
its	O
French	O
machinetranslation	O
and	O
a	O
numerical	O
score	O
to	O
predict	O
,	O
namely	O
the	O
MQM	O
score	O
(	O
Multidimensional	O
Quality	O
Metrics	O
)	O
(	O
Lommel	O
et	O
al	O
.	O
,	O
2014	O
)	O
.	O
This	O
score	O
is	O
computed	O
by	O
annotating	O
and	O
weighting	O
each	O
word	O
-	O
level	O
translation	O
error	O
according	O
to	O
its	O
severity	O
(	O
minor	O
,	O
major	O
and	O
critical	O
):	O

MQM	O
Score	O
=	O
1	O
−	O
n	O
min	O
+	O
5n	O
maj	O
+	O
10n	O
cri	O
n	O

For	O
the	O
sentence	O
-	O
level	O
QE	O
task	O
,	O
each	O
document	O
of	O
the	O
dataset	O
was	O
split	O
into	O
sentences	O
(	O
lines	O
)	O
,	O
where	O
every	O
sentence	O
has	O
its	O
corresponding	O
MQM	O
score	O
computed	O
in	O
the	O
same	O
way	O
as	O
for	O
the	O
document	O
.	O
We	O
note	O
that	O
this	O
variant	O
is	O
different	O
from	O
the	O
official	O
sentence	O
-	O
level	O
track	O
at	O
WMT	O
since	O
for	O
that	O
task	O
visual	O
information	O
is	O
not	O
available	O
.	O

Text	O
features	O
:	O
For	O
the	O
feature	O
-	O
based	O
approach	O
,	O
we	O
extract	O
the	O
same	O
15	O
features	O
as	O
those	O
for	O
the	O
baseline	O
of	O
WMT'18	O
at	O
document	O
level	O
.	O
For	O
the	O
neural	O
-	O
based	O
approaches	O
,	O
text	O
features	O
are	O
either	O
the	O
learned	O
word	O
embeddings	O
(	O
BiRNN	O
)	O
or	O
pre	O
-	O
trained	O
word	O
embeddings	O
(	O
BERT	O
-	O
BiRNN	O
)	O
.	O

Multimodal	O
QE	O

We	O
propose	O
different	O
ways	O
to	O
integrate	O
visual	O
features	O
in	O
our	O
two	O
monomodal	O
QE	O
approaches	O
(	O
Sections	O
3.1	O
and	O
3.2	O
)	O
.	O
We	O
compare	O
each	O
proposed	O
model	O
with	O
its	O
monomodal	O
QE	O
counterpart	O
as	O
baseline	O
,	O
both	O
using	O
the	O
same	O
hyperparameters	O
.	O

Multimodal	O
feature	O
-	O
based	O
QE	O

The	O
feature	O
-	O
based	O
textual	O
features	O
contain	O
15	O
numerical	O
scores	O
,	O
while	O
the	O
visual	O
feature	O
vector	O
contains	O
4,096	O
dimensions	O
.	O
To	O
avoid	O
over	O
-	O
weighting	O
the	O
visual	O
features	O
,	O
we	O
reduce	O
their	O
dimensionality	O
using	O
Principal	O
Component	O
Analysis	O
(	O
PCA	O
)	O
.	O
We	O
consider	O
up	O
to	O
15	O
principal	O
components	O
in	O
order	O
to	O
keep	O
a	O
balance	O
between	O
the	O
visual	O
features	O
and	O
the	O
15	O
text	O
features	O
from	O
QuEst++	O
.	O
We	O
choose	O
the	O
final	O
number	O
of	O
principal	O
components	O
to	O
keep	O
according	O
to	O
the	O
explained	O
variance	O
with	O
the	O
PCA	O
,	O
so	O
this	O
number	O
is	O
treated	O
as	O
a	O
hyperparameter	O
.	O
After	O
analysing	O
the	O
explained	O
variance	O
for	O
up	O
to	O
15	O
kept	O
principal	O
components	O
(	O
see	O
Figure	O
4	O
in	O
Appendix	O
)	O
,	O
we	O
selected	O
six	O
numbers	O
of	O
principal	O
components	O
to	O
train	O
QE	O
models	O
with	O
(	O
1	O
,	O
2	O
,	O
3	O
,	O
5	O
,	O
10	O
,	O
and	O
15	O
)	O
.	O
As	O
fusion	O
strategy	O
,	O
we	O
concatenate	O
the	O
two	O
feature	O
vectors	O
.	O

Multimodal	O
neural	O
-	O
based	O
QE	O

Multimodality	O
is	O
achieved	O
with	O
two	O
changes	O
in	O
our	O
monomodal	O
models	O
:	O
multimodality	O
integration	O
(	O
where	O
to	O
integrate	O
the	O
visual	O
features	O
in	O
the	O
architecture	O
)	O
,	O
and	O
fusion	O
strategy	O
(	O
how	O
to	O
fuse	O
the	O
visual	O
and	O
textual	O
features	O
)	O
.	O
We	O
propose	O
the	O
following	O
places	O
to	O
integrate	O
the	O
visual	O
feature	O
vector	O
into	O
the	O
BiRNN	O
architecture	O
:	O

•	O
annot	O
-the	O
visual	O
feature	O
vector	O
is	O
used	O
after	O
the	O
encoding	O
of	O
the	O
two	O
input	O
sentences	O
by	O
the	O
two	O
bi	O
-	O
directional	O
RNNs	O
;	O
•	O
last	O
-the	O
visual	O
feature	O
vector	O
is	O
used	O
just	O
before	O
the	O
last	O
layer	O
.	O

Figure	O
1	O
presents	O
the	O
high	O
-	O
level	O
architecture	O
of	O
the	O
document	O
-	O
level	O
BiRNN	O
model	O
,	O
with	O
the	O
various	O
multimodality	O
integration	O
and	O
fusion	O
approaches	O
.	O

We	O
use	O
the	O
standard	O
training	O
,	O
development	O
and	O
test	O
datasets	O
from	O
the	O
WMT'18	O
Task	O
4	O
track	O
.	O
For	O
feature	O
-	O
based	O
systems	O
,	O
we	O
follow	O
the	O
built	O
-	O
in	O
crossvalidation	O
in	O
QuEst++	O
,	O
and	O
train	O
a	O
single	O
model	O
with	O
the	O
hyperparameters	O
found	O
by	O
cross	O
-	O
validation	O
.	O
For	O
neural	O
-	O
based	O
models	O
,	O
we	O
use	O
early	O
-	O
stopping	O
with	O
a	O
patience	O
of	O
10	O
to	O
avoid	O
over	O
-	O
fitting	O
,	O
and	O
all	O
reported	O
figures	O
are	O
averaged	O
over	O
5	O
runs	O
corresponding	O
to	O
different	O
seeds	O
.	O

We	O
follow	O
the	O
evaluation	O
method	O
of	O
the	O
WMT	O
QE	O
tasks	O
:	O
Pearson	O
's	O
r	O
correlation	O
as	O
the	O
main	O
metric	O
(	O
Graham	O
,	O
2015	O
)	O
,	O
Mean	O
-	O
Absolute	O
Error	O
(	O
MAE	O
)	O
and	O
Root	O
-	O
Mean	O
-	O
Squared	O
Error	O
(	O
RMSE	O
)	O
as	O
secondary	O
metrics	O
.	O
For	O
statistical	O
significance	O
on	O
Pearson	O
's	O
r	O
,	O
we	O
compute	O
Williams	O
test	O
(	O
Williams	O
,	O
1959	O
)	O
as	O
suggested	O
by	O
Graham	O
and	O
Baldwin	O
(	O
2014	O
)	O
.	O

For	O
all	O
neural	O
-	O
based	O
models	O
,	O
we	O
experiment	O
with	O
the	O
all	O
three	O
integration	O
strategies	O
(	O
'	O
embed	O
'	O
,	O
'	O
annot	O
'	O
and	O
'	O
last	O
'	O
)	O
and	O
all	O
three	O
fusion	O
strategies	O
(	O
'	O
conc	O
'	O
,	O
'	O
mult	O
'	O
and	O
'	O
mult2	O
'	O
)	O
presented	O
in	O
Section	O
3.2	O
.	O
This	O
leads	O
to	O
6	O
multimodal	O
models	O
for	O
each	O
BiRNN	O
and	O
BERT	O
-	O
BiRNN	O
.	O
In	O
Tables	O
2	O
and	O
4	O
,	O
as	O
well	O
as	O
in	O
Figures	O
2	O
and	O
3	O
,	O
we	O
report	O
the	O
top	O
three	O
performing	O
models	O
.	O
We	O
refer	O
the	O
reader	O
to	O
the	O
Appendix	O
for	O
the	O
full	O
set	O
of	O
results	O
.	O

Sentence	O
-	O
level	O
MQE	O

The	O
first	O
part	O
of	O
Table	O
2	O
presents	O
the	O
results	O
for	O
sentence	O
-	O
level	O
multimodal	O
QE	O
with	O
BiRNN	O
.	O
The	O
best	O
model	O
is	O
BiRNN+Vis	O
-	O
embed	O
-	O
mult2	O
,	O
achieving	O
a	O
Pearson	O
's	O
r	O
of	O
0.535	O
,	O
significantly	O
outperforming	O
the	O
baseline	O
(	O
p	O
-	O
value<0.01	O
)	O
.	O
Visual	O
features	O
can	O
,	O
therefore	O
,	O
help	O
to	O
improve	O
the	O
performance	O
of	O
sentence	O
-	O
level	O
neural	O
-	O
based	O
QE	O
systems	O
significantly	O
.	O

Figure	O
2	O
presents	O
the	O
result	O
of	O
Williams	O
significance	O
test	O
for	O
BiRNN	O
model	O
variants	O
.	O
It	O
is	O
a	O
correlation	O
matrix	O
that	O
can	O
be	O
read	O
as	O
follows	O
:	O
the	O
value	O
in	O
cell	O
(	O
i	O
,	O
j	O
)	O
is	O
the	O
p	O
-	O
value	O
of	O
Williams	O
test	O
for	O
the	O
change	O
in	O
performance	O
of	O
the	O
model	O
at	O
row	O
i	O
compared	O
to	O
the	O
model	O
at	O
column	O
j	O
(	O
Graham	O
,	O
2015	O
)	O
.	O

With	O
the	O
pre	O
-	O
trained	O
token	O
-	O
level	O
representations	O
from	O
BERT	O
(	O
second	O
half	O
of	O
Table	O
2	O
)	O
,	O
the	O
best	O
model	O
is	O
BERT	O
-	O
BiRNN+Vis	O
-	O
annot	O
-	O
mult	O
,	O
achieving	O
a	O
Pear-	O
BERT	O
-	O
BiRNN	O
)	O
and	O
their	O
respective	O
top-3	O
best	O
performing	O
multimodal	O
variants	O
(	O
+	O
Vis	O
)	O
.	O
We	O
refer	O
the	O
reader	O
to	O
the	O
Appendix	O
for	O
the	O
full	O
set	O
of	O
results	O
.	O
Here	O
,	O
BERT	O
,	O
ann	O
-	O
mul	O
and	O
emb	O
-	O
mul2	O
correspond	O
to	O
the	O
BERT	O
-	O
BiRNN	O
,	O
the	O
BERT	O
-	O
BiRNN+Vis	O
-	O
annot	O
-	O
mult	O
and	O
the	O
BiRNN+Vis	O
-	O
embed	O
-	O
mult2	O
models	O
of	O
Table	O
2	O
.	O

son	O
's	O
r	O
of	O
0.602	O
.	O
This	O
shows	O
that	O
even	O
when	O
using	O
better	O
word	O
presentations	O
,	O
the	O
visual	O
features	O
help	O
to	O
get	O
further	O
(	O
albeit	O
modest	O
)	O
improvements	O
.	O
Table	O
3	O
shows	O
an	O
example	O
of	O
predicted	O
scores	O
at	O
the	O
sentence	O
-	O
level	O
for	O
the	O
baseline	O
model	O
(	O
BiRNN	O
)	O
and	O
for	O
the	O
best	O
multimodal	O
BiRNN	O
model	O
(	O
BiRNN+Vis	O
-	O
embed	O
-	O
mult2	O
)	O
.	O
The	O
multimodal	O
model	O
has	O
predicted	O
a	O
closer	O
score	O
(	O
-0.002	O
)	O
to	O
the	O
gold	O
MQM	O
score	O
(	O
0.167	O
)	O
than	O
the	O
baseline	O
model	O
(	O
-0.248	O
)	O
.	O
The	O
French	O
translation	O
is	O
poor	O
(	O
cumulative	O
-	O
split	O
is	O
,	O
for	O
instance	O
,	O
not	O
translated	O
)	O
as	O
the	O
low	O
gold	O
MQM	O
score	O
shows	O
.	O
However	O
,	O
the	O
(	O
main	O
)	O
word	O
stopwatch	O
is	O
correctly	O
translated	O
as	O
chronomètre	O
in	O
French	O
.	O
Since	O
the	O
associated	O
picture	O
indeed	O
represents	O
a	O
stopwatch	O
,	O
one	O
explanation	O
for	O
this	O
improvement	O
could	O
be	O
that	O
the	O
multimodal	O
model	O
may	O
have	O
rewarded	O
this	O
correct	O
and	O
important	O
part	O
of	O
the	O
translation	O
.	O

Le	O
chronomètre	O
A601X	O
dispose	O
calendrier	O
cumulative	O
-	O
split	O
.	O
gold	O
MQM	O
score	O
0.167	O
BiRNN	O
-0.248	O
BiRNN+Vis	O
-	O
embed	O
-	O
mult2	O
-0.002	O
Table	O
3	O
:	O
Example	O
of	O
performance	O
of	O
sentence	O
-	O
level	O
multimodal	O
QE	O
.	O
Compared	O
to	O
the	O
baseline	O
prediction	O
(	O
BiRNN	O
)	O
,	O
the	O
prediction	O
from	O
the	O
best	O
multimodal	O
model	O
(	O
BiRNN+Vis	O
-	O
embed	O
-	O
mult2	O
)	O
is	O
closer	O
to	O
the	O
gold	O
MQM	O
score	O
.	O
This	O
could	O
be	O
because	O
the	O
word	O
stopwatch	O
is	O
correctly	O
translated	O
as	O
chronomètre	O
in	O
French	O
,	O
and	O
the	O
additional	O
visual	O
feature	O
confirms	O
it	O
.	O
This	O
could	O
lead	O
to	O
an	O
increase	O
in	O
the	O
predicted	O
score	O
to	O
reward	O
the	O
correct	O
part	O
,	O
despite	O
the	O
poor	O
translation	O
(	O
extracted	O
from	O
the	O
Amazon	O
Reviews	O
Dataset	O
of	O
McAuley	O
et	O
al	O
.	O
,	O
2015	O
)	O
.	O

Document	O
-	O
level	O
MQE	O

Table	O
4	O
presents	O
the	O
results	O
for	O
the	O
documentlevel	O
feature	O
-	O
based	O
and	O
BiRNN	O
neural	O
QE	O
models	O
.	O
1	O
The	O
first	O
section	O
shows	O
the	O
official	O
models	O
from	O
the	O
WMT'18	O
QE	O
Task	O
4	O
report	O
(	O
Specia	O
et	O
al	O
.	O
,	O
2018a	O
)	O
.	O
The	O
neural	O
-	O
based	O
approach	O
SHEF	O
-	O
PT	O
is	O
the	O
winning	O
submission	O
,	O
outperforming	O
another	O
neural	O
-	O
based	O
approach	O
(	O
SHEF	O
-	O
mtl	O
-	O
bRNN	O
)	O
.	O
For	O
our	O
BiRNN	O
models	O
(	O
second	O
section	O
)	O
,	O
BiRNN+Visembed	O
-	O
conc	O
performs	O
only	O
slightly	O
better	O
than	O
the	O
monomodal	O
baseline	O
.	O
For	O
the	O
feature	O
-	O
based	O
models	O
(	O
third	O
section	O
)	O
,	O
on	O
the	O
other	O
hand	O
,	O
the	O
baseline	O
monomodal	O
QuEst++	O
is	O
outperformed	O
by	O
various	O
multimodal	O
variants	O
by	O
a	O
large	O
margin	O
,	O
with	O
the	O
one	O
with	O
two	O
principal	O
components	O
(	O
QuEst+Vis-2	O
)	O
performing	O
the	O
best	O
.	O
The	O
more	O
PCA	O
components	O
kept	O
,	O
the	O
worse	O
the	O
results	O
(	O
see	O
Appendix	O
for	O
full	O
set	O
of	O
results	O
)	O
.	O
Figure	O
3	O
shows	O
the	O
Williams	O
significance	O
test	O
for	O
document	O
-	O
level	O
QuEst++	O
on	O
the	O
WMT'18	O
dataset	O
.	O

As	O
we	O
can	O
see	O
,	O
QuEst+Vis-2	O
model	O
outperforms	O
the	O
baseline	O
with	O
p	O
-	O
value	O
=	O
0.002	O
.	O
Thus	O
,	O
visual	O
features	O
significantly	O
improve	O
the	O
performance	O
of	O
featurebased	O
QE	O
systems	O
compared	O
to	O
the	O
monomodal	O
QE	O
counterparts	O
.	O

We	O
introduced	O
Multimodal	O
Quality	O
Estimation	O
for	O
Machine	O
Translation	O
,	O
where	O
an	O
external	O
modality	O
-visual	O
information	O
-is	O
incorporated	O
to	O
featurebased	O
and	O
neural	O
-	O
based	O
QE	O
approaches	O
,	O
on	O
sentence	O
and	O
document	O
levels	O
.	O
The	O
use	O
of	O
visual	O
features	O
extracted	O
from	O
images	O
has	O
led	O
to	O
significant	O
improvements	O
in	O
the	O
results	O
of	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
QE	O
approaches	O
,	O
especially	O
at	O
sentence	O
level	O
.	O

The	O
version	O
of	O
deepQuest	O
for	O
multimodal	O
QE	O
and	O
scripts	O
to	O
convert	O
document	O
into	O
sentencelevel	O
data	O
are	O
available	O
on	O
https://github.com/	O
sheffieldnlp	O
/	O
deepQuest	O
.	O

A	O
Appendix	O
PCA	O
analysis	O
Figure	O
4	O
shows	O
an	O
almost	O
linear	O
relationship	O
between	O
the	O
number	O
of	O
principal	O
components	O
and	O
the	O
explained	O
variance	O
of	O
the	O
PCA	O
(	O
see	O
Section	O
3.1	O
)	O
,	O
i.e.	O
the	O
higher	O
the	O
number	O
of	O
principal	O
components	O
,	O
the	O
larger	O
the	O
explained	O
variance	O
.	O
Therefore	O
,	O
we	O
experimented	O
with	O
various	O
numbers	O
of	O
components	O
up	O
to	O
15	O
(	O
1	O
,	O
2	O
,	O
3	O
,	O
5	O
,	O
10	O
,	O
and	O
15	O
)	O
on	O
the	O
development	O
set	O
to	O
find	O
the	O
best	O
settings	O
for	O
quality	O
prediction	O
.	O
Complete	O
results	O
Tables	O
5	O
and	O
6	O
present	O
the	O
full	O
set	O
of	O
results	O
of	O
our	O
experiments	O
on	O
document	O
and	O
sentence	O
-	O
level	O
multimodal	O
QE	O
on	O
our	O
main	O
test	O
set	O
,	O
the	O
WMT'18	O
test	O
set	O
.	O
These	O
are	O
a	O
super	O
-	O
set	O
of	O
the	O
results	O
presented	O
in	O
the	O
main	O
paper	O
but	O
include	O
all	O
combinations	O
of	O
multimodality	O
integration	O
and	O
fusion	O
strategies	O
for	O
sentence	O
-	O
level	O
prediction	O
,	O
as	O
well	O
as	O
different	O
numbers	O
of	O
principal	O
components	O
kept	O
for	O
document	O
-	O
level	O
QuEst	O
prediction	O
models	O
.	O

Additional	O
test	O
set	O
Tables	O
7	O
and	O
8	O
present	O
the	O
full	O
set	O
of	O
results	O
of	O
our	O
experiments	O
on	O
the	O
WMT'19	O
Task	O
2	O
test	O
set	O
on	O
document	O
and	O
sentencelevel	O
multimodal	O
QE	O
,	O
respectively	O
.	O
This	O
was	O
the	O
follow	O
-	O
up	O
edition	O
of	O
the	O
WMT'18	O
Task	O
4	O
,	O
where	O
the	O
same	O
training	O
set	O
is	O
used	O
,	O
but	O
a	O
new	O
test	O
set	O
is	O
released	O
.	O

For	O
sentence	O
-	O
level	O
,	O
we	O
observe	O
on	O
the	O
one	O
hand	O
quite	O
significant	O
improvements	O
with	O
a	O
gain	O
of	O
almost	O
8	O
points	O
in	O
Pearson	O
's	O
r	O
over	O
BiRNN	O
,	O
our	O
monomodal	O
baseline	O
without	O
pre	O
-	O
trained	O
word	O
embedding	O
.	O
multimodal	O
variants	O
achieve	O
better	O
performance	O
compared	O
to	O
the	O
monomodal	O
BiRNN	O
baseline	O
,	O
with	O
a	O
peak	O
when	O
the	O
visual	O
features	O
are	O
fused	O
with	O
the	O
word	O
embedding	O
representations	O
by	O
elementwise	O
multiplication	O
.	O
On	O
the	O
other	O
hand	O
,	O
we	O
do	O
not	O
observe	O
any	O
gain	O
in	O
using	O
visual	O
features	O
on	O
the	O
WMT'19	O
test	O
set	O
compared	O
to	O
our	O
monomodal	O
baseline	O
with	O
pre	O
-	O
trained	O
word	O
-	O
embedding	O
(	O
BERT	O
-	O
BiRNN	O
)	O
.	O
Here	O
that	O
the	O
BERT	O
-	O
BiRNN	O
baseline	O
model	O
already	O
performs	O
very	O
well	O
.	O
According	O
to	O
the	O
task	O
organisers	O
,	O
the	O
mean	O
MQM	O
value	O
on	O
the	O
WMT'19	O
test	O
set	O
is	O
higher	O
than	O
on	O
the	O
WMT'18	O
test	O
set	O
,	O
but	O
actually	O
closer	O
to	O
the	O
training	O
data	O
(	O
Fonseca	O

.	O
We	O
therefore	O
hypothesise	O
here	O
that	O
the	O
highly	O
dimensional	O
and	O
contextualised	O
word	O
-	O
level	O
representations	O
from	O
BERT	O
are	O
already	O
enough	O
and	O
do	O
not	O
benefit	O
from	O
the	O
extra	O
information	O
provided	O
by	O
the	O
visual	O
features	O
.	O

The	O
SOFC	O
-	O
Exp	O
Corpus	O
and	O
Neural	O
Approaches	O
to	O
Information	O
Extraction	O
in	O
the	O
Materials	O
Science	O
Domain	O

This	O
paper	O
presents	O
a	O
new	O
challenging	O
information	O
extraction	O
task	O
in	O
the	O
domain	O
of	O
materials	O
science	O
.	O
We	O
develop	O
an	O
annotation	O
scheme	O
for	O
marking	O
information	O
on	O
experiments	O
related	O
to	O
solid	O
oxide	O
fuel	O
cells	O
in	O
scientific	O
publications	O
,	O
such	O
as	O
involved	O
materials	O
and	O
measurement	O
conditions	O
.	O
With	O
this	O
paper	O
,	O
we	O
publish	O
our	O
annotation	O
guidelines	O
,	O
as	O
well	O
as	O
our	O
SOFC	O
-	O
Exp	O
corpus	O
consisting	O
of	O
45	O
openaccess	O
scholarly	O
articles	O
annotated	O
by	O
domain	O
experts	O
.	O
A	O
corpus	O
and	O
an	O
inter	O
-	O
annotator	O
agreement	O
study	O
demonstrate	O
the	O
complexity	O
of	O
the	O
suggested	O
named	O
entity	O
recognition	O
and	O
slot	O
filling	O
tasks	O
as	O
well	O
as	O
high	O
annotation	O
quality	O
.	O
We	O
also	O
present	O
strong	O
neural	O
-	O
network	O
based	O
models	O
for	O
a	O
variety	O
of	O
tasks	O
that	O
can	O
be	O
addressed	O
on	O
the	O
basis	O
of	O
our	O
new	O
data	O
set	O
.	O
On	O
all	O
tasks	O
,	O
using	O
BERT	O
embeddings	O
leads	O
to	O
large	O
performance	O
gains	O
,	O
but	O
with	O
increasing	O
task	O
complexity	O
,	O
adding	O
a	O
recurrent	O
neural	O
network	O
on	O
top	O
seems	O
beneficial	O
.	O
Our	O
models	O
will	O
serve	O
as	O
competitive	O
baselines	O
in	O
future	O
work	O
,	O
and	O
analysis	O
of	O
their	O
performance	O
highlights	O
difficult	O
cases	O
when	O
modeling	O
the	O
data	O
and	O
suggests	O
promising	O
research	O
directions	O
.	O

The	O
design	O
of	O
new	O
experiments	O
in	O
scientific	O
domains	O
heavily	O
depends	O
on	O
domain	O
knowledge	O
as	O
well	O
as	O
on	O
previous	O
studies	O
and	O
their	O
findings	O
.	O
However	O
,	O
the	O
amount	O
of	O
publications	O
available	O
is	O
typically	O
very	O
large	O
,	O
making	O
it	O
hard	O
or	O
even	O
impossible	O
to	O
keep	O
track	O
of	O
all	O
experiments	O
conducted	O
for	O
a	O
particular	O
research	O
question	O
.	O
Since	O
scientific	O
experiments	O
are	O
often	O
time	O
-	O
consuming	O
and	O
expensive	O
,	O
effective	O
knowledge	O
base	O
population	O
methods	O
for	O
finding	O
promising	O
settings	O
based	O
on	O
the	O
published	O
research	O
would	O
be	O
of	O
great	O
value	O
(	O
e.g.	O
,	O
Auer	O
et	O
al	O
.	O
,	O
2018;Manica	O
et	O
al	O
.	O
,	O
2019;Mrdjenovich	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
While	O
such	O
real	O
-	O
life	O
information	O
extraction	O
tasks	O
have	O
received	O
consid-	O
erable	O
attention	O
in	O
the	O
biomedical	O
domain	O
(	O
e.g.	O
,	O
Cohen	O
et	O
al	O
.	O
,	O
2017;Demner	O
-	O
Fushman	O
et	O
al	O
.	O
,	O
2018	O
,	O
there	O
has	O
been	O
little	O
work	O
in	O
other	O
domains	O
(	O
Nastase	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
including	O
materials	O
science	O
(	O
with	O
the	O
notable	O
exception	O
of	O
the	O
work	O
by	O
Mysore	O
et	O
al	O
.	O
,	O
2017Mysore	O
et	O
al	O
.	O
,	O
,	O
2019	O
.	O

In	O
this	O
paper	O
,	O
we	O
introduce	O
a	O
new	O
information	O
extraction	O
use	O
case	O
from	O
the	O
materials	O
science	O
domain	O
and	O
propose	O
a	O
series	O
of	O
new	O
challenging	O
information	O
extraction	O
tasks	O
.	O
We	O
target	O
publications	O
about	O
solid	O
oxide	O
fuel	O
cells	O
(	O
SOFCs	O
)	O
in	O
which	O
the	O
interdependence	O
between	O
chosen	O
materials	O
,	O
measurement	O
conditions	O
and	O
performance	O
is	O
complex	O
(	O
see	O
Figure	O
1	O
)	O
.	O
For	O
making	O
progress	O
within	O
natural	O
language	O
processing	O
(	O
NLP	O
)	O
,	O
the	O
genre	O
-	O
domain	O
combination	O
presents	O
interesting	O
challenges	O
and	O
characteristics	O
,	O
e.g.	O
,	O
domain	O
-	O
specific	O
tokens	O
such	O
as	O
material	O
names	O
and	O
chemical	O
formulas	O
.	O

The	O
task	O
of	O
finding	O
experiment	O
-	O
specific	O
information	O
can	O
be	O
modeled	O
as	O
a	O
retrieval	O
task	O
(	O
i.e.	O
,	O
finding	O
relevant	O
information	O
in	O
documents	O
)	O
and	O
at	O
the	O
same	O
time	O
as	O
a	O
semantic	O
-	O
role	O
-	O
labeling	O
task	O
(	O
i.e.	O
,	O
identifying	O
the	O
slot	O
fillers	O
)	O
.	O
We	O
identify	O
three	O
sub	O
-	O
tasks	O
:	O

(	O
1	O
)	O
identifying	O
sentences	O
describing	O
relevant	O
experiments	O
,	O
(	O
2	O
)	O
identifying	O
mentions	O
of	O
materials	O
,	O
values	O
,	O
and	O
devices	O
,	O
and	O
(	O
3	O
)	O
recognizing	O
mentions	O
of	O
slots	O
and	O
their	O
values	O
related	O
to	O
these	O
experiments	O
.	O
We	O
propose	O
and	O
compare	O
several	O
machine	O
learning	O
methods	O
for	O
the	O
different	O
sub	O
-	O
tasks	O
,	O
including	O
bidirectional	O
long	O
-	O
short	O
term	O
memory	O
(	O
BiLSTM	O
)	O
networks	O
and	O
BERT	O
-	O
based	O
models	O
.	O
In	O
our	O
results	O
,	O
BERT	O
-	O
based	O
models	O
show	O
superior	O
performance	O
.	O
However	O
,	O
with	O
increasing	O
complexity	O
of	O
the	O
task	O
,	O
it	O
is	O
beneficial	O
to	O
combine	O
the	O
two	O
approaches	O
.	O

With	O
the	O
aim	O
of	O
fostering	O
research	O
on	O
challenging	O
information	O
extraction	O
tasks	O
in	O
the	O
scientific	O
domain	O
,	O
we	O
target	O
the	O
domain	O
of	O
SOFC	O
-	O
related	O
experiments	O
as	O
a	O
starting	O
point	O
.	O
Our	O
findings	O
based	O
on	O
this	O
sample	O
use	O
case	O
are	O
transferable	O
to	O
similar	O
experimental	O
domains	O
,	O
which	O
we	O
illustrate	O
by	O
applying	O
our	O
best	O
model	O
configurations	O
to	O
a	O
previously	O
existing	O
related	O
corpus	O
(	O
Mysore	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
achieving	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
.	O

•	O
We	O
provide	O
a	O
new	O
corpus	O
of	O
45	O
materialsscience	O
publications	O
in	O
the	O
research	O
area	O
of	O
SOFCs	O
,	O
manually	O
annotated	O
by	O
domain	O
experts	O
for	O
information	O
on	O
experimental	O
settings	O
and	O
results	O
(	O
Section	O
4	O
)	O
.	O
Our	O
corpus	O
is	O
publicly	O
available	O
.	O
1	O
Our	O
inter	O
-	O
annotator	O
agreement	O
study	O
provides	O
evidence	O
for	O
high	O
annotation	O
quality	O
(	O
Section	O
5	O
)	O
.	O

Information	O
extraction	O
for	O
scientific	O
publications	O
.	O
Recently	O
,	O
several	O
studies	O
addressed	O
information	O
extraction	O
and	O
knowledge	O
base	O
construction	O
in	O
the	O
scientific	O
domain	O
(	O
Augenstein	O
et	O
al	O
.	O
,	O
2017;Luan	O
et	O
al	O
.	O
,	O
2018;Jiang	O
et	O
al	O
.	O
,	O
2019;Buscaldi	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
We	O
also	O
aim	O
at	O
knowledge	O
base	O
construction	O
but	O
target	O
publications	O
about	O
materials	O
science	O
experiments	O
,	O
a	O
domain	O
understudied	O
in	O
NLP	O
to	O
date	O
.	O
Information	O
extraction	O
for	O
materials	O
science	O
.	O
The	O
work	O
closest	O
to	O
ours	O
is	O
the	O
one	O
of	O
Mysore	O
et	O
al	O
.	O
(	O
2019	O
)	O
also	O
retrieve	O
synthesis	O
procedures	O
and	O
extract	O
recipes	O
,	O
though	O
with	O
a	O
coarser	O
-	O
grained	O
label	O
set	O
,	O
focusing	O
on	O
different	O
synthesis	O
operation	O
types	O
.	O
create	O
a	O
dataset	O
for	O
named	O
entity	O
recognition	O
on	O
abstracts	O
of	O
materials	O
science	O
publications	O
.	O
In	O
contrast	O
to	O
our	O
work	O
,	O
their	O
label	O
set	O
(	O
e.g.	O
,	O
Material	O
,	O
Application	O
,	O
Property	O
)	O
is	O
targeted	O
to	O
document	O
indexing	O
rather	O
than	O
information	O
extraction	O
.	O
A	O
notable	O
difference	O
to	O
our	O
work	O
is	O
that	O
we	O
perform	O
full	O
-	O
text	O
annotation	O
while	O
the	O
aforementioned	O
approaches	O
annotate	O
a	O
pre	O
-	O
selected	O
set	O
of	O
paragraphs	O
(	O
see	O
also	O
.	O
Mysore	O
et	O
al	O
.	O
(	O
2017	O
)	O
apply	O
the	O
generative	O
model	O
of	O
Kiddon	O
et	O
al	O
.	O
(	O
2015	O
)	O
to	O
induce	O
action	O
graphs	O
for	O
synthesis	O
procedures	O
of	O
materials	O
from	O
text	O
.	O
In	O
Section	O
7.1	O
,	O
we	O
implement	O
a	O
similar	O
entity	O
extraction	O
system	O
and	O
also	O
apply	O
our	O
algorithms	O
to	O
the	O
dataset	O
of	O
Mysore	O
et	O
al	O
.	O
(	O
2019	O
)	O
.	O
train	O
word2vec	O
(	O
Mikolov	O
et	O
al	O
.	O
,	O
2013	O
)	O
embeddings	O
on	O
materials	O
science	O
publications	O
and	O
show	O
that	O
they	O
can	O
be	O
used	O
for	O
recommending	O
materials	O
for	O
functional	O
applications	O
.	O
Other	O
works	O
adapt	O
the	O
BERT	O
model	O
to	O
clinical	O
and	O
biomedical	O
domains	O
(	O
Alsentzer	O
et	O
al	O
.	O
,	O
2019;Sun	O
and	O
Yang	O
,	O
2019	O
)	O
,	O
or	O
generally	O
to	O
scientific	O
text	O
(	O
Beltagy	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O

Neural	O
entity	O
tagging	O
and	O
slot	O
filling	O
.	O
The	O
neural	O
-	O
network	O
based	O
models	O
we	O
use	O
for	O
entity	O
tagging	O
and	O
slot	O
filling	O
bear	O
similarity	O
to	O
state	O
-	O
ofthe	O
-	O
art	O
models	O
for	O
named	O
entity	O
recognition	O
(	O
e.g.	O
,	O
Huang	O
et	O
al	O
.	O
,	O
2015;Lample	O
et	O
al	O
.	O
,	O
2016;Panchendrarajan	O
and	O
Amaresan	O
,	O
2018;Lange	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Other	O
related	O
work	O
exists	O
in	O
the	O
area	O
of	O
semantic	O
role	O
labeling	O
(	O
e.g.	O
,	O
Roth	O
and	O
Lapata	O
,	O
2015;Kshirsagar	O
et	O
al	O
.	O
,	O
2015;Hartmann	O
et	O
al	O
.	O
,	O
2017;Adel	O
et	O
al	O
.	O
,	O
2018;Swayamdipta	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O

In	O
this	O
section	O
,	O
we	O
describe	O
our	O
annotation	O
scheme	O
and	O
guidelines	O
for	O
marking	O
information	O
on	O
SOFCrelated	O
experiments	O
in	O
scientific	O
publications	O
.	O

We	O
treat	O
the	O
annotation	O
task	O
as	O
identifying	O
instances	O
of	O
a	O
semantic	O
frame	O
(	O
Fillmore	O
,	O
1976	O
)	O
that	O
represents	O
SOFC	O
-	O
related	O
experiments	O
.	O
We	O
include	O
(	O
1	O
)	O
cases	O
that	O
introduce	O
novel	O
content	O
;	O
(	O
2	O
)	O
descriptions	O
of	O
specific	O
previous	O
work	O
;	O
(	O
3	O
)	O
general	O
knowledge	O
that	O
one	O
could	O
find	O
in	O
a	O
textbook	O
or	O
survey	O
;	O
and	O
also	O
(	O
4	O
)	O
suggestions	O
for	O
future	O
work	O
.	O

The	O
above	O
two	O
steps	O
of	O
recognizing	O
relevant	O
sentences	O
and	O
marking	O
coarse	O
-	O
grained	O
entity	O
types	O
are	O
in	O
general	O
applicable	O
to	O
a	O
wide	O
range	O
of	O
experiment	O
types	O
within	O
the	O
materials	O
science	O
domain	O
.	O
We	O
now	O
define	O
a	O
set	O
of	O
slot	O
types	O
particular	O
to	O
experiments	O
on	O
SOFCs	O
.	O
During	O
annotation	O
,	O
we	O
mark	O
these	O
slot	O
types	O
as	O
links	O
between	O
the	O
experimentevoking	O
phrase	O
and	O
the	O
respective	O
slot	O
filler	O
(	O
entity	O
mention	O
)	O
,	O
see	O
Figure	O
1	O
.	O
As	O
a	O
result	O
,	O
experiment	O
frames	O
are	O
represented	O
by	O
graphs	O
rooted	O
in	O
the	O
node	O
corresponding	O
to	O
the	O
frame	O
-	O
evoking	O
element	O
.	O

Our	O
annotation	O
scheme	O
comprises	O
16	O
slot	O
types	O
relevant	O
for	O
SOFC	O
experiments	O
.	O
Here	O
we	O
explain	O
a	O
few	O
of	O
these	O
types	O
for	O
illustration	O
.	O
A	O
full	O
list	O
of	O
these	O
slot	O
types	O
can	O
be	O
found	O
in	O
Supplementary	O
Material	O
Table	O
11	O
;	O
detailed	O
explanations	O
are	O
given	O
in	O
the	O
annotation	O
guidelines	O
published	O
along	O
with	O
our	O
corpus	O
.	O
PowerDensity	O
,	O
Resistance	O
,	O
WorkingTemperature	O
:	O
These	O
slots	O
are	O
generally	O
filled	O
by	O
mentions	O
of	O
type	O
VALUE	O
,	O
i.e.	O
,	O
a	O
numerical	O
value	O
plus	O
a	O
unit	O
.	O
Our	O
annotation	O
guidelines	O
give	O
examples	O
for	O
relevant	O
units	O
and	O
describe	O
special	O
cases	O
.	O
This	O
enables	O
any	O
materials	O
scientist	O
,	O
even	O
if	O
he	O
/	O
she	O
is	O
not	O
an	O
expert	O
on	O
SOFCs	O
,	O
to	O
easily	O
understand	O
and	O
apply	O
our	O
annotation	O
guidelines	O
.	O

SOFC	O
-	O
Exp	O
Corpus	O
.	O
Our	O
corpus	O
consists	O
of	O
45	O

open	O
-	O
access	O
scientific	O
publications	O
about	O
SOFCs	O
and	O
related	O
research	O
,	O
annotated	O
by	O
domain	O
experts	O
.	O

Task	O
definitions	O
.	O
Our	O
rich	O
graph	O
-	O
based	O
annotation	O
scheme	O
allows	O
for	O
a	O
number	O
of	O
information	O
extraction	O
tasks	O
.	O
In	O
the	O
scope	O
of	O
this	O
paper	O
,	O
we	O
address	O
the	O
following	O
steps	O
of	O
(	O
1	O
)	O
identifying	O
sentences	O
that	O
describe	O
SOFC	O
-	O
related	O
experiments	O
,	O
(	O
2	O
)	O
recognizing	O
and	O
typing	O
relevant	O
named	O
entities	O
,	O
and	O

We	O
here	O
present	O
the	O
results	O
of	O
our	O
inter	O
-	O
annotator	O
agreement	O
study	O
,	O
which	O
we	O
perform	O
in	O
order	O
to	O
estimate	O
the	O
degree	O
of	O
reproducibility	O
of	O
our	O
corpus	O
and	O
to	O
put	O
automatic	O
modeling	O
performance	O
into	O
perspective	O
.	O
Six	O
documents	O
(	O
973	O
sentences	O
)	O
have	O
been	O
annotated	O
independently	O
both	O
by	O
our	O
primary	O
annotator	O
,	O
a	O
graduate	O
student	O
of	O
materials	O
science	O
,	O
and	O
a	O
second	O
annotator	O
,	O
who	O
holds	O
a	O
Ph.D.	O
in	O
physics	O
and	O
is	O
active	O
in	O
the	O
field	O
of	O
materials	O
science	O
.	O
The	O
label	O
distribution	O
in	O
this	O
subset	O
is	O
similar	O
to	O
the	O
one	O
of	O
our	O
overall	O
corpus	O
,	O
with	O
each	O
annotator	O
choosing	O
EXPERIMENT	O
about	O
11.8	O
%	O
of	O
the	O
time	O
.	O
Identification	O
of	O
experiment	O
-	O
describing	O
sentences	O
.	O
Agreement	O
on	O
our	O
first	O
task	O
,	O
judging	O
whether	O
a	O
sentence	O
contains	O
relevant	O
experimental	O
information	O
,	O
is	O
0.75	O
in	O
terms	O
of	O
Cohen	O
's	O
κ	O
(	O
Cohen	O
,	O
1968	O
)	O
,	O
indicating	O
substantial	O
agreement	O
according	O
to	O
Landis	O
and	O
Koch	O
(	O
1977	O
)	O
.	O
The	O
observed	O
agreement	O
,	O
corresponding	O
to	O
accuracy	O
,	O
is	O
94.9	O
%	O
;	O
expected	O
agreement	O
amounts	O
to	O
79.2	O
%	O
.	O
Table	O
2	O
shows	O
precision	O
,	O
recall	O
and	O
F1	O
for	O
the	O
doubly	O
-	O
annotated	O
subset	O
,	O
treating	O
one	O
annotator	O
as	O
the	O
gold	O
standard	O
and	O
the	O
other	O
one	O
's	O
labels	O
as	O
predicted	O
.	O
Our	O
primary	O
annotator	O
identifies	O
119	O
out	O
of	O
973	O
sentences	O
as	O
experiment	O
-	O
describing	O
,	O
our	O
secondary	O
annotator	O
111	O
sentences	O
,	O
with	O
an	O
overlap	O
of	O
90	O
sentences	O
.	O
These	O
statistics	O
are	O
helpful	O
to	O
gain	O
further	O
intuition	O
of	O
how	O
well	O
a	O
human	O
can	O
reproduce	O
another	O
annotator	O
's	O
labels	O
and	O
can	O
also	O
be	O
considered	O
an	O
upper	O
bound	O
for	O
system	O
performance	O
.	O

Entity	O
mention	O
detection	O
and	O
type	O
assignment	O
.	O

As	O
mentioned	O
above	O
,	O
relevant	O
entity	O
mentions	O
and	O
their	O
types	O
are	O
only	O
annotated	O
for	O
sentences	O
containing	O
experiment	O
information	O
and	O
neighboring	O
sentences	O
.	O
Therefore	O
,	O
we	O
here	O
compute	O
agreement	O
on	O
the	O
detection	O
of	O
entity	O
mention	O
and	O
type	O
assignment	O
on	O
the	O
subset	O
of	O
90	O
sentences	O
that	O
both	O
annotators	O
considered	O
as	O
containing	O
experimental	O
information	O
.	O
We	O
again	O
look	O
at	O
precision	O
and	O
recall	O
of	O
the	O
annotators	O
versus	O
each	O
other	O
,	O
see	O
Table	O
3	O
.	O

The	O
high	O
precision	O
indicates	O
that	O
our	O
secondary	O
annotator	O
marks	O
essentially	O
the	O
same	O
mentions	O
as	O
our	O
primary	O
annotator	O
,	O
but	O
recall	O
suggests	O
a	O
few	O
missing	O
cases	O
.	O
The	O
difference	O
in	O
marking	O
EXPERI	O
-	O
MENT	O
can	O
be	O
explained	O
by	O
the	O
fact	O
that	O
the	O
primary	O
annotator	O
sometimes	O
marks	O
several	O
verbs	O
per	O
sentence	O
as	O
experiment	O
-	O
evoking	O
elements	O
,	O
connecting	O
them	O
with	O
same	O
exp	O
or	O
exp	O
variation	O
,	O
while	O
the	O
secondary	O
annotator	O
links	O
the	O
mentions	O
of	O
relevant	O
slots	O
to	O
the	O
first	O
experiment	O
-	O
evoking	O
element	O
(	O
see	O
also	O
Supplementary	O
Material	O
Section	O
B	O
)	O
.	O
Overall	O
,	O
the	O
high	O
agreement	O
between	O
domain	O
expert	O
annotators	O
indicates	O
high	O
data	O
quality	O
.	O
Identifying	O
experiment	O
slot	O
fillers	O
.	O
We	O
compute	O
agreement	O
on	O
the	O
task	O
of	O
identifying	O
the	O
slots	O
of	O
an	O
experiment	O
frame	O
filled	O
by	O
the	O
mentions	O
in	O
a	O
sentence	O
on	O
the	O
subset	O
of	O
sentences	O
that	O
both	O
annotators	O
marked	O
as	O
experiment	O
-	O
describing	O
.	O
Slot	O
fillers	O
are	O
the	O
dependents	O
of	O
the	O
respective	O
edges	O
starting	O
at	O
the	O
experiment	O
-	O
evoking	O
element	O
.	O
Table	O
4	O
shows	O
F1	O
scores	O
for	O
the	O
most	O
frequent	O
ones	O
among	O
those	O
categories	O
.	O
See	O
Supplementary	O
Material	O
Section	O
C	O
for	O
all	O
slot	O
types	O
.	O
Overall	O
,	O
our	O
agreement	O
study	O
provides	O
support	O
for	O
the	O
high	O
quality	O
of	O
our	O
annotation	O
scheme	O
and	O
validates	O
the	O
annotated	O
dataset	O
.	O

Experiment	O
detection	O
.	O
The	O
task	O
of	O
experiment	O
detection	O
can	O
be	O
modeled	O
as	O
a	O
binary	O
sentence	O
classification	O
problem	O
.	O
It	O
can	O
also	O
be	O
conceived	O
as	O
a	O
retrieval	O
task	O
,	O
selecting	O
sentences	O
as	O
candidates	O
for	O
experiment	O
frame	O
extraction	O
.	O
We	O
implement	O
a	O
bidirectional	O
long	O
short	O
-	O
term	O
memory	O
(	O
BiLSTM	O
)	O
model	O
with	O
attention	O
for	O
the	O
task	O
of	O
experiment	O
sentence	O
detection	O
.	O
Each	O
input	O
token	O
is	O
represented	O
by	O
a	O
concatenation	O
of	O
several	O
pretrained	O
word	O
embeddings	O
,	O
each	O
of	O
which	O
is	O
fine	O
-	O
tuned	O
during	O
training	O
.	O
We	O
use	O
the	O
Google	O
News	O
word2vec	O
embeddings	O
(	O
Mikolov	O
et	O
al	O
.	O
,	O
2013	O
)	O
,	O
domain	O
-	O
specific	O
word2vec	O
embeddings	O
(	O
mat2vec	O
,	O
,	O
see	O
also	O
Section	O
2	O
)	O
,	O
subword	O
embeddings	O
based	O
on	O
byte	O
-	O
pair	O
encoding	O
(	O
bpe	O
,	O
Heinzerling	O
and	O
Strube	O
,	O
2018	O
)	O
,	O
BERT	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
and	O
SciBERT	O
(	O
Beltagy	O
et	O
al	O
.	O
,	O
2019	O
)	O
embeddings	O
.	O
For	O
BERT	O
and	O
SciBERT	O
,	O
we	O
take	O
the	O
embeddings	O
of	O
the	O
first	O
word	O
piece	O
as	O
token	O
representation	O
.	O
The	O
embeddings	O
are	O
fed	O
into	O
a	O
BiLSTM	O
model	O
followed	O
by	O
an	O
attention	O
layer	O
that	O
computes	O
a	O
vector	O
for	O
the	O
whole	O
sentence	O
.	O
Finally	O
,	O
a	O
softmax	O
layer	O
decides	O
whether	O
the	O
sentence	O
contains	O
an	O
experiment	O
.	O

In	O
addition	O
,	O
we	O
fine	O
-	O
tune	O
the	O
original	O
(	O
uncased	O
)	O
BERT	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
as	O
well	O
as	O
SciBERT	O
(	O
Beltagy	O
et	O
al	O
.	O
,	O
2019	O
)	O
models	O
on	O
our	O
dataset	O
.	O
Sci	O
-	O
BERT	O
was	O
trained	O
on	O
a	O
large	O
corpus	O
of	O
scientific	O
text	O
.	O
We	O
use	O
the	O
implementation	O
of	O
the	O
BERT	O
sentence	O
classifier	O
by	O
Wolf	O
et	O
al	O
.	O
(	O
2019	O
)	O
that	O
uses	O
the	O
CLS	O
token	O
of	O
BERT	O
as	O
input	O
to	O
the	O
classification	O
layer	O
.	O
5	O
Finally	O
,	O
we	O
compare	O
the	O
neural	O
network	O
models	O
with	O
traditional	O
classification	O
models	O
,	O
namely	O
a	O
support	O
vector	O
machine	O
(	O
SVM	O
)	O
and	O
a	O
logistic	O
regression	O
classifier	O
.	O
For	O
both	O
models	O
,	O
we	O
use	O
the	O
following	O
set	O
of	O
input	O
features	O
:	O
bag	O
-	O
of	O
-	O
words	O
vectors	O
indicating	O
which	O
1	O
-	O
to	O
4	O
-	O
grams	O
and	O
part	O
-	O
of	O
-	O
speech	O
tags	O
occur	O
in	O
the	O
sentence	O
.	O
6	O
Entity	O
mention	O
extraction	O
.	O
For	O
entity	O
and	O
concept	O
extraction	O
,	O
we	O
use	O
a	O
sequence	O
-	O
tagging	O
approach	O
similar	O
to	O
(	O
Huang	O
et	O
al	O
.	O
,	O
2015;Lample	O
et	O
al	O
.	O
,	O
2016	O
)	O
,	O
namely	O
a	O
BiLSTM	O
model	O
.	O
We	O
use	O
the	O
same	O
input	O
representation	O
(	O
stacked	O
embeddings	O
)	O
as	O
above	O
,	O
which	O
are	O
fed	O
into	O
a	O
BiLSTM	O
.	O
The	O
subsequent	O
conditional	O
random	O
field	O
(	O
CRF	O
,	O
Lafferty	O
et	O
al	O
.	O
,	O
2001	O
)	O
output	O
layer	O
extracts	O
the	O
most	O
probable	O
label	O
sequence	O
.	O
To	O
cope	O
with	O
multi	O
-	O
token	O
entities	O
,	O
we	O
convert	O
the	O
labels	O
into	O
BIO	O
format	O
.	O

We	O
also	O
fine	O
-	O
tune	O
the	O
original	O
BERT	O
and	O
SciB	O
-	O
ERT	O
sequence	O
tagging	O
models	O
on	O
this	O
task	O
.	O
Since	O
we	O
use	O
BIO	O
labels	O
,	O
we	O
extend	O
it	O
with	O
a	O
CRF	O
output	O
layer	O
to	O
enable	O
it	O
to	O
correctly	O
label	O
multi	O
-	O
token	O
mentions	O
and	O
to	O
enable	O
it	O
to	O
learn	O
transition	O
scores	O
between	O
labels	O
.	O
As	O
a	O
non	O
-	O
neural	O
baseline	O
,	O
we	O
train	O
5	O
https://github.com/huggingface/	O
transformers	O
6	O
We	O
use	O
sklearn	O
,	O
https://scikit-learn.org	O
.	O

a	O
CRF	O
model	O
using	O
the	O
token	O
,	O
its	O
lemma	O
,	O
part	O
-	O
ofspeech	O
tag	O
and	O
mat2vec	O
embedding	O
as	O
features	O
.	O
7	O

Slot	O
filling	O
.	O
As	O
described	O
in	O
Section	O
4	O
,	O
we	O
approach	O
the	O
slot	O
filler	O
extraction	O
task	O
as	O
fine	O
-	O
grained	O
entity	O
-	O
typing	O
-	O
in	O
-	O
context	O
,	O
assuming	O
that	O
each	O
sentence	O
represents	O
a	O
single	O
experiment	O
frame	O
.	O
We	O
use	O
the	O
same	O
sequence	O
tagging	O
architectures	O
as	O
above	O
for	O
tagging	O
the	O
tokens	O
of	O
each	O
experimentdescribing	O
sentence	O
with	O
the	O
set	O
of	O
slot	O
types	O
(	O
see	O
Table	O
11	O
)	O
.	O
Future	O
work	O
may	O
contrast	O
this	O
sequence	O
tagging	O
baseline	O
with	O
graph	O
-	O
induction	O
based	O
frame	O
extraction	O
.	O

Hyperparameters	O
and	O
training	O
.	O
The	O
BiLSTM	O
models	O
are	O
trained	O
with	O
the	O
Adam	O
optimizer	O
(	O
Kingma	O
and	O
Ba	O
,	O
2015	O
)	O
with	O
a	O
learning	O
rate	O
of	O
1e-3	O
.	O
For	O
fine	O
-	O
tuning	O
the	O
original	O
BERT	O
models	O
,	O
we	O
follow	O
the	O
configuration	O
published	O
by	O
Wolf	O
et	O
al	O
.	O
(	O
2019	O
)	O
and	O
use	O
AdamW	O
(	O
Loshchilov	O
and	O
Hutter	O
,	O
2019	O
)	O
as	O
optimizer	O
and	O
a	O
learning	O
rate	O
of	O
4e-7	O
for	O
sentence	O
classification	O
and	O
1e-5	O
for	O
sequence	O
tagging	O
.	O
When	O
adding	O
BERT	O
tokens	O
to	O
the	O
BiLSTM	O
,	O
we	O
also	O
use	O
the	O
AdamW	O
optimizer	O
for	O
the	O
whole	O
model	O
and	O
learning	O
rates	O
of	O
4e-7	O
or	O
1e-5	O
for	O
the	O
BERT	O
part	O
and	O
1e-3	O
for	O
the	O
remainder	O
.	O
For	O
regularization	O
,	O
we	O
employ	O
early	O
stopping	O
on	O
the	O
development	O
set	O
.	O
We	O
use	O
a	O
stacked	O
BiLSTM	O
with	O
two	O
hidden	O
layers	O
and	O
500	O
hidden	O
units	O
for	O
all	O
tasks	O
with	O
the	O
exception	O
of	O
the	O
experiment	O
sentence	O
de-	O
tection	O
task	O
,	O
where	O
we	O
found	O
one	O
BiLSTM	O
layer	O
to	O
work	O
best	O
.	O
The	O
attention	O
layer	O
of	O
the	O
sentence	O
detection	O
model	O
has	O
a	O
hidden	O
size	O
of	O
100	O
.	O

Experiment	O
sentence	O
detection	O
.	O
Table	O
5	O
shows	O
our	O
results	O
on	O
the	O
detection	O
of	O
experimentdescribing	O
sentences	O
.	O
The	O
neural	O
models	O
with	O
bytepair	O
encoding	O
embeddings	O
or	O
BERT	O
clearly	O
outperform	O
the	O
SVM	O
and	O
logistic	O
regression	O
models	O
.	O
Within	O
the	O
neural	O
models	O
,	O
BERT	O
and	O
SciBERT	O
add	O
the	O
most	O
value	O
,	O
both	O
when	O
using	O
their	O
embeddings	O
as	O
another	O
input	O
to	O
the	O
BiLSTM	O
and	O
when	O
finetuning	O
the	O
original	O
BERT	O
models	O
.	O
Note	O
that	O
even	O
the	O
general	O
-	O
domain	O
BERT	O
is	O
strong	O
enough	O
to	O
cope	O
with	O
non	O
-	O
standard	O
domains	O
.	O
Nevertheless	O
,	O
models	O
based	O
on	O
SciBERT	O
outperform	O
BERT	O
-	O
based	O
models	O
,	O
indicating	O
that	O
in	O
-	O
domain	O
information	O
is	O
indeed	O
beneficial	O
.	O
For	O
performance	O
reasons	O
,	O
we	O
use	O
BERT	O
-	O
base	O
in	O
our	O
experiments	O
,	O
but	O
for	O
the	O
sake	O
of	O
completeness	O
,	O
we	O
also	O
run	O
BERT	O
-	O
large	O
for	O
the	O
task	O
of	O
detecting	O
experiment	O
sentences	O
.	O
Because	O
it	O
did	O
not	O
outperform	O
BERT	O
-	O
base	O
in	O
our	O
cross	O
-	O
validation	O
based	O
development	O
setting	O
,	O
we	O
did	O
not	O
further	O
experiment	O
with	O
BERT	O
-	O
large	O
.	O
However	O
,	O
we	O
found	O
that	O
it	O
resulted	O
in	O
the	O
best	O
F1	O
-	O
score	O
achieved	O
on	O
our	O
test	O
set	O
.	O
In	O
general	O
,	O
SciBERT	O
-	O
based	O
models	O
provide	O
very	O
good	O
performance	O
and	O
seem	O
most	O
robust	O
across	O
dev	O
and	O
test	O
sets	O
.	O
Overall	O
,	O
achieving	O
F1	O
-	O
scores	O
around	O
67.0	O
-	O
68.6	O
,	O
such	O
a	O
retrieval	O
model	O
may	O
already	O
be	O
useful	O
in	O
production	O
.	O
However	O
,	O
there	O
certainly	O
is	O
room	O
for	O
improvement	O
.	O
Entity	O
mention	O
extraction	O
.	O
Table	O
6	O
provides	O
our	O
results	O
on	O
entity	O
mention	O
detection	O
and	O
typing	O
.	O

Models	O
are	O
trained	O
and	O
results	O
are	O
reported	O
on	O
the	O
subset	O
of	O
sentences	O
marked	O
as	O
experimentdescribing	O
in	O
the	O
gold	O
standard	O
,	O
amounting	O
to	O
4,590	O
entity	O
mentions	O
in	O
total	O
.	O
9	O
The	O
CRF	O
baseline	O
achieves	O
comparable	O
or	O
better	O
results	O
than	O
the	O
Bi	O
-	O
LSTM	O
with	O
word2vec	O
and/or	O
mat2vec	O
embeddings	O
.	O
However	O
,	O
adding	O
subword	O
-	O
based	O
embeddings	O
(	O
bpe	O
and/or	O
BERT	O
)	O
significantly	O
increases	O
performance	O
of	O
the	O
BiLSTM	O
,	O
indicating	O
that	O
there	O
are	O
many	O
rare	O
words	O
.	O
Again	O
,	O
the	O
best	O
results	O
are	O
obtained	O
when	O
using	O
BERT	O
or	O
SciBERT	O
embeddings	O
or	O
when	O
using	O
the	O
original	O
SciBERT	O
model	O
.	O
It	O
is	O
relatively	O
easy	O
for	O
all	O
model	O
variants	O
to	O
recognize	O
VALUE	O
as	O
these	O
mentions	O
usually	O
consist	O
of	O
a	O
number	O
and	O
unit	O
which	O
the	O
model	O
can	O
easily	O
memorize	O
.	O
Recognizing	O
the	O
types	O
MATERIAL	O
and	O
DEVICE	O
,	O
in	O
contrast	O
,	O
is	O
harder	O
and	O
may	O
profit	O
from	O
using	O
gazetteer	O
-	O
based	O
extensions	O
.	O

Experiment	O
slot	O
filling	O
.	O
Table	O
7	O
shows	O
the	O
macro	O
-	O
average	O
F1	O
scores	O
for	O
our	O
different	O
models	O
on	O
the	O
slot	O
identification	O
task	O
.	O
10	O
As	O
for	O
entity	O
typing	O
,	O
we	O
train	O
and	O
evaluate	O
our	O
model	O
on	O
the	O
subset	O
of	O
sentences	O
marked	O
as	O
experiment	O
-	O
describing	O
,	O
which	O
contain	O
4,263	O
slot	O
instances	O
.	O
Again	O
,	O
the	O
CRF	O
baseline	O
outperforms	O
the	O
BiLSTM	O
when	O
using	O
only	O
mat2vec	O
and/or	O
word2vec	O
embeddings	O
.	O
The	O
addition	O
of	O
BERT	O
or	O
SciBERT	O
embeddings	O
improves	O
performance	O
.	O
However	O
,	O
on	O
this	O
task	O
,	O
the	O
BiLSTM	O
model	O
with	O
(	O
Sci)BERT	O
embeddings	O
outperforms	O
the	O
fine	O
-	O
tuned	O
original	O
(	O
Sci)BERT	O
model	O
.	O
Compared	O
to	O
the	O
other	O
two	O
tasks	O
,	O
this	O
task	O
requires	O
more	O
complex	O
reasoning	O
and	O
has	O
a	O
larger	O
number	O
of	O
possible	O
output	O
classes	O
.	O
We	O
assume	O
that	O
in	O
such	O
a	O
setting	O
,	O
adding	O
more	O
abstraction	O
power	O
to	O
the	O
model	O
(	O
in	O
the	O
form	O
of	O
a	O
BiLSTM	O
)	O
leads	O
to	O
better	O
results	O
.	O
For	O
a	O
more	O
detailed	O
analysis	O
,	O
Table	O
8	O
shows	O
the	O
slot	O
-	O
wise	O
results	O
for	O
the	O
non	O
-	O
neural	O
CRF	O
baseline	O
and	O
the	O
model	O
that	O
performs	O
best	O
on	O
the	O
development	O
set	O
:	O
BiLSTM	O
with	O
SciBERT	O
embeddings	O
.	O
As	O
in	O
the	O
case	O
of	O
entity	O
mention	O
detection	O
,	O
the	O
models	O
do	O
well	O
for	O
the	O
categories	O
that	O
consist	O
of	O
numeric	O
mentions	O
plus	O
particular	O
units	O
.	O
In	O
general	O
,	O
model	O
performance	O
is	O
also	O
tied	O
to	O
the	O
frequency	O
of	O
the	O
slot	O
types	O
in	O
the	O
dataset	O
.	O
Recognizing	O
the	O
role	O
a	O
material	O
plays	O
in	O
an	O
experiment	O
(	O
e.g.	O
,	O
AnodeMaterial	O
vs.	O
CathodeMaterial	O
)	O
remains	O
challenging	O
,	O
possibly	O
requiring	O
background	O
domain	O
knowledge	O
.	O
This	O
type	O
of	O
information	O
is	O
often	O
not	O
stated	O
explicitly	O
in	O
the	O
sentence	O
,	O
but	O
introduced	O
earlier	O
in	O
the	O
discourse	O
and	O
would	O
hence	O
require	O
document	O
-	O
level	O
modeling	O
.	O

Entity	O
Extraction	O
Evaluation	O
on	O
the	O
Synthesis	O
Procedures	O
Dataset	O

As	O
described	O
in	O
Section	O
2	O
,	O
the	O
data	O
set	O
curated	O
by	O
Mysore	O
et	O
al	O
.	O
(	O
2019	O
)	O
contains	O
230	O
synthesis	O
procedures	O
annotated	O
with	O
entity	O
type	O
information	O
.	O
11	O
We	O
apply	O
our	O
models	O
to	O
this	O
entity	O
extraction	O
task	O
in	O
order	O
to	O
estimate	O
the	O
degree	O
of	O
transferability	O
of	O
our	O
findings	O
to	O
similar	O
data	O
sets	O
.	O
To	O
the	O
best	O
of	O
11	O
our	O
knowledge	O
,	O
there	O
have	O
not	O
yet	O
been	O
any	O
publications	O
on	O
the	O
automatic	O
modeling	O
of	O
this	O
data	O
set	O
.	O
We	O
hence	O
compare	O
to	O
the	O
previous	O
work	O
of	O
Mysore	O
et	O
al	O
.	O
(	O
2017	O
)	O
,	O
who	O
perform	O
action	O
graph	O
induction	O
on	O
a	O
similar	O
data	O
set	O
.	O
12	O
Our	O
implementation	O
of	O
BiLSTM	O
-	O
CRF	O
mat2vec+word2vec	O
roughly	O
corresponds	O
to	O
their	O
BiLSTM	O
-	O
CRF	O
system	O
.	O

Table	O
9	O
shows	O
the	O
performance	O
of	O
our	O
models	O
when	O
trained	O
and	O
evaluated	O
on	O
the	O
synthesis	O
procedures	O
dataset	O
.	O
Detailed	O
scores	O
by	O
entity	O
type	O
can	O
be	O
found	O
in	O
the	O
Supplementary	O
Material	O
.	O
We	O
chose	O
to	O
use	O
the	O
data	O
split	O
suggested	O
by	O
the	O
authors	O
for	O
the	O
NER	O
task	O
,	O
using	O
200	O
documents	O
for	O
training	O
,	O
and	O
15	O
documents	O
for	O
each	O
dev	O
and	O
test	O
set	O
.	O
Among	O
the	O
non	O
-	O
BERT	O
-	O
based	O
systems	O
,	O
the	O
BiLSTM	O
variant	O
using	O
both	O
mat2vec	O
and	O
word2vec	O
performs	O
best	O
,	O
indicating	O
that	O
the	O
two	O
pre	O
-	O
trained	O
embeddings	O
contain	O
complementary	O
information	O
with	O
regard	O
to	O
this	O
task	O
.	O
The	O
best	O
performance	O
is	O
reached	O
by	O
the	O
BiL	O
-	O
STM	O
model	O
including	O
word2vec	O
,	O
mat2vec	O
,	O
bpe	O
and	O
SciBERT	O
embeddings	O
,	O
with	O
92.2	O
micro	O
-	O
average	O
F1	O
providing	O
a	O
strong	O
baseline	O
for	O
future	O
work	O
.	O

We	O
have	O
presented	O
a	O
new	O
dataset	O
for	O
information	O
extraction	O
in	O
the	O
materials	O
science	O
domain	O
consisting	O
of	O
45	O
open	O
-	O
access	O
scientific	O
articles	O
related	O
to	O
solid	O
oxide	O
fuel	O
cells	O
.	O
Our	O
detailed	O
corpus	O
and	O
interannotator	O
agreement	O
studies	O
highlight	O
the	O
complexity	O
of	O
the	O
task	O
and	O
verify	O
the	O
high	O
annotation	O
quality	O
.	O
Based	O
on	O
the	O
annotated	O
structures	O
,	O
we	O
suggest	O
three	O
information	O
extraction	O
tasks	O
:	O
the	O
detection	O
of	O
experiment	O
-	O
describing	O
sentences	O
,	O
entity	O
mention	O
recognition	O
and	O
typing	O
,	O
and	O
experiment	O
slot	O
filling	O
.	O
We	O
have	O
presented	O
various	O
strong	O
baselines	O
for	O
them	O
,	O
generally	O
finding	O
that	O
BERT	O
-	O
based	O
models	O
outperform	O
other	O
model	O
variants	O
.	O
While	O
some	O
categories	O
remain	O
challenging	O
,	O
overall	O
,	O
our	O
models	O
show	O
solid	O
performance	O
and	O
thus	O
prove	O
that	O
this	O
type	O
of	O
data	O
modeling	O
is	O
feasible	O
and	O
can	O
lead	O
to	O
systems	O
that	O
are	O
applicable	O
in	O
production	O
settings	O
.	O
Along	O
with	O
this	O
paper	O
,	O
we	O
make	O
the	O
annotation	O
guidelines	O
and	O
the	O
annotated	O
data	O
freely	O
available	O
.	O

Outlook	O
.	O
In	O
Section	O
7.1	O
,	O
we	O
have	O
shown	O
that	O
our	O
findings	O
generalize	O
well	O
by	O
applying	O
model	O
architectures	O
developed	O
on	O
our	O
corpus	O
to	O
another	O
dataset	O
.	O
A	O
natural	O
next	O
step	O
is	O
to	O
combine	O
the	O
datasets	O
in	O
a	O
multi	O
-	O
task	O
setting	O
to	O
investigate	O
to	O
what	O
extent	O
models	O
can	O
profit	O
from	O
combining	O
the	O
information	O
annotated	O
in	O
the	O
respective	O
datasets	O
.	O
Further	O
research	O
will	O
investigate	O
the	O
joint	O
modeling	O
of	O
entity	O
extraction	O
,	O
typing	O
and	O
experiment	O
frame	O
recognition	O
.	O
In	O
addition	O
,	O
there	O
are	O
also	O
further	O
natural	O
language	O
processing	O
tasks	O
that	O
can	O
be	O
researched	O
using	O
our	O
dataset	O
.	O
They	O
include	O
the	O
detection	O
of	O
events	O
and	O
sub	O
-	O
events	O
when	O
regarding	O
the	O
experiment	O
-	O
descriptions	O
as	O
events	O
,	O
and	O
a	O
more	O
linguistically	O
motivated	O
evaluation	O
of	O
the	O
framesemantic	O
approach	O
to	O
experiment	O
descriptions	O
in	O
text	O
,	O
e.g.	O
,	O
moving	O
away	O
from	O
the	O
one	O
-	O
experimentper	O
-	O
sentence	O
and	O
one	O
-	O
sentence	O
-	O
per	O
-	O
experiment	O
assumptions	O
and	O
modeling	O
the	O
graph	O
-	O
based	O
structures	O
as	O
annotated	O
.	O

Table	O
12	O
reports	O
full	O
statistics	O
for	O
the	O
task	O
of	O
identifying	O
experiment	O
-	O
describing	O
sentences	O
,	O
including	O
precision	O
and	O
recall	O
in	O
the	O
dev	O
setting	O
.	O

Position	O
encoding	O
(	O
PE	O
)	O
,	O
an	O
essential	O
part	O
of	O
self	O
-	O
attention	O
networks	O
(	O
SANs	O
)	O
,	O
is	O
used	O
to	O
preserve	O
the	O
word	O
order	O
information	O
for	O
natural	O
language	O
processing	O
tasks	O
,	O
generating	O
fixed	O
position	O
indices	O
for	O
input	O
sequences	O
.	O
However	O
,	O
in	O
cross	O
-	O
lingual	O
scenarios	O
,	O
e.g.	O
,	O
machine	O
translation	O
,	O
the	O
PEs	O
of	O
source	O
and	O
target	O
sentences	O
are	O
modeled	O
independently	O
.	O
Due	O
to	O
word	O
order	O
divergences	O
in	O
different	O
languages	O
,	O
modeling	O
the	O
cross	O
-	O
lingual	O
positional	O
relationships	O
might	O
help	O
SANs	O
tackle	O
this	O
problem	O
.	O
In	O
this	O
paper	O
,	O
we	O
augment	O
SANs	O
with	O
crosslingual	O
position	O
representations	O
to	O
model	O
the	O
bilingually	O
aware	O
latent	O
structure	O
for	O
the	O
input	O
sentence	O
.	O
Specifically	O
,	O
we	O
utilize	O
bracketing	O
transduction	O
grammar	O
(	O
BTG)-based	O
reordering	O
information	O
to	O
encourage	O
SANs	O
to	O
learn	O
bilingual	O
diagonal	O
alignments	O
.	O
Experimental	O
results	O
on	O
WMT'14	O
English⇒German	O
,	O
WAT'17	O
Japanese⇒English	O
,	O
and	O
WMT'17	O
Chinese⇔English	O
translation	O
tasks	O
demonstrate	O
that	O
our	O
approach	O
significantly	O
and	O
consistently	O
improves	O
translation	O
quality	O
over	O
strong	O
baselines	O
.	O
Extensive	O
analyses	O
confirm	O
that	O
the	O
performance	O
gains	O
come	O
from	O
the	O
cross	O
-	O
lingual	O
information	O
.	O

Although	O
self	O
-	O
attention	O
networks	O
(	O
SANs	O
)	O
(	O
Lin	O
et	O
al	O
.	O
,	O
2017	O
)	O
have	O
achieved	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
performance	O
on	O
several	O
natural	O
language	O
processing	O
(	O
NLP	O
)	O
tasks	O
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017;Devlin	O
et	O
al	O
.	O
,	O
2019;Radford	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
they	O
possess	O
the	O
innate	O
disadvantage	O
of	O
sequential	O
modeling	O
due	O
to	O
the	O
lack	O
of	O
positional	O
information	O
.	O
Therefore	O
,	O
absolute	O
position	O
encoding	O
(	O
APE	O
)	O
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017	O
)	O
and	O
relative	O
position	O
encoding	O
(	O
RPE	O
)	O
(	O
Shaw	O
et	O
al	O
.	O
,	O
2018	O
)	O
were	O
introduced	O
to	O
better	O
capture	O
the	O
sequential	O
dependencies	O
.	O
However	O
,	O
either	O
absolute	O
or	O
relative	O
PE	O
is	O
language	O
-	O
independent	O
and	O
its	O
embedding	O
remains	O
fixed	O
.	O
This	O
inhibits	O
the	O
capacity	O
of	O
SANs	O
when	O
modelling	O
multiple	O
languages	O
,	O
which	O
have	O
diverse	O
word	O
orders	O
and	O
structures	O
(	O
Gell	O
-	O
Mann	O
and	O
Ruhlen	O
,	O
2011	O
)	O
.	O
Recent	O
work	O
have	O
shown	O
that	O
modeling	O
cross	O
-	O
lingual	O
information	O
(	O
e.g.	O
,	O
alignment	O
or	O
reordering	O
)	O
at	O
encoder	O
or	O
attention	O
level	O
improves	O
translation	O
performance	O
for	O
different	O
language	O
pairs	O
(	O
Cohn	O
et	O
al	O
.	O
,	O
2016;Du	O
and	O
Way	O
,	O
2017;Zhao	O
et	O
al	O
.	O
,	O
2018;Kawara	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
Inspired	O
by	O
their	O
work	O
,	O
we	O
propose	O
to	O
augment	O
SANs	O
with	O
cross	O
-	O
lingual	O
representations	O
,	O
by	O
encoding	O
reordering	O
indices	O
at	O
embedding	O
level	O
.	O
Taking	O
English⇒Chinese	O
translation	O
task	O
for	O
example	O
,	O
we	O
first	O
reorder	O
the	O
English	O
sentence	O
by	O
deriving	O
a	O
latent	O
bracketing	O
transduction	O
grammar	O
(	O
BTG	O
)	O
tree	O
(	O
Wu	O
,	O
1997	O
)	O
(	O
Fig	O
.	O
1a	O
)	O
.	O
Similar	O
to	O
absolute	O
position	O
,	O
the	O
reordering	O
information	O
can	O
be	O
represented	O
as	O
cross	O
-	O
lingual	O
position	O
(	O
Fig	O
.	O
1b	O
)	O
.	O
In	O
addition	O
,	O
we	O
propose	O
two	O
strategies	O
to	O
incorporate	O
cross	O
-	O
lingual	O
position	O
encoding	O
into	O
SANs	O
.	O
We	O
conducted	O
experiments	O
on	O
three	O
commonlycited	O
datasets	O
of	O
machine	O
translation	O
.	O
Results	O
show	O
that	O
exploiting	O
cross	O
-	O
lingual	O
PE	O
consistently	O
improves	O
translation	O
quality	O
.	O
Further	O
analysis	O
reveals	O
that	O
our	O
method	O
improves	O
the	O
alignment	O
quality	O
(	O
§	O
Sec	O
.	O
4.3	O
)	O
and	O
context	O
-	O
free	O
Transformer	O
(	O
Tang	O
et	O
al	O
.	O
,	O
2019	O
)	O
(	O
§	O
Sec	O
.	O
4.4	O
)	O
.	O
Furthermore	O
,	O
contrastive	O
evaluation	O
demonstrates	O
that	O
NMT	O
models	O
benefits	O
from	O
the	O
cross	O
-	O
lingual	O
information	O
rather	O
than	O
denoising	O
ability	O
(	O
§	O
Sec	O
.	O
4.5	O
)	O
.	O

Position	O
Encoding	O
To	O
tackle	O
the	O
position	O
unaware	O
problem	O
,	O
absolute	O
position	O
information	O
is	O
injected	O
into	O
the	O
SANs	O
:	O

Self	O
-	O
Attention	O
The	O
SANs	O
compute	O
the	O
attention	O
of	O
each	O
pair	O
of	O
elements	O
in	O
parallel	O
.	O
It	O
first	O
converts	O
the	O
input	O
into	O
three	O
matrices	O
Q	O
,	O
K	O
,	O
V	O
,	O
representing	O
queries	O
,	O
keys	O
,	O
and	O
values	O
,	O
respectively	O
:	O

SANs	O
can	O
be	O
implemented	O
with	O
multi	O
-	O
head	O
attention	O
mechanism	O
,	O
which	O
requires	O
extra	O
splitting	O
and	O
concatenation	O
operations	O
.	O
Specifically	O
,	O
W	O
Q	O
,	O
W	O
K	O
,	O
W	O
V	O
and	O
Q	O
,	O
K	O
,	O
V	O
in	O
Eq	O
.	O
(	O
3	O
)	O
is	O
split	O
into	O
H	O
sub	O
-	O
matrices	O
,	O
yielding	O
H	O
heads	O
.	O
For	O
the	O
h	O
-	O
th	O
head	O
,	O
the	O
output	O
is	O
computed	O
by	O
:	O

First	O
,	O
we	O
built	O
a	O
BTG	O
-	O
based	O
reordering	O
model	O
(	O
Neubig	O
et	O
al	O
.	O
,	O
2012	O
)	O
to	O
generate	O
a	O
reordered	O
source	O
sentence	O
according	O
to	O
the	O
word	O
order	O
of	O
its	O
corresponding	O
target	O
sentence	O
.	O
Second	O
,	O
we	O
obtained	O
the	O
reordered	O
word	O
indices	O
pos	O
XL	O
that	O
correspond	O
with	O
the	O
input	O
sentence	O
X.	O
To	O
output	O
the	O
cross	O
-	O
lingual	O
position	O
matrix	O
PE	O
XL	O
,	O
we	O
inherit	O
the	O
sinusoidal	O
function	O
in	O
Eq	O
.	O
(	O
1	O
)	O
.	O
Formally	O
,	O
the	O
process	O
is	O
:	O

As	O
shown	O
in	O
Fig	O
.	O
2	O
,	O
we	O
propose	O
two	O
strategies	O
to	O
integrate	O
the	O
cross	O
-	O
lingual	O
position	O
encoding	O
(	O
XL	O
PE	O
)	O
into	O
SANs	O
:	O
inputting	O
-	O
level	O
XL	O
(	O
InXL	O
)	O
SANs	O
and	O
head	O
-	O
level	O
(	O
HeadXL	O
)	O
SANs	O
.	O

Inputting	O
-	O
level	O
XL	O
SANs	O
As	O
illustrated	O
in	O
Fig	O
.	O
2a	O
,	O
we	O
employ	O
a	O
non	O
-	O
linear	O
function	O
TANH(•	O
)	O
to	O
fuse	O
PE	O
abs	O
and	O
PE	O
XL	O
:	O

Similarly	O
,	O
we	O
use	O
Eq	O
.	O
(	O
3)∼	O
(	O
5	O
)	O
to	O
calculate	O
multiple	O
heads	O
of	O
SANs	O
.	O

Head	O
-	O
level	O
XL	O
SANs	O
Instead	O
of	O
projecting	O
XL	O
PE	O
to	O
all	O
attention	O
heads	O
,	O
we	O
feed	O
partial	O
of	O
them	O
,	O
such	O
that	O
some	O
heads	O
contain	O
XL	O
PE	O
and	O
others	O
contain	O
APE	O
,	O
namely	O
HeadXL	O
.	O
As	O
shown	O
in	O
Fig	O
.	O
2b	O
,	O
we	O
fist	O
add	O
APE	O
and	O
XL	O
PE	O
for	O
X	O
,	O
respectively	O
:	O

We	O
denote	O
the	O
number	O
of	O
XL	O
PE	O
equipped	O
heads	O
as	O
τ	O
∈	O
{	O
0	O
,	O
.	O
.	O
.	O
,	O
H	O
}	O
.	O
To	O
perform	O
the	O
attention	O
calculation	O
,	O

In	O
particular	O
,	O
τ	O
=	O
0	O
refers	O
to	O
the	O
original	O
Transformer	O
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017	O
)	O
and	O
τ	O
=	O
H	O
means	O
that	O
XL	O
PE	O
will	O
propagate	O
over	O
all	O
attention	O
heads	O
.	O

We	O
conduct	O
experiments	O
on	O
word	O
order	O
-	O
diverse	O
language	O
pairs	O
:	O
WMT'14	O
English⇒German	O
(	O
En	O
-	O
De	O
)	O
,	O
WAT'17	O
Japanese⇒English	O
(	O
Ja	O
-	O
En	O
)	O
,	O
and	O
WMT'17	O
Chinese⇔English	O
(	O
Zh	O
-	O
En	O
&	O
En	O
-	O
Zh	O
)	O
.	O

For	O
English⇒German	O
,	O
the	O
training	O
set	O
consists	O
of	O
4.5	O
million	O
sentence	O
pairs	O
and	O
newstest2013	O
&	O
2014	O
are	O
used	O
as	O
the	O
dev	O
.	O
and	O
test	O
sets	O
,	O
respectively	O
.	O
BPE	O
with	O
32	O
K	O
merge	O
operations	O
is	O
used	O
to	O
handle	O
low	O
-	O
frequency	O
words	O
.	O
For	O
Japanese⇒English	O
,	O
we	O
follow	O
Morishita	O
et	O
al	O
.	O
(	O
2017	O
)	O
to	O
use	O
the	O
first	O
two	O
sections	O
as	O
training	O
data	O
,	O
which	O
consists	O
of	O
2.0	O
million	O
sentence	O
pairs	O
.	O
The	O
dev	O
.	O
and	O
test	O
sets	O
contain	O
1790	O
and	O
1812	O
sentences	O
.	O
For	O
Chinese⇔English	O
,	O
we	O
follow	O
Hassan	O
et	O
al	O
.	O
(	O
2018	O
)	O
sentence	O
pairs	O
.	O
We	O
develop	O
on	O
devtest2017	O
and	O
test	O
on	O
newstest2017	O
.	O
We	O
use	O
SacreBLEU	O
(	O
Post	O
,	O
2018	O
)	O
as	O
the	O
evaluation	O
metric	O
with	O
statistical	O
significance	O
test	O
(	O
Collins	O
et	O
al	O
.	O
,	O
2005	O
)	O
.	O
We	O
evaluate	O
the	O
proposed	O
XL	O
PE	O
strategies	O
on	O
Transformer	O
.	O
The	O
baseline	O
systems	O
include	O
Relative	O
PE	O
(	O
Shaw	O
et	O
al	O
.	O
,	O
2018	O
)	O
and	O
directional	O
SAN	O
(	O
DiSAN	O
,	O
Shen	O
et	O
al	O
.	O
2018	O
)	O
.	O
We	O
implement	O
them	O
on	O
top	O
of	O
OpenNMT	O
(	O
Klein	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
In	O
addition	O
,	O
we	O
report	O
the	O
results	O
of	O
previous	O
studies	O
(	O
Hao	O
et	O
al	O
.	O
,	O
2019;Chen	O
et	O
al	O
.	O
,	O
2019b	O
,	O
a;Du	O
and	O
Way	O
,	O
2017;Hassan	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O

The	O
reordered	O
source	O
sentences	O
are	O
generated	O
by	O
BTG	O
-	O
based	O
preordering	O
model	O
(	O
Neubig	O
et	O
al	O
.	O
,	O
2012	O
)	O
trained	O
with	O
above	O
sub	O
-	O
word	O
level	O
1	O
parallel	O
corpus	O
.	O
At	O
training	O
phase	O
,	O
we	O
first	O
obtain	O
word	O
alignments	O
from	O
parallel	O
data	O
using	O
GIZA++	O
or	O
FastAlign	O
,	O
and	O
then	O
the	O
training	O
process	O
is	O
to	O
find	O
the	O
optimal	O
BTG	O
tree	O
for	O
source	O
sentence	O
consistent	O
with	O
the	O
order	O
of	O
the	O
target	O
sentence	O
based	O
on	O
the	O
word	O
alignments	O
and	O
parallel	O
data	O
.	O
At	O
decoding	O
phase	O
,	O
we	O
only	O
provide	O
source	O
sentences	O
as	O
input	O
and	O
the	O
model	O
can	O
output	O
reordering	O
indices	O
,	O
which	O
will	O
be	O
fed	O
into	O
NMT	O
model	O
.	O
Thus	O
,	O
bilingual	O
alignment	O
information	O
is	O
only	O
used	O
to	O
preprocess	O
training	O
data	O
,	O
but	O
not	O
necessary	O
at	O
decoding	O
time	O
.	O

For	O
fair	O
comparison	O
,	O
we	O
keep	O
the	O
Transformer	O
decoder	O
unchanged	O
and	O
validate	O
different	O
position	O
representation	O
strategies	O
on	O
the	O
encoder	O
.	O
We	O
conduct	O
all	O
experiments	O
on	O
the	O
TRANSFORMER	O
-	O
BIG	O
with	O
four	O
V100	O
GPUs	O
.	O

Effect	O
of	O
τ	O
in	O
HeadXL	O
SANs	O

Fig	O
.	O
3	O
reports	O
the	O
results	O
of	O
different	O
τ	O
for	O
Head	O
XL	O
SANs	O
.	O
With	O
increasing	O
of	O
XL	O
PE	O
-	O
informed	O
heads	O
,	O
the	O
best	O
BLEU	O
is	O
achieved	O
when	O
#	O
heads	O
=	O
4	O
,	O
which	O
is	O
therefore	O
left	O
as	O
the	O
default	O
setting	O
for	O
HeadXL	O
.	O
Then	O
,	O
the	O
BLEU	O
score	O
gradually	O
decreases	O
as	O
the	O
#	O
System	O
Architecture	O
BLEU	O
#	O
Param	O
.	O
number	O
of	O
APE	O
-	O
informed	O
heads	O
decrease	O
(	O
τ	O
↑	O
)	O
,	O
indicating	O
that	O
sequential	O
position	O
embedding	O
is	O
still	O
essential	O
for	O
SANs	O
.	O

Tab	O
.	O
1	O
shows	O
the	O
results	O
on	O
En	O
-	O
De	O
,	O
inputting	O
-	O
level	O
cross	O
-	O
lingual	O
PE	O
(	O
+	O
InXL	O
PE	O
)	O
and	O
head	O
-	O
level	O
crosslingual	O
PE	O
(	O
+	O
HeadXL	O
PE	O
)	O
outperform	O
Transformer	O
BIG	O
by	O
0.30	O
and	O
0.36	O
BLEU	O
points	O
,	O
and	O
combining	O
these	O
two	O
strategies	O
2	O
achieves	O
a	O
0.69	O
BLEU	O
point	O
increase	O
.	O
For	O
Ja	O
-	O
En	O
,	O
Zh	O
-	O
En	O
,	O
and	O
En	O
-	O
Zh	O
(	O
Tab	O
.	O
2	O
)	O
,	O
we	O
observe	O
a	O
similar	O
phenomenon	O
,	O
demonstrating	O
that	O
XL	O
PE	O
on	O
SANs	O
do	O
improve	O
the	O
translation	O
performance	O
for	O
several	O
language	O
pairs	O
.	O
It	O
is	O
worth	O
noting	O
that	O
our	O
approach	O
introduces	O
nearly	O
no	O
additional	O
parameters	O
(	O
+0.01	O
M	O
over	O
282.55	O
M	O
)	O
.	O

Our	O
proposed	O
XL	O
PE	O
intuitively	O
encourages	O
SANs	O
to	O
learn	O
bilingual	O
diagonal	O
alignment	O
,	O
so	O
has	O
the	O
2	O
Replace	O
PEXL	O
in	O
Eq	O
.	O
(	O
9	O
)	O
with	O
PEIN	O
-	O
XL	O
in	O
Eq	O
.	O
(	O
8)	O
.	O
potential	O
to	O
induce	O
better	O
attention	O
matrices	O
.	O
We	O
explore	O
this	O
hypothesis	O
on	O
the	O
widely	O
used	O
Gold	O
Alignment	O
dataset	O
3	O
and	O
follow	O
Tang	O
et	O
al	O
.	O
(	O
2019	O
)	O
to	O
perform	O
the	O
alignment	O
.	O
The	O
only	O
difference	O
being	O
that	O
we	O
average	O
the	O
attention	O
matrices	O
across	O
all	O
heads	O
from	O
the	O
penultimate	O
layer	O
(	O
Garg	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
The	O
alignment	O
error	O
rate	O
(	O
AER	O
,	O
Och	O
and	O
Ney	O
2003	O
)	O
,	O
precision	O
(	O
P	O
)	O
and	O
recall	O
(	O
R	O
)	O
are	O
reported	O
as	O
the	O
evaluation	O
metrics	O
.	O
Tab	O
.	O
3	O
summarizes	O
the	O
results	O
.	O
We	O
can	O
see	O
:	O
1	O
)	O
XL	O
PE	O
allows	O
SANs	O
to	O
learn	O
better	O
attention	O
matrices	O
,	O
thereby	O
improving	O
alignment	O
performance	O
(	O
27.4	O
/	O
26.9	O
vs.	O
29.7	O
)	O
;	O
and	O
2	O
)	O
combining	O
the	O
two	O
strategies	O
delivers	O
consistent	O
improvements	O
(	O
24.7	O
vs.	O
29.7	O
)	O
.	O

Augmenting	O
SANs	O
with	O
position	O
representation	O
SANs	O
ignore	O
the	O
position	O
of	O
each	O
token	O
due	O
to	O
its	O
position	O
-	O
unaware	O
"	O
bag	O
-	O
of	O
-	O
words	O
"	O
assumption	O
.	O
The	O
most	O
straightforward	O
strategy	O
is	O
adding	O
the	O
position	O
representations	O
as	O
part	O
of	O
the	O
token	O
representations	O
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017;Shaw	O
et	O
al	O
.	O
,	O
2018	O
lingual	O
position	O
information	O
between	O
languages	O
.	O

Modeling	O
cross	O
-	O
lingual	O
divergence	O
There	O
has	O
been	O
many	O
works	O
modeling	O
cross	O
-	O
lingual	O
divergence	O
(	O
e.g.	O
,	O
reordering	O
)	O
in	O
statistical	O
machine	O
translation	O
(	O
Nagata	O
et	O
al	O
.	O
,	O
2006;Durrani	O
et	O
al	O
.	O
,	O
2011Durrani	O
et	O
al	O
.	O
,	O
,	O
2013	O
.	O
However	O
,	O
it	O
is	O
difficult	O
to	O
migrant	O
them	O
to	O
neural	O
machine	O
translation	O
.	O
Kawara	O
et	O
al	O
.	O
(	O
2018	O
)	O
pre	O
-	O
reordered	O
the	O
source	O
sentences	O
with	O
a	O
recursive	O
neural	O
network	O
model	O
.	O
Chen	O
et	O
al	O
.	O
(	O
2019a	O
)	O
learned	O
the	O
reordering	O
embedding	O
by	O
considering	O
the	O
relationship	O
between	O
the	O
position	O
embedding	O
of	O
a	O
word	O
and	O
SANS	O
-	O
calculated	O
sentence	O
representation	O
.	O
showed	O
that	O
SANs	O
in	O
machine	O
translation	O
could	O
learn	O
word	O
order	O
mainly	O
due	O
to	O
the	O
PE	O
,	O
indicating	O
that	O
modeling	O
cross	O
-	O
lingual	O
information	O
at	O
position	O
representation	O
level	O
may	O
be	O
informative	O
.	O
Thus	O
,	O
we	O
propose	O
a	O
novel	O
cross	O
-	O
lingual	O
PE	O
method	O
to	O
improve	O
SANs	O
.	O

In	O
this	O
paper	O
,	O
we	O
presented	O
a	O
novel	O
cross	O
-	O
lingual	O
position	O
encoding	O
to	O
augment	O
SANs	O
by	O
considering	O
cross	O
-	O
lingual	O
information	O
(	O
i.e.	O
,	O
reordering	O
indices	O
)	O
for	O
the	O
input	O
sentence	O
.	O
We	O
designed	O
two	O
strategies	O
to	O
integrate	O
it	O
into	O
SANs	O
.	O
Experiments	O
indicated	O
that	O
the	O
proposed	O
strategies	O
consistently	O
improve	O
the	O
translation	O
performance	O
.	O
In	O
the	O
future	O
,	O
we	O
plan	O
to	O
extend	O
the	O
cross	O
-	O
lingual	O
position	O
encoding	O
to	O
non	O
-	O
autoregressive	O
MT	O
(	O
Gu	O
et	O
al	O
.	O
,	O
2018	O
)	O
and	O
unsupervised	O
NMT	O
(	O
Lample	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O

We	O
harness	O
neural	O
language	O
and	O
commonsense	O
models	O
to	O
study	O
how	O
cognitive	O
processes	O
of	O
recollection	O
and	O
imagination	O
are	O
engaged	O
in	O
storytelling	O
.	O
We	O
rely	O
on	O
two	O
key	O
aspects	O
of	O
stories	O
:	O
narrative	O
flow	O
(	O
how	O
the	O
story	O
reads	O
)	O
and	O
semantic	O
vs.	O
episodic	O
knowledge	O
(	O
the	O
types	O
of	O
events	O
in	O
the	O
story	O
)	O
.	O
We	O
propose	O
as	O
a	O
measure	O
of	O
narrative	O
flow	O
the	O
likelihood	O
of	O
sentences	O
under	O
generative	O
language	O
models	O
conditioned	O
on	O
varying	O
amounts	O
of	O
history	O
.	O
Then	O
,	O
we	O
quantify	O
semantic	O
knowledge	O
by	O
measuring	O
the	O
frequency	O
of	O
commonsense	O
events	O
(	O
from	O
the	O
ATOMIC	O
knowledge	O
graph	O
;	O
Sap	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
and	O
episodic	O
knowledge	O
by	O
counting	O
realis	O
events	O
(	O
Sims	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
both	O
shown	O
in	O
Figure	O
1	O
.	O

We	O
introduce	O
HIPPOCORPUS	O
,	O
1	O
a	O
dataset	O
of	O
6,854	O
diary	O
-	O
like	O
short	O
stories	O
about	O
salient	O
life	O
events	O
,	O
to	O
examine	O
the	O
cognitive	O
processes	O
of	O
remembering	O
and	O
imagining	O
.	O
Using	O
a	O
crowdsourcing	O
pipeline	O
,	O
we	O
collect	O
pairs	O
of	O
recalled	O
and	O
imagined	O
stories	O
written	O
about	O
the	O
same	O
topic	O
.	O
By	O
design	O
,	O
authors	O
of	O
recalled	O
stories	O
rely	O
on	O
their	O
episodic	O
memory	O
to	O
tell	O
their	O
story	O
.	O

We	O
demonstrate	O
that	O
our	O
measures	O
can	O
uncover	O
differences	O
in	O
imagined	O
and	O
recalled	O
stories	O
in	O
HIPPOCORPUS	O
.	O
Imagined	O
stories	O
contain	O
more	O
commonsense	O
events	O
and	O
elaborations	O
,	O
whereas	O
recalled	O
stories	O
are	O
more	O
dense	O
in	O
concrete	O
events	O
.	O
Additionally	O
,	O
imagined	O
stories	O
flow	O
substantially	O
more	O
linearly	O
than	O
recalled	O
stories	O
.	O
Our	O
findings	O
provide	O
evidence	O
that	O
surface	O
language	O
reflects	O
the	O
differences	O
in	O
cognitive	O
processes	O
used	O
in	O
imagining	O
and	O
remembering	O
.	O

We	O
construct	O
HIPPOCORPUS	O
,	O
containing	O
6,854	O
stories	O
(	O
Table	O
1	O
)	O
,	O
to	O
enable	O
the	O
study	O
of	O
imagined	O
and	O
recalled	O
stories	O
,	O
as	O
most	O
prior	O
corpora	O
are	O
either	O
limited	O
in	O
size	O
or	O
topic	O
(	O
e.g.	O
,	O
Greenberg	O
et	O
al	O
.	O
,	O
1996;Ott	O
et	O
al	O
.	O
,	O
2011	O
)	O
.	O
See	O
Appendix	O
A	O
for	O
additional	O
details	O
(	O
e.g.	O
,	O
worker	O
demographics	O
;	O
§	O
A.2	O
)	O
.	O

Inspired	O
by	O
recent	O
work	O
on	O
discourse	O
modeling	O
(	O
Kang	O
et	O
al	O
.	O
,	O
2019;Nadeem	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
we	O
use	O
language	O
models	O
to	O
assess	O
the	O
narrative	O
linearity	O
of	O
a	O
story	O
by	O
measuring	O
how	O
sentences	O
relate	O
to	O
their	O
context	O
in	O
the	O
story	O
.	O
We	O
compare	O
the	O
likelihoods	O
of	O
sentences	O
under	O
two	O
generative	O
models	O
(	O
Figure	O
2	O
)	O
.	O
The	O
bag	O
model	O
makes	O
the	O
assumption	O
that	O
every	O
sentence	O
is	O
drawn	O
independently	O
from	O
the	O
main	O
theme	O
of	O
the	O
story	O
(	O
represented	O
by	O
E	O
)	O
.	O
On	O
the	O
other	O
hand	O
,	O
the	O
chain	O
model	O
assumes	O
that	O
a	O
story	O
begins	O
with	O
a	O
theme	O
,	O
and	O
sentences	O
linearly	O
follow	O
each	O
other	O
.	O
3	O
.	O
∆	O
l	O
is	O
computed	O
as	O
the	O
difference	O
in	O
negative	O
loglikelihoods	O
between	O
the	O
bag	O
and	O
chain	O
models	O
:	O

We	O
train	O
a	O
realis	O
event	O
tagger	O
(	O
using	O
BERT	O
-	O
base	O
;	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
on	O
the	O
annotated	O
literary	O
events	O
corpus	O
by	O
Sims	O
et	O
al	O
.	O
(	O
2019	O
)	O
,	O
which	O
slightly	O
outperforms	O
the	O
original	O
author	O
's	O
models	O
.	O
We	O
provide	O
further	O
training	O
details	O
in	O
Appendix	O
B.1	O
.	O

Given	O
the	O
social	O
focus	O
of	O
our	O
stories	O
,	O
we	O
use	O
the	O
social	O
commonsense	O
knowledge	O
graph	O
ATOMIC	O
(	O
Sap	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
4	O
For	O
each	O
story	O
,	O
we	O
first	O
match	O
possible	O
ATOMIC	O
events	O
to	O
sentences	O
by	O
selecting	O
events	O
that	O
share	O
noun	O
chunks	O
and	O
verb	O
phrases	O
with	O
sentences	O
(	O
e.g.	O
,	O
"	O
getting	O
married	O
"	O
"	O
Per	O
-	O
sonX	O
gets	O
married	O
"	O
;	O
Figure	O
1	O
)	O
.	O
We	O
then	O
search	O
the	O
matched	O
sentences	O
'	O
surrounding	O
sentences	O
for	O
commonsense	O
inferences	O
(	O
e.g.	O
,	O
"	O
be	O
very	O
happy	O
"	O
"	O
happy	O
"	O
;	O
Figure	O
1	O
)	O
.	O
We	O
describe	O
this	O
algorithm	O
in	O
further	O
detail	O
in	O
Appendix	O
B.2	O
.	O
In	O
our	O
analyses	O
,	O
the	O
measure	O
quantifies	O
the	O
number	O
of	O
story	O
sentences	O
with	O
commonsense	O
tuple	O
matches	O
in	O
the	O
two	O
preceding	O
and	O
following	O
sentences	O
.	O

To	O
supplement	O
our	O
analyses	O
,	O
we	O
compute	O
several	O
coarse	O
-	O
grained	O
lexical	O
counts	O
for	O
each	O
story	O
in	O
HIPPOCORPUS	O
.	O
Such	O
approaches	O
have	O
been	O
used	O
in	O
prior	O
efforts	O
to	O
investigate	O
author	O
mental	O
states	O
,	O
temporal	O
orientation	O
,	O
or	O
counterfactual	O
thinking	O
in	O
language	O
(	O
Tausczik	O
and	O
Pennebaker	O
,	O
2010;Schwartz	O
et	O
al	O
.	O
,	O
2015;Son	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O

We	O
count	O
psychologically	O
relevant	O
word	O
categories	O
using	O
the	O
Linguistic	O
Inquiry	O
Word	O
Count	O
(	O
Pennebaker	O
et	O
al	O
.	O
,	O
2015	O
,	O
LIWC	O
;)	O
,	O
focusing	O
only	O
on	O
the	O
cognitive	O
processes	O
,	O
positive	O
emotion	O
,	O
negative	O
emotion	O
,	O
and	O
I	O
-	O
word	O
categories	O
,	O
as	O
well	O
as	O
the	O
ANALYTIC	O
and	O
TONE	O
summary	O
variables	O
.	O
5	O
Additionally	O
,	O
we	O
measure	O
the	O
average	O
concreteness	O
level	O
of	O
words	O
in	O
stories	O
using	O
the	O
lexicon	O
by	O
Brysbaert	O
et	O
al	O
.	O
(	O
2014	O
)	O
.	O

We	O
summarize	O
the	O
differences	O
between	O
imagined	O
and	O
recalled	O
stories	O
in	O
HIPPOCORPUS	O
in	O
Table	O
2	O
.	O
For	O
our	O
narrative	O
flow	O
and	O
lexicon	O
-	O
based	O
analyses	O
,	O
4	O
ATOMIC	O
contains	O
social	O
and	O
inferential	O
knowledge	O
about	O
the	O
causes	O
(	O
e.g.	O
,	O
"	O
X	O
wants	O
to	O
start	O
a	O
family	O
"	O
)	O
and	O
effects	O
(	O
e.g.	O
,	O
"	O
X	O
throws	O
a	O
party	O
"	O
,	O
"	O
X	O
feels	O
loved	O
"	O
)	O
of	O
everyday	O
situations	O
like	O
"	O
PersonX	O
decides	O
to	O
get	O
married	O
"	O
.	O
5	O
See	O
liwc.wpengine.com/interpretingliwc-output/	O
for	O
more	O
information	O
on	O
LIWC	O
variables	O
.	O
we	O
perform	O
paired	O
t	O
-	O
tests	O
.	O
For	O
realis	O
and	O
commonsense	O
event	O
measures	O
,	O
we	O
perform	O
linear	O
regressions	O
controlling	O
for	O
story	O
length	O
.	O
6	O
We	O
Holmcorrect	O
for	O
multiple	O
comparisons	O
for	O
all	O
our	O
analyses	O
(	O
Holm	O
,	O
1979	O
)	O
.	O

First	O
,	O
we	O
compare	O
the	O
effects	O
of	O
recency	O
of	O
the	O
event	O
described	O
(	O
TIMESINCEEVENT	O
:	O
a	O
continuous	O
variable	O
representing	O
the	O
log	O
time	O
since	O
the	O
event	O
)	O
.	O
9	O
Then	O
,	O
we	O
contrast	O
recalled	O
stories	O
to	O
their	O
retold	O
counterparts	O
in	O
pairwise	O
comparisons	O
.	O
Finally	O
,	O
we	O
measure	O
the	O
effect	O
of	O
how	O
frequently	O
the	O
experienced	O
event	O
is	O
thought	O
or	O
talked	O
about	O
(	O
FREQUENCYOFRECALL	O
:	O
a	O
continuous	O
variable	O
ranging	O
from	O
very	O
rarely	O
to	O
very	O
frequently	O
)	O
.	O
10	O
As	O
in	O
§	O
4	O
,	O
we	O
Holm	O
-	O
correct	O
for	O
multiple	O
comparisons	O
.	O

Frequency	O
of	O
recall	O
.	O
We	O
find	O
that	O
the	O
more	O
an	O
event	O
is	O
thought	O
or	O
talked	O
about	O
(	O
i.e.	O
,	O
higher	O
FRE	O
-	O
QUENCYOFRECALL	O
)	O
,	O
the	O
more	O
linearly	O
its	O
story	O
flows	O
(	O
∆	O
l	O
;	O
|β|	O
=	O
0.07	O
,	O
p	O
<	O
0.001	O
)	O
,	O
and	O
the	O
fewer	O
realis	O
events	O
(	O
|β|	O
=	O
0.09	O
,	O
p	O
<	O
0.001	O
)	O
it	O
contains	O
.	O

Furthermore	O
,	O
using	O
lexicon	O
-	O
based	O
measures	O
,	O
we	O
find	O
that	O
stories	O
with	O
high	O
FREQUENCYOFRE	O
-	O
CALL	O
tend	O
to	O
contain	O
more	O
self	O
references	O
(	O
Iwords	O
;	O
Pearson	O
's	O
|r|	O
=	O
0.07	O
,	O
p	O
<	O
0.001	O
)	O
.	O
Conversely	O
,	O
stories	O
that	O
are	O
less	O
frequently	O
recalled	O
are	O
more	O
logical	O
or	O
hierarchical	O
(	O
LIWC	O
's	O
ANALYTIC	O
;	O
Pearson	O
's	O
|r|	O
=	O
0.09	O
,	O
p	O
<	O
0.001	O
)	O
and	O
more	O
concrete	O
(	O
Pearson	O
's	O
|r|	O
=	O
0.05	O
,	O
p	O
=	O
0.03	O
)	O
.	O

To	O
investigate	O
the	O
use	O
of	O
NLP	O
tools	O
for	O
studying	O
the	O
cognitive	O
traces	O
of	O
recollection	O
versus	O
imagination	O
in	O
stories	O
,	O
we	O
collect	O
and	O
release	O
HIP	O
-	O
POCORPUS	O
,	O
a	O
dataset	O
of	O
imagined	O
and	O
recalled	O
stories	O
.	O
We	O
introduce	O
measures	O
to	O
characterize	O
narrative	O
flow	O
and	O
influence	O
of	O
semantic	O
vs.	O
episodic	O
knowledge	O
in	O
stories	O
.	O
We	O
show	O
that	O
imagined	O
stories	O
have	O
a	O
more	O
linear	O
flow	O
and	O
contain	O
more	O
commonsense	O
knowledge	O
,	O
whereas	O
recalled	O
stories	O
are	O
less	O
connected	O
and	O
contain	O
more	O
specific	O
concrete	O
events	O
.	O
Additionally	O
,	O
we	O
show	O
that	O
our	O
measures	O
can	O
uncover	O
the	O
effect	O
in	O
language	O
of	O
narrativization	O
of	O
memories	O
over	O
time	O
.	O
We	O
hope	O
these	O
findings	O
bring	O
attention	O
to	O
the	O
feasibility	O
of	O
employing	O
statistical	O
natural	O
language	O
processing	O
machinery	O
as	O
tools	O
for	O
exploring	O
human	O
cognition	O
.	O
Figure	O
4	O
:	O
We	O
extract	O
phrases	O
from	O
the	O
main	O
themes	O
of	O
recalled	O
(	O
left	O
)	O
and	O
imagined	O
(	O
right	O
)	O
stories	O
,	O
using	O
RAKE	O
(	O
Rose	O
et	O
al	O
.	O
,	O
2010	O
)	O
;	O
size	O
of	O
words	O
corresponds	O
to	O
frequency	O
in	O
corpus	O
,	O
and	O
color	O
is	O
only	O
for	O
readability	O
.	O

To	O
detect	O
realis	O
events	O
in	O
our	O
stories	O
,	O
we	O
train	O
a	O
tagger	O
(	O
using	O
BERT	O
-	O
base	O
;	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
on	O
the	O
annotated	O
corpus	O
by	O
Sims	O
et	O
al	O
.	O
(	O
2019	O
)	O
.	O
This	O
corpus	O
contains	O
8k	O
realis	O
events	O
annotated	O
by	O
experts	O
in	O
sentences	O
drawn	O
from	O
100	O
English	O
books	O
.	O
With	O
development	O
and	O
test	O
F	O
1	O
scores	O
of	O
83.7	O
%	O
and	O
75.8	O
%	O
,	O
respectively	O
,	O
our	O
event	O
tagger	O
slightly	O
outperforms	O
the	O
best	O
performing	O
model	O
in	O
Sims	O
et	O
al	O
.	O
(	O
2019	O
)	O
,	O
which	O
reached	O
73.9	O
%	O
F	O
1	O
.	O
In	O
our	O
analyses	O
,	O
we	O
use	O
our	O
tagger	O
to	O
detect	O
the	O
number	O
of	O
realis	O
event	O
mentions	O
.	O

We	O
design	O
a	O
commonsense	O
extraction	O
tool	O
that	O
aligns	O
sentences	O
in	O
stories	O
with	O
commonsense	O
tuples	O
,	O
using	O
a	O
heuristic	O
matching	O
algorithm	O
.	O
Given	O
a	O
story	O
,	O
we	O
match	O
possible	O
ATOMIC	O
events	O
to	O
sentences	O
by	O
selecting	O
events	O
that	O
share	O
noun	O
chunks	O
and	O
verb	O
phrases	O
with	O
sentences	O
.	O
For	O
every	O
sentence	O
s	O
i	O
that	O
matches	O
an	O
event	O
E	O
in	O
ATOMIC	O
,	O
we	O
check	O
surrounding	O
sentences	O
for	O
mentions	O
of	O
commonsense	O
inferences	O
(	O
using	O
the	O
same	O
noun	O
and	O
verb	O
phrase	O
matching	O
strategy	O
)	O
;	O
specifically	O
,	O
we	O
check	O
the	O
n	O
c	O
preceding	O
sentences	O
for	O
matches	O
of	O
causes	O
of	O
E	O
,	O
and	O
the	O
n	O
e	O
following	O
sentences	O
for	O
event	O
E	O
's	O
effects	O
.	O

To	O
measure	O
the	O
prevalence	O
of	O
semantic	O
memory	O
in	O
a	O
story	O
,	O
we	O
count	O
the	O
number	O
of	O
sentences	O
that	O
matched	O
ATOMIC	O
knowledge	O
tuples	O
in	O
their	O
surrounding	O
context	O
.	O
We	O
use	O
a	O
context	O
window	O
of	O
size	O
n	O
c	O
=	O
n	O
e	O
=	O
2	O
to	O
match	O
inferences	O
,	O
and	O
use	O
the	O
spaCy	O
pipeline	O
(	O
Honnibal	O
and	O
Montani	O
,	O
2017	O
)	O
to	O
extract	O
noun	O
and	O
verb	O
phrases	O
.	O

C.1	O
Linearity	O
with	O
Varying	O
Context	O
Size	O
Shown	O
in	O
Figure	O
5	O
,	O
we	O
compare	O
the	O
negative	O
loglikelihood	O
of	O
sentences	O
when	O
conditioned	O
on	O
varying	O
history	O
sizes	O
(	O
using	O
the	O
story	O
summary	O
as	O
context	O
E	O
)	O
.	O
As	O
expected	O
,	O
conditioning	O
on	O
longer	O
histories	O
increases	O
the	O
predictability	O
of	O
a	O
sentence	O
.	O
However	O
,	O
this	O
effect	O
is	O
significantly	O
larger	O
for	O
imagined	O
stories	O
,	O
which	O
suggests	O
that	O
imagined	O
stories	O
flow	O
more	O
linearly	O
than	O
recalled	O
stories	O
.	O

Multilingual	O
BERT	O
Post	O
-	O
Pretraining	O
Alignment	O

We	O
propose	O
a	O
simple	O
method	O
to	O
align	O
multilingual	O
contextual	O
embeddings	O
as	O
a	O
postpretraining	O
step	O
for	O
improved	O
cross	O
-	O
lingual	O
transferability	O
of	O
the	O
pretrained	O
language	O
models	O
.	O
Using	O
parallel	O
data	O
,	O
our	O
method	O
aligns	O
embeddings	O
on	O
the	O
word	O
level	O
through	O
the	O
recently	O
proposed	O
Translation	O
Language	O
Modeling	O
objective	O
as	O
well	O
as	O
on	O
the	O
sentence	O
level	O
via	O
contrastive	O
learning	O
and	O
random	O
input	O
shuffling	O
.	O
We	O
also	O
perform	O
sentence	O
-	O
level	O
code	O
-	O
switching	O
with	O
English	O
when	O
finetuning	O
on	O
downstream	O
tasks	O
.	O
On	O
XNLI	O
,	O
our	O
best	O
model	O
(	O
initialized	O
from	O
mBERT	O
)	O
improves	O
over	O
mBERT	O
by	O
4.7	O
%	O
in	O
the	O
zero	O
-	O
shot	O
setting	O
and	O
achieves	O
comparable	O
result	O
to	O
XLM	O
for	O
translate	O
-	O
train	O
while	O
using	O
less	O
than	O
18	O
%	O
of	O
the	O
same	O
parallel	O
data	O
and	O
31	O
%	O
fewer	O
model	O
parameters	O
.	O
On	O
MLQA	O
,	O
our	O
model	O
outperforms	O
XLM	O
-	O
R	O
Base	O
,	O
which	O
has	O
57	O
%	O
more	O
parameters	O
than	O
ours	O
.	O

Introduction	O

Building	O
on	O
the	O
success	O
of	O
monolingual	O
pretrained	O
language	O
models	O
(	O
LM	O
)	O
such	O
as	O
BERT	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
RoBERTa	O
(	O
Liu	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
their	O
multilingual	O
counterparts	O
mBERT	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
XLM	O
-	O
R	O
(	O
Conneau	O
et	O
al	O
.	O
,	O
2020	O
)	O
are	O
trained	O
using	O
the	O
same	O
objectives	O
-	O
Masked	O
Language	O
Modeling	O
(	O
MLM	O
)	O
and	O
in	O
the	O
case	O
of	O
mBERT	O
,	O
Next	O
Sentence	O
Prediction	O
(	O
NSP	O
)	O
.	O
MLM	O
is	O
applied	O
to	O
monolingual	O
text	O
that	O
covers	O
over	O
100	O
languages	O
.	O
Despite	O
the	O
absence	O
of	O
parallel	O
data	O
and	O
explicit	O
alignment	O
signals	O
,	O
these	O
models	O
transfer	O
surprisingly	O
well	O
from	O
high	O
resource	O
languages	O
,	O
such	O
as	O
English	O
,	O
to	O
other	O
languages	O
.	O
On	O
the	O
Natural	O
Language	O
Inference	O
(	O
NLI	O
)	O
task	O
XNLI	O
(	O
Conneau	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
a	O
text	O
classification	O
model	O
trained	O
on	O
English	O
training	O
data	O
can	O
be	O
directly	O
applied	O
to	O
the	O
other	O
14	O
languages	O
and	O
achieve	O
respectable	O
performance	O
.	O
Having	O
a	O
single	O
model	O
that	O
can	O
serve	O
over	O
100	O
languages	O
also	O
has	O
important	O
business	O
applications	O
.	O

Recent	O
work	O
improves	O
upon	O
these	O
pretrained	O
models	O
by	O
adding	O
cross	O
-	O
lingual	O
tasks	O
leveraging	O
parallel	O
data	O
that	O
always	O
involve	O
English	O
.	O
Conneau	O
and	O
Lample	O
(	O
2019	O
)	O
pretrain	O
a	O
new	O
Transformerbased	O
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017	O
)	O
model	O
from	O
scratch	O
with	O
an	O
MLM	O
objective	O
on	O
monolingual	O
data	O
,	O
and	O
a	O
Translation	O
Language	O
Modeling	O
(	O
TLM	O
)	O
objective	O
on	O
parallel	O
data	O
.	O
Cao	O
et	O
al	O
.	O
(	O
2020	O
)	O
align	O
mBERT	O
embeddings	O
in	O
a	O
post	O
-	O
hoc	O
manner	O
:	O
They	O
first	O
apply	O
a	O
statistical	O
toolkit	O
,	O
FastAlign	O
(	O
Dyer	O
et	O
al	O
.	O
,	O
2013	O
)	O
,	O
to	O
create	O
word	O
alignments	O
on	O
parallel	O
sentences	O
.	O
Then	O
,	O
mBERT	O
is	O
tuned	O
via	O
minimizing	O
the	O
mean	O
squared	O
error	O
between	O
the	O
embeddings	O
of	O
English	O
words	O
and	O
those	O
of	O
the	O
corresponding	O
words	O
in	O
other	O
languages	O
.	O
Such	O
post	O
-	O
hoc	O
approach	O
suffers	O
from	O
the	O
limitations	O
of	O
word	O
-	O
alignment	O
toolkits	O
:	O
(	O
1	O
)	O
the	O
noises	O
from	O
FastAlign	O
can	O
lead	O
to	O
error	O
propagation	O
to	O
the	O
rest	O
of	O
the	O
pipeline	O
;	O
(	O
2	O
)	O
FastAlign	O
mainly	O
creates	O
the	O
alignments	O
with	O
word	O
-	O
level	O
translation	O
and	O
usually	O
overlooks	O
the	O
contextual	O
semantic	O
compositions	O
.	O
As	O
a	O
result	O
,	O
the	O
tuned	O
mBERT	O
is	O
biased	O
to	O
shallow	O
cross	O
-	O
lingual	O
correspondence	O
.	O
Importantly	O
,	O
both	O
approaches	O
only	O
involve	O
word	O
-	O
level	O
alignment	O
tasks	O
.	O

Method	O

This	O
section	O
introduces	O
our	O
proposed	O
Post	O
-	O
Pretraining	O
Alignment	O
(	O
PPA	O
)	O
method	O
.	O
We	O
first	O
describe	O
the	O
MoCo	O
contrastive	O
learning	O
framework	O
and	O
how	O
we	O
use	O
it	O
for	O
sentence	O
-	O
level	O
alignment	O
.	O
Next	O
,	O
we	O
describe	O
the	O
finer	O
-	O
grained	O
word	O
-	O
level	O
alignment	O
with	O
TLM	O
.	O
Finally	O
,	O
when	O
training	O
data	O
in	O
the	O
target	O
language	O
is	O
available	O
,	O
we	O
incorporate	O
sentence	O
-	O
level	O
code	O
-	O
switching	O
as	O
a	O
form	O
of	O
both	O
alignment	O
and	O
data	O
augmentation	O
to	O
complement	O
PPA	O
.	O
Figure	O
1	O
shows	O
our	O
overall	O
model	O
structure	O
.	O

Background	O
:	O
Contrastive	O
Learning	O
Instance	O
discrimination	O
-	O
based	O
contrastive	O
learning	O
aims	O
to	O
bring	O
two	O
views	O
of	O
the	O
same	O
source	O
image	O
closer	O
to	O
each	O
other	O
in	O
the	O
representation	O
space	O
while	O
encouraging	O
views	O
of	O
different	O
source	O
images	O
to	O
be	O
dissimilar	O
through	O
a	O
contrastive	O
loss	O
.	O
Recent	O
advances	O
in	O
this	O
area	O
,	O
such	O
as	O
SimCLR	O
(	O
Chen	O
et	O
al	O
.	O
,	O
2020	O
)	O
and	O
MoCo	O
(	O
He	O
et	O
al	O
.	O
,	O
2020	O
)	O
have	O
bridged	O
the	O
gap	O
in	O
performance	O
between	O
self	O
-	O
supervised	O
representation	O
learning	O
and	O
fully	O
-	O
supervised	O
methods	O
on	O
the	O
ImageNet	O
(	O
Deng	O
et	O
al	O
.	O
,	O
2009	O
)	O
dataset	O
.	O
As	O
a	O
key	O
feature	O
for	O
both	O
methods	O
,	O
a	O
large	O
number	O
of	O
negative	O
examples	O
per	O
instance	O
are	O
necessary	O
for	O
the	O
models	O
to	O
learn	O
such	O
good	O
representations	O
.	O
SimCLR	O
uses	O
in	O
-	O
batch	O
negative	O
example	O
sampling	O
,	O
thus	O
requiring	O
a	O
large	O
batch	O
size	O
,	O
whereas	O
MoCo	O
stores	O
negative	O
examples	O
in	O
a	O
queue	O
and	O
casts	O
the	O
contrastive	O
learning	O
task	O
as	O
dictionary	O
(	O
query	O
-	O
key	O
)	O
lookup	O
.	O
In	O
what	O
follows	O
,	O
we	O
first	O
describe	O
MoCo	O
and	O
then	O
how	O
we	O
use	O
it	O
for	O
sentence	O
-	O
level	O
alignment	O
.	O

θ	O
k	O
=	O
mθ	O
k	O
+	O
(	O
1	O
−	O
m)θ	O
q	O
(	O
1	O
)	O

where	O
θ	O
q	O
and	O
θ	O
k	O
are	O
model	O
parameters	O
of	O
f	O
q	O
and	O
f	O
k	O
,	O
respectively	O
.	O
m	O
is	O
the	O
momentum	O
coefficient	O
.	O

Sentence	O
-	O
Level	O
Alignment	O
Objective	O

Our	O
sentence	O
-	O
level	O
alignment	O
falls	O
under	O
the	O
general	O
problem	O
of	O
bringing	O
two	O
views	O
of	O
inputs	O
from	O
the	O
same	O
source	O
closer	O
in	O
the	O
representation	O
space	O
while	O
keeping	O
those	O
from	O
different	O
sources	O
dissimilar	O
through	O
a	O
contrastive	O
loss	O
.	O
From	O
a	O
crosslingual	O
alignment	O
perspective	O
,	O
we	O
treat	O
an	O
English	O
sequence	O
S	O
en	O
i	O
and	O
its	O
translation	O
S	O
tr	O
i	O
in	O
another	O
language	O
tr	O
∈	O
L	O
as	O
two	O
manifestations	O
of	O
the	O
same	O
semantics	O
.	O
At	O
the	O
same	O
time	O
,	O
sentences	O
that	O
are	O
not	O
translations	O
of	O
each	O
other	O
should	O
be	O
further	O
apart	O
in	O
the	O
representation	O
space	O
.	O
Given	O
parallel	O
corpora	O
consisting	O
of	O
{	O
(	O
S	O
en	O
1	O
,	O
S	O
tr	O
1	O
)	O
,	O
.	O
.	O
.	O
,	O
(	O
S	O
en	O
N	O
,	O
S	O
tr	O
N	O
)	O
}	O
,	O
we	O
align	O
sentence	O
representations	O
in	O
all	O
the	O
different	O
languages	O
together	O
using	O
MoCo	O
.	O

We	O
use	O
the	O
pretrained	O
mBERT	O
model	O
to	O
initialize	O
both	O
the	O
query	O
and	O
momentum	O
encoders	O
.	O
mBERT	O
is	O
made	O
of	O
12	O
Transformer	O
blocks	O
,	O
12	O
attention	O
heads	O
,	O
and	O
hidden	O
size	O
d	O
h	O
=	O
768	O
.	O
For	O
input	O
,	O
instead	O
of	O
feeding	O
the	O
query	O
encoder	O
with	O
English	O
examples	O
and	O
the	O
momentum	O
encoder	O
with	O
translation	O
examples	O
or	O
vice	O
versa	O
,	O
we	O
propose	O
a	O
random	O
input	O
shuffling	O
approach	O
.	O
Specifically	O
,	O
we	O
randomly	O
shuffle	O
the	O
order	O
of	O
S	O
en	O
i	O
and	O
S	O
tr	O
i	O
when	O
feeding	O
the	O
two	O
encoders	O
,	O
so	O
that	O
the	O
query	O
encoder	O
sees	O
both	O
English	O
and	O
translation	O
examples	O
.	O
We	O
observe	O
that	O
this	O
is	O
a	O
crucial	O
step	O
towards	O
learning	O
good	O
multilingual	O
representations	O
using	O
our	O
method	O
.	O
The	O
final	O
hidden	O
state	O
h	O
∈	O
R	O
1×d	O
h	O
of	O
the	O
[	O
CLS	O
]	O
token	O
,	O
normalized	O
with	O
L	O
2	O
norm	O
,	O
is	O
treated	O
as	O
the	O
sentence	O
representation	O
1	O
.	O
Following	O
Chen	O
et	O
al	O
.	O
(	O
2020	O
)	O
,	O
we	O
add	O
a	O
non	O
-	O
linear	O
projection	O
layer	O
on	O
top	O
of	O
h	O
:	O

z	O
=	O
W	O
2	O
ReLU	O
(	O
W	O
1	O
h),(2	O
)	O

where	O

W	O
1	O
∈	O
R	O
d	O
h	O
×d	O
h	O
,	O
W	O
2	O
∈	O
R	O
d	O
k	O
×d	O
h	O

,	O
and	O
d	O
k	O
is	O
set	O
to	O
300	O
.	O
The	O
model	O
is	O
trained	O
using	O
the	O
InfoNCE	O
loss	O
:	O

L	O
MoCo	O
=	O
−	O
log	O
exp(z	O
q	O
•	O
z	O
k+	O
/τ	O
)	O
K	O
k=1	O
exp(z	O
q	O
•	O
z	O
k	O
/τ	O
)	O
,	O
(	O
3	O
)	O

where	O
τ	O
is	O
a	O
temperature	O
parameter	O
.	O
In	O
our	O
implementation	O
,	O
we	O
use	O
a	O
relatively	O
small	O
batch	O
size	O
of	O
128	O
,	O
resulting	O
in	O
more	O
frequent	O
parameter	O
updates	O
than	O
if	O
a	O
large	O
batch	O
size	O
were	O
used	O
.	O
Items	O
enqueued	O
early	O
on	O
can	O
thus	O
become	O
outdated	O
with	O
a	O
large	O
queue	O
,	O
so	O
we	O
scale	O
down	O
the	O
queue	O
size	O
to	O
K	O
=	O
32	O
,	O
000	O
to	O
prevent	O
the	O
queue	O
from	O
becoming	O
stale	O
.	O

Word	O
-	O
Level	O
Alignment	O
Objective	O

We	O
use	O
TLM	O
for	O
word	O
-	O
level	O
alignment	O
.	O
TLM	O
is	O
an	O
extension	O
of	O
MLM	O
that	O
operates	O
on	O
bilingual	O
data	O
-	O
parallel	O
sentences	O
are	O
concatenated	O
and	O
MLM	O
is	O
applied	O
to	O
the	O
combined	O
bilingual	O
sequence	O
.	O
Different	O
from	O
Conneau	O
and	O
Lample	O
(	O
2019	O
)	O
,	O
we	O
do	O
not	O
reset	O
positional	O
embeddings	O
when	O
forming	O
the	O
bilingual	O
sequence	O
,	O
and	O
we	O
also	O
do	O
not	O
use	O
language	O
embeddings	O
.	O
In	O
addition	O
,	O
the	O
order	O
of	O
S	O
en	O
i	O
and	O
S	O
tr	O
i	O
during	O
concatenation	O
is	O
determined	O
by	O
the	O
random	O
input	O
shuffling	O
from	O
the	O
sentence	O
-	O
level	O
alignment	O
step	O
and	O
we	O
add	O
a	O
[	O
SEP	O
]	O
token	O
between	O
S	O
en	O
i	O
and	O
S	O
tr	O
i	O
.	O
We	O
randomly	O
mask	O
15	O
%	O
of	O
the	O
WordPiece	O
tokens	O
in	O
each	O
combined	O
sequence	O
.	O
Masking	O
is	O
done	O
by	O
using	O
a	O
special	O
[	O
MASK	O
]	O
token	O
80	O
%	O
of	O
the	O
times	O
,	O
a	O
random	O
token	O
in	O
the	O
vocabulary	O
10	O
%	O
of	O
the	O
times	O
,	O
and	O
unchanged	O
for	O
the	O
remaining	O
10	O
%	O
.	O
TLM	O
is	O
performed	O
using	O
the	O
query	O
encoder	O
of	O
MoCo	O
.	O
Our	O
final	O
PPA	O
model	O
is	O
trained	O
in	O
a	O
multi	O
-	O
task	O
manner	O
with	O
both	O
sentence	O
-	O
level	O
objective	O
and	O
TLM	O
:	O

L	O
=	O
L	O
MoCo	O
+	O
L	O
TLM	O
,	O
(	O
4	O
)	O

Finetuning	O
on	O
Downstream	O
Tasks	O

After	O
an	O
alignment	O
model	O
is	O
trained	O
with	O
PPA	O
,	O
we	O
extract	O
the	O
query	O
encoder	O
from	O
MoCo	O
and	O
finetune	O
it	O
on	O
downstream	O
tasks	O
for	O
evaluation	O
.	O
We	O
follow	O
the	O
standard	O
way	O
of	O
finetuning	O
BERT	O
-	O
like	O
models	O
for	O
sequence	O
classification	O
and	O
QA	O
tasks	O
:	O

(	O
1	O
)	O
on	O
XNLI	O
,	O
we	O
concatenate	O
the	O
premise	O
with	O
the	O
hypothesis	O
,	O
and	O
add	O
a	O
[	O
SEP	O
]	O
token	O
in	O
between	O
.	O

A	O
softmax	O
classifier	O
is	O
added	O
on	O
top	O
of	O
the	O
final	O
hidden	O
state	O
of	O
the	O
[	O
CLS	O
]	O
token	O
;	O
(	O
2	O
)	O
on	O
MLQA	O
,	O
we	O
concatenate	O
the	O
question	O
with	O
the	O
context	O
,	O
and	O
add	O
a	O
[	O
SEP	O
]	O
token	O
in	O
between	O
.	O
We	O
add	O
two	O
linear	O
layers	O
on	O
top	O
of	O
mBERT	O
followed	O
by	O
softmax	O
over	O
the	O
context	O
tokens	O
to	O
predict	O
answer	O
start	O
and	O
end	O
positions	O
,	O
respectively	O
.	O
We	O
conduct	O
experiments	O
in	O
two	O
settings	O
:	O
1	O
.	O
Zeroshot	O
cross	O
-	O
lingual	O
transfer	O
,	O
where	O
training	O
data	O
is	O
available	O
in	O
English	O
but	O
not	O
in	O
target	O
languages	O
.	O
2	O
.	O
Translate	O
-	O
train	O
,	O
where	O
the	O
English	O
training	O
set	O
is	O
(	O
machine	O
)	O
translated	O
to	O
all	O
the	O
target	O
languages	O
.	O
For	O
the	O
latter	O
setting	O
,	O
we	O
perform	O
data	O
augmentation	O
with	O
code	O
-	O
switched	O
inputs	O
,	O
when	O
training	O
on	O
languages	O
other	O
than	O
English	O
.	O
For	O
example	O
,	O
a	O
Spanish	O
question	O
q	O
es	O
and	O
context	O
c	O
es	O
pair	O
can	O
be	O
augmented	O
to	O
two	O
question	O
-	O
context	O
pairs	O
(	O
q	O
es	O
,	O
c	O
en	O
)	O
and	O
(	O
q	O
en	O
,	O
c	O
es	O
)	O
with	O
code	O
-	O
switching	O
,	O
resulting	O
in	O
2x	O
training	O
data	O
2	O
.	O
The	O
same	O
goes	O
for	O
XNLI	O
with	O
premises	O
and	O
hypotheses	O
.	O
The	O
code	O
-	O
switching	O
is	O
always	O
between	O
English	O
,	O
and	O
a	O
target	O
language	O
.	O
During	O
training	O
,	O
we	O
ensure	O
the	O
two	O
augmented	O
pairs	O
appear	O
in	O
the	O
same	O
batch	O
.	O

3	O
Experimental	O
Settings	O

Parallel	O
Data	O
for	O
Post	O
-	O
Pretraining	O

Parallel	O
Data	O
All	O
parallel	O
data	O
we	O
use	O
involve	O
English	O
as	O
the	O
source	O
language	O
.	O
Specifically	O
,	O
we	O
collect	O
en	O
-	O
fr	O
,	O
en	O
-	O
es	O
,	O
en	O
-	O
de	O
parallel	O
pairs	O
from	O
Europarl	O
,	O
en	O
-	O
ar	O
,	O
en	O
-	O
zh	O
from	O
MultiUN	O
(	O
Ziemski	O
et	O
al	O
.	O
,	O
2016	O
)	O
,	O
en	O
-	O
hi	O
from	O
IITB	O
(	O
Kunchukuttan	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
and	O
en	O
-	O
bg	O
from	O
both	O
Europarl	O
and	O
EUbookshop	O
.	O
All	O
datasets	O
were	O
downloaded	O
from	O
the	O
OPUS	O
3	O
website	O
(	O
Tiedemann	O
,	O
2012	O
)	O
.	O
In	O
our	O
experiments	O
,	O
we	O
vary	O
the	O
number	O
of	O
parallel	O
sentence	O
pairs	O
for	O
PPA	O
.	O
For	O
each	O
language	O
,	O
we	O
take	O
the	O
first	O
250k	O
,	O
600k	O
,	O
and	O
2	O
M	O
English	O
-	O
translation	O
parallel	O
sentence	O
pairs	O
except	O
for	O
those	O
too	O
short	O
(	O
where	O
either	O
sentence	O
has	O
less	O
than	O
10	O
WordPiece	O
tokens	O
)	O
,	O
or	O
too	O
long	O
(	O
where	O
both	O
sentences	O
concatenated	O
together	O
have	O
more	O
than	O
128	O
WordPiece	O
tokens	O
)	O
.	O
Table	O
1	O
shows	O
the	O
actual	O
number	O
of	O
parallel	O
pairs	O
in	O
each	O
of	O
our	O
250k	O
,	O
600k	O
,	O
and	O
2	O
M	O
settings	O
.	O

Evaluation	O
Benchmarks	O

XNLI	O
is	O
an	O
evaluation	O
dataset	O
for	O
cross	O
-	O
lingual	O
NLI	O
that	O
covers	O
15	O
languages	O
.	O
The	O
dataset	O
is	O
human	O
-	O
translated	O
from	O
the	O
development	O
and	O
test	O
sets	O
of	O
the	O
English	O
MultiNLI	O
dataset	O
.	O
Given	O
a	O
sentence	O
pair	O
of	O
premise	O
and	O
hypothesis	O
,	O
the	O
task	O
is	O
to	O
classify	O
their	O
relationship	O
as	O
entailment	O
,	O
contradiction	O
,	O
and	O
neutral	O
.	O
For	O
zero	O
-	O
shot	O
cross	O
-	O
lingual	O
transfer	O
,	O
we	O
train	O
on	O
the	O
English	O
MultiNLI	O
training	O
set	O
,	O
and	O
apply	O
the	O
model	O
to	O
the	O
test	O
sets	O
of	O
the	O
other	O
languages	O
.	O
For	O
translatetrain	O
,	O
we	O
train	O
on	O
translation	O
data	O
that	O
come	O
with	O
the	O
dataset	O
4	O
.	O

MLQA	O
is	O
an	O
evaluation	O
dataset	O
for	O
QA	O
that	O
covers	O
seven	O
languages	O
.	O
The	O
dataset	O
is	O
derived	O
from	O
a	O
three	O
step	O
process	O
.	O
We	O
focus	O
on	O
XLT	O
in	O
this	O
work	O
.	O
For	O
zero	O
-	O
shot	O
crosslingual	O
transfer	O
,	O
we	O
train	O
on	O
the	O
English	O
SQuAD	O
v1.1	O
(	O
Rajpurkar	O
et	O
al	O
.	O
,	O
2016	O
)	O
training	O
set	O
.	O
For	O
translate	O
-	O
train	O
,	O
we	O
train	O
on	O
translation	O
data	O
provided	O
in	O
Hu	O
et	O
al	O
.	O
(	O
2020	O
)	O
5	O

Training	O
Details	O

Results	O

We	O
report	O
results	O
on	O
the	O
test	O
set	O
of	O
XNLI	O
and	O
MLQA	O
and	O
we	O
do	O
hyperparameter	O
searching	O
on	O
the	O
development	O
set	O
.	O
All	O
the	O
experiments	O
for	O
translatetrain	O
were	O
done	O
using	O
the	O
code	O
-	O
switching	O
technique	O
introduced	O
in	O
Section	O
2	O
.	O

XNLI	O
Table	O
2	O
shows	O
results	O
on	O
XNLI	O
measured	O
by	O
accuracy	O
.	O
Devlin	O
et	O
al	O
.	O
(	O
2019	O
)	O
only	O
provide	O
results	O
on	O
a	O
few	O
languages	O
6	O
,	O
so	O
we	O
use	O
the	O
mBERT	O
results	O
from	O
as	O
our	O
baseline	O
for	O
zeroshot	O
cross	O
-	O
lingual	O
transfer	O
,	O
and	O
Wu	O
and	O
Dredze	O
(	O
2019	O
)	O
for	O
translate	O
-	O
train	O
.	O
Our	O
best	O
model	O
,	O
trained	O
with	O
2	O
M	O
parallel	O
sentences	O
per	O
language	O
improves	O
over	O
mBERT	O
baseline	O
by	O
4.7	O
%	O
for	O
zero	O
-	O
shot	O
transfer	O
,	O
and	O
3.2	O
%	O
for	O
translate	O
-	O
train	O
.	O

Compared	O
to	O
Cao	O
et	O
al	O
.	O
(	O
2020	O
)	O
,	O
which	O
use	O
250k	O
parallel	O
sentences	O
per	O
language	O
from	O
the	O
same	O
sources	O
as	O
we	O
do	O
for	O
post	O
-	O
pretraining	O
alignment	O
,	O
our	O
250k	O
model	O
does	O
better	O
for	O
all	O
languages	O
considered	O
and	O
we	O
do	O
not	O
rely	O
on	O
the	O
word	O
-	O
to	O
-	O
word	O
pre	O
-	O
alignment	O
step	O
using	O
FastAlign	O
,	O
which	O
is	O
prone	O
to	O
error	O
propagation	O
to	O
the	O
rest	O
of	O
the	O
pipeline	O
.	O

Compared	O
to	O
XLM	O
,	O
our	O
250k	O
,	O
600k	O
and	O
2	O
M	O
settings	O
represent	O
3.1	O
%	O
,	O
7	O
%	O
and	O
17.8	O
%	O
of	O
the	O
parallel	O
data	O
used	O
by	O
XLM	O
,	O
respectively	O
(	O
see	O
Table	O
1	O
)	O
.	O
The	O
XLM	O
model	O
also	O
has	O
45	O
%	O
more	O
parameters	O
than	O
ours	O
as	O
Table	O
3	O
shows	O
.	O
Furthermore	O
,	O
XLM	O
trained	O
with	O
MLM	O
only	O
is	O
already	O
significantly	O
better	O
than	O
mBERT	O
even	O
though	O
the	O
source	O
of	O
its	O
training	O
data	O
is	O
the	O
same	O
as	O
mBERT	O
from	O
Wikipedia	O
.	O
One	O
reason	O
could	O
be	O
that	O
XLM	O
contains	O
45	O
%	O
more	O
model	O
parameters	O
than	O
mBERT	O
as	O
model	O
depth	O
and	O
capacity	O
are	O
shown	O
to	O
be	O
key	O
to	O
cross	O
-	O
lingual	O
success	O
(	O
K	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
Additionally	O
,	O
Wu	O
and	O
Dredze	O
(	O
2019	O
)	O
hypothesize	O
that	O
limiting	O
pretraining	O
to	O
the	O
languages	O
used	O
by	O
downstream	O
tasks	O
may	O
be	O
beneficial	O
since	O
XLM	O
models	O
are	O
pretrained	O
on	O
the	O
15	O
XNLI	O
languages	O
only	O
.	O
Our	O
2	O
M	O
model	O
bridges	O
the	O
gap	O
between	O
mBERT	O
and	O
XLM	O
from	O
7.5	O
%	O
to	O
2.8	O
%	O
for	O
zero	O
-	O
shot	O
transfer	O
.	O
Note	O
that	O
,	O
for	O
bg	O
,	O
our	O
total	O
processed	O
pool	O
of	O
en	O
-	O
bg	O
data	O
consists	O
of	O
456k	O
parallel	O
sentences	O
,	O
so	O
there	O
is	O
no	O
difference	O
in	O
en	O
-	O
bg	O
data	O
between	O
our	O
600k	O
and	O
2	O
M	O
settings	O
.	O
For	O
translatetrain	O
,	O
our	O
model	O
achieves	O
comparable	O
performance	O
to	O
XLM	O
with	O
the	O
further	O
help	O
of	O
code	O
-	O
switching	O
during	O
finetuning	O
.	O

Our	O
alignment	O
-	O
oriented	O
method	O
is	O
,	O
to	O
a	O
large	O
degree	O
,	O
upper	O
-	O
bounded	O
by	O
the	O
English	O
performance	O
,	O
since	O
all	O
our	O
parallel	O
data	O
involve	O
English	O
and	O
all	O
the	O
other	O
languages	O
are	O
implicitly	O
aligning	O
with	O
English	O
through	O
our	O
PPA	O
objectives	O
.	O
Our	O
2	O
M	O
model	O
is	O
able	O
to	O
improve	O
the	O
English	O
performance	O
to	O
82.4	O
from	O
the	O
mBERT	O
baseline	O
,	O
but	O
it	O
is	O
still	O
lower	O
than	O
XLM	O
(	O
MLM	O
)	O
,	O
and	O
much	O
lower	O
than	O
XLM	O
(	O
MLM+TLM	O
)	O
.	O
We	O
hypothesize	O
that	O
more	O
highquality	O
monolingual	O
data	O
and	O
model	O
capacity	O
are	O
needed	O
to	O
further	O
improve	O
our	O
English	O
performance	O
,	O
thereby	O
helping	O
other	O
languages	O
better	O
align	O
with	O
it	O
.	O

MLQA	O
Table	O
4	O
shows	O
results	O
on	O
MLQA	O
measured	O
by	O
F1	O
score	O
.	O
We	O
notice	O
the	O
mBERT	O
baseline	O
from	O
the	O
original	O
MLQA	O
paper	O
is	O
significantly	O
lower	O
than	O
that	O
from	O
,	O
so	O
we	O
use	O
the	O
latter	O
as	O
our	O
baseline	O
.	O
Our	O
2	O
M	O
model	O
outperforms	O
the	O
baseline	O
by	O
2.3	O
%	O
for	O
zero	O
-	O
shot	O
and	O
is	O
also	O
0.2	O
%	O
better	O
than	O
XLM	O
-	O
R	O
Base	O
,	O
which	O
uses	O
57	O
%	O
more	O
model	O
parameters	O
than	O
mBERT	O
as	O
Table	O
3	O
shows	O
.	O
For	O
translate	O
-	O
train	O
,	O
our	O
250k	O
model	O
is	O
1.3	O
%	O
better	O
than	O
the	O
baseline	O
.	O

Comparing	O
our	O
model	O
performance	O
using	O
vary-	O
et	O
al	O
.	O
(	O
2020	O
)	O
.	O
L	O
is	O
the	O
number	O
of	O
Transformer	O
layers	O
,	O
H	O
m	O
is	O
the	O
hidden	O
size	O
,	O
H	O
f	O
f	O
is	O
the	O
dimension	O
of	O
the	O
feed	O
-	O
forward	O
layer	O
,	O
A	O
is	O
the	O
number	O
of	O
attention	O
heads	O
,	O
and	O
V	O
is	O
the	O
vocabulary	O
size	O
.	O

ing	O
amounts	O
of	O
parallel	O
data	O
,	O
we	O
observe	O
that	O
600k	O
per	O
language	O
is	O
our	O
sweet	O
spot	O
considering	O
the	O
trade	O
-	O
off	O
between	O
resource	O
and	O
performance	O
.	O
Going	O
up	O
to	O
2	O
M	O
helps	O
on	O
XNLI	O
,	O
but	O
less	O
significantly	O
compared	O
to	O
the	O
gain	O
going	O
from	O
250k	O
to	O
600k	O
.	O
On	O
MLQA	O
,	O
surprisingly	O
,	O
250k	O
slightly	O
outperforms	O
the	O
other	O
two	O
for	O
translate	O
-	O
train	O
.	O

Ablation	O
Table	O
5	O
shows	O
the	O
contribution	O
of	O
each	O
component	O
of	O
our	O
method	O
on	O
XNLI	O
.	O
Removing	O
TLM	O
(	O
-TLM	O
)	O
consistently	O
leads	O
to	O
about	O
1	O
%	O
accuracy	O
drop	O
across	O
the	O
board	O
,	O
showing	O
positive	O
effects	O
of	O
the	O
word	O
-	O
alignment	O
objective	O
.	O
To	O
better	O
understand	O
TLM	O
's	O
consistent	O
improvement	O
,	O
we	O
replace	O
TLM	O
with	O
MLM	O
(	O
repl	O
TLM	O
w/	O
MLM	O
)	O
,	O
where	O
we	O
treat	O
S	O
en	O
i	O
and	O
S	O
tr	O
i	O
from	O
the	O
parallel	O
corpora	O
as	O
separate	O
monolingual	O
sequences	O
and	O
perform	O
MLM	O
on	O
each	O
of	O
them	O
.	O
The	O
masking	O
scheme	O
is	O
the	O
same	O
as	O
TLM	O
described	O
in	O
Section	O
2	O
.	O
We	O
observe	O
that	O
MLM	O
does	O
not	O
bring	O
significant	O
improvement	O
.	O
This	O
confirms	O
that	O
the	O
improvement	O
of	O
TLM	O
is	O
not	O
from	O
the	O
encoders	O
being	O
trained	O
with	O
more	O
data	O
and	O
iterations	O
.	O
Instead	O
,	O
the	O
word	O
-	O
alignment	O
nature	O
of	O
TLM	O
does	O
help	O
the	O
multilingual	O
training	O
.	O

Comparing	O
our	O
model	O
without	O
word	O
-	O
level	O
alignment	O
,	O
i.e.	O
,	O
-TLM	O
,	O
to	O
the	O
baseline	O
mBERT	O
in	O
Table	O
2	O
,	O
we	O
get	O
2	O
-	O
4	O
%	O
improvement	O
in	O
the	O
zero	O
-	O
shot	O
setting	O
and	O
1	O
-	O
2	O
%	O
improvement	O
in	O
translate	O
-	O
train	O
as	O
the	O
amount	O
of	O
parallel	O
data	O
is	O
increased	O
.	O
These	O
are	O
relatively	O
large	O
improvements	O
considering	O
the	O
fact	O
that	O
only	O
sentence	O
-	O
level	O
alignment	O
is	O
used	O
.	O
This	O
also	O
conforms	O
to	O
our	O
intuition	O
that	O
sentence	O
-	O
level	O
alignment	O
is	O
a	O
good	O
fit	O
here	O
since	O
XNLI	O
is	O
a	O
sentencelevel	O
task	O
.	O

In	O
the	O
zero	O
-	O
shot	O
setting	O
,	O
removing	O
MoCo	O
(	O
-MoCo	O
)	O
performs	O
similarly	O
to	O
-TLM	O
,	O
where	O
we	O
observe	O
an	O
accuracy	O
drop	O
of	O
about	O
1	O
%	O
compared	O
to	O
our	O
full	O
system	O
.	O
In	O
translate	O
-	O
train	O
,	O
-MoCo	O
outperforms	O
-TLM	O
and	O
even	O
matches	O
the	O
full	O
system	O
performance	O
for	O
250k	O
.	O

Finally	O
,	O
we	O
show	O
ablation	O
result	O
for	O
our	O
codeswitching	O
in	O
translate	O
-	O
train	O
.	O
On	O
average	O
,	O
codeswitching	O
provides	O
an	O
additional	O
gain	O
of	O
1	O
%	O
.	O
(	O
Lewis	O
et	O
al	O
.	O
,	O
2020	O
)	O
74.9	O
54.8	O
62.2	O
68.0	O
48.8	O
61.1	O
61.6	O
XLM	O
-	O
R	O
Base	O
(	O
Conneau	O
et	O
al	O
.	O
,	O
2020	O
)	O
77.1	O
54.9	O
60.9	O
67.4	O
59.4	O
61.8	O
63.6	O
Translate	O
-	O
train	O
mBERT	O
from	O
(	O
Lewis	O
et	O
al	O
.	O
,	O
2020	O
)	O
77.7	O
51.8	O
62	O
Training	O
mBERT	O
with	O
Word	O
Alignments	O
Cao	O
et	O
al	O
.	O
(	O
2020	O
)	O
post	O
-	O
align	O
mBERT	O
embeddings	O
by	O
first	O
generating	O
word	O
alignments	O
on	O
parallel	O
sentences	O
that	O
involve	O
English	O
.	O
For	O
each	O
aligned	O
word	O
pair	O
,	O
the	O
L	O
2	O
distance	O
between	O
their	O
embeddings	O
is	O
minimized	O
to	O
train	O
the	O
model	O
.	O
In	O
order	O
to	O
maintain	O
original	O
transferability	O
to	O
downstream	O
tasks	O
,	O
a	O
regularization	O
term	O
is	O
added	O
to	O
prevent	O
the	O
target	O
language	O
embeddings	O
from	O
deviating	O
too	O
much	O
from	O
their	O
mBERT	O
initialization	O
.	O
Our	O
approach	O
post	O
-	O
aligns	O
mBERT	O
with	O
two	O
self	O
-	O
supervised	O
signals	O
from	O
parallel	O
data	O
without	O
using	O
pre	O
-	O
alignment	O
tools	O
.	O
Wang	O
et	O
al	O
.	O
(	O
2019	O
)	O
also	O
align	O
mBERT	O
em-	O
Table	O
5	O
:	O
Ablation	O
Study	O
on	O
XNLI	O
.	O
250k	O
,	O
600k	O
,	O
2	O
M	O
refer	O
to	O
the	O
maximum	O
number	O
of	O
parallel	O
sentence	O
pairs	O
per	O
language	O
used	O
in	O
PPA	O
.	O
MoCo	O
refers	O
to	O
our	O
sentence	O
-	O
level	O
alignment	O
task	O
using	O
contrastive	O
learning	O
.	O
TLM	O
refers	O
to	O
our	O
word	O
-	O
level	O
alignment	O
task	O
with	O
translation	O
language	O
modeling	O
.	O
CS	O
stands	O
for	O
code	O
-	O
switching	O
.	O
We	O
conduct	O
an	O
additional	O
study	O
repl	O
TLM	O
w/	O
MLM	O
,	O
which	O
means	O
instead	O
of	O
TLM	O
training	O
,	O
we	O
augment	O
our	O
sentence	O
-	O
level	O
alignment	O
with	O
regular	O
MLM	O
on	O
monolingual	O
text	O
.	O
This	O
ablation	O
confirms	O
that	O
the	O
TLM	O
objective	O
helps	O
because	O
of	O
its	O
word	O
alignment	O
capability	O
,	O
not	O
because	O
we	O
train	O
the	O
encoders	O
with	O
more	O
data	O
and	O
iterations	O
.	O

beddings	O
using	O
parallel	O
data	O
.	O
They	O
learn	O
a	O
linear	O
transformation	O
that	O
maps	O
a	O
word	O
embedding	O
in	O
a	O
target	O
language	O
to	O
the	O
embedding	O
of	O
the	O
aligned	O
word	O
in	O
the	O
source	O
language	O
.	O
They	O
show	O
that	O
their	O
transformed	O
embeddings	O
are	O
more	O
effective	O
on	O
zero	O
-	O
shot	O
cross	O
-	O
lingual	O
dependency	O
parsing	O
.	O

Besides	O
the	O
aforementioned	O
three	O
major	O
directions	O
,	O
Artetxe	O
and	O
Schwenk	O
(	O
2019	O
)	O
train	O
a	O
multilingual	O
sentence	O
encoder	O
on	O
93	O
languages	O
.	O
Their	O
stacked	O
BiLSTM	O
encoder	O
is	O
trained	O
by	O
first	O
generating	O
embedding	O
of	O
a	O
source	O
sentence	O
and	O
then	O
decoding	O
the	O
embedding	O
into	O
the	O
target	O
sentence	O
in	O
other	O
languages	O
.	O

Concurrent	O
to	O
our	O
work	O
,	O
Chi	O
et	O
al	O
.	O
(	O
2020	O
)	O
,	O
Feng	O
et	O
al	O
.	O
(	O
2020	O
and	O
also	O
leverage	O
variants	O
of	O
contrastive	O
learning	O
for	O
cross	O
-	O
lingual	O
alignment	O
.	O
We	O
focus	O
on	O
a	O
smaller	O
model	O
and	O
improve	O
on	O
it	O
using	O
as	O
little	O
parallel	O
data	O
as	O
possible	O
.	O
We	O
also	O
explore	O
code	O
-	O
switching	O
during	O
finetuning	O
on	O
downtream	O
tasks	O
to	O
complement	O
the	O
post	O
-	O
pretraining	O
alignment	O
objectives	O
.	O

Conclusion	O

Post	O
-	O
pretraining	O
embedding	O
alignment	O
is	O
an	O
efficient	O
means	O
of	O
improving	O
cross	O
-	O
lingual	O
transferability	O
of	O
pretrained	O
multilingual	O
LMs	O
,	O
especially	O
when	O
pretraining	O
from	O
scratch	O
is	O
not	O
feasible	O
.	O
We	O
showed	O
that	O
our	O
self	O
-	O
supervised	O
sentence	O
-	O
level	O
and	O
word	O
-	O
level	O
alignment	O
tasks	O
can	O
greatly	O
improve	O
mBERT	O
's	O
performance	O
on	O
downstream	O
tasks	O
of	O
NLI	O
and	O
QA	O
,	O
and	O
the	O
method	O
can	O
potentially	O
be	O
applied	O
to	O
improve	O
other	O
pretrained	O
multilingual	O
LMs	O
.	O

In	O
addition	O
to	O
zero	O
-	O
shot	O
cross	O
-	O
lingual	O
transfer	O
,	O
we	O
also	O
showed	O
that	O
code	O
-	O
switching	O
with	O
English	O
during	O
finetuning	O
provides	O
additional	O
alignment	O
signals	O
,	O
when	O
training	O
data	O
is	O
available	O
for	O
the	O
target	O
language	O
.	O

Aspect	O
-	O
Controlled	O
Neural	O
Argument	O
Generation	O

We	O
rely	O
on	O
arguments	O
in	O
our	O
daily	O
lives	O
to	O
deliver	O
our	O
opinions	O
and	O
base	O
them	O
on	O
evidence	O
,	O
making	O
them	O
more	O
convincing	O
in	O
turn	O
.	O
However	O
,	O
finding	O
and	O
formulating	O
arguments	O
can	O
be	O
challenging	O
.	O
In	O
this	O
work	O
,	O
we	O
present	O
the	O
Arg	O
-	O
CTRL	O
-	O
a	O
language	O
model	O
for	O
argument	O
generation	O
that	O
can	O
be	O
controlled	O
to	O
generate	O
sentence	O
-	O
level	O
arguments	O
for	O
a	O
given	O
topic	O
,	O
stance	O
,	O
and	O
aspect	O
.	O
We	O
define	O
argument	O
aspect	O
detection	O
as	O
a	O
necessary	O
method	O
to	O
allow	O
this	O
fine	O
-	O
granular	O
control	O
and	O
crowdsource	O
a	O
dataset	O
with	O
5,032	O
arguments	O
annotated	O
with	O
aspects	O
.	O
Our	O
evaluation	O
shows	O
that	O
the	O
Arg	O
-	O
CTRL	O
is	O
able	O
to	O
generate	O
high	O
-	O
quality	O
,	O
aspectspecific	O
arguments	O
,	O
applicable	O
to	O
automatic	O
counter	O
-	O
argument	O
generation	O
.	O
We	O
publish	O
the	O
model	O
weights	O
and	O
all	O
datasets	O
and	O
code	O
to	O
train	O
the	O
Arg	O
-	O
CTRL	O
.	O
1	O
Nuclear	O
reactors	O
produce	O
radioactive	O
waste	O
...	O

Introduction	O

Language	O
models	O
(	O
Bengio	O
et	O
al	O
.	O
,	O
2003	O
)	O
allow	O
to	O
generate	O
text	O
through	O
learned	O
distributions	O
of	O
a	O
language	O
and	O
have	O
been	O
applied	O
to	O
a	O
variety	O
of	O
areas	O
like	O
machine	O
translation	O
(	O
Bahdanau	O
et	O
al	O
.	O
,	O
2015	O
)	O
,	O
summarization	O
(	O
Paulus	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
or	O
dialogue	O
systems	O
(	O
Wen	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
A	O
rather	O
new	O
field	O
for	O
these	O
models	O
is	O
the	O
task	O
of	O
producing	O
text	O
with	O
argumentative	O
content	O
(	O
Wang	O
and	O
Ling	O
,	O
2016	O
)	O
.	O
We	O
believe	O
this	O
technology	O
can	O
support	O
humans	O
in	O
the	O
challenging	O
task	O
of	O
finding	O
and	O
formulating	O
arguments	O
.	O
A	O
politician	O
might	O
use	O
this	O
to	O
prepare	O
for	O
a	O
debate	O
with	O
a	O
political	O
opponent	O
or	O
for	O
a	O
press	O
conference	O
.	O
It	O
may	O
be	O
used	O
to	O
support	O
students	O
in	O
writing	O
argumentative	O
essays	O
or	O
to	O
enrich	O
one	O
-	O
sided	O
discussions	O
with	O
counter	O
-	O
arguments	O
.	O
In	O
contrast	O
to	O
retrieval	O
methods	O
,	O
generation	O
allows	O
to	O
combine	O
and	O
stylistically	O
adapt	O
text	O
(	O
e.g.	O
arguments	O
)	O
based	O
on	O
a	O
given	O
input	O
(	O
usually	O
the	O
beginning	O
of	O
a	O
sentence	O
)	O
.	O
Current	O
argument	O
generation	O
models	O
,	O
however	O
,	O
produce	O
lengthy	O
texts	O
and	O
allow	O
the	O
user	O
little	O
control	O
over	O
the	O
aspect	O
the	O
argument	O
should	O
address	O
Hua	O
and	O
Wang	O
,	O
2018	O
)	O
.	O
We	O
show	O
that	O
argument	O
generation	O
can	O
be	O
enhanced	O
by	O
allowing	O
for	O
a	O
fine	O
-	O
grained	O
control	O
and	O
limiting	O
the	O
argument	O
to	O
a	O
single	O
but	O
concise	O
sentence	O
.	O

Controllable	O
language	O
models	O
like	O
the	O
CTRL	O
(	O
Keskar	O
et	O
al	O
.	O
,	O
2019	O
)	O
allow	O
to	O
condition	O
the	O
model	O
at	O
training	O
time	O
to	O
certain	O
control	O
codes	O
.	O
At	O
inference	O
,	O
these	O
can	O
be	O
used	O
to	O
direct	O
the	O
model	O
's	O
output	O
with	O
regard	O
to	O
content	O
or	O
style	O
.	O
We	O
build	O
upon	O
this	O
architecture	O
to	O
control	O
argument	O
generation	O
based	O
solely	O
on	O
a	O
given	O
topic	O
,	O
stance	O
,	O
and	O
argument	O
aspect	O
.	O
For	O
instance	O
,	O
to	O
enforce	O
focus	O
on	O
the	O
aspect	O
of	O
cancer	O
for	O
the	O
topic	O
of	O
nuclear	O
energy	O
,	O
we	O
input	O
a	O
control	O
code	O
"	O
Nuclear	O
Energy	O
CON	O
cancer	O
"	O
that	O
creates	O
a	O
contra	O
argument	O
discussing	O
this	O
aspect	O
,	O
for	O
instance	O
:	O
"	O
Studies	O
show	O
that	O
people	O
living	O
next	O
to	O
nuclear	O
power	O
plants	O
have	O
a	O
higher	O
risk	O
of	O
developing	O
cancer	O
.	O
"	O
.	O

To	O
obtain	O
control	O
codes	O
from	O
training	O
data	O
,	O
we	O
pre	O
-	O
define	O
a	O
set	O
of	O
topics	O
to	O
retrieve	O
documents	O
for	O
and	O
rely	O
on	O
an	O
existing	O
stance	O
detection	O
model	O
to	O
classify	O
whether	O
a	O
sentence	O
argues	O
in	O
favor	O
(	O
pro	O
)	O
or	O
against	O
(	O
con	O
)	O
the	O
given	O
topic	O
(	O
Stab	O
et	O
al	O
.	O
,	O
2018a	O
)	O
.	O
Regarding	O
argument	O
aspect	O
detection	O
,	O
however	O
,	O
past	O
work	O
has	O
two	O
drawbacks	O
:	O
it	O
either	O
uses	O
simple	O
rule	O
-	O
based	O
extraction	O
of	O
verb	O
-	O
and	O
noun	O
-	O
phrases	O
(	O
Fujii	O
and	O
Ishikawa	O
,	O
2006	O
)	O
or	O
the	O
definition	O
of	O
aspects	O
is	O
based	O
on	O
target	O
-	O
concepts	O
located	O
within	O
the	O
same	O
sentence	O
(	O
Gemechu	O
and	O
Reed	O
,	O
2019	O
)	O
.	O
Aspects	O
as	O
we	O
require	O
and	O
define	O
them	O
are	O
not	O
bound	O
to	O
any	O
part	O
-	O
of	O
-	O
speech	O
tag	O
and	O
(	O
1	O
)	O
hold	O
the	O
core	O
reason	O
upon	O
which	O
the	O
conclusion	O
/	O
evidence	O
is	O
built	O
and	O
(	O
2	O
)	O
encode	O
the	O
stance	O
towards	O
a	O
general	O
but	O
not	O
necessarily	O
explicitly	O
mentioned	O
topic	O
the	O
argument	O
discusses	O
.	O
For	O
instance	O
:	O

Topic	O
:	O
Nuclear	O
Energy	O
Argument	O
:	O
Running	O
nuclear	O
reactors	O
is	O
costly	O
as	O
it	O
involves	O
long	O
-	O
time	O
disposal	O
of	O
radioactive	O
waste	O
.	O

The	O
evidence	O
of	O
this	O
argument	O
is	O
based	O
upon	O
the	O
two	O
underlined	O
aspects	O
.	O
While	O
these	O
aspects	O
encode	O
a	O
negative	O
stance	O
towards	O
the	O
topic	O
of	O
"	O
Nuclear	O
Energy	O
"	O
,	O
the	O
topic	O
itself	O
is	O
not	O
mentioned	O
explicitly	O
in	O
the	O
argument	O
.	O

Our	O
final	O
controlled	O
argument	O
generation	O
pipeline	O
(	O
see	O
Figure	O
1	O
)	O
works	O
as	O
follows	O
:	O
(	O
1	O
)	O
We	O
gather	O
several	O
million	O
documents	O
for	O
eight	O
different	O
topics	O
from	O
two	O
large	O
data	O
sources	O
.	O
All	O
sentences	O
are	O
classified	O
into	O
pro-	O
,	O
con-	O
,	O
and	O
non	O
-	O
arguments	O
.	O
We	O
detect	O
aspects	O
of	O
all	O
arguments	O
with	O
a	O
model	O
trained	O
on	O
a	O
novel	O
dataset	O
and	O
concatenate	O
arguments	O
with	O
the	O
same	O
topic	O
,	O
stance	O
,	O
and	O
aspect	O
into	O
training	O
documents	O
.	O
(	O
2	O
)	O
We	O
use	O
the	O
collected	O
classified	O
data	O
to	O
condition	O
the	O
Arg	O
-	O
CTRL	O
on	O
the	O
topics	O
,	O
stances	O
,	O
and	O
aspects	O
of	O
all	O
gathered	O
arguments	O
.	O

(	O
3	O
)	O
At	O
inference	O
,	O
passing	O
the	O
control	O
code	O
[	O
Topic	O
]	O
[	O
Stance	O
]	O
[	O
Aspect	O
]	O
to	O
the	O
model	O
will	O
generate	O
an	O
argument	O
that	O
follows	O
these	O
commands	O
.	O

Our	O
evaluation	O
shows	O
that	O
the	O
Arg	O
-	O
CTRL	O
is	O
able	O
to	O
produce	O
aspect	O
-	O
specific	O
,	O
high	O
-	O
quality	O
arguments	O
,	O
applicable	O
to	O
automatic	O
counter	O
-	O
argument	O
generation	O
.	O
The	O
contributions	O
are	O
as	O
follows	O
:	O
(	O
i	O
)	O
We	O
adapt	O
and	O
fine	O
-	O
tune	O
the	O
CTRL	O
for	O
aspect	O
-	O
controlled	O
neural	O
argument	O
generation	O
.	O
(	O
ii	O
)	O
We	O
show	O
that	O
detecting	O
argument	O
aspects	O
and	O
conditioning	O
the	O
generation	O
model	O
on	O
them	O
are	O
necessary	O
steps	O
to	O
control	O
the	O
model	O
's	O
training	O
process	O
and	O
its	O
perspective	O
while	O
generating	O
.	O
(	O
iii	O
)	O
We	O
propose	O
several	O
methods	O
to	O
analyze	O
and	O
evaluate	O
the	O
quality	O
of	O
(	O
controllable	O
)	O
argument	O
generation	O
models	O
.	O
(	O
iv	O
)	O
We	O
develop	O
a	O
new	O
scheme	O
to	O
annotate	O
argument	O
aspects	O
and	O
release	O
a	O
dataset	O
with	O
5,032	O
samples	O
.	O

Related	O
Work	O

Argument	O
Aspect	O
Detection	O
Early	O
work	O
by	O
Fujii	O
and	O
Ishikawa	O
(	O
2006	O
)	O
focuses	O
mainly	O
on	O
Japanese	O
and	O
restricts	O
aspects	O
to	O
noun	O
-	O
and	O
verb	O
-	O
phrases	O
,	O
extracted	O
via	O
hand	O
-	O
crafted	O
rules	O
.	O
Boltužić	O
and	O
Šnajder	O
(	O
2017	O
)	O
extract	O
noun	O
-	O
phrases	O
and	O
aggregate	O
them	O
into	O
concepts	O
to	O
analyze	O
the	O
microstructure	O
of	O
claims	O
.	O
Misra	O
et	O
al	O
.	O
(	O
2015	O
)	O
introduce	O
facets	O
as	O
low	O
level	O
issues	O
,	O
used	O
to	O
support	O
or	O
attack	O
an	O
argumentation	O
.	O
In	O
that	O
,	O
facets	O
are	O
conceptually	O
similar	O
to	O
aspects	O
,	O
but	O
not	O
explicitly	O
phrased	O
and	O
instead	O
seen	O
as	O
abstract	O
concepts	O
that	O
define	O
clusters	O
of	O
semantically	O
similar	O
text	O
-	O
spans	O
of	O
summaries	O
.	O
Bilu	O
et	O
al	O
.	O
(	O
2019	O
)	O
define	O
commonplace	O
arguments	O
that	O
are	O
valid	O
in	O
several	O
situations	O
for	O
specified	O
actions	O
(	O
e.g.	O
"	O
ban	O
"	O
)	O
and	O
topics	O
(	O
e.g.	O
"	O
smoking	O
"	O
)	O
.	O
These	O
actions	O
are	O
similar	O
to	O
aspects	O
,	O
but	O
limited	O
in	O
number	O
and	O
manually	O
defined	O
.	O
Gemechu	O
and	O
Reed	O
(	O
2019	O
)	O
detect	O
,	O
amongst	O
others	O
,	O
concepts	O
and	O
aspects	O
in	O
arguments	O
with	O
models	O
trained	O
on	O
expert	O
annotations	O
.	O
However	O
,	O
in	O
their	O
definition	O
,	O
aspects	O
have	O
to	O
point	O
to	O
a	O
target	O
concept	O
mentioned	O
in	O
the	O
argument	O
.	O
In	O
our	O
definition	O
,	O
aspects	O
refer	O
to	O
a	O
general	O
topic	O
which	O
is	O
not	O
necessarily	O
part	O
of	O
the	O
sentence	O
and	O
our	O
annotation	O
scheme	O
is	O
applicable	O
by	O
non	O
-	O
experts	O
.	O

The	O
concept	O
of	O
framing	O
dimensions	O
(	O
Boydstun	O
et	O
al	O
.	O
,	O
2014	O
)	O
is	O
close	O
to	O
argument	O
aspects	O
.	O
In	O
the	O
field	O
of	O
argument	O
mining	O
,	O
Ajjour	O
et	O
al	O
.	O
(	O
2019	O
)	O
recently	O
applied	O
frames	O
to	O
label	O
argument	O
clusters	O
.	O
Yet	O
,	O
their	O
method	O
does	O
not	O
allow	O
to	O
detect	O
frames	O
.	O
Other	O
works	O
present	O
methods	O
to	O
automatically	O
label	O
sentences	O
of	O
news	O
articles	O
and	O
online	O
discussions	O
with	O
frames	O
(	O
Hartmann	O
et	O
al	O
.	O
,	O
2019;Naderi	O
and	O
Hirst	O
,	O
2017	O
)	O
.	O
These	O
methods	O
are	O
,	O
however	O
,	O
limited	O
to	O
a	O
small	O
set	O
of	O
predefined	O
frames	O
that	O
represent	O
high	O
-	O
level	O
concepts	O
.	O
Contrarily	O
,	O
we	O
operate	O
on	O
a	O
fine	O
-	O
grained	O
span	O
-	O
level	O
to	O
detect	O
aspects	O
that	O
are	O
explicitly	O
mentioned	O
in	O
arguments	O
.	O

Argument	O
Generation	O
Early	O
approaches	O
rely	O
on	O
rules	O
from	O
argumentation	O
theory	O
and	O
user	O
preference	O
models	O
(	O
Carenini	O
and	O
Moore	O
,	O
2006;Zukerman	O
et	O
al	O
.	O
,	O
1998	O
)	O
.	O
In	O
a	O
more	O
recent	O
work	O
,	O
Sato	O
et	O
al	O
.	O
(	O
2015	O
)	O
construct	O
rules	O
to	O
find	O
arguments	O
in	O
a	O
large	O
data	O
source	O
,	O
which	O
are	O
then	O
filtered	O
and	O
ordered	O
with	O
a	O
neural	O
network	O
based	O
ranker	O
.	O
Baff	O
et	O
al	O
.	O
(	O
2019	O
)	O
use	O
a	O
clustering	O
and	O
regression	O
approach	O
to	O
assemble	O
discourse	O
units	O
(	O
major	O
claims	O
,	O
pro	O
and	O
con	O
statements	O
)	O
to	O
argumentative	O
texts	O
.	O
However	O
,	O
most	O
of	O
these	O
approaches	O
rely	O
on	O
hand	O
-	O
crafted	O
features	O
and	O
do	O
not	O
generalize	O
well	O
.	O
Moreover	O
,	O
they	O
all	O
require	O
permanent	O
access	O
to	O
large	O
data	O
sources	O
and	O
are	O
not	O
able	O
to	O
generate	O
new	O
arguments	O
.	O

Recently	O
,	O
research	O
on	O
generating	O
arguments	O
with	O
language	O
models	O
gained	O
more	O
attention	O
.	O
use	O
a	O
sequence	O
to	O
sequence	O
model	O
(	O
Sutskever	O
et	O
al	O
.	O
,	O
2014	O
)	O
to	O
generate	O
argumentative	O
text	O
by	O
attending	O
to	O
the	O
input	O
and	O
keyphrases	O
automatically	O
extracted	O
for	O
the	O
input	O
from	O
,	O
for	O
example	O
,	O
Wikipedia	O
.	O
Other	O
work	O
focuses	O
on	O
generating	O
argumentative	O
dialogue	O
(	O
Le	O
et	O
al	O
.	O
,	O
2018	O
)	O
and	O
counterarguments	O
(	O
Hidey	O
and	O
McKeown	O
,	O
2019	O
;	O
based	O
on	O
a	O
given	O
input	O
sentence	O
,	O
or	O
on	O
generating	O
summaries	O
from	O
a	O
set	O
of	O
arguments	O
(	O
Wang	O
and	O
Ling	O
,	O
2016	O
)	O
.	O
Contrarily	O
,	O
we	O
train	O
a	O
language	O
model	O
that	O
does	O
not	O
require	O
a	O
sentence	O
-	O
level	O
input	O
for	O
generation	O
and	O
allows	O
for	O
direct	O
control	O
over	O
the	O
topic	O
,	O
stance	O
,	O
and	O
aspect	O
of	O
the	O
produced	O
argument	O
.	O
Xing	O
et	O
al	O
.	O
(	O
2017	O
)	O
design	O
a	O
language	O
model	O
that	O
attends	O
to	O
topic	O
information	O
to	O
generate	O
responses	O
for	O
chatbots	O
.	O
Dathathri	O
et	O
al	O
.	O
(	O
2019	O
)	O
train	O
two	O
models	O
that	O
control	O
the	O
sentiment	O
and	O
topic	O
of	O
the	O
output	O
of	O
pre	O
-	O
trained	O
language	O
models	O
at	O
inference	O
.	O
Gretz	O
et	O
al	O
.	O
(	O
2020a	O
)	O
fine	O
-	O
tune	O
GPT-2	O
on	O
existing	O
,	O
labeled	O
datasets	O
to	O
generate	O
claims	O
for	O
given	O
topics	O
.	O
However	O
,	O
the	O
latter	O
works	O
do	O
not	O
explore	O
generation	O
for	O
such	O
a	O
fine	O
-	O
grained	O
and	O
explicit	O
control	O
as	O
proposed	O
in	O
this	O
work	O
.	O
We	O
show	O
that	O
argument	O
generation	O
requires	O
the	O
concept	O
of	O
argument	O
aspects	O
to	O
shape	O
the	O
produced	O
argument	O
's	O
perspective	O
and	O
to	O
allow	O
for	O
diverse	O
arguments	O
for	O
a	O
topic	O
of	O
interest	O
.	O

Argument	O
Aspect	O
Detection	O

Argument	O
aspect	O
detection	O
is	O
necessary	O
for	O
our	O
argument	O
generation	O
pipeline	O
,	O
as	O
it	O
allows	O
for	O
a	O
finegrained	O
control	O
over	O
the	O
generation	O
process	O
.	O
We	O
create	O
a	O
new	O
dataset	O
,	O
as	O
existing	O
approaches	O
either	O
rely	O
on	O
coarse	O
-	O
grained	O
frames	O
or	O
can	O
not	O
be	O
applied	O
by	O
non	O
-	O
expert	O
annonators	O
in	O
a	O
scalable	O
manner	O
.	O

Dataset	O
Creation	O

We	O
base	O
our	O
new	O
aspect	O
detection	O
dataset	O
on	O
the	O
UKP	O
Sentential	O
Argument	O
Mining	O
Corpus	O
(	O
UKP	O
-	O
Corpus	O
)	O
by	O
Stab	O
et	O
al	O
.	O
(	O
2018b	O
)	O
,	O
as	O
it	O
already	O
contains	O
sentence	O
-	O
level	O
arguments	O
and	O
two	O
of	O
the	O
control	O
codes	O
we	O
aim	O
to	O
use	O
:	O
topics	O
and	O
stance	O
labels	O
.	O
More	O
precisely	O
,	O
it	O
contains	O
25,474	O
manually	O
labelled	O
sentences	O
for	O
eight	O
controversial	O
topics	O
in	O
English	O
.	O
Each	O
sample	O
consists	O
of	O
a	O
topic	O
and	O
a	O
sentence	O
,	O
labelled	O
as	O
either	O
being	O
supporting	O
,	O
attacking	O
,	O
or	O
no	O
argument	O
towards	O
the	O
given	O
topic	O
.	O
As	O
we	O
are	O
only	O
interested	O
in	O
arguments	O
,	O
we	O
do	O
not	O
consider	O
the	O
non	O
-	O
argumentative	O
sentences	O
.	O

Step	O
1	O
:	O
Preliminary	O
annotations	O
To	O
ensure	O
the	O
feasibility	O
of	O
creating	O
a	O
dataset	O
for	O
this	O
task	O
,	O
two	O
experts	O
(	O
a	O
post	O
-	O
doctoral	O
researcher	O
and	O
an	O
undergraduate	O
student	O
with	O
NLP	O
background	O
)	O
independently	O
annotate	O
800	O
random	O
samples	O
(	O
from	O
four	O
topics	O
,	O
200	O
per	O
topic	O
)	O
taken	O
from	O
the	O
UKP	O
-	O
Corpus	O
.	O
The	O
annotations	O
are	O
binary	O
and	O
on	O
token	O
-	O
level	O
,	O
where	O
multiple	O
spans	O
of	O
tokens	O
could	O
be	O
selected	O
as	O
aspects	O
.	O
The	O
resulting	O
inter	O
-	O
annotator	O
agreement	O
of	O
this	O
study	O
is	O
Krippendorff	O
's	O
α	O
u	O
=	O
.38	O
.	O
While	O
this	O
shows	O
that	O
the	O
task	O
is	O
generally	O
feasible	O
,	O
the	O
agreement	O
on	O
exact	O
token	O
spans	O
is	O
rather	O
low	O
.	O
Hence	O
,	O
in	O
the	O
following	O
steps	O
,	O
we	O
reduce	O
the	O
complexity	O
of	O
the	O
annotation	O
task	O
.	O

Step	O
2	O
:	O
Annotation	O
scheme	O
Instead	O
of	O
free	O
spanlevel	O
annotations	O
,	O
we	O
present	O
annotators	O
with	O
a	O
ranked	O
list	O
of	O
aspect	O
recommendations	O
.	O
To	O
generate	O
meaningful	O
recommendations	O
,	O
we	O
train	O
a	O
ranking	O
model	O
using	O
the	O
preliminary	O
annotations	O
(	O
Step	O
1	O
)	O
.	O

Step	O
2a	O
:	O
Data	O
preparation	O
for	O
ranking	O
To	O
create	O
training	O
data	O
for	O
the	O
ranker	O
,	O
we	O
use	O
a	O
simple	O
heuristic	O
to	O
calculate	O
scores	O
between	O
0	O
and	O
1	O
for	O
all	O
N	O
-	O
grams	O
of	O
a	O
sentence	O
by	O
dividing	O
the	O
number	O
of	O
aspect	O
tokens	O
within	O
an	O
N	O
-	O
gram	O
by	O
its	O
length	O
N	O
:	O
#	O
aspect	O
tokens	O
N	O
∈	O
[	O
0	O
,	O
1	O
]	O
.	O
Our	O
analysis	O
reveals	O
that	O
96	O
%	O
(	O
783	O
of	O
814	O
)	O
of	O
all	O
aspects	O
in	O
the	O
preliminary	O
annotation	O
dataset	O
only	O
contain	O
one	O
to	O
four	O
tokens	O
.	O
We	O
thus	O
decide	O
to	O
ignore	O
all	O
candidates	O
with	O
more	O
than	O
four	O
tokens	O
.	O
No	O
other	O
limitations	O
or	O
filtering	O
mechanisms	O
are	O
applied	O
.	O

Step	O
2b	O
:	O
Training	O
the	O
ranker	O
We	O
use	O
BERT	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
MT	O
-	O
DNN	O
2	O
(	O
base	O
and	O
large	O
)	O
to	O
train	O
a	O
ranker	O
.	O
For	O
training	O
,	O
we	O
create	O
five	O
splits	O
:	O
(	O
1	O
)	O
one	O
in	O
-	O
topic	O
split	O
using	O
a	O
random	O
subset	O
from	O
all	O
four	O
topics	O
and	O
(	O
2	O
)	O
four	O

Topic	O

Five	O
most	O
frequent	O
aspects	O
(	O
frequency	O
)	O
Gun	O
control	O
right	O
(	O
30	O
)	O
,	O
protect	O
(	O
18	O
)	O
,	O
background	O
checks	O
(	O
17	O
)	O
,	O
gun	O
violence	O
(	O
14	O
)	O
,	O
criminal	O
(	O
13	O
)	O
Death	O
penalty	O
cost	O
(	O
16	O
)	O
,	O
innocent	O
(	O
12	O
)	O
,	O
retribution	O
(	O
10	O
)	O
,	O
murder	O
rate	O
(	O
9	O
)	O
,	O
deterrent	O
(	O
8)	O
Abortion	O
right	O
(	O
21	O
)	O
,	O
pain	O
(	O
10	O
)	O
,	O
choice	O
(	O
10	O
)	O
,	O
right	O
to	O
life	O
(	O
9	O
)	O
,	O
risk	O
(	O
9	O
)	O
Marijuana	O
legalization	O
dangerous	O
(	O
16	O
)	O
,	O
cost	O
(	O
13	O
)	O
,	O
risk	O
(	O
12	O
)	O
,	O
harm	O
(	O
10	O
)	O
,	O
black	O
market	O
(	O
9	O
)	O
General	O
aspects	O
dangerous	O
(	O
in	O
8	O
of	O
8	O
topics	O
)	O
,	O
cost	O
/	O
life	O
/	O
risk	O
/	O
safety	O
(	O
in	O
7	O
of	O
8	O
topics	O
)	O
cross	O
-	O
topic	O
splits	O
using	O
a	O
leave	O
-	O
one	O
-	O
topic	O
-	O
out	O
strategy	O
.	O
The	O
cross	O
-	O
topic	O
setup	O
allows	O
us	O
to	O
estimate	O
the	O
ranker	O
's	O
performance	O
on	O
unseen	O
topics	O
of	O
the	O
UKP	O
-	O
Corpus	O
.	O

A	O
single	O
data	O
sample	O
is	O
represented	O
by	O
an	O
argument	O
and	O
an	O
1	O
-	O
to	O
4	O
-	O
gram	O
of	O
this	O
argument	O
,	O
separated	O
by	O
the	O
BERT	O
architecture	O
's	O
[	O
SEP	O
]	O
token	O
.	O
This	O
technique	O
expands	O
the	O
800	O
original	O
samples	O
of	O
the	O
dataset	O
to	O
around	O
80,336	O
.	O
The	O
model	O
is	O
trained	O
for	O
5	O
epochs	O
,	O
with	O
a	O
learning	O
rate	O
of	O
5	O
×	O
10	O
−5	O
,	O
and	O
a	O
batch	O
size	O
of	O
8	O
.	O
We	O
use	O
the	O
mean	O
squared	O
error	O
as	O
loss	O
and	O
take	O
the	O
recall@k	O
to	O
compare	O
the	O
models	O
.	O
The	O
in	O
-	O
and	O
cross	O
-	O
topic	O
results	O
of	O
the	O
bestperforming	O
model	O
(	O
MT	O
-	O
DNN	O
BASE	O
)	O
are	O
reported	O
in	O
Table	O
2	O
.	O
All	O
results	O
are	O
the	O
average	O
over	O
runs	O
with	O
five	O
different	O
seeds	O
(	O
and	O
over	O
all	O
four	O
splits	O
for	O
the	O
cross	O
-	O
topic	O
experiments	O
)	O
.	O

Step	O
2c	O
:	O
Creating	O
the	O
annotation	O
data	O
For	O
each	O
of	O
the	O
four	O
topics	O
that	O
are	O
part	O
of	O
the	O
preliminary	O
annotation	O
dataset	O
,	O
we	O
use	O
the	O
in	O
-	O
topic	O
model	O
to	O
predict	O
aspects	O
of	O
629	O
randomly	O
chosen	O
,	O
unseen	O
arguments	O
from	O
the	O
UKP	O
-	O
Corpus	O
.	O
For	O
the	O
other	O
four	O
topics	O
of	O
the	O
UKP	O
-	O
Corpus	O
,	O
we	O
choose	O
the	O
best	O
cross	O
-	O
topic	O
model	O
to	O
predict	O
aspects	O
for	O
the	O
same	O
amount	O
of	O
samples	O
.	O
To	O
keep	O
a	O
recall	O
of	O
at	O
least	O
80	O
%	O
,	O
we	O
choose	O
the	O
ten	O
and	O
fifteen	O
highest	O
-	O
ranked	O
aspect	O
candidates	O
for	O
samples	O
as	O
predicted	O
by	O
the	O
in	O
-	O
topic	O
and	O
cross	O
-	O
topic	O
model	O
,	O
respectively	O
.	O
We	O
remove	O
aspect	O
candidates	O
that	O
include	O
punctuation	O
,	O
begin	O
or	O
end	O
with	O
stopwords	O
,	O
or	O
contain	O
digits	O
.	O

Step	O
3	O
:	O
Annotation	O
study	O
We	O
use	O
Amazon	O
Mechanical	O
Turk	O
to	O
annotate	O
each	O
sample	O
by	O
eight	O
different	O
workers	O
located	O
in	O
the	O
US	O
,	O
paying	O
$	O
7.6	O
per	O
hour	O
(	O
minimum	O
wage	O
is	O
$	O
7.25	O
per	O
hour	O
)	O
.	O
Based	O
on	O
a	O
subset	O
of	O
232	O
samples	O
,	O
we	O
compute	O
an	O
α	O
u	O
of	O
.67	O
between	O
crowdworkers	O
and	O
experts	O
(	O
three	O
doctoral	O
researchers	O
)	O
.	O
Compared	O
to	O
the	O
initial	O
study	O
,	O
the	O
new	O
approach	O
increases	O
the	O
inter	O
-	O
annotator	O
agreement	O
between	O
experts	O
by	O
approx	O
.	O
11	O
points	O
(	O
see	O
App	O
.	O
A	O
for	O
further	O
details	O
on	O
the	O
annotation	O
study	O
)	O
.	O
Based	O
on	O
this	O
promising	O
result	O
,	O
we	O
create	O
a	O
dataset	O
of	O
5,032	O
high	O
-	O
quality	O
samples	O
that	O
are	O
labelled	O
with	O
aspects	O
,	O
as	O
well	O
as	O
with	O
their	O
original	O
stance	O
labels	O
from	O
the	O
UKP	O
-	O
Corpus	O
.	O
We	O
show	O
the	O
most	O
frequent	O
(	O
lemmatized	O
)	O
aspects	O
that	O
appear	O
in	O
some	O
topics	O
in	O
Table	O
1	O
.	O

Evaluation	O

We	O
create	O
a	O
cross	O
-	O
topic	O
split	O
with	O
the	O
data	O
of	O
two	O
topics	O
as	O
test	O
set	O
(	O
gun	O
control	O
,	O
school	O
uniforms	O
)	O
,	O
one	O
topic	O
as	O
dev	O
set	O
(	O
death	O
penalty	O
)	O
,	O
and	O
the	O
remaining	O
topics	O
as	O
train	O
set	O
and	O
evaluate	O
two	O
models	O
with	O
it	O
.	O
First	O
,	O
we	O
use	O
the	O
ranking	O
approach	O
described	O
in	O
Step	O
2a-2b	O
to	O
fine	O
-	O
tune	O
MT	O
-	O
DNN	O
BASE	O
on	O
the	O
newly	O
generated	O
data	O
(	O
"	O
Ranker	O
"	O
)	O
.	O
At	O
inference	O
,	O
we	O
choose	O
the	O
top	O
T	O
aspects	O
for	O
each	O
argument	O
as	O
candidates	O
.	O
We	O
tune	O
T	O
on	O
the	O
dev	O
set	O
and	O
find	O
T	O
=	O
2	O
to	O
be	O
the	O
best	O
choice	O
.	O
Second	O
,	O
we	O
use	O
BERT	O
for	O
sequence	O
tagging	O
(	O
Wolf	O
et	O
al	O
.	O
,	O
2020	O
)	O
and	O
label	O
all	O
tokens	O
of	O
the	O
samples	O
with	O
BIO	O
tags	O
.	O
As	O
previously	O
done	O
with	O
the	O
ranker	O
,	O
we	O
experiment	O
with	O
BERT	O
and	O
MT	O
-	O
DNN	O
weights	O
and	O
find	O
BERT	O
LARGE	O
to	O
be	O
the	O
best	O
choice	O
(	O
trained	O
for	O
5	O
epochs	O
,	O
with	O
a	O
learning	O
rate	O
of	O
1	O
×	O
10	O
−5	O
and	O
a	O
batch	O
size	O
of	O
32	O
)	O
.	O
We	O
flatten	O
the	O
predictions	O
for	O
all	O
test	O
samples	O
and	O
calculate	O
the	O
F	O
1	O
,	O
Precision	O
,	O
and	O
Recall	O
macro	O
scores	O
.	O
All	O
models	O
are	O
trained	O
over	O
five	O
seeds	O
and	O
the	O
averaged	O
results	O
are	O
reported	O
in	O
Table	O
3	O
.	O

Data	O
Collection	O
Pipeline	O

This	O
section	O
describes	O
the	O
data	O
collection	O
and	O
preprocessing	O
for	O
the	O
argument	O
generation	O
pipeline	O
.	O

BERT	O
LARGE	O
predicts	O
classes	O
B	O
and	O
I	O
with	O
an	O
F	O
1	O
of	O
.65	O
and	O
.53	O
,	O
hence	O
aspects	O
with	O
more	O
than	O
one	O
token	O
are	O
less	O
well	O
identified	O
.	O
A	O
difference	O
is	O
to	O
be	O
expected	O
,	O
as	O
the	O
class	O
balance	O
of	O
B	O
's	O
to	O
I	O
's	O
is	O
2,768	O
to	O
2,103	O
.	O
While	O
the	O
ranker	O
performs	O
worse	O
based	O
on	O
the	O
shown	O
metrics	O
,	O
it	O
has	O
a	O
slightly	O
higher	O
recall	O
for	O
class	O
I.	O
We	O
assume	O
this	O
is	O
due	O
to	O
the	O
fact	O
that	O
it	O
generally	O
ranks	O
aspects	O
with	O
more	O
than	O
one	O
token	O
on	O
top	O
,	O
i.e.	O
there	O
will	O
often	O
be	O
at	O
least	O
one	O
or	O
more	O
I	O
's	O
in	O
the	O
prediction	O
.	O
In	O
contrast	O
to	O
that	O
,	O
BERT	O
LARGE	O
focuses	O
more	O
on	O
shorter	O
aspects	O
,	O
which	O
is	O
also	O
in	O
accordance	O
with	O
the	O
average	O
aspect	O
length	O
of	O
1.8	O
tokens	O
per	O
aspect	O
in	O
the	O
dataset	O
.	O
In	O
total	O
,	O
BERT	O
LARGE	O
outperforms	O
the	O
ranker	O
by	O
almost	O
6	O
percentage	O
points	O
in	O
F	O
1	O
macro	O
.	O

We	O
aim	O
to	O
train	O
a	O
model	O
that	O
is	O
able	O
to	O
transfer	O
argumentative	O
information	O
concisely	O
within	O
a	O
single	O
sentence	O
.	O
We	O
define	O
such	O
an	O
argument	O
as	O
the	O
combination	O
of	O
a	O
topic	O
and	O
a	O
sentence	O
holding	O
evidence	O
with	O
a	O
specific	O
stance	O
towards	O
this	O
topic	O
(	O
Stab	O
et	O
al	O
.	O
,	O
2018b	O
)	O
.	O
Consequently	O
,	O
the	O
following	O
preprocessing	O
steps	O
ultimately	O
target	O
retrieval	O
and	O
classification	O
of	O
sentences	O
.	O
To	O
evaluate	O
different	O
data	O
sources	O
,	O
we	O
use	O
a	O
dump	O
from	O
Common-	O
We	O
notice	O
that	O
many	O
sentences	O
are	O
not	O
relevant	O
with	O
regard	O
to	O
the	O
document	O
's	O
topic	O
.	O
To	O
enforce	O
topicrelevance	O
,	O
we	O
decide	O
to	O
filter	O
out	O
all	O
sentences	O
that	O
do	O
not	O
contain	O
at	O
least	O
one	O
token	O
of	O
the	O
respective	O
topic	O
or	O
its	O
defined	O
synonyms	O
(	O
see	O
App	O
.	O
B	O
)	O
.	O
We	O
use	O
the	O
ArgumenText	O
API	O
's	O
6	O
argument	O
and	O
stance	O
classification	O
models	O
(	O
Stab	O
et	O
al	O
.	O
,	O
2018a	O
)	O
to	O
classify	O
all	O
sentences	O
into	O
argument	O
or	O
non	O
-	O
argument	O
(	O
F	O
1	O
macro	O
=	O
.7384	O
)	O
,	O
and	O
remaining	O
arguments	O
into	O
pro	O
or	O
con	O
with	O
regard	O
to	O
the	O
topic	O
(	O
F	O
1	O
macro	O
=	O
.7661	O
)	O
.	O

Aspect	O
Detection	O
We	O
detect	O
aspects	O
on	O
all	O
remaining	O
arguments	O
.	O
To	O
speed	O
up	O
the	O
detection	O
on	O
millions	O
of	O
sentences	O
,	O
we	O
use	O
BERT	O
BASE	O
instead	O
of	O
BERT	O
LARGE	O
(	O
see	O
Table	O
3	O
)	O
.	O

Training	O
Document	O
Generation	O
We	O
create	O
the	O
final	O
training	O
documents	O
for	O
the	O
argument	O
generation	O
model	O
by	O
concatenating	O
all	O
arguments	O
that	O
have	O
the	O
same	O
topic	O
,	O
stance	O
,	O
and	O
aspect	O
(	O
i.e.	O
the	O
same	O
control	O
code	O
)	O
.	O
Further	O
,	O
we	O
aggregate	O
all	O
arguments	O
that	O
include	O
an	O
aspect	O
with	O
the	O
same	O
stem	O
into	O
the	O
same	O
document	O
(	O
e.g.	O
arguments	O
with	O
cost	O
and	O
costs	O
as	O
aspect	O
)	O
.	O
To	O
cope	O
with	O
limited	O
hardware	O
resources	O
,	O
we	O
restrict	O
the	O
total	O
number	O
of	O
arguments	O
for	O
each	O
topic	O
and	O
stance	O
to	O
100,000	O
(	O
i.e.	O
1.6	O
M	O
over	O
all	O
eight	O
topics	O
)	O
.	O
Also	O
,	O
as	O
some	O
aspects	O
dominate	O
by	O
means	O
of	O
quantity	O
of	O
related	O
arguments	O
and	O
others	O
appear	O
only	O
rarely	O
,	O
we	O
empirically	O
determine	O
an	O
upper	O
and	O
lower	O
bound	O
of	O
1,500	O
and	O
15	O
arguments	O
for	O
each	O
document	O
,	O
which	O
still	O
allows	O
us	O
to	O
retrieve	O
the	O
above	O
defined	O
amount	O
of	O
training	O
arguments	O
.	O

Model	O
Training	O
and	O
Analysis	O

In	O
the	O
following	O
,	O
we	O
describe	O
the	O
architecture	O
and	O
the	O
training	O
process	O
of	O
the	O
Arg	O
-	O
CTRL	O
and	O
analyze	O
its	O
performance	O
.	O

Model	O
and	O
Training	O

Model	O
The	O
goal	O
of	O
a	O
statistical	O
language	O
model	O
is	O
to	O
learn	O
the	O
conditional	O
probability	O
of	O
the	O
next	O
word	O
given	O
all	O
(	O
or	O
a	O
subset	O
of	O
)	O
the	O
previous	O
ones	O
(	O
Bengio	O
et	O
al	O
.	O
,	O
2003	O
)	O
.	O
That	O
is	O
,	O
for	O
a	O
sequence	O
of	O
tokens	O
x	O
=	O
(	O
x	O
1	O
,	O
...	O
,	O
x	O
n	O
)	O
,	O
the	O
model	O
learns	O
p(x	O
i	O
|x	O
<	O
i	O
)	O
where	O
x	O
i	O
is	O
the	O
i	O
-	O
th	O
word	O
of	O
sequence	O
x.	O
For	O
this	O
work	O
,	O
we	O
use	O
the	O
1.63	O
billion	O
-	O
parameter	O
Conditional	O
Transformer	O
Language	O
Model	O
(	O
CTRL	O
)	O
by	O
Keskar	O
et	O
al	O
.	O
(	O
2019	O
)	O
,	O
which	O
is	O
built	O
on	O
a	O
transformerbased	O
sequence	O
to	O
sequence	O
architecture	O
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
The	O
CTRL	O
has	O
shown	O
to	O
produce	O
high	O
quality	O
text	O
,	O
is	O
general	O
enough	O
to	O
be	O
adapted	O
for	O
conditioning	O
on	O
the	O
control	O
codes	O
we	O
aim	O
to	O
use	O
,	O
and	O
we	O
do	O
not	O
need	O
to	O
pre	O
-	O
train	O
the	O
weights	O
from	O
scratch	O
.	O
Formally	O
,	O
the	O
CTRL	O
adds	O
an	O
extra	O
condition	O
to	O
each	O
sequence	O
by	O
prepending	O
a	O
control	O
code	O
c	O
,	O
hence	O
learning	O
p(x	O
i	O
|x	O
<	O
i	O
,	O
c	O
)	O
.	O
The	O
control	O
code	O
is	O
represented	O
by	O
a	O
single	O
token	O
and	O
can	O
then	O
be	O
used	O
to	O
direct	O
the	O
model	O
output	O
at	O
inference	O
.	O
We	O
extend	O
the	O
model	O
from	O
its	O
previous	O
limit	O
of	O
a	O
singletoken	O
control	O
code	O
to	O
accept	O
multiple	O
tokens	O
.	O
For	O
The	O
respective	O
control	O
code	O
is	O
prepended	O
to	O
each	O
sequence	O
of	O
256	O
subwords	O
of	O
a	O
document	O
.	O

Analysis	O

Generation	O
At	O
inference	O
,	O
we	O
gather	O
multiple	O
generated	O
arguments	O
from	O
a	O
control	O
code	O
input	O
by	O
splitting	O
the	O
generated	O
output	O
text	O
into	O
sentences	O
with	O
NLTK	O
(	O
Bird	O
et	O
al	O
.	O
,	O
2009	O
)	O
.	O
We	O
observe	O
that	O
for	O
the	O
first	O
generated	O
argument	O
,	O
the	O
Arg	O
-	O
CTRL	O
mostly	O
outputs	O
very	O
short	O
phrases	O
,	O
as	O
it	O
tries	O
to	O
incorporate	O
the	O
control	O
code	O
into	O
a	O
meaningful	O
start	O
of	O
an	O
argument	O
.	O
We	O
prevent	O
this	O
by	O
adding	O
punctuation	O
marks	O
after	O
each	O
control	O
code	O
(	O
e.g.	O
a	O
period	O
or	O
colon	O
)	O
,	O
signaling	O
the	O
model	O
to	O
start	O
a	O
new	O
sentence	O
.	O
In	O
this	O
fashion	O
,	O
we	O
generate	O
proand	O
con	O
-	O
arguments	O
up	O
to	O
the	O
pre	O
-	O
defined	O
training	O
split	O
size	O
7	O
for	O
each	O
topic	O
of	O
the	O
UKP	O
-	O
Corpus	O
,	O
resulting	O
in	O
7,991	O
newly	O
generated	O
arguments	O
.	O
We	O
do	O
this	O
with	O
both	O
models	O
and	O
use	O
the	O
generated	O
arguments	O
as	O
a	O
basis	O
for	O
the	O
following	O
analysis	O
and	O
evaluation	O
methods	O
.	O
Examples	O
of	O
generated	O
arguments	O
can	O
be	O
found	O
in	O
Tables	O
4	O
,	O
6	O
,	O
and	O
7	O
(	O
as	O
part	O
of	O
the	O
evaluation	O
,	O
see	O
Section	O
7	O
)	O
.	O

Results	O
With	O
no	O
other	O
previous	O
work	O
on	O
explicit	O
control	O
of	O
argument	O
generation	O
(	O
to	O
the	O
best	O
of	O
our	O
knowledge	O
)	O
,	O
we	O
decide	O
to	O
proof	O
our	O
concept	O
of	O
aspect	O
-	O
controlled	O
neural	O
argument	O
generation	O
by	O
7	O
Not	O
counting	O
non	O
-	O
arguments	O
from	O
the	O
splits	O
.	O

comparing	O
both	O
generation	O
models	O
to	O
a	O
retrieval	O
approach	O
as	O
a	O
strong	O
upper	O
bound	O
.	O
The	O
retrieval	O
approach	O
returns	O
all	O
arguments	O
from	O
the	O
classified	O
training	O
data	O
(	O
see	O
Section	O
4	O
)	O
that	O
match	O
a	O
given	O
topic	O
,	O
stance	O
,	O
and	O
aspect	O
.	O
Both	O
the	O
retrieval	O
and	O
generation	O
approaches	O
are	O
evaluated	O
against	O
reference	O
data	O
from	O
debate	O
portals	O
and	O
compared	O
via	O
METEOR	O
(	O
Lavie	O
and	O
Agarwal	O
,	O
2007	O
)	O
and	O
ROUGE	O
-	O
L	O
(	O
Lin	O
,	O
2004	O
)	O
metrics	O
.	O
The	O
retrieval	O
approach	O
has	O
an	O
advantage	O
in	O
this	O
setup	O
,	O
as	O
the	O
arguments	O
are	O
also	O
of	O
human	O
origin	O
and	O
aspects	O
are	O
always	O
explicitly	O
stated	O
within	O
a	O
belonging	O
argument	O
.	O

The	O
reference	O
data	O
was	O
crawled	O
from	O
two	O
debate	O
portals	O
8	O
and	O
consists	O
of	O
pro	O
-	O
and	O
con	O
-	O
paragraphs	O
discussing	O
the	O
eight	O
topics	O
of	O
the	O
UKP	O
-	O
Corpus	O
.	O
As	O
the	O
paragraphs	O
may	O
include	O
non	O
-	O
arguments	O
,	O
we	O
filter	O
these	O
out	O
by	O
classifying	O
all	O
sentences	O
with	O
the	O
ArgumenText	O
API	O
into	O
arguments	O
and	O
nonarguments	O
.	O
This	O
leaves	O
us	O
with	O
349	O
pro	O
-	O
and	O
355	O
con	O
-	O
arguments	O
over	O
all	O
topics	O
(	O
see	O
App	O
.	O
D	O
for	O
the	O
topic	O
-	O
wise	O
distribution	O
)	O
.	O
Next	O
,	O
we	O
detect	O
all	O
aspects	O
in	O
these	O
arguments	O
.	O
Arguments	O
with	O
the	O
same	O
topic	O
,	O
stance	O
,	O
and	O
aspect	O
are	O
then	O
grouped	O
and	O
used	O
as	O
reference	O
for	O
arguments	O
from	O
the	O
(	O
a	O
)	O
generated	O
arguments	O
and	O
(	O
b	O
)	O
retrieval	O
approach	O
arguments	O
if	O
these	O
hold	O
the	O
same	O
topic	O
,	O
stance	O
,	O
and	O
aspect	O
.	O
The	O
results	O
reveal	O
that	O
both	O
the	O
average	O
METEOR	O
and	O
ROUGE	O
-	O
L	O
scores	O
are	O
only	O
marginally	O
lower	O
than	O
the	O
retrieval	O
scores	O
(	O
METEOR	O
is	O
0.5/1.1	O
points	O
lower	O
for	O
the	O
Arg	O
-	O
CTRL	O
REDDIT	O
/Arg	O
-	O
CTRL	O
CC	O
,	O
see	O
Table	O
5	O
)	O
.	O
It	O
not	O
only	O
shows	O
the	O
strength	O
of	O
the	O
architecture	O
,	O
but	O
also	O
the	O
success	O
in	O
generating	O
sound	O
aspect	O
-	O
specific	O
arguments	O
with	O
our	O
approach	O
.	O
Overlap	O
with	O
Training	O
Data	O
We	O
find	O
arguments	O
generated	O
by	O
the	O
models	O
to	O
be	O
genuine	O
,	O
i.e.	O
demonstrating	O
substantial	O
differences	O
to	O
the	O
training	O
data	O
.	O
For	O
each	O
of	O
the	O
7,991	O
generated	O
arguments	O
,	O
we	O
find	O
the	O
most	O
similar	O
argument	O
in	O
the	O
training	O
data	O
based	O
on	O
the	O
cosine	O
similarity	O
of	O
their	O
BERT	O
embeddings	O
We	O
compare	O
all	O
models	O
by	O
verifying	O
whether	O
or	O
not	O
the	O
aspect	O
used	O
for	O
generation	O
(	O
including	O
synonyms	O
and	O
their	O
stems	O
and	O
lemmas	O
)	O
can	O
be	O
found	O
in	O
the	O
generated	O
arguments	O
.	O
For	O
the	O
original	O
models	O
conditioned	O
on	O
aspects	O
,	O
this	O
is	O
true	O
in	O
79	O
%	O
of	O
Generated	O
sentence	O
:	O
We	O
do	O
n't	O
need	O
more	O
gun	O
control	O
laws	O
when	O
we	O
already	O
have	O
enough	O
restrictions	O
on	O
who	O
can	O
buy	O
guns	O
in	O
this	O
country	O
.	O

Training	O
sentence	O
:	O
We	O
have	O
some	O
of	O
the	O
strongest	O
gun	O
laws	O
in	O
the	O
country	O
,	O
but	O
guns	O
do	O
n't	O
respect	O
boundaries	O
any	O
more	O
than	O
criminals	O
do	O
.	O
Cosine	O
similarity	O
/	O
edit	O
distance	O
/	O
rel	O
.	O
overlap	O
:	O
95.59	O
/	O
88	O
/	O
8	O
%	O
Generated	O
sentence	O
:	O
The	O
radioactivity	O
of	O
the	O
spent	O
fuel	O
is	O
a	O
concern	O
,	O
as	O
it	O
can	O
be	O
used	O
to	O
make	O
weapons	O
and	O
has	O
been	O
linked	O
to	O
cancer	O
in	O
humans	O
.	O
Training	O
sentence	O
:	O
However	O
,	O
it	O
does	O
produce	O
radioactive	O
waste	O
,	O
which	O
must	O
be	O
disposed	O
of	O
carefully	O
as	O
it	O
can	O
cause	O
health	O
problems	O
and	O
can	O
be	O
used	O
to	O
make	O
nuclear	O
weapons	O
Cosine	O
similarity	O
/	O
edit	O
distance	O
/	O
rel	O
.	O
overlap	O
:	O
92.40	O
/	O
99	O
/	O
17	O
%	O
the	O
cases	O
for	O
Arg	O
-	O
CTRL	O
REDDIT	O
and	O
in	O
74	O
%	O
of	O
the	O
cases	O
for	O
Arg	O
-	O
CTRL	O
CC	O
.	O
For	O
the	O
model	O
that	O
was	O
not	O
conditioned	O
on	O
aspects	O
,	O
however	O
,	O
it	O
is	O
only	O
true	O
in	O
8	O
%	O
of	O
the	O
cases	O
.	O
It	O
clearly	O
shows	O
the	O
necessity	O
to	O
condition	O
the	O
model	O
on	O
aspects	O
explicitly	O
,	O
implying	O
the	O
need	O
for	O
argument	O
aspect	O
detection	O
,	O
as	O
the	O
model	O
is	O
unable	O
to	O
learn	O
generating	O
aspect	O
-	O
related	O
arguments	O
otherwise	O
.	O
Moreover	O
,	O
without	O
prior	O
detection	O
of	O
aspects	O
,	O
we	O
have	O
no	O
means	O
for	O
proper	O
aggregation	O
over	O
aspects	O
.	O
We	O
notice	O
that	O
for	O
the	O
model	O
without	O
prior	O
knowledge	O
of	O
aspects	O
,	O
79	O
%	O
of	O
all	O
aspects	O
in	O
the	O
training	O
data	O
appear	O
in	O
only	O
one	O
argument	O
.	O
For	O
these	O
aspects	O
,	O
the	O
model	O
will	O
likely	O
not	O
pick	O
up	O
a	O
strong	O
enough	O
signal	O
to	O
learn	O
them	O
.	O

Evaluation	O

We	O
evaluate	O
the	O
quality	O
(	O
intrinsic	O
evaluation	O
)	O
of	O
the	O
Arg	O
-	O
CTRL	O
and	O
its	O
performance	O
on	O
an	O
exemplary	O
task	O
(	O
extrinsic	O
evaluation	O
)	O
.	O
As	O
a	O
basis	O
,	O
we	O
use	O
the	O
7,991	O
arguments	O
generated	O
in	O
Section	O
5	O
.	O

Intrinsic	O
Evaluation	O

Human	O
Evaluation	O
We	O
conduct	O
an	O
expert	O
evaluation	O
on	O
a	O
subset	O
of	O
generated	O
arguments	O
with	O
two	O
researchers	O
(	O
field	O
of	O
expertise	O
is	O
natural	O
language	O
processing	O
)	O
not	O
involved	O
in	O
this	O
paper	O
.	O
Two	O
aspects	O
are	O
evaluated	O
:	O
fluency	O
and	O
persuasiveness	O
.	O
We	O
consider	O
a	O
sentence	O
as	O
fluent	O
if	O
it	O
is	O
grammatically	O
correct	O
,	O
i.e.	O
contains	O
neither	O
semantic	O
nor	O
syntactic	O
errors	O
,	O
and	O
arrange	O
this	O
as	O
a	O
binary	O
task	O
.	O
To	O
reduce	O
subjectivity	O
for	O
the	O
persuasiveness	O
evaluation	O
,	O
the	O
experts	O
do	O
not	O
annotate	O
single	O
arguments	O
but	O
instead	O
compare	O
pairs	O
(	O
Habernal	O
and	O
Gurevych	O
,	O
2016	O
)	O
of	O
generated	O
and	O
refer	O
-	O
ence	O
data	O
arguments	O
(	O
see	O
Section	O
5.2	O
)	O
.	O
The	O
experts	O
could	O
either	O
choose	O
one	O
argument	O
as	O
being	O
more	O
persuasive	O
or	O
both	O
as	O
being	O
equally	O
persuasive	O
.	O
In	O
total	O
,	O
the	O
experts	O
compared	O
100	O
(	O
randomly	O
sorted	O
and	O
ordered	O
)	O
argument	O
pairs	O
for	O
persuasiveness	O
and	O
fluency	O
(	O
50	O
from	O
both	O
the	O
Arg	O
-	O
CTRL	O
REDDIT	O
and	O
the	O
Arg	O
-	O
CTRL	O
CC	O
)	O
.	O
A	O
pair	O
of	O
arguments	O
always	O
had	O
the	O
same	O
topic	O
and	O
stance	O
.	O
For	O
fluency	O
,	O
only	O
the	O
annotations	O
made	O
for	O
generated	O
arguments	O
were	O
extracted	O
and	O
taken	O
into	O
account	O
.	O
Averaged	O
results	O
of	O
both	O
experts	O
show	O
that	O
in	O
33	O
%	O
of	O
the	O
cases	O
,	O
the	O
generated	O
argument	O
is	O
either	O
more	O
convincing	O
(	O
29	O
%	O
)	O
or	O
as	O
convincing	O
(	O
4	O
%	O
)	O
as	O
the	O
reference	O
argument	O
.	O
Moreover	O
,	O
83	O
%	O
of	O
generated	O
arguments	O
are	O
fluent	O
.	O
The	O
inter	O
-	O
annotator	O
agreement	O
(	O
Cohen	O
,	O
1960	O
)	O
between	O
the	O
two	O
experts	O
is	O
Cohen	O
's	O
κ	O
=	O
.30	O
(	O
percentage	O
agreement	O
:	O
.62	O
)	O
for	O
persuasiveness	O
and	O
κ	O
=	O
.43	O
(	O
percentage	O
agreement	O
:	O
.72	O
)	O
for	O
fluency	O
,	O
which	O
can	O
be	O
interpreted	O
as	O
"	O
fair	O
"	O
and	O
"	O
moderate	O
"	O
agreement	O
,	O
respectively	O
(	O
Landis	O
and	O
Koch	O
,	O
1977	O
)	O
.	O
As	O
we	O
compare	O
to	O
high	O
-	O
quality	O
,	O
curated	O
data	O
,	O
the	O
perceived	O
persuasiveness	O
of	O
the	O
generated	O
arguments	O
shows	O
the	O
potential	O
of	O
the	O
work	O
-	O
further	O
strengthened	O
in	O
the	O
remainder	O
of	O
this	O
section	O
.	O

Argument	O
Quality	O
We	O
introduce	O
a	O
novel	O
method	O
to	O
evaluate	O
generated	O
arguments	O
based	O
on	O
the	O
argument	O
quality	O
detection	O
approach	O
proposed	O
by	O
Gretz	O
et	O
al	O
.	O
(	O
2020b	O
)	O
.	O
They	O
create	O
an	O
argument	O
quality	O
dataset	O
that	O
contains	O
around	O
30,000	O
arguments	O
over	O
71	O
topics	O
.	O
For	O
each	O
argument	O
,	O
annotators	O
were	O
asked	O
whether	O
or	O
not	O
they	O
would	O
recommend	O
a	O
friend	O
to	O
use	O
the	O
displayed	O
argument	O
in	O
a	O
speech	O
.	O
The	O
quality	O
scores	O
for	O
each	O
argument	O
result	O
from	O
a	O
weighted	O
average	O
(	O
WA	O
)	O
or	O
MACE	O
Probability	O
function	O
of	O
all	O
annotations	O
and	O
range	O
between	O
0	O
(	O
lowest	O
quality	O
)	O
and	O
1.0	O
(	O
highest	O
quality	O
)	O
.	O
We	O
use	O
the	O
WA	O
-	O
score	O
as	O
label	O
,	O
the	O
same	O
model	O
(	O
BERT	O
BASE	O
)	O
and	O
hyperparameters	O
as	O
given	O
in	O
the	O
original	O
paper	O
,	O
and	O
reproduce	O
the	O
reported	O
correlations	O
of	O
.52	O
(	O
Pearson	O
)	O
and	O
.48	O
(	O
Spearman	O
)	O
on	O
the	O
test	O
dataset	O
(	O
averaged	O
over	O
five	O
different	O
seeds	O
)	O
.	O
The	O
model	O
predicts	O
an	O
average	O
argument	O
quality	O
of	O
.71	O
for	O
the	O
Arg	O
-	O
CTRL	O
REDDIT	O
arguments	O
,	O
.75	O
for	O
the	O
training	O
arguments	O
of	O
the	O
UKP	O
-	O
Corpus	O
,	O
and	O
even	O
.76	O
for	O
the	O
Arg	O
-	O
CTRL	O
CC	O
arguments	O
.	O
It	O
shows	O
that	O
our	O
model	O
is	O
able	O
to	O
produce	O
arguments	O
that	O
are	O
generally	O
on	O
a	O
similar	O
quality	O
level	O
as	O
arguments	O
made	O
by	O
humans	O
.	O
The	O
difference	O
of	O
5	O
points	O
between	O
the	O
Arg	O
-	O
CTRL	O
CC	O
and	O
the	O
Arg	O
-	O
CTRL	O
REDDIT	O
,	O
however	O
,	O
shows	O
that	O
training	O
on	O
REDDIT	O
data	O
leads	O
to	O
a	O
lower	O
quality	O
of	O
generated	O
arguments	O
.	O
Exemplary	O
Human	O
:	O
Nuclear	O
energy	O
produces	O
waste	O
that	O
stays	O
radioactive	O
for	O
thousands	O
of	O
years	O
and	O
pollutes	O
the	O
environment	O
.	O
Arg	O
-	O
CTRLCC	O
:	O
(	O
nuclear	O
energy	O
PRO	O
waste	O
.	O
)	O
The	O
only	O
thing	O
that	O
's	O
going	O
to	O
be	O
left	O
over	O
is	O
the	O
spent	O
fuel	O
rods	O
,	O
which	O
are	O
not	O
very	O
radioactive	O
and	O
can	O
be	O
reprocessed	O
[	O
...	O
]	O
Arg	O
-	O
CTRLCC	O
:	O
(	O
nuclear	O
energy	O
PRO	O
radioactive	O
.	O
)	O
The	O
radioactivity	O
of	O
the	O
waste	O
is	O
not	O
a	O
problem	O
,	O
because	O
it	O
will	O
decay	O
away	O
in	O
about	O
300	O
years	O
or	O
so	O
[	O
...	O
]	O
Arg	O
-	O
CTRLCC	O
:	O
(	O
nuclear	O
energy	O
PRO	O
environment	O
.	O
)	O
The	O
fact	O
that	O
the	O
radioactive	O
waste	O
is	O
not	O
only	O
stored	O
in	O
a	O
safe	O
manner	O
,	O
but	O
also	O
protected	O
from	O
any	O
potential	O
threat	O
to	O
human	O
health	O
or	O
the	O
environment	O
for	O
thousands	O
of	O
years	O
[	O
...	O
]	O
Human	O
:	O
School	O
uniforms	O
are	O
expensive	O
and	O
affect	O
the	O
pupil	O
's	O
individuality	O
.	O
Arg	O
-	O
CTRLCC	O
:	O
(	O
school	O
uniforms	O
PRO	O
expensive	O
.	O
)	O
The	O
cost	O
of	O
the	O
uniform	O
is	O
not	O
that	O
much	O
more	O
than	O
a	O
regular	O
shirt	O
and	O
shorts	O
[	O
...	O
]	O
Arg	O
-	O
CTRLCC	O
:	O
(	O
school	O
uniforms	O
PRO	O
individuality	O
.	O
)	O
The	O
uniform	O
is	O
a	O
symbol	O
of	O
unity	O
and	O
identity	O
,	O
which	O
helps	O
to	O
foster	O
an	O
environment	O
where	O
students	O
can	O
feel	O
comfortable	O
about	O
expressing	O
their	O
own	O
individual	O
style	O
without	O
being	O
judged	O
[	O
...	O
]	O
for	O
three	O
topics	O
,	O
we	O
show	O
the	O
generated	O
arguments	O
with	O
the	O
highest	O
and	O
lowest	O
argument	O
quality	O
in	O
Table	O
4	O
(	O
see	O
App	O
.	O
E	O
for	O
the	O
full	O
table	O
)	O
.	O

Extrinsic	O
Evaluation	O
:	O

Counter	O
-	O
Arguments	O

Drafting	O
counter	O
-	O
arguments	O
is	O
an	O
important	O
skill	O
for	O
debating	O
,	O
to	O
provide	O
constructive	O
feedback	O
,	O
and	O
to	O
foster	O
critical	O
thinking	O
.	O
We	O
lean	O
onto	O
the	O
work	O
of	O
Wachsmuth	O
et	O
al	O
.	O
(	O
2018	O
)	O
who	O
describe	O
a	O
counterargument	O
as	O
discussing	O
the	O
same	O
aspect	O
as	O
an	O
initial	O
argument	O
,	O
but	O
with	O
a	O
switched	O
stance	O
.	O
Hence	O
,	O
given	O
our	O
defined	O
control	O
codes	O
,	O
our	O
model	O
is	O
especially	O
fit	O
for	O
counter	O
-	O
argument	O
generation	O
.	O
Unlike	O
current	O
models	O
for	O
this	O
task	O
,	O
we	O
do	O
not	O
require	O
a	O
specific	O
dataset	O
with	O
argument	O
and	O
counterargument	O
pairs	O
(	O
Hidey	O
and	O
McKeown	O
,	O
2019	O
;	O
.	O
Also	O
,	O
in	O
contrast	O
to	O
the	O
model	O
by	O
that	O
implicitly	O
integrates	O
inputrelated	O
"	O
Keyphrases	O
"	O
into	O
the	O
process	O
of	O
counterargument	O
generation	O
,	O
our	O
model	O
is	O
able	O
to	O
concentrate	O
on	O
every	O
aspect	O
of	O
the	O
input	O
explicitly	O
and	O
with	O
a	O
separate	O
argument	O
,	O
allowing	O
for	O
more	O
transparency	O
and	O
interpretability	O
over	O
the	O
process	O
of	O
counter	O
-	O
argument	O
generation	O
.	O
We	O
exemplary	O
show	O
how	O
the	O
combination	O
of	O
aspect	O
detection	O
and	O
controlled	O
argument	O
generation	O
can	O
be	O
successfully	O
leveraged	O
to	O
tackle	O
this	O
task	O
.	O
For	O
that	O
,	O
we	O
manually	O
compose	O
initial	O
arguments	O
for	O
the	O
topics	O
nuclear	O
energy	O
and	O
school	O
uniforms	O
.	O
Then	O
,	O
we	O
automatically	O
detect	O
their	O
aspects	O
and	O
generate	O
a	O
counterargument	O
for	O
each	O
aspect	O
by	O
passing	O
the	O
topic	O
,	O
opposite	O
stance	O
of	O
the	O
original	O
argument	O
,	O
and	O
one	O
of	O
the	O
aspects	O
into	O
the	O
Arg	O
-	O
CTRL	O
CC	O
.	O
For	O
both	O
topics	O
,	O
the	O
Arg	O
-	O
CTRL	O
CC	O
produces	O
meaningful	O
counterarguments	O
based	O
on	O
the	O
detected	O
aspects	O
(	O
see	O
Table	O
7	O
)	O
.	O

Conclusion	O

We	O
apply	O
the	O
concept	O
of	O
controlled	O
neural	O
text	O
generation	O
to	O
the	O
domain	O
of	O
argument	O
generation	O
.	O
Our	O
Arg	O
-	O
CTRL	O
is	O
conditioned	O
on	O
topics	O
,	O
stances	O
,	O
and	O
aspects	O
and	O
can	O
reliably	O
create	O
arguments	O
using	O
these	O
control	O
codes	O
.	O
We	O
show	O
that	O
arguments	O
generated	O
with	O
our	O
approach	O
are	O
genuine	O
and	O
of	O
high	O
argumentative	O
and	O
grammatical	O
quality	O
in	O
general	O
.	O
Moreover	O
,	O
we	O
show	O
that	O
our	O
approach	O
can	O
be	O
used	O
to	O
generate	O
counter	O
-	O
arguments	O
in	O
a	O
transparent	O
and	O
interpretable	O
way	O
.	O
We	O
fine	O
-	O
tune	O
the	O
Arg	O
-	O
CTRL	O
on	O
two	O
different	O
data	O
sources	O
and	O
find	O
that	O
using	O
mixed	O
data	O
from	O
Common	O
-	O
Crawl	O
results	O
in	O
a	O
higher	O
quality	O
of	O
generated	O
arguments	O
than	O
using	O
user	O
discussions	O
from	O
Reddit	O
-	O
Comments	O
.	O
Further	O
,	O
we	O
define	O
argument	O
aspect	O
detection	O
for	O
controlled	O
argument	O
generation	O
and	O
introduce	O
a	O
novel	O
annotation	O
scheme	O
to	O
crowdsource	O
argument	O
aspect	O
annotations	O
,	O
resulting	O
in	O
a	O
high	O
-	O
quality	O
dataset	O
.	O
We	O
publish	O
the	O
model	O
weights	O
,	O
data	O
,	O
and	O
all	O
code	O
necessary	O
to	O
train	O
the	O
Arg	O
-	O
CTRL	O
.	O

Ethics	O
Statement	O

Models	O
for	O
argument	O
and	O
claim	O
generation	O
have	O
been	O
discussed	O
in	O
our	O
related	O
work	O
and	O
are	O
widely	O
available	O
.	O
Gretz	O
et	O
al	O
.	O
(	O
2020a	O
)	O
suggest	O
that	O
,	O
in	O
order	O
to	O
allow	O
for	O
a	O
fine	O
-	O
grained	O
control	O
over	O
claim	O
/	O
argument	O
generation	O
,	O
aspect	O
selection	O
needs	O
to	O
be	O
handled	O
carefully	O
,	O
which	O
is	O
what	O
we	O
have	O
focused	O
on	O
in	O
this	O
work	O
.	O
The	O
dangers	O
of	O
misuse	O
of	O
language	O
models	O
like	O
the	O
CTRL	O
have	O
been	O
extensively	O
discussed	O
by	O
its	O
authors	O
(	O
Keskar	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
The	O
ethical	O
impact	O
of	O
these	O
works	O
has	O
been	O
weighed	O
and	O
deemed	O
justifiable	O
.	O
Argument	O
generation	O
-	O
and	O
natural	O
language	O
generation	O
as	O
a	O
whole	O
-	O
is	O
subject	O
to	O
dual	O
use	O
.	O
The	O
technology	O
can	O
be	O
used	O
to	O
create	O
arguments	O
that	O
can	O
not	O
be	O
distinguished	O
from	O
human	O
-	O
made	O
arguments	O
.	O
While	O
our	O
intentions	O
are	O
to	O
support	O
society	O
,	O
to	O
foster	O
diversity	O
in	O
debates	O
,	O
and	O
to	O
encourage	O
research	O
on	O
this	O
important	O
topic	O
,	O
we	O
are	O
aware	O
of	O
the	O
possibility	O
of	O
harmful	O
applications	O
this	O
model	O
can	O
be	O
used	O
for	O
.	O
For	O
instance	O
,	O
the	O
model	O
could	O
be	O
used	O
to	O
generate	O
only	O
opposing	O
(	O
or	O
supporting	O
)	O
arguments	O
on	O
one	O
of	O
the	O
pretrained	O
topics	O
and	O
aspects	O
and	O
,	O
as	O
such	O
,	O
bias	O
a	O
debate	O
into	O
a	O
certain	O
direction	O
.	O
Also	O
,	O
bots	O
could	O
use	O
the	O
generated	O
arguments	O
to	O
spread	O
them	O
via	O
social	O
media	O
.	O
The	O
same	O
is	O
true	O
,	O
however	O
,	O
for	O
argument	O
search	O
engines	O
,	O
which	O
can	O
be	O
used	O
by	O
malicious	O
parties	O
to	O
retrieve	O
(	O
and	O
then	O
spread	O
)	O
potentially	O
harmful	O
information	O
.	O

However	O
,	O
controllable	O
argument	O
generation	O
can	O
also	O
be	O
used	O
to	O
support	O
finding	O
and	O
formulating	O
(	O
counter-)arguments	O
for	O
debates	O
,	O
for	O
writing	O
essays	O
,	O
to	O
enrich	O
one	O
-	O
sided	O
discussions	O
,	O
and	O
thus	O
,	O
to	O
make	O
discourse	O
more	O
diverse	O
overall	O
.	O
For	O
instance	O
,	O
anticipating	O
opposing	O
arguments	O
is	O
crucial	O
for	O
critical	O
thinking	O
,	O
which	O
is	O
the	O
foundation	O
for	O
any	O
democratic	O
society	O
.	O
The	O
skill	O
is	O
extensively	O
taught	O
in	O
school	O
and	O
university	O
education	O
.	O
However	O
,	O
confirmation	O
bias	O
(	O
or	O
myside	O
bias	O
)	O
(	O
Stanovich	O
et	O
al	O
.	O
,	O
2013	O
)	O
,	O
i.e.	O
the	O
tendency	O
to	O
ignore	O
opposing	O
arguments	O
,	O
is	O
an	O
ever	O
-	O
present	O
issue	O
.	O
Technologies	O
like	O
ours	O
could	O
be	O
used	O
to	O
mitigate	O
this	O
issue	O
by	O
,	O
for	O
instance	O
,	O
automatically	O
providing	O
topic	O
-	O
and	O
aspectspecific	O
counter	O
-	O
arguments	O
for	O
all	O
arguments	O
of	O
a	O
given	O
text	O
(	O
this	O
has	O
been	O
shown	O
for	O
single	O
arguments	O
in	O
Section	O
7.2	O
)	O
.	O
We	O
believe	O
that	O
working	O
on	O
and	O
providing	O
access	O
to	O
such	O
models	O
is	O
of	O
major	O
importance	O
and	O
,	O
overall	O
,	O
a	O
benefit	O
to	O
society	O
.	O

Open	O
-	O
sourcing	O
such	O
language	O
models	O
also	O
encourages	O
the	O
work	O
on	O
counter	O
-	O
measures	O
to	O
detect	O
malicious	O
use	O
:	O
While	O
many	O
works	O
have	O
been	O
published	O
on	O
the	O
topic	O
of	O
automatic	O
fake	O
news	O
detection	O
in	O
texts	O
(	O
Kaliyar	O
et	O
al	O
.	O
,	O
2020;Reis	O
et	O
al	O
.	O
,	O
2019;Hanselowski	O
et	O
al	O
.	O
,	O
2018;Pérez	O
-	O
Rosas	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
the	O
recent	O
emergence	O
of	O
large	O
-	O
scale	O
language	O
models	O
has	O
also	O
encouraged	O
research	O
to	O
focus	O
on	O
detecting	O
the	O
creator	O
of	O
these	O
texts	O
(	O
Varshney	O
et	O
al	O
.	O
,	O
2020;Zellers	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
The	O
former	O
approaches	O
are	O
aimed	O
at	O
detecting	O
fake	O
news	O
in	O
general	O
,	O
i.e.	O
independent	O
of	O
who	O
(	O
or	O
what	O
)	O
composed	O
a	O
text	O
,	O
whereas	O
the	O
latter	O
approaches	O
are	O
designed	O
to	O
recognize	O
if	O
a	O
text	O
was	O
written	O
by	O
a	O
human	O
or	O
generated	O
by	O
a	O
language	O
model	O
.	O
We	O
encourage	O
the	O
work	O
on	O
both	O
types	O
of	O
methods	O
.	O
Ideally	O
,	O
social	O
networks	O
and	O
news	O
platforms	O
would	O
indicate	O
if	O
a	O
statement	O
was	O
automatically	O
generated	O
in	O
addition	O
to	O
its	O
factual	O
correctness	O
.	O

Further	O
,	O
we	O
point	O
out	O
some	O
limitations	O
of	O
the	O
Arg	O
-	O
CTRL	O
that	O
mitigate	O
the	O
risks	O
discussed	O
before	O
.	O
One	O
of	O
these	O
limitations	O
is	O
that	O
it	O
can	O
not	O
be	O
used	O
to	O
generate	O
arguments	O
for	O
unseen	O
topics	O
,	O
which	O
makes	O
a	O
widespread	O
application	O
(	O
e.g.	O
to	O
produce	O
fake	O
news	O
)	O
rather	O
unlikely	O
(	O
using	O
an	O
unseen	O
topic	O
as	O
control	O
code	O
results	O
in	O
nonsensical	O
repetitions	O
of	O
the	O
input	O
)	O
.	O
The	O
analysis	O
in	O
Section	O
6	O
of	O
the	O
paper	O
shows	O
that	O
the	O
model	O
fails	O
to	O
produce	O
aspectspecific	O
sentences	O
in	O
92	O
%	O
of	O
the	O
cases	O
if	O
it	O
was	O
not	O
explicitly	O
conditioned	O
on	O
them	O
at	O
training	O
time	O
.	O
Even	O
in	O
case	O
of	O
success	O
,	O
the	O
aspect	O
has	O
to	O
exist	O
in	O
the	O
training	O
data	O
.	O
Also	O
,	O
the	O
model	O
is	O
trained	O
with	O
balanced	O
classes	O
,	O
i.e.	O
both	O
supporting	O
and	O
opposing	O
arguments	O
for	O
each	O
topic	O
are	O
seen	O
with	O
equal	O
frequency	O
to	O
prevent	O
possible	O
bias	O
into	O
one	O
or	O
the	O
other	O
direction	O
.	O

To	O
further	O
restrict	O
malicious	O
use	O
,	O
we	O
release	O
the	O
training	O
data	O
for	O
the	O
Arg	O
-	O
CTRLs	O
with	O
an	O
additional	O
clause	O
that	O
forbids	O
use	O
for	O
any	O
other	O
than	O
research	O
purposes	O
.	O
Also	O
,	O
all	O
the	O
training	O
datasets	O
for	O
the	O
Arg	O
-	O
CTRLs	O
will	O
be	O
accessible	O
only	O
via	O
access	O
control	O
(	O
e	O
-	O
mail	O
,	O
name	O
,	O
and	O
purpose	O
of	O
use	O
)	O
.	O
Lastly	O
,	O
this	O
work	O
has	O
been	O
reviewed	O
by	O
the	O
ethics	O
committee	O
of	O
the	O
Technical	O
University	O
of	O
Darmstadt	O
that	O
issued	O
a	O
positive	O
vote	O
.	O
page	O
833	O
-	O
838	O
,	O
USA	O
.	O
American	O
Association	O
for	O
Artificial	O
Intelligence	O
.	O

A	O
Argument	O
Aspect	O
Annotation	O
Study	O

For	O
the	O
final	O
crowdsourcing	O
study	O
,	O
we	O
use	O
Amazon	O
Mechanical	O
Turk	O
.	O
Workers	O
had	O
to	O
take	O
a	O
qualification	O
test	O
,	O
have	O
an	O
acceptance	O
rate	O
of	O
at	O
least	O
95	O
%	O
,	O
and	O
location	O
within	O
the	O
US	O
.	O
We	O
paid	O
$	O
7.6	O
per	O
hour	O
(	O
minimum	O
wage	O
is	O
$	O
7.25	O
per	O
hour	O
)	O
.	O
Each	O
data	O
sample	O
is	O
annotated	O
by	O
eight	O
crowdworkers	O
.	O
In	O
case	O
the	O
ranker	O
cut	O
off	O
the	O
real	O
aspect(s	O
)	O
from	O
the	O
list	O
of	O
candidates	O
,	O
crowdworkers	O
could	O
select	O
any	O
sequence	O
up	O
to	O
four	O
tokens	O
from	O
a	O
second	O
list	O
.	O

Figure	O
2	O
shows	O
the	O
annotation	O
guidelines	O
for	O
the	O
Amazon	O
Mechanical	O
Turk	O
study	O
.	O
Figure	O
3	O
shows	O
one	O
example	O
of	O
a	O
HIT	O
with	O
two	O
aspects	O
selected	O
.	O
Selected	O
aspects	O
are	O
highlighted	O
in	O
the	O
sentence	O
.	O
We	O
did	O
not	O
allow	O
to	O
choose	O
overlapping	O
aspects	O
.	O
If	O
the	O
aspect	O
was	O
not	O
found	O
in	O
the	O
first	O
list	O
provided	O
by	O
the	O
learned	O
ranker	O
,	O
crowdworkers	O
could	O
choose	O
from	O
as	O
second	O
list	O
with	O
the	O
remaining	O
1	O
-	O
4	O
-	O
grams	O
of	O
the	O
sentence	O
(	O
aspect	O
candidates	O
starting	O
or	O
ending	O
with	O
stopwords	O
,	O
as	O
well	O
as	O
candidates	O
with	O
punctuation	O
and	O
numbers	O
,	O
were	O
removed	O
from	O
the	O
list	O
)	O
.	O
Additional	O
checkboxes	O
were	O
added	O
to	O
choose	O
from	O
if	O
the	O
sentence	O
contained	O
no	O
aspect	O
or	O
the	O
aspect	O
was	O
not	O
explicitly	O
mentioned	O
.	O
Figure	O
4	O
shows	O
a	O
ranked	O
list	O
of	O
aspect	O
candidates	O
for	O
an	O
example	O
.	O

The	O
structure	O
of	O
the	O
final	O
dataset	O
is	O
described	O
in	O
Section	O
F.	O
For	O
reproducibility	O
of	O
results	O
,	O
we	O
create	O
fixed	O
splits	O
for	O
in	O
-	O
and	O
cross	O
-	O
topic	O
experiments	O
.	O
9	O
,	O
we	O
show	O
the	O
synonyms	O
used	O
for	O
filtering	O
prior	O
to	O
the	O
argument	O
and	O
stance	O
classification	O
step	O
.	O
We	O
filtered	O
out	O
all	O
sentences	O
that	O
did	O
not	O
contain	O
tokens	O
from	O
the	O
topic	O
they	O
belong	O
to	O
or	O
any	O
synonyms	O
defined	O
for	O
this	O
topic	O
.	O

B	O
Search	O
Query	O
and	O
Topic	O
Relevance	O
Synonyms	O

C	O
Model	O
Parameters	O
and	O
Details	O

All	O
arguments	O
of	O
the	O
training	O
documents	O
are	O
tokenized	O
with	O
a	O
BPE	O
model	O
(	O
Sennrich	O
et	O
al	O
.	O
,	O
2016	O
)	O
trained	O
by	O
the	O
authors	O
of	O
the	O
CTRL	O
(	O
Keskar	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Both	O
the	O
Arg	O
-	O
CTRL	O
CC	O
and	O
the	O
Arg	O
-	O
CTRL	O
REDDIT	O
are	O
fine	O
-	O
tuned	O
on	O
a	O
Tesla	O
V100	O
with	O
32	O
GB	O
of	O
Memory	O
.	O
We	O
mainly	O
keep	O
the	O
default	O
hyperparameters	O
but	O
reduce	O
the	O
batch	O
size	O
to	O
4	O
and	O
train	O
both	O
models	O
for	O
1	O
epoch	O
.	O
Each	O
model	O
takes	O
around	O
five	O
days	O
to	O
train	O
on	O
the	O
1.6	O
M	O
training	O
sentences	O
.	O

D	O
Reference	O
Data	O
Statistics	O

Table	O
10	O
shows	O
the	O
sources	O
and	O
number	O
of	O
arguments	O
for	O
all	O
topics	O
of	O
the	O
reference	O
dataset	O
.	O
The	O
dataset	O
is	O
used	O
to	O
compare	O
the	O
argument	O
generation	O
models	O
to	O
a	O
retrieval	O
approach	O
.	O

E	O
Examples	O
of	O
Generated	O
Arguments	O

For	O
all	O
eight	O
topics	O
,	O
we	O
show	O
the	O
generated	O
argument	O
with	O
the	O
highest	O
and	O
lowest	O
argument	O
quality	O
score	O
in	O
tables	O
11	O
(	O
Arg	O
-	O
CTRL	O
CC	O
)	O
and	O
12	O
(	O
Arg	O
-	O
CTRL	O
REDDIT	O
)	O
.	O
Text	O
in	O
bold	O
shows	O
the	O
given	O
control	O
code	O
,	O
text	O
afterwards	O
represents	O
the	O
generated	O
argument	O
.	O
Numbers	O
in	O
brackets	O
after	O
the	O
text	O
show	O
the	O
quality	O
score	O
as	O
predicted	O
by	O
the	O
argument	O
quality	O
model	O
.	O

F	O
Argument	O
Aspect	O
Detection	O
Dataset	O

The	O
argument	O
aspect	O
detection	O
dataset	O
contains	O
a	O
total	O
of	O
5,032	O
samples	O
in	O
JSONL	O
-	O
format	O
,	O
i.e.	O
each	O
dataset	O
sample	O
has	O
a	O
separate	O
line	O
and	O
can	O
be	O
parsed	O
as	O
JSON	O
.	O
A	O
sample	O
contains	O
the	O
keys	O
:	O

•	O
hash	O
:	O
Unique	O
identifier	O
.	O

•	O
aspect_pos	O
:	O
List	O
of	O
string	O
tuples	O
"	O
(	O
begin	O
,	O
length	O
)	O
"	O
,	O
marking	O
the	O
character	O
position	O
and	O
length	O
of	O
each	O
aspect	O
within	O
the	O
argument	O
.	O

•	O
aspect_pos_string	O
:	O
The	O
aspects	O
as	O
a	O
list	O
of	O
strings	O
.	O

•	O
stance	O
:	O
Original	O
stance	O
label	O
of	O
the	O
argument	O
towards	O
the	O
topic	O
,	O
taken	O
from	O
the	O
UKP	O
-	O
Corpus	O
(	O
Stab	O
et	O
al	O
.	O
,	O
2018b	O
)	O
.	O
Either	O
"	O
Argument_for	O
"	O
or	O
"	O
Argument_against	O
"	O
.	O

•	O
topic	O
:	O
The	O
topic	O
of	O
the	O
argument	O
.	O

•	O
sentence	O
:	O
The	O
argument	O
.	O

For	O
reproducibility	O
,	O
we	O
define	O
a	O
fixed	O
cross	O
-	O
topic	O
split	O
with	O
the	O
data	O
of	O
two	O
topics	O
as	O
test	O
set	O
(	O
gun	O
control	O
,	O
school	O
uniforms	O
)	O
,	O
the	O
data	O
of	O
one	O
topic	O
as	O
development	O
set	O
(	O
death	O
penalty	O
)	O
,	O
and	O
the	O
data	O
of	O
the	O
remaining	O
five	O
topics	O
as	O
train	O
set	O
.	O
We	O
also	O
create	O
a	O
fixed	O
in	O
-	O
topic	O
split	O
by	O
randomly	O
taking	O
3,532	O
samples	O
of	O
all	O
topics	O
for	O
training	O
,	O
500	O
for	O
development	O
,	O
and	O
1,000	O
for	O
testing	O
.	O
nuclear	O
AND	O
(	O
energy	O
OR	O
fission	O
OR	O
power	O
OR	O
plant	O
)	O
In	O
addition	O
,	O
we	O
must	O
continue	O
developing	O
safer	O
technologies	O
like	O
small	O
modular	O
reactors	O
which	O
will	O
help	O
us	O
meet	O
our	O
nation	O
's	O
need	O
for	O
reliable	O
,	O
emission	O
-	O
free	O
sources	O
of	O
low	O
-	O
emission	O
energy	O
while	O
also	O
creating	O
jobs	O
and	O
providing	O
solutions	O
to	O
some	O
of	O
the	O
world	O
s	O
most	O
pressing	O
problems	O
:	O
climate	O
change	O
,	O
food	O
security	O
and	O
sustainable	O
development	O
.	O
(	O
0.96	O
)	O
nuclear	O
energy	O
CON	O
leak	O
.	O
"	O
We	O
are	O
concerned	O
about	O
the	O
possibility	O
of	O
further	O
releases	O
of	O
radioactivity	O
due	O
to	O
possible	O
melting	O
or	O
cracking	O
of	O
fuel	O
rods	O
at	O
the	O
No	O
.	O
(	O
0.47	O
)	O
death	O
penalty	O
CON	O
inhuman	O
.	O
Amnesty	O
International	O
opposes	O
the	O
death	O
penalty	O
in	O
all	O
cases	O
as	O
the	O
ultimate	O
form	O
of	O
cruel	O
,	O
inhuman	O
or	O
degrading	O
punishment	O
and	O
a	O
violation	O
of	O
fundamental	O
rights	O
-the	O
right	O
to	O
life	O
and	O
the	O
prohibition	O
of	O
torture	O
.	O

(	O
1.00	O
)	O
death	O
penalty	O
CON	O
god	O
.	O
And	O
yet	O
,	O
while	O
the	O
Church	O
exhorts	O
civil	O
authorities	O
.	O
(	O
0.41	O
)	O
school	O
uniforms	O
CON	O
resources	O
.	O
The	O
lack	O
of	O
a	O
uniform	O
system	O
for	O
the	O
collection	O
and	O
use	O
of	O
data	O
,	O
as	O
well	O
as	O
insufficient	O
funding	O
to	O
collect	O
it	O
,	O
are	O
major	O
barriers	O
that	O
limit	O
access	O
to	O
information	O
on	O
student	O
achievement	O
in	O
schools	O
with	O
high	O
concentrations	O
of	O
students	O
from	O
low	O
-	O
income	O
families	O
.	O
(	O
0.92	O
)	O
school	O
uniforms	O
PRO	O
fun	O
:	O
The	O
kids	O
are	O
having	O
a	O
lot	O
of	O
fun	O
.	O
(	O
0.38	O
)	O
gun	O
control	O
PRO	O
homicides	O
.	O
In	O
addition	O
to	O
being	O
an	O
effective	O
crime	O
deterrent	O
and	O
reducing	O
suicides	O
,	O
research	O
has	O
shown	O
that	O
defensive	O
firearm	O
use	O
prevents	O
more	O
than	O
80	O
percent	O
of	O
all	O
gun	O
-	O
related	O
violent	O
crimes	O
including	O
homicides	O
,	O
robberies	O
,	O
assaults	O
,	O
rapes	O
,	O
and	O
aggravated	O
assaults	O
[	O
1	O
]	O
.	O
(	O
0.96	O
)	O
gun	O
control	O
PRO	O
prevent	O
;	O
You	O
liberals	O
need	O
to	O
wake	O
up	O
and	O
smell	O
the	O
coffee	O
.	O
(	O
0.43	O
)	O
marijuana	O
legalization	O
PRO	O
safer	O
:	O
Legalizing	O
cannabis	O
will	O
help	O
reduce	O
crime	O
rates	O
(	O
especially	O
violent	O
crimes	O
)	O
and	O
make	O
society	O
safer	O
overall	O
.	O
(	O
0.96	O
)	O
marijuana	O
legalization	O
PRO	O
benefits	O
.	O
Decrease	O
amount	O
of	O
police	O
officers	O
needed	O
6	O
.	O
(	O
0.37	O
)	O
minimum	O
wage	O
PRO	O
poor	O
:	O
Raising	O
the	O
minimum	O
wage	O
will	O
not	O
only	O
benefit	O
those	O
working	O
full	O
time	O
but	O
also	O
reduce	O
government	O
expenditures	O
on	O
social	O
services	O
such	O
as	O
food	O
stamps	O
and	O
Medicaid	O
which	O
disproportionately	O
affect	O
the	O
poor	O
.	O
(	O
0.97	O
)	O
minimum	O
wage	O
CON	O
cost	O
:	O
If	O
you	O
raise	O
the	O
price	O
of	O
a	O
Big	O
Mac	O
to	O
$	O
10	O
and	O
then	O
pay	O
an	O
extra	O
dime	O
or	O
two	O
per	O
burger	O
so	O
that	O
it	O
's	O
still	O
only	O
$	O
9	O
...	O
well	O
,	O
maybe	O
your	O
business	O
is	O
n't	O
worth	O
saving	O
at	O
all	O
because	O
there	O
just	O
wo	O
n't	O
be	O
anyone	O
willing	O
to	O
eat	O
out	O
after	O
they	O
'	O
ve	O
had	O
their	O
fill	O
(	O
unless	O
perhaps	O
they	O
're	O
on	O
welfare	O
)	O
and	O
now	O
have	O
no	O
job	O
and	O
ca	O
n't	O
afford	O
health	O
care	O
eitherbut	O
I	O
doubt	O
very	O
seriously	O
that	O
most	O
people	O
making	O
those	O
kinds	O
of	O
wages	O
/	O
salaries	O
would	O
suddenly	O
decide	O
not	O
to	O
work	O
if	O
forced	O
to	O
shoulder	O
the	O
added	O
cost	O
.	O
(	O
0.44	O
)	O
12	O
:	O
Generated	O
arguments	O
with	O
the	O
Arg	O
-	O
CTRL	O
REDDIT	O
.	O
Text	O
in	O
bold	O
shows	O
the	O
given	O
control	O
code	O
,	O
text	O
afterwards	O
represents	O
the	O
generated	O
argument	O
.	O
Numbers	O
in	O
brackets	O
after	O
the	O
text	O
show	O
the	O
quality	O
score	O
as	O
predicted	O
by	O
the	O
argument	O
quality	O
model	O
.	O

Acknowledgements	O

We	O
thank	O
Tilman	O
Beck	O
and	O
Nandan	O
Thakur	O
for	O
their	O
support	O
in	O
the	O
human	O
evaluation	O
(	O
Section	O
7.1	O
)	O
.	O
This	O
work	O
has	O
been	O
supported	O
by	O
the	O
German	O
Research	O
Foundation	O
within	O
the	O
project	O
"	O
Open	O
Argument	O
Mining	O
"	O
(	O
GU	O
798/25	O
-	O
1	O
)	O
,	O
associated	O
with	O
the	O
Priority	O
Program	O
"	O
Robust	O
Argumentation	O
Machines	O
(	O
RATIO	O
)	O
"	O
(	O
SPP-1999	O
)	O
.	O

Linking	O
Entities	O
to	O
Unseen	O
Knowledge	O
Bases	O
with	O
Arbitrary	O
Schemas	O

In	O
entity	O
linking	O
,	O
mentions	O
of	O
named	O
entities	O
in	O
raw	O
text	O
are	O
disambiguated	O
against	O
a	O
knowledge	O
base	O
(	O
KB	O
)	O
.	O
This	O
work	O
focuses	O
on	O
linking	O
to	O
unseen	O
KBs	O
that	O
do	O
not	O
have	O
training	O
data	O
and	O
whose	O
schema	O
is	O
unknown	O
during	O
training	O
.	O
Our	O
approach	O
relies	O
on	O
methods	O
to	O
flexibly	O
convert	O
entities	O
with	O
several	O
attribute	O
-	O
value	O
pairs	O
from	O
arbitrary	O
KBs	O
into	O
flat	O
strings	O
,	O
which	O
we	O
use	O
in	O
conjunction	O
with	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
for	O
zero	O
-	O
shot	O
linking	O
.	O
We	O
further	O
improve	O
the	O
generalization	O
of	O
our	O
model	O
using	O
two	O
regularization	O
schemes	O
based	O
on	O
shuffling	O
of	O
entity	O
attributes	O
and	O
handling	O
of	O
unseen	O
attributes	O
.	O
Experiments	O
on	O
English	O
datasets	O
where	O
models	O
are	O
trained	O
on	O
the	O
CoNLL	O
dataset	O
,	O
and	O
tested	O
on	O
the	O
TAC	O
-	O
KBP	O
2010	O
dataset	O
show	O
that	O
our	O
models	O
are	O
12	O
%	O
(	O
absolute	O
)	O
more	O
accurate	O
than	O
baseline	O
models	O
that	O
simply	O
flatten	O
entities	O
from	O
the	O
target	O
KB	O
.	O
Unlike	O
prior	O
work	O
,	O
our	O
approach	O
also	O
allows	O
for	O
seamlessly	O
combining	O
multiple	O
training	O
datasets	O
.	O
We	O
test	O
this	O
ability	O
by	O
adding	O
both	O
a	O
completely	O
different	O
dataset	O
(	O
Wikia	O
)	O
,	O
as	O
well	O
as	O
increasing	O
amount	O
of	O
training	O
data	O
from	O
the	O
TAC	O
-	O
KBP	O
2010	O
training	O
set	O
.	O
Our	O
models	O
are	O
more	O
accurate	O
across	O
the	O
board	O
compared	O
to	O
baselines	O
.	O

Introduction	O

Entity	O
linking	O
consists	O
of	O
linking	O
mentions	O
of	O
entities	O
found	O
in	O
text	O
against	O
canonical	O
entities	O
found	O
in	O
a	O
target	O
knowledge	O
base	O
(	O
KB	O
)	O
.	O
Early	O
work	O
in	O
this	O
area	O
was	O
motivated	O
by	O
the	O
availability	O
of	O
large	O
KBs	O
with	O
millions	O
of	O
entities	O
(	O
Bunescu	O
and	O
Paşca	O
,	O
2006	O
)	O
.	O
Most	O
subsequent	O
work	O
has	O
followed	O
this	O
tradition	O
of	O
linking	O
to	O
a	O
handful	O
of	O
large	O
,	O
publicly	O
available	O
KBs	O
such	O
as	O
Wikipedia	O
,	O
DBPedia	O
(	O
Auer	O
et	O
al	O
.	O
,	O
2007	O
)	O
or	O
the	O
KBs	O
used	O
in	O
the	O
now	O
decade	O
-	O
old	O
TAC	O
-	O
KBP	O
challenges	O
(	O
McNamee	O
and	O
Dang	O
,	O
2009;Ji	O
et	O
al	O
.	O
,	O
2010	O
)	O
.	O
As	O
a	O
result	O
,	O
previous	O
work	O
always	O
assumes	O
complete	O
knowledge	O
of	O
the	O
schema	O
of	O
the	O
target	O
KB	O
that	O
entity	O
linking	O
models	O
are	O
trained	O
for	O
,	O
i.e.	O
how	O
many	O
and	O
which	O
attributes	O
are	O
used	O
to	O
represent	O
entities	O
in	O
the	O
KB	O
.	O
This	O
allows	O
training	O
supervised	O
machine	O
learning	O
models	O
that	O
exploit	O
the	O
schema	O
along	O
with	O
labeled	O
data	O
that	O
link	O
mentions	O
to	O
this	O
a	O
priori	O
known	O
KB	O
.	O
However	O
,	O
this	O
strong	O
assumption	O
breaks	O
down	O
in	O
scenarios	O
which	O
require	O
linking	O
to	O
KBs	O
that	O
are	O
not	O
known	O
at	O
training	O
time	O
.	O
For	O
example	O
,	O
a	O
company	O
might	O
want	O
to	O
automatically	O
link	O
mentions	O
of	O
its	O
products	O
to	O
an	O
internal	O
KB	O
of	O
products	O
that	O
has	O
a	O
rich	O
schema	O
with	O
several	O
attributes	O
such	O
as	O
product	O
category	O
,	O
description	O
,	O
dimensions	O
,	O
etc	O
.	O
It	O
is	O
very	O
unlikely	O
that	O
the	O
company	O
will	O
have	O
training	O
data	O
of	O
this	O
nature	O
,	O
i.e.	O
mentions	O
of	O
products	O
linked	O
to	O
its	O
database	O
.	O

Our	O
focus	O
is	O
on	O
linking	O
entities	O
to	O
unseen	O
KBs	O
with	O
arbitrary	O
schemas	O
.	O
One	O
solution	O
is	O
to	O
annotate	O
data	O
that	O
can	O
be	O
used	O
to	O
train	O
specialized	O
models	O
for	O
each	O
target	O
KB	O
of	O
interest	O
,	O
but	O
this	O
is	O
not	O
scalable	O
.	O
A	O
more	O
generic	O
solution	O
is	O
to	O
build	O
entity	O
linking	O
models	O
that	O
work	O
with	O
arbitrary	O
KBs	O
.	O
We	O
follow	O
this	O
latter	O
approach	O
and	O
build	O
entity	O
linking	O
models	O
that	O
link	O
to	O
target	O
KBs	O
that	O
have	O
not	O
been	O
observed	O
during	O
training	O
.	O
1	O
Our	O
solution	O
builds	O
on	O
recent	O
models	O
for	O
zero	O
-	O
shot	O
entity	O
linking	O
(	O
Wu	O
et	O
al	O
.	O
,	O
2020;Logeswaran	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
However	O
,	O
these	O
models	O
assume	O
the	O
same	O
,	O
simple	O
KB	O
schema	O
during	O
training	O
and	O
inference	O
.	O
We	O
generalize	O
these	O
models	O
to	O
handle	O
different	O
KBs	O
during	O
training	O
and	O
inference	O
,	O
containing	O
entities	O
represented	O
with	O
an	O
arbitrary	O
set	O
of	O
attribute	O
-	O
value	O
pairs	O
.	O
This	O
generalization	O
relies	O
on	O
two	O
key	O
ideas	O
.	O
First	O
,	O
we	O
convert	O
KB	O
entities	O
into	O
strings	O
that	O
are	O
consumed	O
by	O
the	O
models	O
for	O
zero	O
-	O
shot	O
linking	O
.	O
Central	O
to	O
the	O
string	O
representation	O
are	O
special	O
tokens	O
called	O
attribute	O
separators	O
,	O
which	O
represent	O
frequently	O
occurring	O
attributes	O
in	O
the	O
training	O
KB(s	O
)	O
,	O
and	O
carry	O
over	O
their	O
knowledge	O
to	O
unseen	O
KBs	O
during	O
inference	O
(	O
Section	O
4.1	O
)	O
.	O
Second	O
,	O
we	O
generate	O
more	O
flexible	O
string	O
representations	O
by	O
shuffling	O
entity	O
attributes	O
before	O
converting	O
them	O
to	O
strings	O
,	O

Generic	O
EL	O

Zero	O
-	O
shot	O
EL	O
Linking	O
to	O
any	O
DB	O
This	O
work	O
(	O
Logeswaran	O
et	O
al	O
.	O
,	O
2019	O
)	O
(	O
Sil	O
et	O
al	O
.	O
,	O
2012	O
)	O
Test	O
entities	O
not	O
seen	O
during	O
training	O
Test	O
KB	O
schema	O
unknown	O
Out	O
-	O
of	O
-	O
domain	O
test	O
data	O
Unrestricted	O
Candidate	O
Set	O
and	O
by	O
stochastically	O
removing	O
attribute	O
separators	O
to	O
generalize	O
to	O
unseen	O
attributes	O
(	O
Section	O
4.2	O
)	O
.	O

Our	O
primary	O
experiments	O
are	O
cross	O
-	O
KB	O
and	O
focus	O
on	O
English	O
datasets	O
.	O
We	O
train	O
models	O
to	O
link	O
to	O
one	O
KB	O
during	O
training	O
(	O
viz	O
.	O
Wikidata	O
)	O
,	O
and	O
evaluate	O
them	O
for	O
their	O
ability	O
to	O
link	O
to	O
an	O
unseen	O
KB	O
(	O
viz	O
.	O
the	O
TAC	O
-	O
KBP	O
Knowledge	O
Base	O
)	O
.	O
These	O
experiments	O
reveal	O
that	O
our	O
model	O
with	O
attributeseparators	O
and	O
the	O
two	O
generalization	O
schemes	O
are	O
12	O
-	O
14	O
%	O
more	O
accurate	O
than	O
the	O
baseline	O
zero	O
-	O
shot	O
models	O
.	O
Ablation	O
studies	O
reveal	O
that	O
all	O
components	O
individually	O
contribute	O
to	O
this	O
improvement	O
,	O
but	O
combining	O
all	O
of	O
them	O
yields	O
the	O
most	O
accurate	O
models	O
.	O

Unlike	O
previous	O
work	O
,	O
our	O
models	O
also	O
allow	O
seamless	O
mixing	O
of	O
multiple	O
training	O
datasets	O
which	O
link	O
to	O
different	O
KBs	O
with	O
different	O
schemas	O
.	O
We	O
investigate	O
the	O
impact	O
of	O
training	O
on	O
multiple	O
datasets	O
in	O
two	O
sets	O
of	O
experiments	O
involving	O
additional	O
training	O
data	O
that	O
links	O
to	O
(	O
a	O
)	O
a	O
third	O
KB	O
that	O
is	O
different	O
from	O
our	O
original	O
training	O
and	O
testing	O
KBs	O
,	O
and	O
(	O
b	O
)	O
the	O
same	O
KB	O
as	O
the	O
test	O
data	O
.	O
These	O
experiments	O
reveal	O
that	O
our	O
models	O
perform	O
favorably	O
under	O
all	O
conditions	O
compared	O
to	O
baselines	O
.	O

Background	O

Conventional	O
entity	O
linking	O
models	O
are	O
trained	O
and	O
evaluated	O
on	O
the	O
same	O
KB	O
,	O
which	O
is	O
typically	O
Wikipedia	O
,	O
or	O
derived	O
from	O
Wikipedia	O
(	O
Bunescu	O
and	O
Paşca	O
,	O
2006	O
;	O
.	O
This	O
limited	O
scope	O
allows	O
models	O
to	O
use	O
other	O
sources	O
of	O
information	O
to	O
improve	O
linking	O
,	O
including	O
alias	O
tables	O
,	O
frequency	O
statistics	O
,	O
and	O
rich	O
metadata	O
.	O

Beyond	O
Conventional	O
Entity	O
Linking	O
There	O
have	O
been	O
several	O
attempts	O
to	O
go	O
beyond	O
such	O
conventional	O
settings	O
,	O
e.g.	O
by	O
linking	O
to	O
KBs	O
from	O
diverse	O
domains	O
such	O
as	O
the	O
biomedical	O
sciences	O
(	O
Zheng	O
et	O
al	O
.	O
,	O
2014;D'Souza	O
and	O
Ng	O
,	O
2015	O
)	O
and	O
music	O
(	O
Oramas	O
et	O
al	O
.	O
,	O
2016	O
)	O
or	O
even	O
being	O
completely	O
domain	O
and	O
language	O
independent	O
Onoe	O
and	O
Durrett	O
,	O
2020	O
)	O
.	O
Lin	O
et	O
al	O
.	O
(	O
2017	O
)	O
discuss	O
approaches	O
to	O
link	O
entities	O
to	O
a	O
KB	O
that	O
simply	O
contains	O
a	O
list	O
of	O
names	O
without	O
any	O
other	O
information	O
.	O
Sil	O
et	O
al	O
.	O
(	O
2012	O
)	O
use	O
databaseagnostic	O
features	O
to	O
link	O
against	O
arbitrary	O
databases	O
.	O
However	O
,	O
their	O
approach	O
still	O
requires	O
training	O
data	O
from	O
the	O
target	O
KB	O
.	O
In	O
contrast	O
,	O
this	O
work	O
aims	O
to	O
train	O
entity	O
linking	O
models	O
that	O
do	O
not	O
rely	O
on	O
training	O
data	O
from	O
the	O
target	O
KB	O
,	O
and	O
can	O
be	O
trained	O
on	O
arbitrary	O
KBs	O
,	O
and	O
applied	O
to	O
a	O
different	O
set	O
of	O
KBs	O
.	O
Pan	O
et	O
al	O
.	O
(	O
2015	O
)	O
also	O
do	O
unsupervised	O
entity	O
linking	O
by	O
generating	O
rich	O
context	O
representations	O
for	O
mentions	O
using	O
Abstract	O
Meaning	O
Representations	O
(	O
Banarescu	O
et	O
al	O
.	O
,	O
2013	O
)	O
,	O
followed	O
by	O
unsupervised	O
graph	O
inference	O
to	O
compare	O
contexts	O
.	O
They	O
assume	O
a	O
rich	O
target	O
KB	O
that	O
can	O
be	O
converted	O
to	O
a	O
connected	O
graph	O
.	O
This	O
works	O
for	O
Wikipedia	O
and	O
adjacent	O
resources	O
but	O
not	O
for	O
arbitrary	O
KBs	O
.	O
Logeswaran	O
et	O
al	O
.	O
(	O
2019	O
)	O
introduce	O
a	O
novel	O
zeroshot	O
framework	O
to	O
"	O
develop	O
entity	O
linking	O
systems	O
that	O
can	O
generalize	O
to	O
unseen	O
specialized	O
entities	O
"	O
.	O
Table	O
1	O
summarizes	O
differences	O
between	O
our	O
framework	O
and	O
those	O
from	O
prior	O
work	O
.	O

Contextualized	O
Representations	O
for	O
Entity	O
Linking	O
Models	O
in	O
this	O
work	O
are	O
based	O
on	O
BERT	O
.	O
While	O
many	O
studies	O
have	O
tried	O
to	O
explain	O
the	O
effectiveness	O
of	O
BERT	O
for	O
NLP	O
tasks	O
(	O
Rogers	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
the	O
work	O
by	O
Tenney	O
et	O
al	O
.	O
(	O
2019	O
)	O
is	O
most	O
relevant	O
as	O
they	O
use	O
probing	O
tasks	O
to	O
show	O
that	O
BERT	O
encodes	O
knowledge	O
of	O
entities	O
.	O
This	O
has	O
also	O
been	O
shown	O
empirically	O
by	O
many	O
works	O
that	O
use	O
BERT	O
and	O
other	O
contextualized	O
models	O
for	O
entity	O
linking	O
and	O
disambiguation	O
(	O
Broscheit	O
,	O
2019;Shahbazi	O
et	O
al	O
.	O
,	O
2019;Yamada	O
et	O
al	O
.	O
,	O
2020;Févry	O
et	O
al	O
.	O
,	O
2020;Poerner	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O

Preliminaries	O

Entity	O
Linking	O
Setup	O

Entity	O
linking	O
consists	O
of	O
disambiguating	O
entity	O
mentions	O
M	O
from	O
one	O
or	O
more	O
documents	O
to	O
a	O
target	O
knowledge	O
base	O
,	O
KB	O
,	O
containing	O
unique	O
entities	O
.	O
We	O
assume	O
that	O
each	O
entity	O
e	O
∈	O
KB	O
is	O
represented	O
using	O
a	O
set	O
of	O
attribute	O
-	O
value	O
pairs	O

{	O
(	O
k	O
i	O
,	O
v	O
i	O
)	O
}	O
n	O
i=1	O
.	O

The	O
attributes	O
k	O
i	O
collectively	O
form	O
the	O
schema	O
of	O
KB	O
.	O
The	O
disambiguation	O
of	O
each	O
m	O
∈	O
M	O
is	O
aided	O
by	O
the	O
context	O
c	O
in	O
which	O
m	O
appears	O
.	O

Models	O
for	O
entity	O
linking	O
typically	O
consist	O
of	O
two	O
stages	O
that	O
balance	O
recall	O
and	O
precision	O
.	O

Typically	O
,	O
models	O
for	O
candidate	O
generation	O
are	O
less	O
complex	O
(	O
and	O
hence	O
,	O
less	O
precise	O
)	O
than	O
those	O
used	O
in	O
the	O
following	O
(	O
re	O
-	O
ranking	O
)	O
stage	O
since	O
they	O
handle	O
all	O
entities	O
in	O
KB	O
.	O

1	O
.	O
Candidate	O
generation	O
:	O
The	O
objective	O
of	O
this	O
stage	O
is	O
to	O
select	O
K	O
candidate	O
entities	O
E	O
⊂	O
KB	O
for	O
each	O
mention	O
m	O
∈	O
M	O
,	O
where	O
K	O
is	O
a	O
hyperparameter	O
and	O
K	O
<	O
<	O
|KB|	O
.	O

Instead	O
,	O
the	O
goal	O
of	O
these	O
models	O
is	O
to	O
produce	O
a	O
small	O
but	O
high	O
-	O
recall	O
candidate	O
list	O
E.	O
Ergo	O
,	O
the	O
success	O
of	O
this	O
stage	O
is	O
measured	O
using	O
a	O
metric	O
such	O
as	O
recall@K	O
i.e.	O
whether	O
the	O
candidate	O
list	O
contains	O
the	O
correct	O
entity	O
.	O

2	O
.	O
Candidate	O
Reranking	O
:	O
This	O
stage	O
ranks	O
the	O
candidates	O
in	O
E	O
by	O
how	O
likely	O
they	O
are	O
to	O
be	O
the	O
correct	O
entity	O
.	O
Unlike	O
candidate	O
generation	O
,	O
models	O
for	O
re	O
-	O
ranking	O
are	O
typically	O
more	O
complex	O
and	O
oriented	O
towards	O
generating	O
a	O
high	O
-	O
precision	O
ranked	O
list	O
since	O
the	O
objective	O
of	O
this	O
stage	O
is	O
to	O
identify	O
the	O
most	O
likely	O
entity	O
for	O
each	O
mention	O
.	O
This	O
stage	O
is	O
evaluated	O
using	O
precision@1	O
(	O
or	O
accuracy	O
)	O
i.e.	O
whether	O
the	O
highest	O
ranked	O
entity	O
is	O
the	O
correct	O
entity	O
.	O

In	O
traditional	O
entity	O
linking	O
,	O
the	O
training	O
mentions	O
M	O
train	O
and	O
test	O
mentions	O
M	O
test	O
both	O
link	O
to	O
the	O
same	O
KB	O
.	O
Even	O
in	O
the	O
zero	O
-	O
shot	O
settings	O
of	O
Logeswaran	O
et	O
al	O
.	O
(	O
2019	O
)	O
,	O
while	O
the	O
training	O
and	O
target	O
domains	O
and	O
KBs	O
are	O
mutually	O
exclusive	O
,	O
the	O
schema	O
of	O
the	O
KB	O
is	O
constant	O
and	O
known	O
.	O
On	O
the	O
contrary	O
,	O
our	O
goal	O
is	O
to	O
link	O
test	O
mentions	O
M	O
test	O
to	O
a	O
knowledge	O
base	O
KB	O
test	O
which	O
is	O
not	O
known	O
during	O
training	O
.	O
The	O
objective	O
is	O
to	O
train	O
models	O
on	O
mentions	O
M	O
train	O
that	O
link	O
to	O
KB	O
train	O
and	O
directly	O
use	O
these	O
models	O
to	O
link	O
M	O
test	O
to	O
KB	O
test	O
.	O

Zero	O
-	O
shot	O
Entity	O
Linking	O

The	O
starting	O
point	O
(	O
and	O
baselines	O
)	O
for	O
our	O
work	O
are	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
models	O
for	O
zero	O
-	O
shot	O
entity	O
linking	O
,	O
which	O
we	O
briefly	O
describe	O
here	O
(	O
Wu	O
et	O
al	O
.	O
,	O
2020;Logeswaran	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
2	O
Candidate	O
Generation	O
Our	O
baseline	O
candidate	O
generation	O
approach	O
relies	O
on	O
similarities	O
between	O
mentions	O
and	O
candidates	O
in	O
a	O
vector	O
space	O
to	O
identify	O
the	O
candidates	O
for	O
each	O
mention	O
(	O
Wu	O
et	O
al	O
.	O
,	O
2020	O
)	O
using	O
two	O
BERT	O
models	O
.	O
The	O
first	O
BERT	O
model	O
encodes	O
a	O
mention	O
m	O
along	O
with	O
its	O
context	O
c	O
into	O
a	O
vector	O
representation	O
v	O
m	O
.	O
v	O
m	O
is	O
obtained	O
from	O
the	O
pooled	O
representation	O
captured	O
by	O
the	O
[	O
CLS	O
]	O
token	O
used	O
in	O
BERT	O
models	O
to	O
indicate	O
the	O
start	O
of	O
a	O
sequence	O
.	O
In	O
this	O
encoder	O
,	O
a	O
binary	O
(	O
0/1	O
)	O
indicator	O
vector	O
is	O
used	O
to	O
identify	O
the	O
mention	O
span	O
.	O
The	O
embeddings	O
for	O
this	O
indicator	O
vector	O
(	O
indicator	O
embeddings	O
)	O
are	O
added	O
to	O
the	O
token	O
embeddings	O
of	O
the	O
mention	O
as	O
in	O
Logeswaran	O
et	O
al	O
.	O
(	O
2019	O
)	O
.	O

The	O
second	O
unmodified	O
BERT	O
model	O
(	O
i.e.	O
not	O
containing	O
the	O
indicator	O
embeddings	O
as	O
in	O
the	O
mention	O
encoder	O
)	O
independently	O
encodes	O
each	O
e	O
∈	O
KB	O
into	O
vectors	O
.	O
The	O
candidates	O
E	O
for	O
a	O
mention	O
are	O
the	O
K	O
entities	O
whose	O
representations	O
are	O
most	O
similar	O
to	O
v	O
m	O
.	O
Both	O
BERT	O
models	O
are	O
fine	O
-	O
tuned	O
jointly	O
using	O
a	O
cross	O
-	O
entropy	O
loss	O
to	O
maximize	O
the	O
similarity	O
between	O
a	O
mention	O
and	O
its	O
corresponding	O
correct	O
entity	O
,	O
when	O
compared	O
to	O
other	O
random	O
entities	O
.	O

Candidate	O
Re	O
-	O
ranking	O
The	O
candidate	O
reranking	O
approach	O
uses	O
a	O
BERT	O
-	O
based	O
crossattention	O
encoder	O
to	O
jointly	O
encode	O
a	O
mention	O
and	O
its	O
context	O
along	O
with	O
each	O
candidate	O
from	O
E	O
(	O
Logeswaran	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Specifically	O
,	O
the	O
mention	O
m	O
is	O
concatenated	O
with	O
its	O
context	O
on	O
the	O
left	O
(	O
c	O
l	O
)	O
,	O
its	O
context	O
on	O
the	O
right	O
(	O
c	O
r	O
)	O
,	O
and	O
a	O
single	O
candidate	O
entity	O
e	O
∈	O
E.	O
An	O
[	O
SEP	O
]	O
token	O
,	O
which	O
is	O
used	O
in	O
BERT	O
to	O
separate	O
inputs	O
from	O
different	O
segments	O
,	O
is	O
used	O
here	O
to	O
separate	O
the	O
mention	O
in	O
context	O
,	O
from	O
the	O
candidate	O
.	O
This	O
concatenated	O
string	O
is	O
encoded	O
using	O
BERT	O
3	O
to	O
obtain	O
,	O
h	O
m	O
,	O
e	O
a	O
representation	O
for	O
this	O
mention	O
/	O
candidate	O
pair	O
(	O
from	O
the	O
[	O
CLS	O
]	O
token	O
)	O
.	O
Given	O
a	O
candidate	O
list	O
E	O
of	O
size	O
K	O
generated	O
in	O
the	O
previous	O
stage	O
,	O
K	O
scores	O
are	O
generated	O
for	O
each	O
mention	O
,	O
which	O
are	O
subsequently	O
scored	O
using	O
a	O
dot	O
-	O
product	O
with	O
a	O
learned	O
weight	O
vector	O
(	O
w	O
)	O
.	O
Thus	O
,	O

h	O
m	O
,	O
e	O
=	O
BERT([CLS	O
]	O
c	O
l	O
m	O
c	O
r	O
[	O
SEP	O
]	O
e	O
[	O
SEP	O
]	O
)	O
,	O
score	O
m	O
,	O
e	O
=	O
w	O
T	O
h	O
m	O
,	O
e	O
.	O

The	O
candidate	O
with	O
the	O
highest	O
score	O
is	O
chosen	O
as	O
the	O
correct	O
entity	O
,	O
i.e.	O

Linking	O
to	O
Unseen	O
Knowledge	O
Bases	O

The	O
models	O
in	O
Section	O
3	O
were	O
designed	O
to	O
operate	O
in	O
settings	O
where	O
the	O
entities	O
in	O
the	O
target	O
KB	O
were	O
only	O
represented	O
using	O
a	O
textual	O
description	O
.	O
For	O
example	O
,	O
the	O
entity	O
Douglas	O
Adams	O
would	O
be	O
represented	O
in	O
such	O
a	O
database	O
using	O
a	O
description	O
as	O
follows	O
:	O
"	O
Douglas	O
Adams	O
was	O
an	O
English	O
author	O
,	O
screenwriter	O
,	O
essayist	O
,	O
humorist	O
,	O
satirist	O
and	O
dramatist	O
.	O
He	O
was	O
the	O
author	O
of	O
The	O
Hitchhiker	O
's	O
Guide	O
to	O
the	O
Galaxy	O
.	O
"	O

However	O
,	O
linking	O
to	O
unseen	O
KBs	O
requires	O
handling	O
entities	O
with	O
an	O
arbitrary	O
number	O
and	O
type	O
of	O
attributes	O
.	O
The	O
same	O
entity	O
(	O
Douglas	O
Adams	O
)	O
can	O
be	O
represented	O
in	O
a	O
different	O
KB	O
using	O
attributes	O
such	O
as	O
"	O
name	O
"	O
,	O
"	O
place	O
of	O
birth	O
"	O
,	O
etc	O
.	O
(	O
top	O
of	O
Figure	O
1	O
)	O
.	O
This	O
raises	O
the	O
question	O
of	O
whether	O
such	O
models	O
,	O
that	O
harness	O
the	O
power	O
of	O
pre	O
-	O
trained	O
language	O
models	O
,	O
generalize	O
to	O
linking	O
mentions	O
to	O
unseen	O
KBs	O
,	O
including	O
those	O
without	O
such	O
textual	O
descriptions	O
.	O
This	O
section	O
presents	O
multiple	O
ideas	O
to	O
this	O
end	O
.	O

Representing	O
Arbitrary	O
Entities	O
using	O

Attribute	O
Separators	O

One	O
way	O
of	O
using	O
these	O
models	O
for	O
linking	O
against	O
arbitrary	O
KBs	O
is	O
by	O
defining	O
an	O
attribute	O
-	O
to	O
-	O
text	O
function	O
f	O
,	O
that	O
maps	O
arbitrary	O
entities	O
with	O
any	O
set	O
of	O
attributes	O
{	O
k	O
i	O
,	O
v	O
i	O
}	O
n	O
i=1	O
to	O
a	O
string	O
representation	O
e	O
that	O
can	O
be	O
consumed	O
by	O
BERT	O
,	O
i.e.	O

e	O
=	O
f	O
(	O
{	O
k	O
i	O
,	O
v	O
i	O
}	O
n	O
i=1	O
)	O
.	O

If	O
all	O
entities	O
in	O
the	O
KB	O
are	O
represented	O
using	O
such	O
string	O
representations	O
,	O
then	O
the	O
models	O
described	O
in	O
Section	O
3	O
can	O
directly	O
be	O
used	O
for	O
arbitrary	O
schemas	O
.	O
This	O
leads	O
to	O
the	O
question	O
:	O
how	O
can	O
we	O
generate	O
string	O
representations	O
for	O
entities	O
from	O
arbitrary	O
KBs	O
such	O
that	O
they	O
can	O
be	O
used	O
for	O
BERT	O
-	O
based	O
models	O
?	O
Alternatively	O
,	O
what	O
form	O
can	O
f	O
take	O
?	O

A	O
simple	O
answer	O
to	O
this	O
question	O
is	O
concatenation	O
of	O
the	O
values	O
v	O
i	O
,	O
given	O
by	O

f	O
(	O
{	O
k	O
i	O
,	O
v	O
i	O
}	O
n	O
i=1	O
)	O
=	O
v	O
1	O
v	O
2	O
...	O
v	O
n	O
.	O

We	O
can	O
improve	O
on	O
this	O
by	O
adding	O
some	O
structure	O
to	O
this	O
representation	O
by	O
teaching	O
our	O
model	O
that	O
the	O
v	O
i	O
belong	O
to	O
different	O
segments	O
.	O
As	O
in	O
the	O
baseline	O
candidate	O
re	O
-	O
ranking	O
model	O
,	O
we	O
do	O
this	O
by	O
separating	O
them	O
with	O
[	O
SEP	O
]	O
tokens	O
.	O
We	O
call	O
this	O
[	O
SEP]-separation	O
.	O
This	O
approach	O
is	O
also	O
used	O
by	O
Logeswaran	O
et	O
al	O
.	O
(	O
2019	O
)	O
andMulang	O
'	O
et	O
al	O
.	O
(	O
2020	O
)	O
"	O
name	O
"	O
:	O
"	O
Douglas	O
Adams	O
"	O
"	O
place	O
of	O
birth	O
"	O
:	O
"	O
Cambridge	O
"	O
"	O
occupation	O
"	O
:	O
"	O
novelist	O
"	O
"	O
employer	O
"	O
:	O
"	O
BBC	O
"	O
to	O
separate	O
the	O
entity	O
attributes	O
in	O
their	O
respective	O
KBs	O
.	O

f	O
(	O
{	O
k	O
i	O
,	O
v	O
i	O
}	O
n	O
i=1	O
)	O
=	O
[	O
SEP	O
]	O
v	O
1	O
[	O
SEP	O
]	O
v	O
2	O
...	O
[	O
SEP	O
]	O
v	O
n	O

The	O
above	O
two	O
definitions	O
of	O
f	O
use	O
the	O
values	O
v	O
i	O
,	O
but	O
not	O
the	O
attributes	O
k	O
i	O
,	O
which	O
also	O
contain	O
meaningful	O
information	O
.	O
For	O
example	O
,	O
if	O
an	O
entity	O
seen	O
during	O
inference	O
has	O
a	O
capital	O
attribute	O
with	O
the	O
value	O
"	O
New	O
Delhi	O
"	O
,	O
seeing	O
the	O
capital	O
attribute	O
allows	O
us	O
to	O
infer	O
that	O
the	O
target	O
entity	O
is	O
likely	O
to	O
be	O
a	O
place	O
,	O
rather	O
than	O
a	O
person	O
,	O
especially	O
if	O
we	O
have	O
seen	O
the	O
capital	O
attribute	O
during	O
training	O
.	O
We	O
capture	O
this	O
information	O
using	O
attribute	O
separators	O
,	O
which	O
are	O
reserved	O
tokens	O
(	O
in	O
the	O
vein	O
of	O
[	O
SEP	O
]	O
tokens	O
)	O
corresponding	O
to	O
attributes	O
.	O
In	O
this	O
case	O
,	O

f	O
(	O
{	O
k	O
i	O
,	O
v	O
i	O
}	O
n	O
i=1	O
)	O
=	O
[	O
K	O
1	O
]	O
v	O
1	O
[	O
K	O
2	O
]	O
v	O
2	O
...	O
[	O
K	O
n	O
]	O
v	O
n	O
.	O

These	O
Figure	O
1	O
illustrates	O
the	O
three	O
instantiations	O
of	O
f	O
.	O
In	O
all	O
cases	O
,	O
attribute	O
-	O
value	O
pairs	O
are	O
ordered	O
in	O
descending	O
order	O
of	O
the	O
frequency	O
with	O
which	O
they	O
appear	O
in	O
the	O
training	O
KB	O
.	O
Finally	O
,	O
since	O
both	O
the	O
candidate	O
generation	O
and	O
candidate	O
re	O
-	O
ranking	O
models	O
we	O
build	O
on	O
use	O
BERT	O
,	O
the	O
techniques	O
discussed	O
here	O
can	O
be	O
applied	O
to	O
both	O
stages	O
,	O
but	O
we	O
only	O
focus	O
on	O
re	O
-	O
ranking	O
.	O

Regularization	O
Schemes	O
for	O
Improving	O
Generalization	O

Building	O
models	O
for	O
entity	O
linking	O
against	O
unseen	O
KBs	O
requires	O
that	O
such	O
models	O
do	O
not	O
overfit	O
to	O
the	O
training	O
data	O
by	O
memorizing	O
characteristics	O
of	O
the	O
training	O
KB	O
.	O
This	O
is	O
done	O
by	O
using	O
two	O
regularization	O
schemes	O
that	O
we	O
apply	O
on	O
top	O
of	O
the	O
candidate	O
string	O
generation	O
techniques	O
discussed	O
in	O
the	O
previous	O
section	O
.	O

The	O
first	O
scheme	O
,	O
which	O
we	O
call	O
attribute	O
-	O
OOV	O
,	O
prevents	O
models	O
from	O
overtly	O
relying	O
on	O
individual	O
[	O
K	O
i	O
]	O
tokens	O
and	O
generalize	O
to	O
attributes	O
that	O
are	O
not	O
seen	O
during	O
training	O
.	O
Analogous	O
to	O
how	O
out	O
-	O
of	O
-	O
vocabulary	O
tokens	O
are	O
commonly	O
handled	O
(	O
Dyer	O
et	O
al	O
.	O
,	O
2015	O
,	O
inter	O
alia	O
)	O
,	O
every	O
[	O
K	O
i	O
]	O
token	O
is	O
stochastically	O
replaced	O
with	O
the	O
[	O
SEP	O
]	O
token	O
during	O
training	O
with	O
probability	O
p	O
drop	O
.	O
This	O
encourages	O
the	O
model	O
to	O
encode	O
semantics	O
of	O
the	O
attributes	O
in	O
not	O
only	O
the	O
[	O
K	O
i	O
]	O
tokens	O
,	O
but	O
also	O
in	O
the	O
[	O
SEP	O
]	O
token	O
,	O
which	O
is	O
used	O
when	O
unseen	O
attributes	O
are	O
encountered	O
during	O
inference	O
.	O

The	O
second	O
regularization	O
scheme	O
discourages	O
the	O
model	O
from	O
memorizing	O
the	O
order	O
in	O
which	O
particular	O
attributes	O
occur	O
.	O
Under	O
attribute	O
-	O
shuffle	O
,	O
every	O
time	O
an	O
entity	O
is	O
encountered	O
during	O
training	O
,	O
its	O
attribute	O
/	O
values	O
are	O
randomly	O
shuffled	O
before	O
it	O
is	O
converted	O
to	O
a	O
string	O
representation	O
using	O
the	O
techniques	O
from	O
Section	O
4.1	O
.	O

Experiments	O
and	O
Discussion	O

Data	O

Our	O
held	O
-	O
out	O
test	O
bed	O
is	O
the	O
TAC	O
-	O
KBP	O
2010	O
data	O
(	O
LDC2018T16	O
)	O
which	O
consists	O
of	O
documents	O
from	O
English	O
newswire	O
,	O
discussion	O
forum	O
and	O
web	O
data	O
(	O
Ji	O
et	O
al	O
.	O
,	O
2010	O
)	O
.	O
4	O
The	O
target	O
KB	O
(	O
KB	O
test	O
)	O
is	O
the	O
TAC	O
-	O
KBP	O
Reference	O
KB	O
and	O
is	O
built	O
from	O
English	O
Wikipedia	O
articles	O
and	O
their	O
associated	O
infoboxes	O
(	O
LDC2014T16	O
)	O
.	O
5	O
Our	O
primary	O
training	O
and	O
validation	O
data	O
is	O
the	O
CoNLL	O
-	O
YAGO	O
dataset	O
(	O
Hoffart	O
et	O
al	O
.	O
,	O
2011	O
)	O
Table	O
2	O
describes	O
the	O
sizes	O
of	O
these	O
various	O
datasets	O
along	O
with	O
the	O
number	O
of	O
entities	O
in	O
their	O
respective	O
KBs	O
.	O

While	O
covering	O
similar	O
domains	O
,	O
Wikidata	O
and	O
the	O
TAC	O
-	O
KBP	O
Reference	O
KB	O
have	O
different	O
schemas	O
.	O
Wikidata	O
is	O
more	O
structured	O
and	O
entities	O
are	O
associated	O
with	O
statements	O
represented	O
using	O
attribute	O
-	O
value	O
pairs	O
,	O
which	O
are	O
short	O
snippets	O
rather	O
than	O
full	O
sentences	O
.	O
The	O
TAC	O
-	O
KBP	O
Reference	O
KB	O
contains	O
both	O
short	O
snippets	O
like	O
these	O
,	O
along	O
with	O
the	O
text	O
of	O
the	O
Wikipedia	O
article	O
of	O
the	O
entity	O
.	O
The	O
two	O
KBs	O
also	O
differ	O
in	O
size	O
,	O
with	O
Wikidata	O
containing	O
almost	O
seven	O
times	O
the	O
number	O
of	O
entities	O
in	O
TAC	O
KBP	O
.	O

Both	O
during	O
training	O
and	O
inference	O
,	O
we	O
only	O
retain	O
the	O
100	O
most	O
frequent	O
attributes	O
in	O
the	O
respective	O
KBs	O
.	O
The	O
attribute	O
-	O
separators	O
(	O
Section	O
4.1	O
)	O
are	O
created	O
corresponding	O
to	O
the	O
100	O
most	O
frequent	O
attributes	O
in	O
the	O
training	O
KB	O
.	O
Candidates	O
and	O
mentions	O
(	O
with	O
context	O
)	O
are	O
represented	O
using	O
strings	O
of	O
128	O
sub	O
-	O
word	O
tokens	O
each	O
,	O
across	O
all	O
models	O
.	O

839	O

Hyperparameters	O

All	O
BERT	O
models	O
are	O
uncased	O
BERT	O
-	O
base	O
models	O
with	O
12	O
layers	O
,	O
768	O
hidden	O
units	O
,	O
and	O
12	O
heads	O
with	O
default	O
parameters	O
,	O
and	O
trained	O
on	O
English	O
Wikipedia	O
and	O
the	O
BookCorpus	O
.	O
The	O
probability	O
p	O
drop	O
for	O
attribute	O
-	O
OOV	O
is	O
set	O
to	O
0.3	O
.	O
Both	O
candidate	O
generation	O
and	O
re	O
-	O
ranking	O
models	O
are	O
trained	O
using	O
the	O
BERT	O
Adam	O
optimizer	O
(	O
Kingma	O
and	O
Ba	O
,	O
2015	O
)	O
,	O
with	O
a	O
linear	O
warmup	O
for	O
10	O
%	O
of	O
the	O
first	O
epoch	O
to	O
a	O
peak	O
learning	O
rate	O
of	O
2	O
×	O
10	O
−5	O
and	O
a	O
linear	O
decay	O
from	O
there	O
till	O
the	O
learning	O
rate	O
approaches	O
zero	O
.	O
9	O
Candidate	O
generation	O
models	O
are	O
trained	O
for	O
200	O
epochs	O
with	O
a	O
batch	O
size	O
of	O
256	O
.	O
Re	O
-	O
ranking	O
models	O
are	O
trained	O
for	O
4	O
epochs	O
with	O
a	O
batch	O
size	O
of	O
2	O
,	O
and	O
operate	O
on	O
the	O
top	O
32	O
candidates	O
returned	O
by	O
the	O
generation	O
model	O
.	O
Hyperparameters	O
are	O
chosen	O
such	O
that	O
models	O
can	O
be	O
run	O
on	O
a	O
single	O
NVIDIA	O
V100	O
Tensor	O
Core	O
GPU	O
with	O
32	O
GB	O
RAM	O
,	O
and	O
are	O
not	O
extensively	O
tuned	O
.	O
All	O
models	O
have	O
the	O
same	O
number	O
of	O
parameters	O
except	O
the	O
ones	O
with	O
attribute	O
-	O
separators	O
which	O
have	O
100	O
extra	O
token	O
embeddings	O
(	O
of	O
size	O
768	O
each	O
)	O
.	O

Candidate	O
generation	O
Since	O
the	O
focus	O
of	O
our	O
experiments	O
is	O
on	O
re	O
-	O
ranking	O
,	O
we	O
use	O
a	O
fixed	O
candidate	O
generation	O
model	O
for	O
all	O
experiments	O
that	O
combines	O
the	O
architecture	O
of	O
Wu	O
et	O
al	O
.	O
(	O
2020	O
)	O
(	O
Section	O
3	O
)	O
with	O
[	O
SEP]-separation	O
to	O
generate	O
candidate	O
strings	O
.	O
This	O
model	O
also	O
has	O
no	O
knowledge	O
of	O
the	O
test	O
KB	O
and	O
is	O
trained	O
only	O
once	O
on	O
the	O
CoNLL	O
-	O
Wikidata	O
dataset	O
.	O
It	O
achieves	O
a	O
recall@32	O
of	O
91.25	O
when	O
evaluated	O
on	O
the	O
unseen	O
TAC	O
-	O
KBP	O
2010	O
data	O
.	O

Research	O
Questions	O

We	O
evaluate	O
the	O
re	O
-	O
ranking	O
model	O
(	O
Section	O
3	O
)	O
in	O
several	O
settings	O
to	O
answer	O
the	O
following	O
questions	O
:	O
For	O
all	O
experiments	O
,	O
we	O
report	O
the	O
mean	O
and	O
standard	O
deviation	O
of	O
the	O
accuracy	O
across	O
five	O
runs	O
with	O
different	O
random	O
seeds	O
.	O

Main	O
results	O

Our	O
primary	O
experiments	O
focus	O
on	O
the	O
first	O
two	O
research	O
questions	O
and	O
study	O
the	O
accuracy	O
of	O
the	O
model	O
that	O
uses	O
the	O
re	O
-	O
ranking	O
architecture	O
from	O
Section	O
3	O
with	O
the	O
three	O
core	O
components	O
introduced	O
in	O
Section	O
4	O
viz	O
.	O
attribute	O
-	O
separators	O
to	O
generate	O
string	O
representations	O
of	O
candidates	O
,	O
along	O
with	O
attribute	O
-	O
OOV	O
and	O
attribute	O
-	O
shuffle	O
for	O
regularization	O
.	O
We	O
compare	O
this	O
against	O
two	O
baselines	O
without	O
these	O
components	O
that	O
use	O
the	O
same	O
architecture	O
and	O
use	O
concatenation	O
and	O
[	O
SEP]separation	O
instead	O
of	O
attribute	O
-	O
separators	O
.	O
As	O
a	O
reminder	O
,	O
all	O
models	O
are	O
trained	O
as	O
well	O
as	O
validated	O
on	O
CoNLL	O
-	O
Wikidata	O
and	O
evaluated	O
on	O
the	O
completely	O
unseen	O
TAC	O
-	O
KBP	O
2010	O
test	O
set	O
.	O

Results	O
confirm	O
that	O
adding	O
structure	O
to	O
the	O
candidate	O
string	O
representations	O
via	O
[	O
SEP	O
]	O
tokens	O
leads	O
to	O
more	O
accurate	O
models	O
compared	O
to	O
generating	O
strings	O
by	O
concatenation	O
(	O
Table	O
3	O
)	O
.	O
Using	O
attributeseparators	O
instead	O
of	O
[	O
SEP	O
]	O
tokens	O
leads	O
to	O
an	O
absolute	O
gain	O
of	O
over	O
5	O
%	O
and	O
handling	O
unseen	O
attributes	O
via	O
attribute	O
-	O
OOV	O
further	O
increases	O
the	O
accuracy	O
to	O
56.2	O
%	O
,	O
a	O
7.1	O
%	O
increase	O
over	O
the	O
[	O
SEP	O
]	O
baseline	O
.	O
These	O
results	O
show	O
that	O
the	O
attributeseparators	O
capture	O
meaningful	O
information	O
about	O
attributes	O
,	O
even	O
when	O
only	O
a	O
small	O
number	O
of	O
attributes	O
from	O
the	O
training	O
data	O
(	O
15	O
)	O
are	O
observed	O
during	O
inference	O
.	O
Shuffling	O
attribute	O
-	O
value	O
pairs	O
before	O
converting	O
them	O
to	O
a	O
string	O
representation	O
using	O
attributeseparators	O
also	O
independently	O
provides	O
an	O
absolute	O
gain	O
of	O
3.5	O
%	O
over	O
the	O
model	O
which	O
uses	O
attribute	O
-	O
separators	O
without	O
shuffling	O
.	O
Overall	O
,	O
models	O
that	O
combine	O
attribute	O
-	O
shuffling	O
and	O
attribute	O
-	O
OOV	O
are	O
the	O
most	O
accurate	O
with	O
an	O
accuracy	O
of	O
61.6	O
%	O
,	O
which	O
represents	O
a	O
12	O
%	O
absolute	O
gain	O
over	O
the	O
best	O
baseline	O
model	O
.	O

Prior	O
work	O
(	O
Raiman	O
and	O
Raiman	O
,	O
2018;Cao	O
et	O
al	O
.	O
,	O
2018;Wu	O
et	O
al	O
.	O
,	O
2020;Févry	O
et	O
al	O
.	O
,	O
2020	O
)	O
reports	O
higher	O
accuracies	O
on	O
the	O
TAC	O
data	O
but	O
they	O
are	O
fundamentally	O
incomparable	O
with	O
our	O
numbers	O
due	O
to	O
the	O
simple	O
fact	O
that	O
we	O
are	O
solving	O
a	O
different	O
task	O
with	O
three	O
key	O
differences	O
:	O
(	O
1	O
)	O
Models	O
in	O
prior	O
work	O
are	O
trained	O
and	O
evaluated	O
using	O
mentions	O
that	O
link	O
to	O
the	O
same	O
KB	O
.	O
On	O
the	O
contrary	O
,	O
we	O
show	O
how	O
far	O
we	O
can	O
go	O
without	O
such	O
in	O
-	O
KB	O
training	O
mentions	O
.	O

(	O
2	O
)	O
The	O
test	O
KB	O
used	O
by	O
these	O
works	O
is	O
different	O
from	O
our	O
test	O
KB	O
.	O
Each	O
entry	O
in	O
the	O
KB	O
used	O
by	O
prior	O
work	O
simply	O
consists	O
of	O
the	O
name	O
of	O
the	O
entity	O
with	O
a	O
textual	O
description	O
,	O
while	O
each	O
entity	O
in	O
our	O
KB	O
is	O
represented	O
via	O
multiple	O
attribute	O
-	O
value	O
pairs	O
.	O
(	O
3	O
)	O
These	O
models	O
exploit	O
the	O
homogeneous	O
nature	O
of	O
the	O
KBs	O
and	O
usually	O
pre	O
-	O
train	O
models	O
on	O
millions	O
of	O
mentions	O
from	O
Wikipedia	O
.	O
This	O
is	O
beneficial	O
when	O
the	O
training	O
and	O
test	O
KBs	O
are	O
Wikipedia	O
or	O
similar	O
,	O
but	O
is	O
beyond	O
the	O
scope	O
of	O
this	O
work	O
,	O
as	O
we	O
build	O
models	O
applicable	O
to	O
arbitrary	O
databases	O
.	O

Training	O
on	O
multiple	O
unrelated	O
datasets	O

An	O
additional	O
benefit	O
of	O
being	O
able	O
to	O
link	O
to	O
multiple	O
KBs	O
is	O
the	O
ability	O
to	O
train	O
on	O
more	O
than	O
one	O
dataset	O
,	O
each	O
of	O
which	O
links	O
to	O
a	O
different	O
KB	O
with	O
different	O
schemas	O
.	O
While	O
prior	O
work	O
has	O
been	O
unable	O
to	O
do	O
so	O
due	O
to	O
its	O
reliance	O
on	O
knowledge	O
of	O
KB	O
test	O
,	O
this	O
ability	O
is	O
more	O
crucial	O
in	O
the	O
settings	O
we	O
investigate	O
,	O
as	O
it	O
allows	O
us	O
to	O
stack	O
independent	O
datasets	O
for	O
training	O
.	O
This	O
allows	O
us	O
to	O
answer	O
our	O
third	O
research	O
question	O
.	O
Specifically	O
,	O
we	O
compare	O
the	O
[	O
SEP]-separation	O
baseline	O
with	O
our	O
full	O
model	O
that	O
uses	O
attribute	O
-	O
separators	O
,	O
attributeshuffle	O
,	O
and	O
attribute	O
-	O
OOV	O
.	O
We	O
ask	O
whether	O
the	O
%	O
of	O
TAC	O
4	O
)	O
.	O
In	O
contrast	O
,	O
the	O
baseline	O
model	O
observes	O
a	O
bigger	O
increase	O
in	O
accuracy	O
from	O
49.1	O
%	O
to	O
62.6	O
%	O
.	O
While	O
the	O
difference	O
between	O
the	O
two	O
models	O
reduces	O
,	O
the	O
full	O
model	O
remains	O
more	O
accurate	O
.	O
These	O
results	O
also	O
show	O
that	O
the	O
seamless	O
stacking	O
of	O
multiple	O
datasets	O
allowed	O
by	O
our	O
models	O
is	O
effective	O
empirically	O
.	O

Impact	O
of	O
schema	O
-	O
aware	O
training	O
data	O

Finally	O
,	O
we	O
investigate	O
to	O
what	O
extent	O
do	O
components	O
introduced	O
by	O
us	O
help	O
in	O
linking	O
when	O
there	O
is	O
training	O
data	O
available	O
that	O
links	O
to	O
the	O
inference	O
KB	O
,	O
KB	O
test	O
.	O
We	O
hypothesize	O
that	O
while	O
attributeseparators	O
will	O
still	O
be	O
useful	O
,	O
attribute	O
-	O
OOV	O
and	O
attribute	O
-	O
shuffle	O
will	O
be	O
less	O
useful	O
as	O
there	O
is	O
a	O
smaller	O
gap	O
between	O
training	O
and	O
test	O
scenarios	O
,	O
reducing	O
the	O
need	O
for	O
regularization	O
.	O

For	O
these	O
experiments	O
,	O
models	O
from	O
Section	O
5.4	O
are	O
further	O
trained	O
with	O
increasing	O
amounts	O
of	O
data	O
from	O
the	O
TAC	O
-	O
KBP	O
2010	O
training	O
set	O
.	O
A	O
sample	O
of	O
200	O
documents	O
is	O
held	O
out	O
from	O
the	O
training	O
data	O
as	O
a	O
validation	O
set	O
.	O
The	O
models	O
are	O
trained	O
with	O
the	O
exact	O
same	O
configuration	O
as	O
the	O
base	O
models	O
,	O
except	O
with	O
a	O
smaller	O
constant	O
learning	O
rate	O
of	O
2	O
×	O
10	O
−6	O
to	O
not	O
overfit	O
on	O
the	O
small	O
amounts	O
of	O
data	O
.	O
Unsurprisingly	O
,	O
the	O
accuracy	O
of	O
all	O
models	O
increases	O
as	O
the	O
amount	O
of	O
TAC	O
training	O
data	O
in-	O
Crucially	O
,	O
the	O
model	O
with	O
only	O
attribute	O
separators	O
is	O
the	O
most	O
accurate	O
model	O
across	O
the	O
spectrum	O
.	O
Moreover	O
,	O
the	O
difference	O
between	O
this	O
model	O
and	O
the	O
baseline	O
model	O
sharply	O
increases	O
as	O
the	O
amount	O
of	O
schema	O
-	O
aware	O
data	O
decreases	O
(	O
e.g.	O
when	O
using	O
13	O
annotated	O
documents	O
,	O
i.e.	O
1	O
%	O
of	O
the	O
training	O
data	O
,	O
we	O
get	O
a	O
9	O
%	O
boost	O
in	O
accuracy	O
over	O
the	O
model	O
that	O
does	O
not	O
see	O
any	O
schema	O
-	O
aware	O
data	O
)	O
.	O
These	O
trends	O
show	O
that	O
our	O
models	O
are	O
not	O
only	O
useful	O
in	O
settings	O
without	O
any	O
data	O
from	O
the	O
target	O
KB	O
,	O
but	O
also	O
in	O
settings	O
where	O
limited	O
data	O
is	O
available	O
.	O

Qualitative	O
Analysis	O

Beyond	O
the	O
quantitative	O
evaluations	O
above	O
,	O
we	O
further	O
qualitatively	O
analyze	O
the	O
predictions	O
of	O
the	O
best	O
model	O
from	O
Table	O
3	O
to	O
provide	O
insights	O
into	O
our	O
modeling	O
decisions	O
and	O
suggest	O
avenues	O
for	O
improvements	O
.	O

Improvements	O
over	O
baseline	O

First	O
,	O
we	O
categorize	O
all	O
newly	O
correct	O
mentions	O
,	O
i.e.	O
mentions	O
that	O
are	O
correctly	O
linked	O
by	O
the	O
top	O
model	O
but	O
incorrectly	O
linked	O
by	O
the	O
[	O
SEP]-separation	O
baseline	O
by	O
the	O
entity	O
type	O
of	O
the	O
gold	O
entity	O
.	O
This	O
type	O
is	O
one	O
of	O
person	O
(	O
PER	O
)	O
,	O
organization	O
(	O
ORG	O
)	O
,	O
geo	O
-	O
political	O
entity	O
(	O
GPE	O
)	O
,	O
and	O
a	O
catchall	O
unknown	O
10	O
The	O
0	O
%	O
results	O
are	O
the	O
same	O
as	O
those	O
in	O
Table	O
3	O
.	O
category	O
(	O
UKN	O
)	O
.	O
11	O
This	O
categorization	O
reveals	O
that	O
the	O
newly	O
correct	O
mentions	O
represent	O
about	O
15	O
%	O
of	O
the	O
total	O
mentions	O
of	O
the	O
ORG	O
,	O
GPE	O
,	O
and	O
UKN	O
categories	O
and	O
as	O
much	O
as	O
25	O
%	O
of	O
the	O
total	O
mentions	O
of	O
the	O
PER	O
category	O
.	O
This	O
distributed	O
improvement	O
highlights	O
that	O
the	O
relatively	O
higher	O
accuracy	O
of	O
our	O
model	O
is	O
due	O
to	O
a	O
holistic	O
improvement	O
in	O
modeling	O
unseen	O
KBs	O
across	O
all	O
entity	O
types	O
.	O

Why	O
does	O
PER	O
benefit	O
more	O
than	O
other	O
entity	O
types	O
?	O
To	O
answer	O
this	O
,	O
we	O
count	O
the	O
fraction	O
of	O
mentions	O
of	O
each	O
entity	O
type	O
that	O
have	O
at	O
least	O
one	O
column	O
represented	O
using	O
attribute	O
separators	O
.	O
This	O
counting	O
reveals	O
that	O
approximately	O
56	O
-	O
58	O
%	O
of	O
mentions	O
of	O
type	O
ORG	O
,	O
GPE	O
,	O
and	O
UKN	O
have	O
at	O
least	O
one	O
such	O
column	O
.	O
On	O
the	O
other	O
hand	O
,	O
this	O
number	O
is	O
71	O
%	O
for	O
PER	O
mentions	O
.	O
This	O
suggests	O
that	O
the	O
difference	O
is	O
directly	O
attributable	O
to	O
more	O
PER	O
entities	O
having	O
a	O
column	O
that	O
has	O
been	O
modeled	O
using	O
attribute	O
separators	O
,	O
further	O
highlighting	O
the	O
benefits	O
of	O
this	O
modeling	O
decision	O
.	O

Error	O
Analysis	O

To	O
identify	O
the	O
shortcomings	O
of	O
our	O
best	O
model	O
,	O
we	O
categorize	O
100	O
random	O
mentions	O
that	O
are	O
incorrectly	O
linked	O
by	O
this	O
model	O
into	O
six	O
categories	O
(	O
demonstrated	O
with	O
examples	O
in	O
Table	O
6	O
)	O
,	O
inspired	O
by	O
the	O
taxonomy	O
of	O
.	O

Under	O
this	O
taxonomy	O
,	O
a	O
common	O
error	O
(	O
33	O
%	O
)	O
is	O
predicting	O
a	O
more	O
specific	O
entity	O
than	O
that	O
indicated	O
by	O
the	O
mention	O
(	O
the	O
city	O
of	O
Hartford	O
,	O
Connecticut	O
,	O
rather	O
than	O
the	O
state	O
)	O
.	O
The	O
reverse	O
is	O
also	O
observed	O
(	O
i.e.	O
the	O
model	O
predicts	O
a	O
more	O
general	O
entity	O
)	O
,	O
but	O
far	O
less	O
frequently	O
(	O
6	O
%	O
)	O
.	O
Another	O
major	O
error	O
category	O
(	O
33	O
%	O
)	O
is	O
when	O
the	O
model	O
fails	O
to	O
pick	O
up	O
the	O
correct	O
signals	O
from	O
the	O
context	O
and	O
assigns	O
a	O
similarly	O
named	O
entity	O
of	O
a	O
similar	O
type	O
(	O
e.g.	O
the	O
river	O
Mobile	O
,	O
instead	O
of	O
the	O
city	O
Mobile	O
,	O
both	O
of	O
which	O
are	O
locations	O
)	O
.	O
21	O
%	O
of	O
the	O
errors	O
are	O
cases	O
where	O
the	O
model	O
predicts	O
an	O
entity	O
that	O
is	O
related	O
to	O
the	O
gold	O
entity	O
,	O
but	O
is	O
neither	O
more	O
specific	O
,	O
nor	O
more	O
generic	O
,	O
but	O
rather	O
of	O
a	O
different	O
type	O
(	O
Santos	O
Football	O
Club	O
instead	O
of	O
the	O
city	O
of	O
Santos	O
)	O
.	O

Errors	O
in	O
the	O
last	O
category	O
occur	O
when	O
the	O
model	O
predicts	O
an	O
entity	O
whose	O
name	O
has	O
no	O
string	O
overlap	O
with	O
that	O
of	O
the	O
gold	O
entity	O
or	O
the	O
mention	O
.	O
This	O
likely	O
happens	O
when	O
the	O
signals	O
from	O
the	O
context	O
override	O
the	O
signals	O
from	O
the	O
mention	O
itself	O
.	O

Conclusion	O

The	O
primary	O
contribution	O
of	O
this	O
work	O
is	O
a	O
novel	O
framework	O
for	O
entity	O
linking	O
against	O
unseen	O
target	O
KBs	O
with	O
unknown	O
schemas	O
.	O
To	O
this	O
end	O
,	O
we	O
introduce	O
methods	O
to	O
generalize	O
existing	O
models	O
for	O
zero	O
-	O
shot	O
entity	O
linking	O
to	O
link	O
to	O
unseen	O
KBs	O
.	O
These	O
methods	O
rely	O
on	O
converting	O
arbitrary	O
entities	O
represented	O
using	O
a	O
set	O
of	O
attribute	O
-	O
value	O
pairs	O
into	O
a	O
string	O
representation	O
that	O
can	O
be	O
then	O
consumed	O
by	O
models	O
from	O
prior	O
work	O
.	O

There	O
is	O
still	O
a	O
significant	O
gap	O
between	O
models	O
used	O
in	O
this	O
work	O
and	O
schema	O
-	O
aware	O
models	O
that	O
are	O
trained	O
on	O
the	O
same	O
KB	O
as	O
the	O
inference	O
KB	O
.	O
One	O
way	O
to	O
close	O
this	O
gap	O
is	O
by	O
using	O
automatic	O
table	O
-	O
to	O
-	O
text	O
generation	O
techniques	O
to	O
convert	O
arbitrary	O
entities	O
into	O
fluent	O
and	O
adequate	O
text	O
(	O
Kukich	O
,	O
1983;McKeown	O
,	O
1985;Reiter	O
and	O
Dale	O
,	O
1997;Wiseman	O
et	O
al	O
.	O
,	O
2017;Chisholm	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
Another	O
promising	O
direction	O
is	O
to	O
move	O
beyond	O
BERT	O
to	O
other	O
pre	O
-	O
trained	O
representations	O
that	O
are	O
better	O
known	O
to	O
encode	O
entity	O
information	O
(	O
Zhang	O
et	O
al	O
.	O
,	O
2019;Guu	O
et	O
al	O
.	O
,	O
2020;Poerner	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O

Finally	O
,	O
while	O
the	O
focus	O
of	O
this	O
work	O
is	O
only	O
on	O
English	O
entity	O
linking	O
,	O
challenges	O
associated	O
with	O
this	O
work	O
naturally	O
occur	O
in	O
multilingual	O
settings	O
as	O
well	O
.	O
Just	O
as	O
we	O
can	O
not	O
expect	O
labeled	O
data	O
for	O
every	O
target	O
KB	O
of	O
interest	O
,	O
we	O
also	O
can	O
not	O
expect	O
labeled	O
data	O
for	O
different	O
KBs	O
in	O
different	O
languages	O
.	O
In	O
future	O
work	O
,	O
we	O
aim	O
to	O
investigate	O
how	O
we	O
can	O
port	O
the	O
solutions	O
introduced	O
here	O
to	O
multilingual	O
settings	O
as	O
well	O
develop	O
novel	O
solutions	O
for	O
scenarios	O
where	O
the	O
documents	O
and	O
the	O
KB	O
are	O
in	O
languages	O
other	O
than	O
English	O
(	O
Sil	O
et	O
al	O
.	O
,	O
2018;Upadhyay	O
et	O
al	O
.	O
,	O
2018;Botha	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O

Acknowledgements	O

The	O
authors	O
would	O
like	O
to	O
thank	O
colleagues	O
from	O
Amazon	O
AI	O
for	O
many	O
helpful	O
discussions	O
that	O
shaped	O
this	O
work	O
,	O
and	O
for	O
reading	O
and	O
providing	O
feedback	O
on	O
earlier	O
drafts	O
of	O
the	O
paper	O
.	O
They	O
also	O
thank	O
all	O
the	O
anonymous	O
reviewers	O
for	O
their	O
helpful	O
feedback	O
.	O

Datasets	O
.	O
We	O
conduct	O
experiments	O
on	O
English	O
-	O
Macedonian	O
(	O
En	O
-	O
Mk	O
)	O
and	O
English	O
-	O
Albanian	O
(	O
En	O
-	O
Sq	O
)	O
,	O
as	O
Mk	O
,	O
Sq	O
are	O
low	O
-	O
resource	O
languages	O
,	O
where	O
lexical	O
-	O
level	O
alignment	O
can	O
be	O
most	O
beneficial	O
.	O
We	O
use	O
3	O
K	O
randomly	O
sampled	O
sentences	O
of	O
SETIMES	O
(	O
Tiedemann	O
,	O
2012	O
)	O
as	O
validation	O
/	O
test	O
sets	O
.	O
We	O
also	O
use	O
68	O
M	O
En	O
sentences	O
from	O
NewsCrawl	O
.	O
For	O
Sq	O
and	O
Mk	O
we	O
use	O
all	O
the	O
CommonCrawl	O
corpora	O
from	O
Ortiz	O
Suárez	O
et	O
al	O
.	O
(	O
2019	O
)	O
,	O
which	O
are	O
4	O
M	O
Sq	O
and	O
2.4	O
M	O
Mk	O
sentences	O
.	O

Baseline	O
.	O
We	O
use	O
a	O
method	O
that	O
relies	O
on	O
crosslingual	O
language	O
model	O
pretraining	O
,	O
namely	O
XLM	O
(	O
Lample	O
and	O
Conneau	O
,	O
2019	O
)	O
.	O
This	O
approach	O
trains	O
a	O
bilingual	O
MLM	O
separately	O
for	O
En	O
-	O
Mk	O
and	O
En	O
-	O
Sq	O
,	O
which	O
is	O
used	O
to	O
initialize	O
the	O
encoder	O
-	O
decoder	O
of	O
the	O
corresponding	O
NMT	O
system	O
.	O
Each	O
system	O
is	O
then	O
trained	O
in	O
an	O
unsupervised	O
way	O
.	O

The	O
scores	O
presented	O
are	O
significantly	O
different	O
(	O
p	O
<	O
0.05	O
)	O
from	O
the	O
respective	O
baseline	O
.	O
CHRF1	O
refers	O
to	O
character	O
n	O
-	O
gram	O
F1	O
score	O
(	O
Popović	O
,	O
2015	O
)	O
.	O
The	O
models	O
in	O
italics	O
are	O
ours	O
.	O

Table	O
1	O
shows	O
the	O
results	O
of	O
our	O
approach	O
compared	O
to	O
two	O
pretraining	O
approaches	O
that	O
rely	O
on	O
In	O
the	O
case	O
of	O
XLM	O
,	O
the	O
effect	O
of	O
cross	O
-	O
lingual	O
lexical	O
alignment	O
is	O
more	O
evident	O
for	O
En	O
-	O
Mk	O
,	O
as	O
Mk	O
is	O
less	O
similar	O
to	O
En	O
,	O
compared	O
to	O
Sq	O
.	O
This	O
is	O
mainly	O
the	O
case	O
because	O
the	O
two	O
languages	O
use	O
a	O
different	O
alphabet	O
(	O
Latin	O
for	O
En	O
and	O
Cyrillic	O
for	O
Mk	O
)	O
.	O
This	O
is	O
also	O
true	O
for	O
RE	O
-	O
LM	O
when	O
translating	O
out	O
of	O
En	O
,	O
showing	O
that	O
enhancing	O
the	O
fine	O
-	O
tuning	O
step	O
of	O
MLM	O
with	O
pretrained	O
embeddings	O
is	O
helpful	O
and	O
improves	O
the	O
final	O
UNMT	O
performance	O
.	O

In	O
Table	O
2	O
,	O
we	O
observe	O
that	O
lexical	O
alignment	O
is	O
more	O
beneficial	O
for	O
En	O
-	O
Mk	O
.	O
This	O
can	O
be	O
explained	O
by	O
the	O
limited	O
vocabulary	O
overlap	O
of	O
the	O
two	O
languages	O
,	O
which	O
does	O
not	O
provide	O
sufficient	O
crosslingual	O
signal	O
for	O
the	O
training	O
of	O
MLM	O
.	O
By	O
contrast	O
,	O
initializing	O
an	O
MLM	O
with	O
pretrained	O
embeddings	O
largely	O
improves	O
performance	O
,	O
even	O
for	O
a	O
higherperforming	O
model	O
,	O
such	O
as	O
RE	O
-	O
LM	O
.	O
In	O
En	O
-	O
Sq	O
,	O
the	O
effect	O
of	O
our	O
approach	O
is	O
smaller	O
yet	O
consistent	O
.	O
This	O
can	O
be	O
attributed	O
to	O
the	O
fact	O
that	O
the	O
two	O
languages	O
use	O
the	O
same	O
script	O
.	O

Overall	O
,	O
our	O
method	O
enhances	O
the	O
lexical	O
-	O
level	O
information	O
captured	O
by	O
pretrained	O
MLMs	O
,	O
as	O
shown	O
empirically	O
.	O
This	O
is	O
consistent	O
with	O
our	O
intuition	O
that	O
cross	O
-	O
lingual	O
embeddings	O
capture	O
a	O
bilingual	O
signal	O
that	O
can	O
benefit	O
MLM	O
representations	O
.	O
1	O
-	O
gram	O
precision	O
scores	O
.	O
To	O
examine	O
whether	O
the	O
improved	O
translation	O
performance	O
is	O
a	O
result	O
of	O
the	O
lexical	O
-	O
level	O
information	O
provided	O
by	O
static	O
embeddings	O
,	O
we	O
present	O
1	O
-	O
gram	O
precision	O
scores	O
in	O
Ta-	O
ble	O
3	O
,	O
as	O
they	O
can	O
be	O
directly	O
attributed	O
to	O
lexical	O
alignment	O
.	O
The	O
biggest	O
performance	O
gains	O
(	O
up	O
to	O
+10.4	O
)	O
are	O
obtained	O
when	O
the	O
proposed	O
approach	O
is	O
applied	O
to	O
XLM	O
.	O
This	O
correlates	O
with	O
the	O
BLEU	O
scores	O
of	O
Table	O
1	O
.	O
Moreover	O
,	O
the	O
En	O
-	O
Mk	O
language	O
pair	O
benefits	O
more	O
than	O
En	O
-	O
Sq	O
from	O
the	O
lexicallevel	O
alignment	O
both	O
in	O
terms	O
of	O
1	O
-	O
gram	O
precision	O
and	O
BLEU	O
.	O
These	O
results	O
show	O
that	O
the	O
improved	O
BLEU	O
scores	O
can	O
be	O
attributed	O
to	O
the	O
enhanced	O
lexical	O
representations	O
.	O
How	O
should	O
static	O
embeddings	O
be	O
integrated	O
in	O
the	O
MLM	O
training	O
?	O
We	O
explore	O
different	O
ways	O
of	O
incorporating	O
the	O
lexical	O
knowledge	O
of	O
pretrained	O
cross	O
-	O
lingual	O
embeddings	O
to	O
the	O
second	O
,	O
masked	O
language	O
modeling	O
stage	O
of	O
our	O
approach	O
(	O
§	O
2.2	O
)	O
.	O
Specifically	O
,	O
we	O
keep	O
the	O
aligned	O
embeddings	O
fixed	O
(	O
frozen	O
)	O
during	O
XLM	O
training	O
and	O
compare	O
the	O
performance	O
of	O
the	O
final	O
UNMT	O
model	O
to	O
the	O
proposed	O
(	O
fine	O
-	O
tuned	O
)	O
method	O
.	O
We	O
point	O
out	O
that	O
,	O
after	O
we	O
transfer	O
the	O
trained	O
MLM	O
to	O
an	O
encoder	O
-	O
decoder	O
model	O
,	O
all	O
layers	O
are	O
trained	O
for	O
UNMT	O
.	O

We	O
tie	O
the	O
embedding	O
and	O
output	O
(	O
projection	O
)	O
layers	O
of	O
both	O
LM	O
and	O
NMT	O
models	O
(	O
Press	O
and	O
Wolf	O
,	O
2017	O
)	O
.	O
We	O
use	O
a	O
dropout	O
rate	O
of	O
0.1	O
and	O
GELU	O
activations	O
(	O
Hendrycks	O
and	O
Gimpel	O
,	O
2017	O
)	O
.	O
We	O
use	O
the	O
default	O
parameters	O
of	O
Lample	O
and	O
Conneau	O
(	O
2019	O
)	O
in	O
order	O
to	O
train	O
our	O
models	O
.	O

In	O
this	O
work	O
,	O
we	O
focus	O
on	O
self	O
-	O
supervised	O
,	O
alignment	O
-	O
oriented	O
training	O
tasks	O
using	O
minimum	O
parallel	O
data	O
to	O
improve	O
mBERT	O
's	O
cross	O
-	O
lingual	O
transferability	O
.	O
We	O
propose	O
a	O
Post	O
-	O
Pretraining	O
Alignment	O
(	O
PPA	O
)	O
method	O
consisting	O
of	O
both	O
wordlevel	O
and	O
sentence	O
-	O
level	O
alignment	O
,	O
as	O
well	O
as	O
a	O
finetuning	O
technique	O
on	O
downstream	O
tasks	O
that	O
take	O
pairs	O
of	O
text	O
as	O
input	O
,	O
such	O
as	O
NLI	O
and	O
Question	O
Answering	O
(	O
QA	O
)	O
.	O
Specifically	O
,	O
we	O
use	O
a	O
slightly	O
different	O
version	O
of	O
TLM	O
as	O
our	O
word	O
-	O
level	O
alignment	O
task	O
and	O
contrastive	O
learning	O
(	O
Hadsell	O
et	O
al	O
.	O
,	O
2006	O
)	O
on	O
mBERT	O
's	O
[	O
CLS	O
]	O
tokens	O
to	O
align	O
sentence	O
-	O
level	O
representations	O
.	O
Both	O
tasks	O
are	O
self	O
-	O
supervised	O
and	O
do	O
not	O
require	O
pre	O
-	O
alignment	O
tools	O
such	O
as	O
FastAlign	O
.	O
Our	O
sentence	O
-	O
level	O
alignment	O
is	O
implemented	O
using	O
MoCo	O
(	O
He	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
an	O
instance	O
discrimination	O
-	O
based	O
method	O
of	O
contrastive	O
learn-	O
ing	O
that	O
was	O
recently	O
proposed	O
for	O
self	O
-	O
supervised	O
representation	O
learning	O
in	O
computer	O
vision	O
.	O
Lastly	O
,	O
when	O
finetuning	O
on	O
NLI	O
and	O
QA	O
tasks	O
for	O
non	O
-	O
English	O
languages	O
,	O
we	O
perform	O
sentence	O
-	O
level	O
codeswitching	O
with	O
English	O
as	O
a	O
form	O
of	O
both	O
alignment	O
and	O
data	O
augmentation	O
.	O
We	O
conduct	O
controlled	O
experiments	O
on	O
XNLI	O
and	O
MLQA	O
(	O
Lewis	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
leveraging	O
varying	O
amounts	O
of	O
parallel	O
data	O
during	O
alignment	O
.	O
We	O
then	O
conduct	O
an	O
ablation	O
study	O
that	O
shows	O
the	O
effectiveness	O
of	O
our	O
method	O
.	O
On	O
XNLI	O
,	O
our	O
aligned	O
mBERT	O
improves	O
over	O
the	O
original	O
mBERT	O
by	O
4.7	O
%	O
for	O
zero	O
-	O
shot	O
transfer	O
,	O
and	O
outperforms	O
Cao	O
et	O
al	O
.	O
(	O
2020	O
)	O
while	O
using	O
the	O
same	O
amount	O
of	O
parallel	O
data	O
from	O
the	O
same	O
source	O
.	O
For	O
translate	O
-	O
train	O
,	O
where	O
translation	O
of	O
English	O
training	O
data	O
is	O
available	O
in	O
the	O
target	O
language	O
,	O
our	O
model	O
achieves	O
comparable	O
performance	O
to	O
XLM	O
while	O
using	O
far	O
fewer	O
resources	O
.	O
On	O
MLQA	O
,	O
we	O
get	O
2.3	O
%	O
improvement	O
over	O
mBERT	O
and	O
outperform	O
XLM	O
-	O
R	O
Base	O
for	O
zero	O
-	O
shot	O
transfer	O
.	O

Concretely	O
,	O
MoCo	O
employs	O
a	O
dual	O
-	O
encoder	O
architecture	O
.	O
Given	O
two	O
views	O
v	O
1	O
and	O
v	O
2	O
of	O
the	O
same	O
image	O
,	O
v	O
1	O
is	O
encoded	O
by	O
the	O
query	O
encoder	O
f	O
q	O
and	O
v	O
2	O
by	O
the	O
momentum	O
encoder	O
f	O
k	O
.	O
v	O
1	O
and	O
v	O
2	O
form	O
a	O
positive	O
pair	O
.	O
Negative	O
examples	O
are	O
views	O
of	O
different	O
source	O
images	O
,	O
and	O
are	O
stored	O
in	O
a	O
queue	O
∈	O
K	O
,	O
which	O
is	O
randomly	O
initialized	O
.	O
K	O
is	O
usually	O
a	O
large	O
number	O
(	O
e.g.	O
,	O
K	O
=	O
65	O
,	O
536	O
for	O
ImageNet	O
)	O
.	O
Negative	O
pairs	O
are	O
formed	O
by	O
comparing	O
v	O
1	O
with	O
each	O
item	O
in	O
the	O
queue	O
.	O
Similarity	O
between	O
pairs	O
is	O
measured	O
by	O
dot	O
product	O
.	O
MoCo	O
uses	O
the	O
InfoNCE	O
loss	O
(	O
van	O
den	O
Oord	O
et	O
al	O
.	O
,	O
2019	O
)	O
to	O
bring	O
positive	O
pairs	O
closer	O
to	O
each	O
other	O
and	O
push	O
negative	O
pairs	O
apart	O
.	O
After	O
a	O
batch	O
of	O
view	O
pairs	O
are	O
processed	O
,	O
those	O
encoded	O
by	O
the	O
momentum	O
encoder	O
are	O
added	O
to	O
the	O
queue	O
as	O
negative	O
examples	O
for	O
future	O
queries	O
.	O
During	O
training	O
,	O
the	O
query	O
encoder	O
is	O
updated	O
by	O
the	O
optimizer	O
while	O
the	O
momentum	O
encoder	O
is	O
updated	O
by	O
the	O
exponential	O
moving	O
average	O
of	O
the	O
query	O
encoder	O
's	O
parameters	O
to	O
maintain	O
queue	O
consistency	O
:	O

For	O
both	O
PPA	O
and	O
finetuning	O
on	O
downstream	O
tasks	O
,	O
we	O
use	O
the	O
AdamW	O
optimizer	O
with	O
0.01	O
weight	O
decay	O
and	O
a	O
linear	O
learning	O
rate	O
scheduler	O
.	O
For	O
PPA	O
,	O
we	O
use	O
a	O
batch	O
size	O
of	O
128	O
,	O
mBERT	O
max	O
sequence	O
length	O
128	O
and	O
learning	O
rate	O
warmup	O
for	O
the	O
first	O
10	O
%	O
of	O
the	O
total	O
iterations	O
,	O
peaking	O
at	O
0.00003	O
.	O
The	O
MoCo	O
momentum	O
is	O
set	O
to	O
0.999	O
,	O
queue	O
size	O
32000	O
and	O
temperature	O
0.05	O
.	O
Our	O
PPA	O
models	O
are	O
trained	O
for	O
10	O
epochs	O
,	O
except	O
for	O
the	O
2	O
M	O
setting	O
where	O
5	O
epochs	O
are	O
trained	O
.	O
On	O
XNLI	O
,	O
we	O
use	O
a	O
batch	O
size	O
of	O
32	O
,	O
mBERT	O
max	O
sequence	O
length	O
128	O
and	O
finetune	O
the	O
PPA	O
model	O
for	O
2	O
epochs	O
.	O
Learning	O
rate	O
peaks	O
at	O
0.00005	O
and	O
warmup	O
is	O
done	O
to	O
the	O
first	O
1000	O
iterations	O
.	O
On	O
MLQA	O
,	O
mBERT	O
max	O
sequence	O
length	O
is	O
set	O
to	O
386	O
and	O
peak	O
learning	O
rate	O
0.00003	O
.	O
The	O
other	O
parameters	O
are	O
the	O
same	O
as	O
XNLI	O
.	O
Our	O
experiments	O
are	O
run	O
on	O
a	O
single	O
32	O
GB	O
V100	O
GPU	O
,	O
except	O
for	O
PPA	O
training	O
that	O
involves	O
either	O
MLM	O
or	O
TLM	O
,	O
where	O
two	O
such	O
GPUs	O
are	O
used	O
.	O
We	O
also	O
use	O
mixed	O
-	O
precision	O
training	O
to	O
save	O
on	O
GPU	O
memory	O
and	O
speed	O
up	O
experiments	O
.	O

Unsupervised	O
multiple	O
-	O
choice	O
question	O
generation	O
for	O
out	O
-	O
of	O
-	O
domain	O
Q&A	O
fine	O
-	O
tuning	O

Pre	O
-	O
trained	O
models	O
have	O
shown	O
very	O
good	O
performances	O
on	O
a	O
number	O
of	O
question	O
answering	O
benchmarks	O
especially	O
when	O
fine	O
-	O
tuned	O
on	O
multiple	O
question	O
answering	O
datasets	O
at	O
once	O
.	O
In	O
this	O
work	O
,	O
we	O
propose	O
an	O
approach	O
for	O
generating	O
a	O
fine	O
-	O
tuning	O
dataset	O
thanks	O
to	O
a	O
rule	O
-	O
based	O
algorithm	O
that	O
generates	O
questions	O
and	O
answers	O
from	O
unannotated	O
sentences	O
.	O
We	O
show	O
that	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
model	O
UnifiedQA	O
can	O
greatly	O
benefit	O
from	O
such	O
a	O
system	O
on	O
a	O
multiple	O
-	O
choice	O
benchmark	O
about	O
physics	O
,	O
biology	O
and	O
chemistry	O
it	O
has	O
never	O
been	O
trained	O
on	O
.	O
We	O
further	O
show	O
that	O
improved	O
performances	O
may	O
be	O
obtained	O
by	O
selecting	O
the	O
most	O
challenging	O
distractors	O
(	O
wrong	O
answers	O
)	O
,	O
with	O
a	O
dedicated	O
ranker	O
based	O
on	O
a	O
pretrained	O
RoBERTa	O
model	O
.	O

Introduction	O

In	O
the	O
past	O
years	O
,	O
deep	O
learning	O
models	O
have	O
greatly	O
improved	O
their	O
performances	O
on	O
a	O
large	O
range	O
of	O
question	O
answering	O
tasks	O
,	O
especially	O
using	O
pretrained	O
models	O
such	O
as	O
BERT	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
RoBERTa	O
(	O
Liu	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
T5	O
(	O
Raffel	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
More	O
recently	O
,	O
these	O
models	O
have	O
shown	O
even	O
better	O
performances	O
when	O
fine	O
-	O
tuned	O
on	O
multiple	O
question	O
answering	O
datasets	O
at	O
once	O
.	O
Such	O
a	O
model	O
is	O
UnifiedQA	O
(	O
Khashabi	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
which	O
,	O
starting	O
from	O
a	O
T5	O
model	O
,	O
is	O
trained	O
on	O
a	O
large	O
number	O
of	O
question	O
answering	O
datasets	O
including	O
multiple	O
choices	O
,	O
yes	O
/	O
no	O
,	O
extractive	O
and	O
abstractive	O
question	O
answering	O
.	O
UnifiedQA	O
is	O
,	O
at	O
the	O
time	O
of	O
writing	O
,	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
on	O
a	O
large	O
number	O
of	O
question	O
answering	O
datasets	O
including	O
multiple	O
-	O
choice	O
datasets	O
like	O
OpenBookQA	O
(	O
Mihaylov	O
et	O
al	O
.	O
,	O
2018	O
)	O
or	O
ARC	O
.	O
However	O
,	O
even	O
if	O
Uni	O
-	O
fiedQA	O
achieves	O
good	O
results	O
on	O
previously	O
unseen	O
datasets	O
,	O
it	O
often	O
fails	O
to	O
achieve	O
optimal	O
performances	O
on	O
these	O
datasets	O
until	O
it	O
is	O
further	O
finetuned	O
on	O
dedicated	O
human	O
annotated	O
data	O
.	O
This	O
tendency	O
is	O
increased	O
when	O
the	O
target	O
dataset	O
deals	O
with	O
questions	O
about	O
a	O
very	O
specific	O
domain	O
.	O

One	O
solution	O
to	O
this	O
problem	O
would	O
be	O
to	O
finetune	O
or	O
retrain	O
these	O
models	O
with	O
additionnal	O
human	O
annotated	O
data	O
.	O
However	O
,	O
this	O
is	O
expensive	O
both	O
in	O
time	O
and	O
resources	O
.	O
Instead	O
,	O
a	O
lot	O
of	O
work	O
has	O
been	O
done	O
lately	O
on	O
automatically	O
generating	O
training	O
data	O
for	O
fine	O
-	O
tuning	O
or	O
even	O
training	O
completely	O
unsupervised	O
models	O
for	O
question	O
answering	O
.	O
One	O
commonly	O
used	O
dataset	O
for	O
unsupervised	O
question	O
answering	O
is	O
the	O
extractive	O
dataset	O
SQUAD	O
(	O
Rajpurkar	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
proposed	O
a	O
question	O
generation	O
method	O
for	O
SQUAD	O
using	O
an	O
unsupervised	O
neural	O
based	O
translation	O
method	O
.	O
Fabbri	O
et	O
al	O
.	O
(	O
2020	O
)	O
and	O
further	O
gave	O
improved	O
unsupervised	O
performances	O
on	O
SQUAD	O
and	O
showed	O
that	O
simple	O
rulebased	O
question	O
generation	O
could	O
be	O
as	O
effective	O
as	O
the	O
previously	O
mentioned	O
neural	O
method	O
.	O
These	O
approches	O
are	O
rarely	O
applied	O
to	O
multiple	O
-	O
choice	O
questions	O
answering	O
in	O
part	O
due	O
to	O
the	O
difficulty	O
of	O
selecting	O
distractors	O
.	O
A	O
few	O
research	O
papers	O
however	O
proposed	O
distractor	O
selection	O
methods	O
for	O
multiple	O
-	O
choice	O
questions	O
using	O
either	O
supervised	O
approaches	O
(	O
Sakaguchi	O
et	O
al	O
.	O
,	O
2013;Liang	O
et	O
al	O
.	O
,	O
2018	O
)	O
or	O
general	O
purpose	O
knowledge	O
bases	O
(	O
Ren	O
and	O
Q.	O
Zhu	O
,	O
2021	O
)	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
an	O
unsupervised	O
process	O
to	O
generate	O
questions	O
,	O
answers	O
and	O
associated	O
distractors	O
in	O
order	O
to	O
fine	O
-	O
tune	O
and	O
improve	O
the	O
performance	O
of	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
model	O
UnifiedQA	O
on	O
unseen	O
domains	O
.	O
This	O
method	O
,	O
being	O
unsupervised	O
,	O
needs	O
no	O
additional	O
annotated	O
domain	O
specific	O
data	O
requiring	O
only	O
a	O
set	O
of	O
unannotated	O
sentences	O
of	O
the	O
domain	O
of	O
interest	O
from	O
which	O
the	O
questions	O
are	O
created	O
.	O
Contrarily	O
to	O
most	O
of	O
the	O
aforementioned	O
works	O
,	O
our	O
aim	O
is	O
not	O
to	O
train	O
a	O
new	O
completely	O
unsupervised	O
model	O
but	O
rather	O
to	O
incorporate	O
new	O
information	O
into	O
an	O
existing	O
stateof	O
-	O
the	O
-	O
art	O
model	O
and	O
thus	O
to	O
take	O
advantage	O
of	O
the	O
question	O
-	O
answering	O
knowledge	O
already	O
learned	O
.	O

We	O
conduct	O
our	O
experiments	O
on	O
the	O
SciQ	O
dataset	O
(	O
Welbl	O
et	O
al	O
.	O
,	O
2017	O
choice	O
questions	O
(	O
4	O
choices	O
)	O
featuring	O
subjects	O
centered	O
around	O
physics	O
,	O
biology	O
and	O
chemistry	O
.	O
An	O
example	O
of	O
question	O
can	O
be	O
found	O
in	O
Figure	O
1	O
.	O
We	O
focus	O
on	O
the	O
SciQ	O
dataset	O
because	O
it	O
has	O
not	O
yet	O
been	O
used	O
for	O
training	O
UnifiedQA	O
and	O
it	O
requires	O
precise	O
scientific	O
knowledge	O
.	O
Furthermore	O
,	O
our	O
experiments	O
reveal	O
that	O
the	O
direct	O
application	O
of	O
UnifiedQA	O
on	O
the	O
SciQ	O
benchmark	O
leads	O
to	O
a	O
much	O
lower	O
performance	O
than	O
when	O
fine	O
-	O
tuning	O
it	O
on	O
the	O
SciQ	O
training	O
set	O
(	O
see	O
Section	O
4	O
)	O
.	O
Our	O
objective	O
in	O
this	O
work	O
is	O
to	O
solve	O
this	O
gap	O
between	O
UnifiedQA	O
and	O
UnifiedQA	O
fine	O
-	O
tuned	O
on	O
supervised	O
data	O
with	O
the	O
unsupervised	O
question	O
generation	O
approach	O
described	O
in	O
Section	O
2	O
.	O
We	O
additionally	O
test	O
our	O
method	O
on	O
two	O
commonly	O
used	O
multiple	O
choice	O
question	O
answering	O
datasets	O
:	O
Common	O
-	O
senseQA	O
(	O
Talmor	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
QASC	O
.	O
These	O
datasets	O
contain	O
questions	O
with	O
similar	O
domains	O
to	O
SciQ	O
even	O
though	O
the	O
questions	O
are	O
slightly	O
less	O
specific	O
.	O
Furthermore	O
,	O
neither	O
of	O
them	O
has	O
been	O
used	O
during	O
the	O
initial	O
training	O
of	O
UnifiedQA	O
.	O

Question	O
Generation	O
Method	O

We	O
propose	O
a	O
method	O
for	O
generating	O
multiplechoice	O
questions	O
in	O
order	O
to	O
fine	O
-	O
tune	O
and	O
improve	O
UnifiedQA	O
.	O
This	O
process	O
is	O
based	O
on	O
3	O
steps	O
.	O
First	O
,	O
a	O
set	O
of	O
sentences	O
is	O
being	O
selected	O
(	O
Section	O
2.1	O
)	O
from	O
which	O
a	O
generic	O
question	O
generation	O
system	O
is	O
applied	O
(	O
Section	O
2.2	O
)	O
.	O
Then	O
a	O
number	O
of	O
distractors	O
are	O
added	O
to	O
each	O
question	O
(	O
Section	O
2.3	O
)	O
.	O

Sentence	O
Selection	O

Our	O
question	O
generation	O
method	O
uses	O
a	O
set	O
of	O
unannotated	O
sentences	O
from	O
which	O
the	O
questions	O
will	O
be	O
generated	O
.	O
We	O
compare	O
three	O
selection	O
methods	O
.	O
First	O
,	O
we	O
consider	O
a	O
scenario	O
where	O
the	O
application	O
developer	O
does	O
not	O
manually	O
collect	O
any	O
sentence	O
,	O
but	O
simply	O
gives	O
the	O
name	O
(	O
or	O
topic	O
)	O
of	O
the	O
target	O
domain	O
.	O
In	O
our	O
case	O
,	O
the	O
topics	O
are	O
"	O
Physics	O
"	O
,	O
"	O
Biology	O
"	O
and	O
"	O
Chemistry	O
"	O
since	O
these	O
are	O
the	O
main	O
domains	O
in	O
SciQ.	O
A	O
simple	O
information	O
retrieval	O
strategy	O
is	O
then	O
applied	O
to	O
automatically	O
mine	O
sentences	O
from	O
Wikipedia	O
.	O
We	O
first	O
compute	O
a	O
list	O
of	O
Wikipedia	O
categories	O
by	O
recursively	O
visiting	O
all	O
subcategories	O
starting	O
from	O
the	O
target	O
topic	O
names	O
.	O
The	O
maximum	O
recursion	O
number	O
is	O
limited	O
to	O
4	O
.	O
We	O
then	O
extract	O
the	O
summary	O
(	O
head	O
paragraph	O
of	O
each	O
Wikipedia	O
article	O
)	O
for	O
each	O
of	O
the	O
articles	O
matching	O
the	O
previously	O
extracted	O
categories	O
and	O
subcategories	O
.	O
We	O
only	O
keep	O
articles	O
with	O
more	O
than	O
800	O
average	O
visitors	O
per	O
day	O
for	O
the	O
last	O
ten	O
days	O
(	O
on	O
April	O
27	O
,	O
2021	O
)	O
,	O
resulting	O
in	O
12	O
656	O
pages	O
.	O

The	O
two	O
other	O
selection	O
methods	O
extract	O
sentences	O
from	O
SciQ	O
itself	O
and	O
therefore	O
are	O
not	O
entirely	O
unsupervised	O
but	O
rather	O
simulate	O
a	O
situation	O
where	O
we	O
have	O
access	O
to	O
unannotated	O
texts	O
that	O
precisely	O
describe	O
the	O
domains	O
of	O
interest	O
such	O
as	O
a	O
school	O
book	O
for	O
example	O
.	O
The	O
SciQ	O
dataset	O
includes	O
a	O
support	O
paragraph	O
for	O
each	O
question	O
(	O
see	O
Figure	O
1	O
)	O
.	O
Pooled	O
together	O
,	O
these	O
support	O
paragraphs	O
provide	O
us	O
with	O
a	O
large	O
dataset	O
of	O
texts	O
about	O
the	O
domains	O
of	O
interest	O
.	O
We	O
gather	O
the	O
paragraphs	O
corresponding	O
to	O
all	O
questions	O
and	O
split	O
them	O
into	O
sentences	O
to	O
produce	O
a	O
large	O
set	O
of	O
sentences	O
that	O
are	O
no	O
longer	O
associated	O
with	O
any	O
particular	O
question	O
but	O
cover	O
all	O
the	O
topics	O
found	O
in	O
the	O
questions	O
.	O
We	O
compare	O
two	O
different	O
setups	O
.	O
In	O
the	O
first	O
one	O
,	O
we	O
include	O
all	O
the	O
sentences	O
extracted	O
from	O
the	O
train	O
,	O
validation	O
and	O
test	O
sets	O
thus	O
simulating	O
a	O
perfect	O
selection	O
of	O
sentences	O
that	O
cover	O
all	O
the	O
knowledge	O
expressed	O
in	O
the	O
questions	O
.	O
Still	O
,	O
we	O
only	O
use	O
the	O
support	O
paragraphs	O
and	O
not	O
the	O
annotated	O
questions	O
themselves	O
.	O
As	O
compared	O
to	O
the	O
classical	O
supervised	O
paradigm	O
,	O
this	O
setting	O
removes	O
all	O
annotation	O
costs	O
for	O
the	O
application	O
developer	O
,	O
but	O
it	O
still	O
requires	O
to	O
gather	O
sentences	O
that	O
are	O
deemed	O
useful	O
for	O
the	O
test	O
set	O
of	O
interest	O
.	O
We	O
then	O
compare	O
this	O
setup	O
with	O
another	O
one	O
,	O
where	O
only	O
the	O
sentences	O
from	O
the	O
train	O
set	O
are	O
included	O
.	O
This	O
scenario	O
arguably	O
meets	O
more	O
practical	O
needs	O
since	O
it	O
would	O
suffice	O
to	O
gather	O
sentences	O
close	O
to	O
the	O
domain	O
of	O
interest	O
.	O
The	O
number	O
of	O
sentences	O
for	O
each	O
dataset	O
is	O
presented	O
in	O
Table	O
1	O
.	O

Questions	O
Generation	O

The	O
generation	O
of	O
questions	O
from	O
a	O
sentence	O
relies	O
on	O
the	O
jsRealB	O
text	O
realizer	O
(	O
Lapalme	O
,	O
2021	O
)	O
which	O
generates	O
an	O
affirmative	O
sentence	O
from	O
a	O
constituent	O
structure	O
.	O
It	O
can	O
also	O
be	O
parameterized	O
to	O
generate	O
variations	O
of	O
the	O
original	O
sentence	O
such	O
as	O
its	O
negation	O
,	O
its	O
passive	O
form	O
and	O
different	O
types	O
of	O
questions	O
such	O
as	O
who	O
,	O
what	O
,	O
when	O
,	O
etc	O
.	O
The	O
constituency	O
structure	O
of	O
a	O
sentence	O
is	O
most	O
often	O
created	O
by	O
a	O
user	O
or	O
by	O
a	O
program	O
from	O
data	O
.	O
In	O
this	O
work	O
,	O
it	O
is	O
instead	O
built	O
from	O
a	O
Universal	O
Dependency	O
(	O
UD	O
)	O
structure	O
using	O
a	O
technique	O
developed	O
for	O
SR'19	O
(	O
Lapalme	O
,	O
2019	O
)	O
.	O
The	O
UD	O
structure	O
of	O
a	O
sentence	O
is	O
the	O
result	O
of	O
a	O
dependency	O
parse	O
with	O
Stanza	O
(	O
Qi	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
We	O
thus	O
have	O
a	O
pipeline	O
composed	O
of	O
a	O
neural	O
dependency	O
parser	O
,	O
followed	O
by	O
a	O
program	O
to	O
create	O
a	O
constituency	O
structure	O
used	O
as	O
input	O
for	O
a	O
text	O
realizer	O
,	O
both	O
in	O
JavaScript	O
.	O
Used	O
without	O
modification	O
,	O
this	O
would	O
create	O
a	O
complex	O
echo	O
program	O
for	O
the	O
original	O
affirmative	O
sentence	O
,	O
but	O
by	O
changing	O
parameters	O
,	O
its	O
output	O
can	O
vary	O
.	O

In	O
order	O
to	O
create	O
questions	O
from	O
a	O
single	O
constituency	O
structure	O
,	O
jsRealB	O
uses	O
the	O
classical	O
grammar	O
transformations	O
:	O
for	O
a	O
who	O
question	O
,	O
it	O
removes	O
the	O
subject	O
(	O
i.e.	O
the	O
first	O
noun	O
phrase	O
before	O
the	O
verb	O
phrase	O
)	O
,	O
for	O
a	O
what	O
question	O
,	O
it	O
removes	O
the	O
subject	O
or	O
the	O
direct	O
object	O
(	O
i.e.	O
the	O
first	O
noun	O
phrase	O
within	O
the	O
verb	O
phrase	O
)	O
;	O
for	O
other	O
types	O
of	O
questions	O
(	O
when	O
,	O
where	O
)	O
it	O
removes	O
the	O
first	O
prepositional	O
phrase	O
within	O
the	O
verb	O
phrase	O
.	O
Depending	O
on	O
the	O
preposition	O
,	O
the	O
question	O
will	O
be	O
a	O
when	O
or	O
a	O
where	O
.	O
Note	O
that	O
the	O
removed	O
part	O
becomes	O
the	O
answer	O
to	O
the	O
question	O
.	O

In	O
order	O
to	O
determine	O
which	O
questions	O
are	O
appropriate	O
for	O
a	O
given	O
sentence	O
,	O
we	O
examine	O
the	O
dependency	O
structure	O
of	O
the	O
original	O
sentence	O
and	O
check	O
if	O
it	O
contains	O
the	O
required	O
part	O
to	O
be	O
removed	O
before	O
parameterizing	O
the	O
realization	O
.	O
The	O
generated	O
questions	O
are	O
then	O
filtered	O
to	O
remove	O
any	O
question	O
for	O
which	O
the	O
answer	O
is	O
composed	O
of	O
a	O
single	O
stopword	O
.	O
Table	O
1	O
shows	O
the	O
number	O
of	O
questions	O
generated	O
for	O
each	O
dataset	O
.	O
An	O
example	O
of	O
a	O
synthetic	O
question	O
is	O
shown	O
in	O
Figure	O
3	O
.	O

Distractors	O
Selection	O

Since	O
SciQ	O
is	O
a	O
multiple	O
-	O
choice	O
dataset	O
,	O
we	O
must	O
add	O
distractors	O
to	O
each	O
question	O
we	O
generate	O
,	O
to	O
match	O
the	O
format	O
of	O
SciQ.	O
A	O
simple	O
solution	O
to	O
this	O
problem	O
is	O
to	O
select	O
random	O
distractors	O
among	O
answers	O
to	O
other	O
similar	O
questions	O
generated	O
from	O
the	O
dataset	O
of	O
sentences	O
we	O
gathered	O
.	O
Obviously	O
,	O
selecting	O
random	O
distractors	O
may	O
lead	O
to	O
a	O
fine	O
-	O
tuning	O
dataset	O
that	O
is	O
too	O
easy	O
to	O
solve	O
.	O
Therefore	O
,	O
we	O
propose	O
another	O
strategy	O
that	O
selects	O
hard	O
distractors	O
for	O
each	O
question	O
.	O
To	O
do	O
so	O
,	O
starting	O
from	O
our	O
synthetic	O
dataset	O
with	O
random	O
distractors	O
,	O
we	O
finetune	O
RoBERTa	O
(	O
Liu	O
et	O
al	O
.	O
,	O
2019	O
)	O
using	O
the	O
standard	O
method	O
of	O
training	O
for	O
multiple	O
choices	O
question	O
answering	O
.	O
Each	O
pair	O
question	O
/	O
choice	O
is	O
fed	O
to	O
RoBERTa	O
and	O
the	O
embedding	O
corresponding	O
to	O
the	O
first	O
token	O
(	O
"	O
[	O
CLS	O
]	O
"	O
)	O
is	O
given	O
to	O
a	O
linear	O
layer	O
to	O
produce	O
a	O
single	O
scalar	O
score	O
for	O
each	O
choice	O
.	O
The	O
scores	O
corresponding	O
to	O
every	O
choice	O
for	O
a	O
given	O
question	O
are	O
then	O
compared	O
to	O
each	O
other	O
by	O
a	O
softmax	O
and	O
a	O
cross	O
-	O
entropy	O
loss	O
.	O
With	O
this	O
method	O
,	O
RoBERTa	O
is	O
trained	O
to	O
score	O
a	O
possible	O
answer	O
for	O
a	O
given	O
question	O
,	O
based	O
on	O
whether	O
or	O
not	O
it	O
is	O
a	O
credible	O
answer	O
to	O
that	O
question	O
.	O
For	O
each	O
question	O
,	O
we	O
then	O
randomly	O
select	O
a	O
number	O
of	O
candidate	O
distractors	O
from	O
the	O
answers	O
to	O
other	O
questions	O
and	O
we	O
use	O
our	O
trained	O
RoBERTa	O
to	O
score	O
each	O
of	O
these	O
candidates	O
.	O
The	O
3	O
candidates	O
with	O
the	O
highest	O
scores	O
(	O
and	O
thus	O
the	O
most	O
credible	O
answers	O
)	O
are	O
selected	O
.	O
The	O
idea	O
is	O
that	O
during	O
this	O
first	O
training	O
,	O
RoBERTa	O
will	O
learn	O
a	O
large	O
amount	O
of	O
simplistic	O
logic	O
.	O
For	O
example	O
,	O
because	O
of	O
the	O
initial	O
random	O
selection	O
of	O
distractors	O
,	O
it	O
is	O
highly	O
unlikely	O
that	O
even	O
one	O
of	O
the	O
distractors	O
will	O
be	O
close	O
enough	O
to	O
the	O
question	O
's	O
semantic	O
field	O
.	O
Furthermore	O
,	O
a	O
lot	O
distractors	O
have	O
an	O
incorrect	O
grammar	O
(	O
eg	O
:	O
a	O
distractor	O
might	O
be	O
plural	O
when	O
the	O
question	O
expects	O
a	O
singular	O
)	O
.	O
Therefore	O
,	O
in	O
this	O
initial	O
training	O
,	O
RoBERTa	O
might	O
learn	O
to	O
isolate	O
the	O
answer	O
with	O
a	O
corresponding	O
semantic	O
field	O
or	O
the	O
one	O
with	O
correct	O
grammar	O
.	O
The	O
re	O
-	O
selection	O
then	O
minimizes	O
the	O
amount	O
of	O
trivial	O
distractors	O
and	O
models	O
trained	O
on	O
this	O
new	O
refined	O
dataset	O
will	O
have	O
to	O
focus	O
on	O
deeper	O
and	O
more	O
meaningful	O
relations	O
between	O
the	O
questions	O
and	O
the	O
answers	O
.	O
The	O
process	O
is	O
better	O
shown	O
in	O
Figure	O
4	O
,	O
and	O
an	O
example	O
of	O
refined	O
distractors	O
can	O
be	O
found	O
in	O
Figure	O
3	O
.	O

The	O
number	O
of	O
scored	O
candidate	O
distractors	O
is	O
an	O
hyper	O
-	O
parameter	O
.	O
A	O
small	O
number	O
of	O
candidates	O
may	O
result	O
in	O
a	O
situation	O
where	O
none	O
of	O
the	O
candidates	O
are	O
credible	O
enough	O
,	O
while	O
a	O
large	O
number	O
requires	O
more	O
computation	O
time	O
,	O
since	O
the	O
score	O
of	O
each	O
candidate	O
for	O
every	O
question	O
needs	O
to	O
be	O
computed	O
,	O
and	O
has	O
a	O
higher	O
risk	O
of	O
proposing	O
multiple	O
valid	O
answers	O
.	O
In	O
our	O
experiments	O
,	O
we	O
use	O
a	O
number	O
of	O
64	O
candidates	O
in	O
order	O
to	O
limit	O
computation	O
time	O
.	O

Training	O
and	O
Implementation	O
Details	O

To	O
refine	O
distractors	O
,	O
we	O
use	O
the	O
"	O
Large	O
"	O
version	O
of	O
RoBERTa	O
and	O
all	O
models	O
are	O
trained	O
for	O
4	O
epochs	O
and	O
a	O
learning	O
rate	O
of	O
1	O
×	O
10	O
−5	O
.	O
These	O
hyperparameters	O
are	O
chosen	O
based	O
on	O
previous	O
experiments	O
with	O
RoBERTa	O
on	O
other	O
multiple	O
-	O
choice	O
datasets	O
.	O
The	O
final	O
UnifiedQA	O
fine	O
-	O
tuning	O
is	O
done	O
using	O
the	O
same	O
multiple	O
choices	O
question	O
answering	O
setup	O
as	O
the	O
one	O
used	O
in	O
the	O
original	O
UnifiedQA	O
paper	O
(	O
Khashabi	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
We	O
use	O
the	O
"	O
Large	O
"	O
version	O
of	O
UnifiedQA	O
and	O
all	O
the	O
models	O
are	O
trained	O
for	O
4	O
epochs	O
using	O
Adafactor	O
and	O
a	O
learning	O
rate	O
of	O
1	O
×	O
10	O
−5	O
.	O
The	O
learning	O
rate	O
is	O
loosely	O
tuned	O
to	O
get	O
the	O
best	O
performance	O
on	O
the	O
validation	O
set	O
during	O
the	O
supervised	O
training	O
of	O
UnifiedQA	O
.	O
We	O
use	O
the	O
Hugging	O
Face	O
pytorch	O
-	O
transformers	O
(	O
Wolf	O
et	O
al	O
.	O
,	O
2020	O
)	O
library	O
for	O
model	O
implementation	O
.	O
Experiments	O
presented	O
in	O
this	O
paper	O
were	O
carried	O
out	O
using	O
the	O
Grid'5000	O
testbed	O
(	O
Balouek	O
et	O
al	O
.	O
,	O
2013	O
)	O
,	O
supported	O
by	O
a	O
scientific	O
interest	O
group	O
hosted	O
by	O
Inria	O
and	O
including	O
CNRS	O
,	O
RENATER	O
and	O
several	O
Universities	O
as	O
well	O
as	O
other	O
organizations	O
(	O
see	O
https://www.grid5000.fr	O
)	O
.	O

Results	O

Accuracy	O
results	O
in	O
Table	O
2	O
have	O
a	O
95	O
%	O
Wald	O
confidence	O
interval	O
of	O
±2.8	O
%	O
.	O
The	O
first	O
row	O
of	O
Table	O
2	O
presents	O
the	O
accuracy	O
results	O
of	O
a	O
vanilla	O
UnifiedQA	O
large	O
model	O
on	O
SciQ.	O
The	O
second	O
line	O
shows	O
the	O
accuracy	O
when	O
UnifiedQA	O
is	O
fine	O
-	O
tuned	O
over	O
the	O
full	O
training	O
corpus	O
.	O
Our	O
objective	O
is	O
thus	O
to	O
get	O
as	O
close	O
as	O
possible	O
to	O
this	O
accuracy	O
score	O
using	O
only	O
un	O
-	O
supervised	O
methods	O
.	O
The	O
results	O
using	O
Wikipedia	O
are	O
the	O
only	O
ones	O
that	O
are	O
unsupervised	O
and	O
therefore	O
are	O
the	O
ones	O
directly	O
comparable	O
to	O
UnifiedQA	O
with	O
no	O
fine	O
-	O
tuning	O
or	O
other	O
unsupervised	O
methods	O
.	O
Table	O
2	O
:	O
Accuracy	O
on	O
SciQ	O
by	O
UnifiedQA	O
fine	O
-	O
tuned	O
on	O
our	O
synthetic	O
datasets	O
.	O
"	O
SciQ	O
data	O
"	O
refers	O
to	O
the	O
questions	O
generated	O
using	O
the	O
support	O
paragraphs	O
in	O
SciQ	O
while	O
"	O
Wikipedia	O
data	O
"	O
refers	O
to	O
questions	O
generated	O
using	O
sentences	O
harvested	O
from	O
Wikipedia	O
.	O
All	O
scores	O
are	O
averaged	O
over	O
3	O
independent	O
runs	O
(	O
including	O
the	O
complete	O
question	O
generation	O
process	O
and	O
the	O
final	O
Uni	O
-	O
fiedQA	O
fine	O
-	O
tuning	O
)	O
.	O

Fine	O
-	O
tuning	O
UnifiedQA	O
on	O
synthetic	O
questions	O
with	O
random	O
distractors	O
improves	O
the	O
results	O
as	O
compared	O
to	O
the	O
baseline	O
and	O
,	O
as	O
expected	O
,	O
the	O
closer	O
the	O
unlabeled	O
sentences	O
are	O
to	O
the	O
topics	O
of	O
the	O
questions	O
,	O
the	O
better	O
is	O
the	O
accuracy	O
.	O
Hence	O
,	O
generating	O
questions	O
from	O
only	O
the	O
train	O
set	O
of	O
SciQ	O
gives	O
performances	O
that	O
are	O
comparable	O
but	O
slightly	O
lower	O
to	O
the	O
ones	O
obtained	O
from	O
the	O
combined	O
train	O
,	O
dev	O
and	O
test	O
set	O
of	O
SciQ.	O
Finally	O
,	O
questions	O
selected	O
from	O
Wikipedia	O
also	O
improve	O
the	O
results	O
,	O
despite	O
being	O
loosely	O
related	O
to	O
the	O
target	O
test	O
corpus	O
.	O
Our	O
distractor	O
selection	O
method	O
further	O
boosts	O
the	O
accuracy	O
results	O
in	O
all	O
setups	O
.	O
This	O
suggests	O
that	O
a	O
careful	O
selection	O
of	O
distractors	O
is	O
important	O
,	O
and	O
that	O
the	O
hard	O
selection	O
criterion	O
used	O
here	O
seems	O
adequate	O
in	O
our	O
context	O
.	O

The	O
results	O
for	O
CommonsenseQA	O
and	O
QASC	O
using	O
the	O
same	O
selection	O
of	O
sentences	O
from	O
Wikipedia	O
are	O
reported	O
in	O
table	O
3	O
.	O
Overall	O
,	O
we	O
obtain	O
similar	O
results	O
to	O
SciQ	O
with	O
a	O
large	O
improvement	O
of	O
performances	O
when	O
generating	O
questions	O
and	O
a	O
further	O
boost	O
with	O
refined	O
distractors	O
.	O
However	O
compared	O
to	O
SciQ	O
,	O
the	O
improvement	O
brought	O
by	O
the	O
distractor	O
refining	O
process	O
is	O
less	O
significant	O
.	O
This	O
could	O
be	O
partly	O
explained	O
by	O
the	O
fact	O
that	O
the	O
distractors	O
in	O
the	O
original	O
QASC	O
and	O
CommonsenseQA	O
datasets	O
are	O
overall	O
easier	O
and	O
therefore	O
it	O
is	O
less	O
advantageous	O
for	O
a	O
model	O
to	O
be	O
trained	O
on	O
harder	O
questions	O
.	O

Conclusion	O

In	O
this	O
work	O
,	O
we	O
proposed	O
a	O
multiple	O
-	O
choice	O
question	O
generation	O
method	O
that	O
can	O
be	O
used	O
to	O
fine	O
-	O
tune	O
the	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
UnifiedQA	O
model	O
and	O
improve	O
its	O
performance	O
on	O
an	O
unseen	O
and	O
out	O
of	O
domain	O
dataset	O
.	O
Our	O
contributions	O
are	O
:	O

•	O
We	O
have	O
shown	O
that	O
simple	O
unsupervised	O
methods	O
could	O
be	O
used	O
to	O
finetune	O
existing	O
multipurpose	O
question	O
answering	O
models	O
(	O
in	O
our	O
case	O
UnifiedQA	O
)	O
to	O
new	O
datasets	O
or	O
domains	O
.	O

•	O
We	O
propose	O
a	O
novel	O
distractor	O
refining	O
method	O
able	O
to	O
select	O
harder	O
distractors	O
for	O
a	O
given	O
generated	O
question	O
and	O
show	O
its	O
superiority	O
compared	O
to	O
a	O
random	O
selection	O
.	O

Future	O
work	O
includes	O
comparing	O
our	O
method	O
to	O
other	O
question	O
generation	O
methods	O
(	O
including	O
supervised	O
methods	O
:	O
,	O
Puri	O
et	O
al	O
.	O
(	O
2020	O
)	O
)	O
in	O
order	O
to	O
assess	O
the	O
effect	O
of	O
both	O
the	O
generation	O
method	O
and	O
the	O
questions	O
quality	O
on	O
the	O
final	O
performances	O
of	O
our	O
models	O
.	O
Also	O
,	O
we	O
will	O
further	O
compare	O
different	O
variations	O
of	O
our	O
question	O
generation	O
and	O
distractor	O
refining	O
methods	O
in	O
order	O
to	O
more	O
thoroughly	O
understand	O
the	O
effect	O
of	O
hyper	O
-	O
parameters	O
such	O
as	O
the	O
number	O
of	O
candidate	O
distractors	O
.	O

Global	O
Entity	O
Disambiguation	O
with	O
BERT	O

We	O
propose	O
a	O
global	O
entity	O
disambiguation	O
(	O
ED	O
)	O
model	O
based	O
on	O
BERT	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
To	O
capture	O
global	O
contextual	O
information	O
for	O
ED	O
,	O
our	O
model	O
treats	O
not	O
only	O
words	O
but	O
also	O
entities	O
as	O
input	O
tokens	O
,	O
and	O
solves	O
the	O
task	O
by	O
sequentially	O
resolving	O
mentions	O
to	O
their	O
referent	O
entities	O
and	O
using	O
resolved	O
entities	O
as	O
inputs	O
at	O
each	O
step	O
.	O
We	O
train	O
the	O
model	O
using	O
a	O
large	O
entity	O
-	O
annotated	O
corpus	O
obtained	O
from	O
Wikipedia	O
.	O
We	O
achieve	O
new	O
state	O
-	O
of	O
-	O
the	O
-	O
art	O
results	O
on	O
five	O
standard	O
ED	O
datasets	O
:	O
AIDA	O
-	O
CoNLL	O
,	O
MSNBC	O
,	O
AQUAINT	O
,	O
ACE2004	O
,	O
and	O
WNED	O
-	O
WIKI	O
.	O
The	O
source	O
code	O
and	O
model	O
checkpoint	O
are	O
available	O
at	O
https	O
:	O
//github.com	O
/	O
studio	O
-	O
ousia	O
/	O
luke	O
.	O

Introduction	O

Entity	O
disambiguation	O
(	O
ED	O
)	O
refers	O
to	O
the	O
task	O
of	O
assigning	O
mentions	O
in	O
a	O
document	O
to	O
corresponding	O
entities	O
in	O
a	O
knowledge	O
base	O
(	O
KB	O
)	O
.	O
This	O
task	O
is	O
challenging	O
because	O
of	O
the	O
ambiguity	O
between	O
mentions	O
(	O
e.g.	O
,	O
"	O
World	O
Cup	O
"	O
)	O
and	O
the	O
entities	O
they	O
refer	O
to	O
(	O
e.g.	O
,	O
FIFA	O
World	O
Cup	O
or	O
Rugby	O
World	O
Cup	O
)	O
.	O
ED	O
models	O
typically	O
rely	O
on	O
local	O
contextual	O
information	O
based	O
on	O
words	O
that	O
co	O
-	O
occur	O
with	O
the	O
mention	O
and	O
global	O
contextual	O
information	O
based	O
on	O
the	O
entity	O
-	O
based	O
coherence	O
of	O
the	O
disambiguation	O
decisions	O
.	O
A	O
key	O
to	O
improve	O
the	O
performance	O
of	O
ED	O
is	O
to	O
effectively	O
combine	O
both	O
local	O
and	O
global	O
contextual	O
information	O
(	O
Ganea	O
and	O
Hofmann	O
,	O
2017;Le	O
and	O
Titov	O
,	O
2018	O
)	O
.	O

In	O
this	O
study	O
,	O
we	O
propose	O
a	O
global	O
ED	O
model	O
based	O
on	O
BERT	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Our	O
model	O
treats	O
words	O
and	O
entities	O
in	O
the	O
document	O
as	O
input	O
tokens	O
,	O
and	O
is	O
trained	O
by	O
predicting	O
randomly	O
masked	O
entities	O
in	O
a	O
large	O
entity	O
-	O
annotated	O
corpus	O
obtained	O
from	O
Wikipedia	O
.	O
This	O
training	O
enables	O
the	O
model	O
to	O
learn	O
how	O
to	O
disambiguate	O
masked	O
entities	O
based	O
on	O
words	O
and	O
non	O
-	O
masked	O
entities	O
.	O
At	O
the	O
inference	O
time	O
,	O
our	O
model	O
disambiguates	O
*	O
Work	O
done	O
at	O
RIKEN	O
.	O

mentions	O
sequentially	O
using	O
words	O
and	O
already	O
resolved	O
entities	O
(	O
see	O
Figure	O
1	O
)	O
.	O
This	O
sequential	O
inference	O
effectively	O
accumulates	O
the	O
global	O
contextual	O
information	O
and	O
enhances	O
the	O
coherence	O
of	O
disambiguation	O
decisions	O
.	O
We	O
conducted	O
extensive	O
experiments	O
using	O
six	O
standard	O
ED	O
datasets	O
,	O
i.e.	O
,	O
AIDA	O
-	O
CoNLL	O
,	O
MSNBC	O
,	O
AQUAINT	O
,	O
ACE2004	O
,	O
WNED	O
-	O
WIKI	O
,	O
and	O
WNED	O
-	O
CWEB	O
.	O
As	O
a	O
result	O
,	O
the	O
global	O
contextual	O
information	O
consistently	O
improved	O
the	O
performance	O
.	O
Furthermore	O
,	O
we	O
achieved	O
new	O
state	O
of	O
the	O
art	O
on	O
all	O
datasets	O
except	O
for	O
WNED	O
-	O
CWEB	O
.	O
The	O
source	O
code	O
and	O
model	O
checkpoint	O
are	O
available	O
at	O
https://github.com/	O
studio	O
-	O
ousia	O
/	O
luke	O
.	O

Related	O
Work	O

Transformer	O
-	O
based	O
ED	O
.	O
Several	O
recent	O
studies	O
have	O
proposed	O
ED	O
models	O
based	O
on	O
Transformer	O
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017	O
)	O
trained	O
with	O
a	O
large	O
entity	O
-	O
annotated	O
corpus	O
obtained	O
from	O
Wikipedia	O
(	O
Broscheit	O
,	O
2019;Ling	O
et	O
al	O
.	O
,	O
2020;Cao	O
et	O
al	O
.	O
,	O
2021;Barba	O
et	O
al	O
.	O
,	O
2022	O
)	O
.	O
Broscheit	O
(	O
2019	O
)	O
trained	O
an	O
ED	O
model	O
based	O
on	O
BERT	O
by	O
classifying	O
each	O
word	O
in	O
the	O
document	O
to	O
the	O
corresponding	O
entity	O
.	O
Similarly	O
,	O
addressed	O
ED	O
using	O
BERT	O
by	O
classifying	O
mention	O
spans	O
to	O
the	O
corresponding	O
entities	O
.	O
Ling	O

Words	O
Entities	O

Input	O

Position	O
emb	O
.	O
(	O
Lewis	O
et	O
al	O
.	O
,	O
2020	O
)	O
to	O
generate	O
referent	O
entity	O
titles	O
of	O
target	O
mentions	O
in	O
an	O
autoregressive	O
manner	O
.	O
Barba	O
et	O
al	O
.	O
(	O
2022	O
)	O
formulated	O
ED	O
as	O
a	O
text	O
extraction	O
problem	O
;	O
they	O
fed	O
the	O
document	O
and	O
candidate	O
entity	O
titles	O
to	O
BART	O
and	O
Longformer	O
(	O
Beltagy	O
et	O
al	O
.	O
,	O
2020	O
)	O
and	O
disambiguated	O
a	O
mention	O
in	O
the	O
document	O
by	O
extracting	O
the	O
referent	O
entity	O
title	O
of	O
the	O
mention	O
.	O
However	O
,	O
unlike	O
our	O
model	O
,	O
these	O
models	O
addressed	O
the	O
task	O
based	O
only	O
on	O
local	O
contextual	O
information	O
.	O

Treating	O
entities	O
as	O
inputs	O
of	O
Transformer	O
.	O
Recent	O
studies	O
Yamada	O
et	O
al	O
.	O
,	O
2020;Sun	O
et	O
al	O
.	O
,	O
2020	O
)	O
have	O
proposed	O
Transformerbased	O
models	O
that	O
treat	O
entities	O
as	O
input	O
tokens	O
to	O
enrich	O
their	O
expressiveness	O
using	O
additional	O
information	O
contained	O
in	O
the	O
entity	O
embeddings	O
.	O
However	O
,	O
these	O
models	O
were	O
designed	O
to	O
solve	O
general	O
NLP	O
tasks	O
and	O
not	O
tested	O
on	O
ED	O
.	O
We	O
treat	O
entities	O
as	O
input	O
tokens	O
to	O
capture	O
the	O
global	O
context	O
that	O
is	O
shown	O
to	O
be	O
highly	O
effective	O
for	O
ED	O
.	O

ED	O
as	O
sequential	O
decision	O
task	O
.	O
Past	O
studies	O
Fang	O
et	O
al	O
.	O
,	O
2019	O
)	O
have	O
solved	O
ED	O
by	O
casting	O
it	O
as	O
a	O
sequential	O
decision	O
task	O
to	O
capture	O
global	O
contextual	O
information	O
.	O
We	O
adopt	O
a	O
similar	O
method	O
with	O
an	O
enhanced	O
Transformer	O
architecture	O
,	O
a	O
training	O
task	O
,	O
and	O
an	O
inference	O
method	O
to	O
implement	O
the	O
global	O
ED	O
model	O
based	O
on	O
BERT	O
.	O

Model	O

Given	O
a	O
document	O
with	O
N	O
mentions	O
,	O
each	O
of	O
which	O
has	O
K	O
entity	O
candidates	O
,	O
our	O
model	O
solves	O
ED	O
by	O
selecting	O
a	O
correct	O
referent	O
entity	O
from	O
the	O
entity	O
candidates	O
for	O
each	O
mention	O
.	O

Model	O
Architecture	O

Our	O
model	O
is	O
based	O
on	O
BERT	O
and	O
takes	O
words	O
and	O
entities	O
(	O
Wikipedia	O
entities	O
or	O
the	O
[	O
MASK	O
]	O
entity	O
)	O
.	O

The	O
input	O
representation	O
of	O
a	O
word	O
or	O
an	O
entity	O
is	O
constructed	O
by	O
summing	O
the	O
token	O
,	O
token	O
type	O
,	O
and	O
position	O
embeddings	O
(	O
see	O
Figure	O
2	O
):	O

Token	O
embedding	O
is	O
the	O
embedding	O
of	O
the	O
corresponding	O
token	O
.	O
The	O
matrices	O
of	O
the	O
word	O
and	O
entity	O
token	O
embeddings	O
are	O
represented	O
as	O
A	O
∈	O
R	O
Vw×H	O
and	O
B	O
∈	O
R	O
Ve×H	O
,	O
respectively	O
,	O
where	O
H	O
is	O
the	O
size	O
of	O
the	O
hidden	O
states	O
of	O
BERT	O
,	O
and	O
V	O
w	O
and	O
V	O
e	O
are	O
the	O
number	O
of	O
items	O
in	O
the	O
word	O
vocabulary	O
and	O
that	O
of	O
the	O
entity	O
vocabulary	O
,	O
respectively	O
.	O

Token	O
type	O
embedding	O
represents	O
the	O
type	O
of	O
token	O
,	O
namely	O
word	O
(	O
C	O
word	O
)	O
or	O
entity	O
(	O
C	O
entity	O
)	O
.	O

Position	O
embedding	O
represents	O
the	O
position	O
of	O
the	O
token	O
in	O
a	O
word	O
sequence	O
.	O
A	O
word	O
and	O
an	O
entity	O
appearing	O
at	O
the	O
i	O
-	O
th	O
position	O
in	O
the	O
sequence	O
are	O
represented	O
as	O
D	O
i	O
and	O
E	O
i	O
,	O
respectively	O
.	O
If	O
an	O
entity	O
mention	O
contains	O
multiple	O
words	O
,	O
its	O
position	O
embedding	O
is	O
computed	O
by	O
averaging	O
the	O
embeddings	O
of	O
the	O
corresponding	O
positions	O
(	O
see	O
Figure	O
2	O
)	O
.	O
Following	O
Devlin	O
et	O
al	O
.	O
(	O
2019	O
)	O
,	O
we	O
tokenize	O
the	O
document	O
text	O
using	O
the	O
BERT	O
's	O
wordpiece	O
tokenizer	O
,	O
and	O
insert	O
[	O
CLS	O
]	O
and	O
[	O
SEP	O
]	O
tokens	O
as	O
the	O
first	O
and	O
last	O
words	O
,	O
respectively	O
.	O

Training	O
Task	O

Similar	O
to	O
the	O
masked	O
language	O
model	O
(	O
MLM	O
)	O
objective	O
adopted	O
in	O
BERT	O
,	O
our	O
model	O
is	O
trained	O
by	O
predicting	O
randomly	O
masked	O
entities	O
.	O
Specifically	O
,	O
we	O
randomly	O
replace	O
some	O
percentage	O
of	O
the	O
entities	O
with	O
special	O
[	O
MASK	O
]	O
entity	O
tokens	O
and	O
then	O
trains	O
the	O
model	O
to	O
predict	O
masked	O
entities	O
.	O

We	O
adopt	O
a	O
model	O
equivalent	O
to	O
the	O
one	O
used	O
to	O
predict	O
words	O
in	O
MLM	O
.	O
Formally	O
,	O
we	O
predict	O
the	O
original	O
entity	O
corresponding	O
to	O
a	O
masked	O
entity	O
by	O
applying	O
softmax	O
over	O
all	O
entities	O
:	O

ED	O
Model	O

Local	O
ED	O
Model	O
.	O
Our	O
local	O
ED	O
model	O
takes	O
words	O
and	O
N	O
[	O
MASK	O
]	O
tokens	O
corresponding	O
to	O
the	O
mentions	O
in	O
the	O
document	O
.	O
The	O
model	O
then	O
computes	O
the	O
embedding	O
m	O
′	O
e	O
∈	O
R	O
H	O
for	O
each	O
[	O
MASK	O
]	O
token	O
using	O
Eq.(2	O
)	O
and	O
predicts	O
the	O
entity	O
using	O
softmax	O
over	O
the	O
K	O
entity	O
candidates	O
:	O

where	O
B	O
*	O
∈	O
R	O
K×H	O
and	O
b	O
*	O
o	O
∈	O
R	O
K	O
consist	O
of	O
the	O
entity	O
token	O
embeddings	O
and	O
the	O
bias	O
corresponding	O
to	O
the	O
entity	O
candidates	O
,	O
respectively	O
.	O
Note	O
that	O
B	O
*	O
and	O
b	O
*	O
o	O
are	O
the	O
subsets	O
of	O
B	O
and	O
b	O
o	O
,	O
respectively	O
.	O
Global	O
ED	O
Model	O
.	O
Our	O
global	O
ED	O
model	O
resolves	O
mentions	O
sequentially	O
for	O
N	O
steps	O
(	O
see	O
Algorithm	O
1	O
)	O
.	O
First	O
,	O
the	O
model	O
initializes	O
the	O
entity	O
of	O
each	O
mention	O
using	O
the	O
[	O
MASK	O
]	O
token	O
.	O
Then	O
,	O
for	O
each	O
step	O
,	O
it	O
predicts	O
an	O
entity	O
for	O
each	O
[	O
MASK	O
]	O
token	O
,	O
selects	O
the	O
prediction	O
with	O
the	O
highest	O
probability	O
produced	O
by	O
the	O
softmax	O
function	O
in	O
Eq.(3	O
)	O
,	O
and	O
resolves	O
the	O
corresponding	O
mention	O
by	O
assigning	O
the	O
predicted	O
entity	O
to	O
it	O
.	O
This	O
model	O
is	O
denoted	O
as	O
confidence	O
-	O
order	O
.	O
We	O
also	O
test	O
a	O
model	O
that	O
selects	O
mentions	O
according	O
to	O
their	O
order	O
of	O
appearance	O
in	O
the	O
document	O
and	O
denote	O
it	O
by	O
natural	O
-	O
order	O
.	O

Modeling	O
Details	O

Our	O
model	O
is	O
based	O
on	O
BERT	O
LARGE	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
The	O
parameters	O
shared	O
with	O
BERT	O
are	O
initialized	O
using	O
BERT	O
,	O
and	O
the	O
other	O
parameters	O
are	O
initialized	O
randomly	O
.	O
We	O
treat	O
the	O
hyperlinks	O
in	O
Wikipedia	O
as	O
entity	O
annotations	O
and	O
randomly	O
mask	O
30	O
%	O
of	O
all	O
entities	O
.	O
We	O
train	O
the	O
model	O
by	O
maximizing	O
the	O
log	O
likelihood	O
of	O
entity	O
predictions	O
.	O
Further	O
details	O
are	O
described	O
in	O
Appendix	O
A.	O

Experiments	O

Our	O
experimental	O
setup	O
follows	O
Le	O
and	O
Titov	O
(	O
2018	O
)	O
.	O
In	O
particular	O
,	O
we	O
test	O
the	O
proposed	O
ED	O
models	O
using	O
six	O
standard	O
datasets	O
:	O
AIDA	O
-	O
CoNLL	O
(	O
CoNLL	O
)	O
(	O
Hoffart	O
et	O
al	O
.	O
,	O
2011	O
)	O
,	O
MSNBC	O
,	O
AQUAINT	O
,	O
ACE2004	O
,	O
WNED	O
-	O
CWEB	O
(	O
CWEB	O
)	O
,	O
and	O
WNED	O
-	O
WIKI	O
(	O
WIKI	O
)	O
(	O
Guo	O
and	O
Barbosa	O
,	O
2018	O
)	O
.	O
We	O
consider	O
only	O
the	O
mentions	O
that	O
refer	O
to	O
valid	O
entities	O
in	O
Wikipedia	O
.	O
For	O
all	O
datasets	O
,	O
we	O
use	O
the	O
KB+YAGO	O
entity	O
candidates	O
and	O
their	O
associatedp(e|m	O
)	O
(	O
Ganea	O
and	O
Hofmann	O
,	O
2017	O
)	O
,	O
and	O
use	O
the	O
top	O
30	O
candidates	O
based	O
onp(e|m	O
)	O
.	O

For	O
the	O
CoNLL	O
dataset	O
,	O
we	O
also	O
test	O
the	O
performance	O
using	O
PPRforNED	O
entity	O
candidates	O
(	O
Pershina	O
et	O
al	O
.	O
,	O
2015	O
)	O
.	O
We	O
report	O
the	O
in	O
-	O
KB	O
accuracy	O
for	O
the	O
CoNLL	O
dataset	O
and	O
the	O
micro	O
F1	O
score	O
(	O
averaged	O
per	O
mention	O
)	O
for	O
the	O
other	O
datasets	O
.	O
Further	O
details	O
of	O
the	O
datasets	O
are	O
provided	O
in	O
Appendix	O
C.	O
Furthermore	O
,	O
we	O
optionally	O
fine	O
-	O
tune	O
the	O
model	O
by	O
maximizing	O
the	O
log	O
likelihood	O
of	O
the	O
ED	O
predictions	O
(	O
ŷ	O
ED	O
)	O
using	O
the	O
training	O
set	O
of	O
the	O
CoNLL	O
dataset	O
with	O
the	O
KB+YAGO	O
candidates	O
.	O
We	O
mask	O
90	O
%	O
of	O
the	O
mentions	O
and	O
fix	O
the	O
entity	O
token	O
embeddings	O
(	O
B	O
and	O
B	O
*	O
)	O
and	O
the	O
bias	O
(	O
The	O
model	O
is	O
trained	O
for	O
two	O
epochs	O
using	O
AdamW.	O
Additional	O
details	O
are	O
provided	O
in	O
Appendix	O
B.	O
Our	O
global	O
models	O
consistently	O
perform	O
better	O
than	O
the	O
local	O
model	O
,	O
demonstrating	O
the	O
effectiveness	O
of	O
using	O
global	O
contextual	O
information	O
even	O
if	O
local	O
contextual	O
information	O
is	O
captured	O
using	O
expressive	O
BERT	O
model	O
.	O
Moreover	O
,	O
the	O
confidenceorder	O
model	O
performs	O
better	O
than	O
the	O
natural	O
-	O
order	O
model	O
on	O
most	O
datasets	O
.	O
An	O
analysis	O
investigating	O
why	O
the	O
confidence	O
-	O
order	O
model	O
outperforms	O
the	O
natural	O
-	O
order	O
model	O
is	O
provided	O
in	O
the	O
next	O
section	O
.	O

Results	O

The	O
fine	O
-	O
tuning	O
on	O
the	O
CoNLL	O
dataset	O
significantly	O
improves	O
the	O
performance	O
on	O
this	O
dataset	O
(	O
Table	O
1	O
)	O
.	O
However	O
,	O
it	O
generally	O
degrades	O
the	O
performance	O
on	O
the	O
other	O
datasets	O
(	O
Table	O
2	O
)	O
.	O
This	O
suggests	O
that	O
Wikipedia	O
entity	O
annotations	O
are	O
more	O
suitable	O
than	O
the	O
CoNLL	O
dataset	O
to	O
train	O
generalpurpose	O
ED	O
models	O
.	O

Additionally	O
,	O
our	O
models	O
perform	O
worse	O
than	O
Yang	O
et	O
al	O
.	O
(	O
2018	O
)	O
on	O
the	O
CWEB	O
dataset	O
.	O
This	O
is	O
because	O
this	O
dataset	O
is	O
significantly	O
longer	O
on	O
average	O
than	O
other	O
datasets	O
,	O
i.e.	O
,	O
approximately	O
1,700	O
words	O
per	O
document	O
on	O
average	O
,	O
which	O
is	O
more	O
than	O
three	O
times	O
longer	O
than	O
the	O
512	O
-	O
word	O
limit	O
that	O
can	O
be	O
handled	O
by	O
BERT	O
-	O
based	O
models	O
including	O
ours	O
.	O
Yang	O
et	O
al	O
.	O
(	O
2018	O
)	O
achieved	O
excellent	O
performance	O
on	O
this	O
dataset	O
because	O
their	O
model	O
uses	O
various	O
hand	O
-	O
engineered	O
features	O
capturing	O
document	O
-	O
level	O
contextual	O
information	O
.	O

Analysis	O

To	O
investigate	O
how	O
global	O
contextual	O
information	O
helps	O
our	O
model	O
to	O
improve	O
performance	O
,	O
we	O
manually	O
analyze	O
the	O
difference	O
between	O
the	O
predictions	O
of	O
the	O
local	O
,	O
natural	O
-	O
order	O
,	O
and	O
confidence	O
-	O
order	O
models	O
.	O
We	O
use	O
the	O
fine	O
-	O
tuned	O
model	O
using	O
the	O
CoNLL	O
dataset	O
with	O
the	O
YAGO+KB	O
candidates	O
.	O
Although	O
all	O
models	O
perform	O
well	O
on	O
most	O
mentions	O
,	O
the	O
local	O
model	O
often	O
fails	O
to	O
resolve	O
mentions	O
of	O
common	O
names	O
referring	O
to	O
specific	O
entities	O
(	O
e.g.	O
,	O
"	O
New	O
York	O
"	O
referring	O
to	O
New	O
York	O
Knicks	O
)	O
.	O
Global	O
models	O
are	O
generally	O
better	O
to	O
resolve	O
such	O
difficult	O
cases	O
because	O
of	O
the	O
presence	O
of	O
strong	O
global	O
contextual	O
information	O
(	O
e.g.	O
,	O
mentions	O
refer	O
-	O
ring	O
to	O
basketball	O
teams	O
)	O
.	O

Furthermore	O
,	O
we	O
find	O
that	O
the	O
confidence	O
-	O
order	O
model	O
works	O
especially	O
well	O
for	O
mentions	O
that	O
require	O
a	O
highly	O
detailed	O
context	O
to	O
resolve	O
.	O
For	O
example	O
,	O
a	O
mention	O
of	O
"	O
Matthew	O
Burke	O
"	O
can	O
refer	O
to	O
two	O
different	O
former	O
Australian	O
rugby	O
players	O
.	O
Although	O
the	O
local	O
and	O
natural	O
-	O
order	O
models	O
incorrectly	O
resolve	O
this	O
mention	O
to	O
the	O
player	O
who	O
has	O
the	O
larger	O
number	O
of	O
occurrences	O
in	O
our	O
Wikipediabased	O
corpus	O
,	O
the	O
confidence	O
-	O
order	O
model	O
successfully	O
resolves	O
this	O
by	O
disambiguating	O
its	O
contextual	O
mentions	O
,	O
including	O
his	O
teammates	O
,	O
in	O
advance	O
.	O
We	O
provide	O
detailed	O
inference	O
sequence	O
of	O
the	O
corresponding	O
document	O
in	O
Appendix	O
D.	O

Performance	O
for	O
Rare	O
Entities	O

We	O
examine	O
whether	O
our	O
model	O
learns	O
effective	O
embeddings	O
for	O
rare	O
entities	O
using	O
the	O
CoNLL	O
dataset	O
.	O
Following	O
Ganea	O
and	O
Hofmann	O
(	O
2017	O
)	O
,	O
we	O
use	O
the	O
mentions	O
of	O
which	O
entity	O
candidates	O
contain	O
their	O
gold	O
entities	O
and	O
measure	O
the	O
performance	O
by	O
dividing	O
the	O
mentions	O
based	O
on	O
the	O
frequency	O
of	O
their	O
entities	O
in	O
the	O
Wikipedia	O
annotations	O
used	O
to	O
train	O
the	O
embeddings	O
.	O

As	O
presented	O
in	O
Table	O
3	O
,	O
our	O
models	O
achieve	O
enhanced	O
performance	O
for	O
rare	O
entities	O
.	O
Furthermore	O
,	O
the	O
global	O
models	O
consistently	O
outperform	O
the	O
local	O
model	O
both	O
for	O
rare	O
and	O
frequent	O
entities	O
.	O

Conclusion	O
and	O
Future	O
Work	O

We	O
propose	O
a	O
new	O
global	O
ED	O
model	O
based	O
on	O
BERT	O
.	O

Our	O
extensive	O
experiments	O
on	O
a	O
wide	O
range	O
of	O
ED	O
datasets	O
demonstrate	O
its	O
effectiveness	O
.	O

One	O
limitation	O
of	O
our	O
model	O
is	O
that	O
,	O
similar	O
to	O
existing	O
ED	O
models	O
,	O
our	O
model	O
can	O
not	O
handle	O
entities	O
that	O
are	O
not	O
included	O
in	O
the	O
vocabulary	O
.	O
In	O
our	O
future	O
work	O
,	O
we	O
will	O
investigate	O
the	O
method	O
to	O
compute	O
the	O
embeddings	O
of	O
such	O
entities	O
using	O
a	O
post	O
-	O
hoc	O
training	O
with	O
an	O
extended	O
vocabulary	O
(	O
Tai	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O

Appendix	O
for	O
"	O
Global	O
Entity	O
Disambiguation	O
with	O
BERT	O
"	O
A	O
Details	O
of	O
Proposed	O
Model	O

As	O
the	O
input	O
corpus	O
for	O
training	O
our	O
model	O
,	O
we	O
use	O
the	O
December	O
2018	O
version	O
of	O
Wikipedia	O
,	O
comprising	O
approximately	O
3.5	O
billion	O
words	O
and	O
11	O
million	O
entity	O
annotations	O
.	O
We	O
generate	O
input	O
sequences	O
by	O
splitting	O
the	O
content	O
of	O
each	O
page	O
into	O
sequences	O
comprising	O
≤	O
512	O
words	O
and	O
their	O
entity	O
annotations	O
(	O
i.e.	O
,	O
hyperlinks	O
)	O
.	O
The	O
input	O
text	O
is	O
tokenized	O
using	O
BERT	O
's	O
tokenizer	O
with	O
its	O
vocabulary	O
consisting	O
of	O
V	O
w	O
=	O
30	O
,	O
000	O
words	O
.	O
Similar	O
to	O
Ganea	O
and	O
Hofmann	O
(	O
2017	O
)	O
,	O
we	O
create	O
an	O
entity	O
vocabulary	O
consisting	O
of	O
V	O
e	O
=	O
128	O
,	O
040	O
entities	O
,	O
which	O
are	O
contained	O
in	O
the	O
entity	O
candidates	O
in	O
the	O
datasets	O
used	O
in	O
our	O
experiments	O
.	O

Our	O
model	O
consists	O
of	O
approximately	O
440	O
million	O
parameters	O
.	O
To	O
reduce	O
the	O
training	O
time	O
,	O
the	O
parameters	O
that	O
are	O
shared	O
with	O
BERT	O
are	O
initialized	O
using	O
BERT	O
.	O
The	O
other	O
parameters	O
are	O
initialized	O
randomly	O
.	O
The	O
model	O
is	O
trained	O
via	O
iterations	O
over	O
Wikipedia	O
pages	O
in	O
a	O
random	O
order	O
for	O
seven	O
epochs	O
.	O
To	O
stabilize	O
the	O
training	O
,	O
we	O
update	O
only	O
those	O
parameters	O
that	O
are	O
randomly	O
initialized	O
(	O
i.e.	O
,	O
fixed	O
the	O
parameters	O
initialized	O
using	O
BERT	O
)	O
at	O
the	O
first	O
epoch	O
,	O
and	O
update	O
all	O
parameters	O
in	O
the	O
remaining	O
six	O
epochs	O
.	O
We	O
implement	O
the	O
model	O
using	O
PyTorch	O
(	O
Paszke	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
Hugging	O
Face	O
Transformers	O
(	O
Wolf	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
and	O
the	O
training	O
takes	O
approximately	O
ten	O
days	O
using	O
eight	O
Tesla	O
V100	O
GPUs	O
.	O
We	O
optimize	O
the	O
model	O
using	O
AdamW.	O
The	O
hyper	O
-	O
parameters	O
used	O
in	O
the	O
training	O
are	O
detailed	O
in	O
Table	O
4	O
.	O

B	O
Details	O
of	O
Fine	O
-	O
tuning	O
on	O
CoNLL	O
Dataset	O

The	O
hyper	O
-	O
parameters	O
used	O
in	O
the	O
fine	O
-	O
tuning	O
on	O
the	O
CoNLL	O
dataset	O
are	O
detailed	O
in	O
Table	O
5	O
.	O
We	O
select	O
these	O
hyper	O
-	O
parameters	O
from	O
the	O
search	O
space	O
described	O
in	O
Devlin	O
et	O
al	O
.	O
(	O
2019	O
)	O
based	O
on	O
the	O
accuracy	O
on	O
the	O
development	O
set	O
of	O
the	O
CoNLL	O
dataset	O
.	O

A	O
document	O
is	O
split	O
if	O
it	O
is	O
longer	O
than	O
512	O
words	O
,	O
which	O
is	O
the	O
maximum	O
word	O
length	O
of	O
the	O
BERT	O
model	O
.	O

C	O
Details	O
of	O
ED	O
Datasets	O

The	O
statistics	O
of	O
the	O
ED	O
datasets	O
used	O
in	O
our	O
experiments	O
are	O
provided	O
in	O
Table	O
6	O
.	O

D	O
Example	O
of	O
Inference	O
by	O

Confidence	O
-	O
order	O
Model	O
Figure	O
3	O
shows	O
an	O
example	O
of	O
the	O
inference	O
performed	O
by	O
our	O
confidence	O
-	O
order	O
model	O
fine	O
-	O
tuned	O
on	O
the	O
CoNLL	O
dataset	O
.	O
The	O
document	O
is	O
obtained	O
from	O
the	O
test	O
set	O
of	O
the	O
CoNLL	O
dataset	O
.	O
As	O
shown	O
in	O
the	O
figure	O
,	O
the	O
model	O
starts	O
with	O
unambiguous	O
player	O
names	O
to	O
recognize	O
the	O
topic	O
of	O
the	O
document	O
,	O
and	O
subsequently	O
resolves	O
the	O
mentions	O
that	O
are	O
challenging	O
to	O
resolve	O
.	O
Notably	O
,	O
the	O
model	O
correctly	O
resolves	O
the	O
mention	O
"	O
Nigel	O
Walker	O
"	O
to	O
the	O
corresponding	O
former	O
rugby	O
player	O
instead	O
of	O
a	O
football	O
player	O
,	O
and	O
the	O
mention	O
"	O
Matthew	O
Burke	O
"	O
to	O
the	O
correct	O
former	O
Australian	O
rugby	O
player	O
born	O
in	O
1973	O
instead	O
of	O
the	O
former	O
Australian	O
rugby	O
player	O
born	O
in	O
1964	O
.	O
This	O
is	O
accomplished	O
by	O
resolving	O
other	O
contextual	O
mentions	O
,	O
including	O
their	O
colleague	O
players	O
,	O
in	O
advance	O
.	O
These	O
two	O
mentions	O
are	O
denoted	O
in	O
red	O
in	O
the	O
figure	O
.	O
Note	O
that	O
our	O
local	O
model	O
fails	O
to	O
resolve	O
both	O
mentions	O
,	O
and	O
our	O
natural	O
-	O
order	O
model	O
fails	O
to	O
resolve	O
"	O
Matthew	O
Burke	O
.	O
"	O

A	O
Matter	O
of	O
Framing	O
:	O
The	O
Impact	O
of	O
Linguistic	O
Formalism	O
on	O
Probing	O
Results	O

Deep	O
pre	O
-	O
trained	O
contextualized	O
encoders	O
like	O
BERT	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
demonstrate	O
remarkable	O
performance	O
on	O
a	O
range	O
of	O
downstream	O
tasks	O
.	O
A	O
recent	O
line	O
of	O
research	O
in	O
probing	O
investigates	O
the	O
linguistic	O
knowledge	O
implicitly	O
learned	O
by	O
these	O
models	O
during	O
pretraining	O
.	O
While	O
most	O
work	O
in	O
probing	O
operates	O
on	O
the	O
task	O
level	O
,	O
linguistic	O
tasks	O
are	O
rarely	O
uniform	O
and	O
can	O
be	O
represented	O
in	O
a	O
variety	O
of	O
formalisms	O
.	O
Any	O
linguistics	O
-	O
based	O
probing	O
study	O
thereby	O
inevitably	O
commits	O
to	O
the	O
formalism	O
used	O
to	O
annotate	O
the	O
underlying	O
data	O
.	O
Can	O
the	O
choice	O
of	O
formalism	O
affect	O
probing	O
results	O
?	O
To	O
investigate	O
,	O
we	O
conduct	O
an	O
in	O
-	O
depth	O
cross	O
-	O
formalism	O
layer	O
probing	O
study	O
in	O
role	O
semantics	O
.	O
We	O
find	O
linguistically	O
meaningful	O
differences	O
in	O
the	O
encoding	O
of	O
semantic	O
role	O
-	O
and	O
proto	O
-	O
role	O
information	O
by	O
BERT	O
depending	O
on	O
the	O
formalism	O
and	O
demonstrate	O
that	O
layer	O
probing	O
can	O
detect	O
subtle	O
differences	O
between	O
the	O
implementations	O
of	O
the	O
same	O
linguistic	O
formalism	O
.	O
Our	O
results	O
suggest	O
that	O
linguistic	O
formalism	O
is	O
an	O
important	O
dimension	O
in	O
probing	O
studies	O
and	O
should	O
be	O
investigated	O
along	O
with	O
the	O
commonly	O
used	O
cross	O
-	O
task	O
and	O
cross	O
-	O
lingual	O
experimental	O
settings	O
.	O

Introduction	O

The	O
emergence	O
of	O
deep	O
pre	O
-	O
trained	O
contextualized	O
encoders	O
has	O
had	O
a	O
major	O
impact	O
on	O
the	O
field	O
of	O
natural	O
language	O
processing	O
.	O
Boosted	O
by	O
the	O
availability	O
of	O
general	O
-	O
purpose	O
frameworks	O
like	O
AllenNLP	O
and	O
Transformers	O
(	O
Wolf	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
pre	O
-	O
trained	O
models	O
like	O
ELMO	O
and	O
BERT	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
have	O
caused	O
a	O
shift	O
towards	O
simple	O
architectures	O
where	O
a	O
strong	O
pre	O
-	O
trained	O
encoder	O
is	O
paired	O
with	O
a	O
shallow	O
downstream	O
model	O
,	O
often	O
outperforming	O
the	O
intricate	O
task	O
-	O
specific	O
architectures	O
of	O
the	O
past	O
.	O

The	O
versatility	O
of	O
pre	O
-	O
trained	O
representations	O
implies	O
that	O
they	O
encode	O
some	O
aspects	O
of	O
general	O

L=0	O
L=8	O
L=11	O

Figure	O
1	O
:	O
Intra	O
-	O
sentence	O
similarity	O
by	O
layer	O
L	O
of	O
the	O
multilingual	O
BERT	O
-	O
base	O
.	O
Functional	O
tokens	O
are	O
similar	O
in	O
L	O
=	O
0	O
,	O
syntactic	O
groups	O
emerge	O
at	O
higher	O
levels	O
.	O

linguistic	O
knowledge	O
(	O
Reif	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Indeed	O
,	O
even	O
an	O
informal	O
inspection	O
of	O
layer	O
-	O
wise	O
intrasentence	O
similarities	O
(	O
Fig	O
.	O
1	O
)	O
suggests	O
that	O
these	O
models	O
capture	O
elements	O
of	O
linguistic	O
structure	O
,	O
and	O
those	O
differ	O
depending	O
on	O
the	O
layer	O
of	O
the	O
model	O
.	O
A	O
grounded	O
investigation	O
of	O
these	O
regularities	O
allows	O
to	O
interpret	O
the	O
model	O
's	O
behaviour	O
,	O
design	O
better	O
pre	O
-	O
trained	O
encoders	O
and	O
inform	O
the	O
downstream	O
model	O
development	O
.	O
Such	O
investigation	O
is	O
the	O
main	O
subject	O
of	O
probing	O
,	O
and	O
recent	O
studies	O
confirm	O
that	O
BERT	O
implicitly	O
captures	O
many	O
aspects	O
of	O
language	O
use	O
,	O
lexical	O
semantics	O
and	O
grammar	O
(	O
Rogers	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O

Most	O
probing	O
studies	O
use	O
linguistics	O
as	O
a	O
theoretical	O
scaffolding	O
and	O
operate	O
on	O
a	O
task	O
level	O
.	O
However	O
,	O
there	O
often	O
exist	O
multiple	O
ways	O
to	O
represent	O
the	O
same	O
linguistic	O
phenomenon	O
:	O
for	O
example	O
,	O
English	O
dependency	O
syntax	O
can	O
be	O
encoded	O
using	O
a	O
variety	O
of	O
formalisms	O
,	O
incl	O
.	O
Universal	O
(	O
Schuster	O
and	O
Manning	O
,	O
2016	O
)	O
,	O
Stanford	O
(	O
de	O
Marneffe	O
and	O
Manning	O
,	O
2008	O
)	O
and	O
CoNLL-2009	O
dependencies	O
(	O
Hajič	O
et	O
al	O
.	O
,	O
2009	O
)	O
,	O
all	O
using	O
different	O
label	O
sets	O
and	O
syntactic	O
head	O
attachment	O
rules	O
.	O
Any	O
probing	O
study	O
inevitably	O
commits	O
to	O
the	O
specific	O
theoretical	O
framework	O
used	O
to	O
produce	O
the	O
underlying	O
data	O
.	O
The	O
differences	O
between	O
linguistic	O
formalisms	O
,	O
however	O
,	O
can	O
be	O
substantial	O
.	O

Can	O
these	O
differences	O
affect	O
the	O
probing	O
results	O
?	O
This	O
question	O
is	O
intriguing	O
for	O
several	O
reasons	O
.	O
Lin	O
-	O
guistic	O
formalisms	O
are	O
well	O
-	O
documented	O
,	O
and	O
if	O
the	O
choice	O
of	O
formalism	O
indeed	O
has	O
an	O
effect	O
on	O
probing	O
,	O
cross	O
-	O
formalism	O
comparison	O
will	O
yield	O
new	O
insights	O
into	O
the	O
linguistic	O
knowledge	O
obtained	O
by	O
contextualized	O
encoders	O
during	O
pre	O
-	O
training	O
.	O
If	O
,	O
alternatively	O
,	O
the	O
probing	O
results	O
remain	O
stable	O
despite	O
substantial	O
differences	O
between	O
formalisms	O
,	O
this	O
prompts	O
a	O
further	O
scrutiny	O
of	O
what	O
the	O
pretrained	O
encoders	O
in	O
fact	O
encode	O
.	O
Finally	O
,	O
on	O
the	O
reverse	O
side	O
,	O
cross	O
-	O
formalism	O
probing	O
might	O
be	O
used	O
as	O
a	O
tool	O
to	O
empirically	O
compare	O
the	O
formalisms	O
and	O
their	O
language	O
-	O
specific	O
implementations	O
.	O
To	O
the	O
best	O
of	O
our	O
knowledge	O
we	O
are	O
the	O
first	O
to	O
explicitly	O
address	O
the	O
influence	O
of	O
formalism	O
on	O
probing	O
.	O

Ideally	O
,	O
the	O
task	O
chosen	O
for	O
a	O
cross	O
-	O
formalism	O
study	O
should	O
be	O
encoded	O
in	O
multiple	O
formalisms	O
using	O
the	O
same	O
textual	O
data	O
to	O
rule	O
out	O
the	O
influence	O
of	O
the	O
domain	O
and	O
text	O
type	O
.	O
While	O
many	O
linguistic	O
corpora	O
contain	O
several	O
layers	O
of	O
linguistic	O
information	O
,	O
having	O
the	O
same	O
textual	O
data	O
annotated	O
with	O
multiple	O
formalisms	O
for	O
the	O
same	O
task	O
is	O
rare	O
.	O
We	O
focus	O
on	O
role	O
semantics	O
-a	O
family	O
of	O
shallow	O
semantic	O
formalisms	O
at	O
the	O
interface	O
between	O
syntax	O
and	O
propositional	O
semantics	O
that	O
assign	O
roles	O
to	O
the	O
participants	O
of	O
natural	O
language	O
utterances	O
,	O
determining	O
who	O
did	O
what	O
to	O
whom	O
,	O
where	O
,	O
when	O
etc	O
.	O
Decades	O
of	O
research	O
in	O
theoretical	O
linguistics	O
have	O
produced	O
a	O
range	O
of	O
rolesemantic	O
frameworks	O
that	O
have	O
been	O
operationalized	O
in	O
NLP	O
:	O
syntax	O
-	O
driven	O
PropBank	O
(	O
Palmer	O
et	O
al	O
.	O
,	O
2005	O
)	O
,	O
coarse	O
-	O
grained	O
VerbNet	O
(	O
Kipper	O
-	O
Schuler	O
,	O
2005	O
)	O
,	O
fine	O
-	O
grained	O
FrameNet	O
(	O
Baker	O
et	O
al	O
.	O
,	O
1998	O
)	O
,	O
and	O
,	O
recently	O
,	O
decompositional	O
Semantic	O
Proto	O
-	O
Roles	O
(	O
SPR	O
)	O
(	O
Reisinger	O
et	O
al	O
.	O
,	O
2015;White	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
The	O
SemLink	O
project	O
(	O
Bonial	O
et	O
al	O
.	O
,	O
2013	O
)	O
offers	O
parallel	O
annotation	O
for	O
PropBank	O
,	O
VerbNet	O
and	O
FrameNet	O
for	O
English	O
.	O
This	O
allows	O
us	O
to	O
isolate	O
the	O
object	O
of	O
our	O
study	O
:	O
apart	O
from	O
the	O
rolesemantic	O
labels	O
,	O
the	O
underlying	O
data	O
and	O
conditions	O
for	O
the	O
three	O
formalisms	O
are	O
identical	O
.	O
SR3DE	O
(	O
Mújdricza	O
-	O
Maydt	O
et	O
al	O
.	O
,	O
2016	O
)	O
provides	O
compatible	O
annotation	O
in	O
three	O
formalisms	O
for	O
German	O
,	O
enabling	O
cross	O
-	O
lingual	O
validation	O
of	O
our	O
results	O
.	O
Combined	O
,	O
these	O
factors	O
make	O
role	O
semantics	O
an	O
ideal	O
target	O
for	O
our	O
cross	O
-	O
formalism	O
probing	O
study	O
.	O

A	O
solid	O
body	O
of	O
evidence	O
suggests	O
that	O
encoders	O
like	O
BERT	O
capture	O
syntactic	O
and	O
lexical	O
-	O
semantic	O
properties	O
,	O
but	O
only	O
few	O
studies	O
have	O
considered	O
probing	O
for	O
predicate	O
-	O
level	O
semantics	O
(	O
Tenney	O
et	O
al	O
.	O
,	O
2019b;Kovaleva	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
To	O
the	O
best	O
of	O
our	O
knowledge	O
we	O
are	O
the	O
first	O
to	O
conduct	O
a	O
cross	O
-	O
formalism	O
probing	O
study	O
on	O
role	O
semantics	O
,	O
thereby	O
contributing	O
to	O
the	O
line	O
of	O
research	O
on	O
how	O
and	O
whether	O
pre	O
-	O
trained	O
BERT	O
encodes	O
higher	O
-	O
level	O
semantic	O
phenomena	O
.	O

Contributions	O
.	O
This	O
work	O
studies	O
the	O
effect	O
of	O
the	O
linguistic	O
formalism	O
on	O
probing	O
results	O
.	O
We	O
conduct	O
cross	O
-	O
formalism	O
experiments	O
on	O
PropBank	O
,	O
VerbNet	O
and	O
FrameNet	O
role	O
prediction	O
in	O
English	O
and	O
German	O
,	O
and	O
show	O
that	O
the	O
formalism	O
can	O
affect	O
probing	O
results	O
in	O
a	O
linguistically	O
meaningful	O
way	O
;	O
in	O
addition	O
,	O
we	O
demonstrate	O
that	O
layer	O
probing	O
can	O
detect	O
subtle	O
differences	O
between	O
implementations	O
of	O
the	O
same	O
formalism	O
in	O
different	O
languages	O
.	O
On	O
the	O
technical	O
side	O
,	O
we	O
advance	O
the	O
recently	O
introduced	O
edge	O
and	O
layer	O
probing	O
framework	O
(	O
Tenney	O
et	O
al	O
.	O
,	O
2019b	O
)	O
;	O
in	O
particular	O
,	O
we	O
introduce	O
anchor	O
tasks	O
-an	O
analytical	O
tool	O
inspired	O
by	O
feature	O
-	O
based	O
systems	O
that	O
allows	O
deeper	O
qualitative	O
insights	O
into	O
the	O
pre	O
-	O
trained	O
models	O
'	O
behaviour	O
.	O
Finally	O
,	O
advancing	O
the	O
current	O
knowledge	O
about	O
the	O
encoding	O
of	O
predicate	O
semantics	O
in	O
BERT	O
,	O
we	O
perform	O
a	O
fine	O
-	O
grained	O
semantic	O
proto	O
-	O
role	O
probing	O
study	O
and	O
demonstrate	O
that	O
semantic	O
proto	O
-	O
role	O
properties	O
can	O
be	O
extracted	O
from	O
pre	O
-	O
trained	O
BERT	O
,	O
contrary	O
to	O
the	O
existing	O
reports	O
.	O
Our	O
results	O
suggest	O
that	O
along	O
with	O
task	O
and	O
language	O
,	O
linguistic	O
formalism	O
is	O
an	O
important	O
dimension	O
to	O
be	O
accounted	O
for	O
in	O
probing	O
research	O
.	O

Related	O
Work	O

BERT	O
as	O
Encoder	O

BERT	O
is	O
a	O
Transformer	O
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017	O
)	O
encoder	O
pre	O
-	O
trained	O
by	O
jointly	O
optimizing	O
two	O
unsupervised	O
objectives	O
:	O
masked	O
language	O
model	O
and	O
next	O
sentence	O
prediction	O
.	O
It	O
uses	O
WordPiece	O
(	O
WP	O
,	O
Wu	O
et	O
al	O
.	O
(	O
2016	O
)	O
)	O
subword	O
tokens	O
along	O
with	O
positional	O
embeddings	O
as	O
input	O
,	O
and	O
gradually	O
constructs	O
sentence	O
representations	O
by	O
applying	O
tokenlevel	O
self	O
-	O
attention	O
pooling	O
over	O
a	O
stack	O
of	O
layers	O
L.	O
The	O
result	O
of	O
BERT	O
encoding	O
is	O
a	O
layer	O
-	O
wise	O
representation	O
of	O
the	O
input	O
wordpiece	O
tokens	O
with	O
higher	O
layers	O
representing	O
higher	O
-	O
level	O
abstractions	O
over	O
the	O
input	O
sequence	O
.	O
Thanks	O
to	O
the	O
joint	O
pre	O
-	O
training	O
objective	O
,	O
BERT	O
can	O
encode	O
words	O
and	O
sentences	O
in	O
a	O
unified	O
fashion	O
:	O
the	O
encoding	O
of	O
a	O
sentence	O
or	O
a	O
sentence	O
pair	O
is	O
stored	O
in	O
a	O
special	O
token	O
[	O
CLS	O
]	O
.	O

To	O
facilitate	O
multilingual	O
experiments	O
,	O
we	O
use	O
the	O
multilingual	O
BERT	O
-	O
base	O
(	O
mBERT	O
)	O
published	O
by	O
Devlin	O
et	O
al	O
.	O
(	O
2019	O
)	O
.	O
Although	O
several	O
recent	O
encoders	O
have	O
outperformed	O
BERT	O
on	O
benchmarks	O
Lan	O
et	O
al	O
.	O
,	O
2019;Raffel	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
we	O
use	O
the	O
original	O
BERT	O
architecture	O
,	O
since	O
it	O
allows	O
us	O
to	O
inherit	O
the	O
probing	O
methodology	O
and	O
to	O
build	O
upon	O
the	O
related	O
findings	O
.	O

Probing	O

Due	O
to	O
space	O
limitations	O
we	O
omit	O
high	O
-	O
level	O
discussions	O
on	O
benchmarking	O
(	O
Wang	O
et	O
al	O
.	O
,	O
2018	O
)	O
and	O
sentence	O
-	O
level	O
probing	O
(	O
Conneau	O
et	O
al	O
.	O
,	O
2018a	O
)	O
,	O
and	O
focus	O
on	O
the	O
recent	O
findings	O
related	O
to	O
the	O
representation	O
of	O
linguistic	O
structure	O
in	O
BERT	O
.	O
Surface	O
-	O
level	O
information	O
generally	O
tends	O
to	O
be	O
represented	O
in	O
the	O
lower	O
layers	O
of	O
deep	O
encoders	O
,	O
while	O
higher	O
layers	O
store	O
hierarchical	O
and	O
semantic	O
information	O
(	O
Belinkov	O
et	O
al	O
.	O
,	O
2017;Lin	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Tenney	O
et	O
al	O
.	O
(	O
2019a	O
)	O
show	O
that	O
the	O
abstraction	O
strategy	O
applied	O
by	O
the	O
English	O
pre	O
-	O
trained	O
BERT	O
encoder	O
follows	O
the	O
order	O
of	O
the	O
classical	O
NLP	O
pipeline	O
.	O
Strengthening	O
the	O
claim	O
about	O
linguistic	O
capabilities	O
of	O
BERT	O
,	O
Hewitt	O
and	O
Manning	O
(	O
2019	O
)	O
demonstrate	O
that	O
BERT	O
implicitly	O
learns	O
syntax	O
,	O
and	O
Reif	O
et	O
al	O
.	O
(	O
2019	O
)	O
show	O
that	O
it	O
encodes	O
fine	O
-	O
grained	O
lexicalsemantic	O
distinctions	O
.	O
Rogers	O
et	O
al	O
.	O
(	O
2020	O
)	O
provide	O
a	O
comprehensive	O
overview	O
of	O
BERT	O
's	O
properties	O
discovered	O
to	O
date	O
.	O

While	O
recent	O
results	O
indicate	O
that	O
BERT	O
successfully	O
represents	O
lexical	O
-	O
semantic	O
and	O
grammatical	O
information	O
,	O
the	O
evidence	O
of	O
its	O
high	O
-	O
level	O
semantic	O
capabilities	O
is	O
inconclusive	O
.	O
Tenney	O
et	O
al	O
.	O
(	O
2019a	O
)	O
show	O
that	O
the	O
English	O
PropBank	O
semantics	O
can	O
be	O
extracted	O
from	O
the	O
encoder	O
and	O
follows	O
syntax	O
in	O
the	O
layer	O
structure	O
.	O
However	O
,	O
out	O
of	O
all	O
formalisms	O
PropBank	O
is	O
most	O
closely	O
tied	O
to	O
syntax	O
,	O
and	O
the	O
results	O
on	O
proto	O
-	O
role	O
and	O
relation	O
probing	O
do	O
not	O
follow	O
the	O
same	O
pattern	O
.	O
Kovaleva	O
et	O
al	O
.	O
(	O
2019	O
)	O
identify	O
two	O
attention	O
heads	O
in	O
BERT	O
responsible	O
for	O
FrameNet	O
relations	O
.	O
However	O
,	O
they	O
find	O
that	O
disabling	O
them	O
in	O
a	O
fine	O
-	O
tuning	O
evaluation	O
on	O
the	O
GLUE	O
(	O
Wang	O
et	O
al	O
.	O
,	O
2018	O
)	O
benchmark	O
does	O
not	O
result	O
in	O
decreased	O
performance	O
.	O

Although	O
we	O
are	O
not	O
aware	O
of	O
any	O
systematic	O
studies	O
dedicated	O
to	O
the	O
effect	O
of	O
formalism	O
on	O
probing	O
results	O
,	O
the	O
evidence	O
of	O
such	O
effects	O
is	O
scattered	O
across	O
the	O
related	O
work	O
:	O
for	O
example	O
,	O
the	O
aforementioned	O
results	O
in	O
Tenney	O
et	O
al	O
.	O
(	O
2019a	O
)	O
show	O
a	O
difference	O
in	O
layer	O
utilization	O
between	O
constituents	O
-	O
and	O
dependency	O
-	O
based	O
syntactic	O
probes	O
and	O
semantic	O
role	O
and	O
proto	O
-	O
role	O
probes	O
.	O
It	O
is	O
not	O
clear	O
whether	O
this	O
effect	O
is	O
due	O
to	O
the	O
differences	O
in	O
the	O
underlying	O
datasets	O
and	O
task	O
architecture	O
or	O
the	O
formalism	O
per	O
se	O
.	O

Our	O
probing	O
methodology	O
builds	O
upon	O
the	O
edge	O
and	O
layer	O
probing	O
framework	O
.	O
The	O
encoding	O
produced	O
by	O
a	O
frozen	O
BERT	O
model	O
can	O
be	O
seen	O
as	O
a	O
layer	O
-	O
wise	O
snapshot	O
that	O
reflects	O
how	O
the	O
model	O
has	O
constructed	O
the	O
high	O
-	O
level	O
abstractions	O
.	O
Tenney	O
et	O
al	O
.	O
(	O
2019b	O
)	O
introduce	O
the	O
edge	O
probing	O
task	O
design	O
:	O
a	O
simple	O
classifier	O
is	O
tasked	O
with	O
predicting	O
a	O
linguistic	O
property	O
given	O
a	O
pair	O
of	O
spans	O
encoded	O
using	O
a	O
frozen	O
pre	O
-	O
trained	O
model	O
.	O
Tenney	O
et	O
al	O
.	O
(	O
2019a	O
)	O
use	O
edge	O
probing	O
to	O
analyse	O
the	O
layer	O
utilization	O
of	O
a	O
pre	O
-	O
trained	O
BERT	O
model	O
via	O
scalar	O
mixing	O
weights	O
learned	O
during	O
training	O
.	O
We	O
revisit	O
this	O
framework	O
in	O
Section	O
3	O
.	O

Role	O
Semantics	O

We	O
now	O
turn	O
to	O
the	O
object	O
of	O
our	O
investigation	O
:	O
role	O
semantics	O
.	O
For	O
further	O
discussion	O
,	O
consider	O
the	O
following	O
synthetic	O
example	O
:	O

a.	O
Despite	O
surface	O
-	O
level	O
differences	O
,	O
the	O
sentences	O
express	O
the	O
same	O
meaning	O
,	O
suggesting	O
an	O
underlying	O
semantic	O
representation	O
in	O
which	O
these	O
sentences	O
are	O
equivalent	O
.	O
One	O
such	O
representation	O
is	O
offered	O
by	O
role	O
semantics	O
-a	O
shallow	O
predicatesemantic	O
formalism	O
closely	O
related	O
to	O
syntax	O
.	O
In	O
terms	O
of	O
role	O
semantics	O
,	O
Mary	O
,	O
book	O
and	O
John	O
are	O
semantic	O
arguments	O
of	O
the	O
predicate	O
give	O
,	O
and	O
are	O
assigned	O
roles	O
from	O
a	O
pre	O
-	O
defined	O
inventory	O
,	O
for	O
example	O
,	O
Agent	O
,	O
Recipient	O
and	O
Theme	O
.	O

Semantic	O
roles	O
and	O
their	O
properties	O
have	O
received	O
extensive	O
attention	O
in	O
linguistics	O
(	O
Fillmore	O
,	O
1968;Levin	O
and	O
Rappaport	O
Hovav	O
,	O
2005;Dowty	O
,	O
1991	O
)	O
and	O
are	O
considered	O
a	O
universal	O
feature	O
of	O
human	O
language	O
.	O
The	O
size	O
and	O
organization	O
of	O
the	O
role	O
and	O
predicate	O
inventory	O
are	O
subject	O
to	O
debate	O
,	O
giving	O
rise	O
to	O
a	O
variety	O
of	O
role	O
-	O
semantic	O
formalisms	O
.	O

PropBank	O
assumes	O
a	O
predicate	O
-	O
independent	O
labeling	O
scheme	O
where	O
predicates	O
are	O
distinguished	O
by	O
their	O
sense	O
(	O
get.01	O
)	O
,	O
and	O
semantic	O
arguments	O
are	O
labeled	O
with	O
generic	O
numbered	O
core	O
(	O
Arg0	O
-	O
5	O
)	O
and	O
modifier	O
(	O
e.g.	O
AM	O
-	O
TMP	O
)	O
roles	O
.	O
Core	O
roles	O
are	O
not	O
tied	O
to	O
specific	O
definitions	O
,	O
but	O
the	O
effort	O
has	O
been	O
made	O
to	O
keep	O
the	O
role	O
assignments	O
consistent	O
for	O
similar	O
verbs	O
;	O
Arg0	O
and	O
Arg1	O
correspond	O
to	O
the	O
Proto	O
-	O
Agent	O
and	O
Proto	O
-	O
Patient	O
roles	O
as	O
per	O
Dowty	O
(	O
1991	O
)	O
.	O
The	O
semantic	O
interpretation	O
of	O
core	O
roles	O
depends	O
on	O
the	O
predicate	O
sense	O
.	O

VerbNet	O
follows	O
a	O
different	O
categorization	O
scheme	O
.	O
Motivated	O
by	O
the	O
regularities	O
in	O
verb	O
behavior	O
,	O
Levin	O
(	O
1993	O
)	O
has	O
introduced	O
the	O
group	O
-	O
ing	O
of	O
verbs	O
into	O
intersective	O
classes	O
(	O
ILC	O
)	O
.	O
This	O
methodology	O
has	O
been	O
adopted	O
by	O
VerbNet	O
:	O
for	O
example	O
,	O
the	O
VerbNet	O
class	O
get-13.5.1	O
would	O
include	O
verbs	O
earn	O
,	O
fetch	O
,	O
gain	O
etc	O
.	O
A	O
verb	O
in	O
Verb	O
-	O
Net	O
can	O
belong	O
to	O
several	O
classes	O
corresponding	O
to	O
different	O
senses	O
;	O
each	O
class	O
is	O
associated	O
with	O
a	O
set	O
of	O
roles	O
and	O
licensed	O
syntactic	O
transformations	O
.	O
Unlike	O
PropBank	O
,	O
VerbNet	O
uses	O
a	O
set	O
of	O
approx	O
.	O
30	O
thematic	O
roles	O
that	O
have	O
universal	O
definitions	O
and	O
are	O
shared	O
among	O
predicates	O
,	O
e.g.	O
Agent	O
,	O
Beneficiary	O
,	O
Instrument	O
.	O

FrameNet	O
takes	O
a	O
meaning	O
-	O
driven	O
stance	O
on	O
the	O
role	O
encoding	O
by	O
modeling	O
it	O
in	O
terms	O
of	O
frame	O
semantics	O
:	O
predicates	O
are	O
grouped	O
into	O
frames	O
(	O
e.g.	O
Commerce	O
buy	O
)	O
,	O
which	O
specify	O
role	O
-	O
like	O
slots	O
to	O
be	O
filled	O
.	O
FrameNet	O
offers	O
fine	O
-	O
grained	O
frame	O
distinctions	O
,	O
and	O
roles	O
in	O
FrameNet	O
are	O
frame	O
-	O
specific	O
,	O
e.g.	O
Buyer	O
,	O
Seller	O
and	O
Money	O
.	O
The	O
resource	O
accompanies	O
each	O
frame	O
with	O
a	O
description	O
of	O
the	O
situation	O
and	O
its	O
core	O
and	O
peripheral	O
participants	O
.	O

SPR	O
follows	O
the	O
work	O
of	O
Dowty	O
(	O
1991	O
)	O
and	O
discards	O
the	O
notion	O
of	O
categorical	O
semantic	O
roles	O
in	O
favor	O
of	O
feature	O
bundles	O
.	O

Instead	O
of	O
a	O
fixed	O
role	O
label	O
,	O
each	O
argument	O
is	O
assessed	O
via	O
a	O
11	O
-	O
dimensional	O
cardinal	O
feature	O
set	O
including	O
Proto	O
-	O
Agent	O
and	O
Proto	O
-	O
Patient	O
properties	O
like	O
volitional	O
,	O
sentient	O
,	O
destroyed	O
,	O
etc	O
.	O
The	O
feature	O
-	O
based	O
approach	O
eliminates	O
some	O
of	O
the	O
theoretical	O
issues	O
associated	O
with	O
categorical	O
role	O
inventories	O
and	O
allows	O
for	O
more	O
flexible	O
modeling	O
of	O
role	O
semantics	O
.	O

Each	O
of	O
the	O
role	O
labeling	O
formalisms	O
offers	O
certain	O
advantages	O
and	O
disadvantages	O
(	O
Giuglea	O
and	O
Moschitti	O
,	O
2006;Mújdricza	O
-	O
Maydt	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
While	O
being	O
close	O
to	O
syntax	O
and	O
thereby	O
easier	O
to	O
predict	O
,	O
PropBank	O
does	O
n't	O
contribute	O
much	O
semantics	O
to	O
the	O
representation	O
.	O
On	O
the	O
opposite	O
side	O
of	O
the	O
spectrum	O
,	O
FrameNet	O
offers	O
rich	O
predicatesemantic	O
representations	O
for	O
verbs	O
and	O
nouns	O
,	O
but	O
suffers	O
from	O
high	O
granularity	O
and	O
coverage	O
gaps	O
(	O
Hartmann	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
VerbNet	O
takes	O
a	O
middle	O
ground	O
by	O
following	O
grammatical	O
criteria	O
while	O
still	O
encoding	O
coarse	O
-	O
grained	O
semantics	O
,	O
but	O
only	O
focuses	O
on	O
verbs	O
and	O
core	O
(	O
not	O
modifier	O
)	O
roles	O
.	O
SPR	O
avoids	O
the	O
granularity	O
-	O
generalization	O
trade	O
-	O
off	O
of	O
the	O
categorical	O
inventories	O
,	O
but	O
is	O
yet	O
to	O
find	O
its	O
way	O
into	O
practical	O
NLP	O
applications	O
.	O

Probing	O
Methodology	O

We	O
take	O
the	O
edge	O
probing	O
setup	O
by	O
Tenney	O
et	O
al	O
.	O
(	O
2019b	O
)	O
as	O
our	O
starting	O
point	O
.	O
Edge	O
probing	O
aims	O
to	O
predict	O
a	O
label	O
given	O
a	O
pair	O
of	O
contextualized	O
span	O
or	O
word	O
encodings	O
.	O
More	O
formally	O
,	O
we	O
encode	O
a	O
WP	O
-	O
tokenized	O
sentence	O
[	O
wp	O
1	O
,	O
wp	O
2	O
,	O
...	O
wp	O
k	O
]	O
with	O
a	O
frozen	O
pre	O
-	O
trained	O
model	O
,	O
producing	O
contextual	O
embeddings	O
[	O
e	O
1	O
,	O
e	O
2	O
,	O
...	O
e	O
k	O
]	O
,	O
each	O
of	O
which	O
is	O
a	O
layered	O
representation	O
over	O
L	O
=	O
{	O
l	O
0	O
,	O
l	O
1	O
,	O
...	O
l	O
m	O
}	O
layers	O
,	O
with	O
encoding	O
at	O
layer	O
l	O
n	O
for	O
the	O
wordpiece	O
wp	O
i	O
further	O
denoted	O
as	O
e	O
n	O
i	O
.	O
A	O
trainable	O
scalar	O
mix	O
is	O
applied	O
to	O
the	O
layered	O
representation	O
to	O
produce	O
the	O
final	O
encoding	O
given	O
the	O
per	O
-	O
layer	O
mixing	O
weights	O
{	O
a	O
0	O
,	O
a	O
1	O
..	O
a	O
m	O
}	O
and	O
a	O
scaling	O
parameter	O
γ	O
:	O

e	O
i	O
=	O
γ	O
m	O
l=0	O
sof	O
tmax(a	O
l	O
)	O
e	O
l	O
i	O

Given	O
the	O
source	O
src	O
and	O
target	O
tgt	O
wordpieces	O
encoded	O
as	O
e	O
src	O
and	O
e	O
tgt	O
,	O
our	O
goal	O
is	O
to	O
predict	O
the	O
label	O
y.	O

Due	O
to	O
its	O
task	O
-	O
agnostic	O
architecture	O
,	O
edge	O
probing	O
can	O
be	O
applied	O
to	O
a	O
wide	O
variety	O
of	O
unary	O
(	O
by	O
omitting	O
tgt	O
)	O
and	O
binary	O
labeling	O
tasks	O
in	O
a	O
unified	O
manner	O
,	O
facilitating	O
the	O
cross	O
-	O
task	O
comparison	O
.	O
The	O
original	O
setup	O
has	O
several	O
limitations	O
that	O
we	O
address	O
in	O
our	O
implementation	O
.	O

Regression	O
tasks	O
.	O
The	O
original	O
edge	O
probing	O
setup	O
only	O
considers	O
classification	O
tasks	O
.	O
Many	O
language	O
phenomena	O
-including	O
positional	O
information	O
and	O
semantic	O
proto	O
-	O
roles	O
,	O
are	O
naturally	O
modeled	O
as	O
regression	O
.	O
We	O
extend	O
the	O
architecture	O
by	O
Tenney	O
et	O
al	O
.	O
(	O
2019b	O
)	O
and	O
support	O
both	O
classification	O
and	O
regression	O
:	O
the	O
former	O
achieved	O
via	O
softmax	O
,	O
the	O
latter	O
via	O
direct	O
linear	O
regression	O
to	O
the	O
target	O
value	O
.	O

Flat	O
model	O
.	O
To	O
decrease	O
the	O
models	O
'	O
own	O
expressive	O
power	O
(	O
Hewitt	O
and	O
Liang	O
,	O
2019	O
)	O
,	O
we	O
keep	O
the	O
number	O
of	O
parameters	O
in	O
our	O
probing	O
model	O
as	O
low	O
as	O
possible	O
.	O
While	O
Tenney	O
et	O
al	O
.	O
(	O
2019b	O
)	O
utilize	O
pooled	O
self	O
-	O
attentional	O
span	O
representations	O
and	O
a	O
projection	O
layer	O
to	O
enable	O
cross	O
-	O
model	O
comparison	O
,	O
we	O
directly	O
feed	O
the	O
wordpiece	O
encoding	O
into	O
the	O
classifier	O
,	O
using	O
the	O
first	O
wordpiece	O
of	O
a	O
word	O
.	O
To	O
further	O
increase	O
the	O
selectivity	O
of	O
the	O
model	O
,	O
we	O
directly	O
project	O
the	O
source	O
and	O
target	O
wordpiece	O
representations	O
into	O
the	O
label	O
space	O
,	O
opposed	O
to	O
the	O
two	O
-	O
layer	O
MLP	O
classifier	O
used	O
in	O
the	O
original	O
setup	O
.	O

Separate	O
scalar	O
mixes	O
.	O
To	O
enable	O
fine	O
-	O
grained	O
analysis	O
of	O
probing	O
results	O
,	O
we	O
train	O
and	O
analyze	O
separate	O
scalar	O
mixes	O
for	O
source	O
and	O
target	O
wordpieces	O
,	O
motivated	O
by	O
the	O
fact	O
that	O
the	O
classifier	O
might	O
utilize	O
different	O
aspects	O
of	O
their	O
representation	O
for	O
prediction	O
1	O
.	O
Indeed	O
,	O
we	O
find	O
that	O
the	O
mixing	O
weights	O
learned	O
for	O
source	O
and	O
target	O
wordpieces	O
might	O
show	O
substantial	O
-and	O
linguistically	O
meaningful	O
-variation	O
.	O
Combined	O
with	O
regressionbased	O
objective	O
,	O
separating	O
the	O
scalar	O
mixes	O
allows	O
us	O
to	O
scrutinize	O
layer	O
utilization	O
patterns	O
for	O
semantic	O
proto	O
-	O
roles	O
.	O

Sentence	O
-	O
level	O
probes	O
.	O
Utilizing	O
the	O
BERTspecific	O
sentence	O
representation	O
[	O
CLS	O
]	O
allows	O
us	O
to	O
incorporate	O
the	O
sentence	O
-	O
level	O
natural	O
language	O
inference	O
(	O
NLI	O
)	O
probe	O
into	O
our	O
kit	O
.	O

Anchor	O
tasks	O
.	O
We	O
employ	O
two	O
analytical	O
tools	O
from	O
the	O
original	O
layer	O
probing	O
setup	O
.	O
Mixing	O
weight	O
plotting	O
compares	O
layer	O
utilization	O
among	O
tasks	O
by	O
visually	O
aligning	O
the	O
respective	O
learned	O
weight	O
distributions	O
transformed	O
via	O
a	O
softmax	O
function	O
.	O
Layer	O
center	O
-	O
of	O
-	O
gravity	O
is	O
used	O
as	O
a	O
summary	O
statistic	O
for	O
a	O
task	O
's	O
layer	O
utilization	O
.	O
While	O
the	O
distribution	O
of	O
mixing	O
weights	O
along	O
the	O
layers	O
allows	O
us	O
to	O
estimate	O
the	O
order	O
in	O
which	O
information	O
is	O
processed	O
during	O
encoding	O
,	O
it	O
does	O
n't	O
allow	O
to	O
directly	O
assess	O
the	O
similarity	O
between	O
the	O
layer	O
utilization	O
of	O
the	O
probing	O
tasks	O
.	O
Tenney	O
et	O
al	O
.	O
(	O
2019a	O
)	O
have	O
demonstrated	O
that	O
the	O
order	O
in	O
which	O
linguistic	O
information	O
is	O
stored	O
in	O
BERT	O
mirrors	O
the	O
traditional	O
NLP	O
pipeline	O
.	O
A	O
prominent	O
property	O
of	O
the	O
NLP	O
pipelines	O
is	O
their	O
use	O
of	O
low	O
-	O
level	O
features	O
to	O
predict	O
downstream	O
phenomena	O
.	O
In	O
the	O
context	O
of	O
layer	O
probing	O
,	O
probing	O
tasks	O
can	O
be	O
seen	O
as	O
end	O
-	O
to	O
-	O
end	O
feature	O
extractors	O
.	O
Following	O
this	O
intuition	O
,	O
we	O
define	O
two	O
groups	O
of	O
probing	O
tasks	O
:	O
target	O
tasks	O
-the	O
main	O
tasks	O
under	O
investigation	O
,	O
and	O
anchor	O
tasks	O
-a	O
set	O
of	O
related	O
tasks	O
that	O
serve	O
as	O
a	O
basis	O
for	O
qualitative	O
comparison	O
between	O
the	O
targets	O
.	O
The	O
softmax	O
transformation	O
of	O
the	O
scalar	O
mixing	O
weights	O
allows	O
to	O
treat	O
them	O
as	O
probability	O
distributions	O
:	O
the	O
higher	O
the	O
mixing	O
weight	O
of	O
a	O
layer	O
,	O
the	O
more	O
likely	O
the	O
probe	O
is	O
to	O
utilize	O
information	O
from	O
this	O
layer	O
during	O
prediction	O
.	O
We	O
use	O
Kullback	O
-	O
Leibler	O
divergence	O
to	O
compare	O
target	O
tasks	O
(	O
e.g.	O
role	O
labeling	O
in	O
different	O
formalisms	O
)	O
in	O
terms	O
of	O
their	O
similarity	O
to	O
lowerlevel	O
anchor	O
tasks	O
(	O
e.g.	O
dependency	O
relation	O
and	O
lemma	O
)	O
.	O
Note	O
that	O
the	O
notion	O
of	O
anchor	O
task	O
is	O
contextual	O
:	O
the	O
same	O
task	O
can	O
serve	O
as	O
a	O
target	O
and	O
as	O
an	O
anchor	O
,	O
depending	O
on	O
the	O
focus	O
of	O
the	O
study	O
.	O
jections	O
in	O
the	O
background	O
,	O
but	O
do	O
not	O
investigate	O
the	O
differences	O
between	O
the	O
learned	O
projections	O
.	O

Probing	O
tasks	O

Our	O
probing	O
kit	O
spans	O
a	O
wide	O
range	O
of	O
probing	O
tasks	O
,	O
from	O
primitive	O
surface	O
-	O
level	O
tasks	O
mostly	O
utilized	O
as	O
anchors	O
later	O
to	O
high	O
-	O
level	O
semantic	O
tasks	O
that	O
language	O
en	O
de	O
aim	O
to	O
provide	O
a	O
representational	O
upper	O
bound	O
to	O
predicate	O
semantics	O
.	O
We	O
follow	O
the	O
training	O
,	O
test	O
and	O
development	O
splits	O
from	O
the	O
original	O
SR3de	O
,	O
CoNLL-2009	O
and	O
SPR	O
data	O
.	O
The	O
XNLI	O
task	O
is	O
sourced	O
from	O
the	O
development	O
set	O
and	O
only	O
used	O
for	O
scalar	O
mix	O
analysis	O
.	O
To	O
reduce	O
the	O
number	O
of	O
labels	O
in	O
some	O
of	O
the	O
probing	O
tasks	O
,	O
we	O
collect	O
frequency	O
statistics	O
over	O
the	O
corresponding	O
training	O
sets	O
and	O
only	O
consider	O
up	O
to	O
250	O
most	O
frequent	O
labels	O
.	O
Below	O
we	O
define	O
the	O
tasks	O
in	O
order	O
of	O
their	O
complexity	O
,	O
Table	O
2	O
provides	O
the	O
probing	O
task	O
statistics	O
,	O
Table	O
3	O
compares	O
the	O
categorical	O
role	O
labeling	O
formalisms	O
in	O
terms	O
of	O
granularity	O
,	O
and	O
Table	O
4	O
provides	O
examples	O
.	O
We	O
evaluate	O
the	O
classification	O
performance	O
using	O
Accuracy	O
,	O
while	O
regression	O
tasks	O
are	O
scored	O
via	O
R	O
2	O
.	O

Token	O
type	O
(	O
ttype	O
)	O
predicts	O
the	O
type	O
of	O
a	O
word	O
.	O
This	O
requires	O
contextual	O
processing	O
since	O
a	O
word	O
might	O
consist	O
of	O
several	O
wordpieces	O
;	O
Token	O
position	O
(	O
token.ix	O
)	O
predicts	O
the	O
linear	O
position	O
of	O
a	O
word	O
,	O
cast	O
as	O
a	O
regression	O
task	O
over	O
the	O
first	O
20	O
words	O
in	O
the	O
sentence	O
.	O
Again	O
,	O
the	O
task	O
is	O
non	O
-	O
trivial	O
since	O
it	O
requires	O
the	O
words	O
to	O
be	O
assembled	O
from	O
the	O
wordpieces	O
.	O
Part	O
-	O
of	O
-	O
speech	O
(	O
pos	O
)	O
predicts	O
the	O
languagespecific	O
part	O
-	O
of	O
-	O
speech	O
tag	O
for	O
the	O
given	O
token	O
.	O
Lexical	O
unit	O
(	O
lex.unit	O
)	O
predicts	O
the	O
lemma	O
and	O
POS	O
of	O
the	O
given	O
word	O
-a	O
common	O
input	O
representation	O
for	O
the	O
entries	O
in	O
lexical	O
resources	O
.	O
We	O
extract	O
coarse	O
POS	O
tags	O
by	O
using	O
the	O
first	O
character	O
of	O
the	O
language	O
-	O
specific	O
POS	O
tag	O
.	O

Dependency	O
relation	O
(	O
deprel	O
)	O
predicts	O
the	O
dependency	O
relation	O
between	O
the	O
parent	O
src	O
and	O
dependent	O
tgt	O
tokens	O
;	O
Semantic	O
role	O
(	O
role.[frm	O
]	O
)	O
predicts	O
the	O
semantic	O
role	O
given	O
a	O
predicate	O
src	O
and	O
an	O
argument	O
tgt	O
token	O
in	O
one	O
of	O
the	O
three	O
role	O
labeling	O
formalisms	O
:	O
PropBank	O
pb	O
,	O
VerbNet	O
vn	O
and	O
FrameNet	O
fn	O
.	O
Note	O
that	O
we	O
only	O
probe	O
for	O
the	O
role	O
label	O
,	O
and	O
the	O
model	O
has	O
no	O
access	O
to	O
the	O
verb	O
sense	O
information	O
from	O
the	O
data	O
.	O
Semantic	O
proto	O
-	O
role	O
(	O
spr	O
.	O
[	O
prop	O
]	O
)	O
is	O
a	O
set	O
of	O
eleven	O
regression	O
tasks	O
predicting	O
the	O
values	O
of	O
the	O
proto	O
-	O
role	O
properties	O
as	O
defined	O
in	O
(	O
Reisinger	O
et	O
al	O
.	O
,	O
2015	O
)	O
,	O
given	O
a	O
predicate	O
src	O
and	O
an	O
argument	O
tgt	O
.	O
XNLI	O
is	O
a	O
sentence	O
-	O
level	O
NLI	O
task	O
directly	O
sourced	O
from	O
the	O
corresponding	O
dataset	O
.	O
Given	O
two	O
sentences	O
,	O
the	O
goal	O
is	O
to	O
determine	O
whether	O
an	O
entailment	O
or	O
a	O
contradiction	O
relationship	O
holds	O
between	O
them	O
.	O
We	O
use	O
NLI	O
to	O
investigate	O
the	O
layer	O
utilization	O
of	O
mBERT	O
for	O
high	O
-	O
level	O
semantic	O
tasks	O
.	O
We	O
extract	O
the	O
sentence	O
pair	O
representation	O
via	O
the	O
[	O
CLS	O
]	O
token	O
and	O
treat	O
it	O
as	O
a	O
unary	O
probing	O
task	O
.	O

Results	O

Our	O
probing	O
framework	O
is	O
implemented	O
using	O
AllenNLP	O
.	O
2	O
We	O
train	O
the	O
probes	O
for	O
20	O
epochs	O
using	O
the	O
Adam	O
optimizer	O
with	O
default	O
parameters	O
and	O
a	O
batch	O
size	O
of	O
32	O
.	O
Due	O
to	O
the	O
frozen	O
encoder	O
and	O
flat	O
model	O
architecture	O
,	O
the	O
total	O
runtime	O
of	O
the	O
main	O
experiments	O
is	O
under	O
8	O
hours	O
on	O
a	O
single	O
Tesla	O
V100	O
GPU	O
.	O
In	O
addition	O
to	O
pre	O
-	O
trained	O
mBERT	O
we	O
report	O
baseline	O
performance	O
using	O
a	O
frozen	O
untrained	O
mBERT	O
model	O
obtained	O
by	O
randomizing	O
the	O
encoder	O
weights	O
post	O
-	O
initialization	O
as	O
in	O
Jawahar	O
et	O
al	O
.	O
(	O
2019	O
)	O
.	O

General	O
Trends	O

While	O
absolute	O
performance	O
is	O
secondary	O
to	O
our	O
analysis	O
,	O
we	O
report	O
the	O
probing	O
task	O
scores	O
on	O
respective	O
development	O
sets	O
in	O
Table	O
5	O
.	O
We	O
observe	O
that	O
grammatical	O
tasks	O
score	O
high	O
,	O
while	O
core	O
role	O
labeling	O
lags	O
behind	O
-in	O
line	O
with	O
the	O
findings	O
of	O
Tenney	O
et	O
al	O
.	O
(	O
2019a	O
)	O
3	O
We	O
observe	O
lower	O
scores	O
for	O
German	O
role	O
labeling	O
which	O
we	O
attribute	O
to	O
the	O
lack	O
of	O
training	O
data	O
.	O
Surprisingly	O
,	O
as	O
we	O
show	O
below	O
,	O
this	O
does	O
n't	O
prevent	O
the	O
edge	O
probe	O
from	O
task	O
en	O
de	O
*	O
token.ix	O
0.95	O
(	O
0.93	O
)	O
0.92	O
(	O
0	O
.	O
learning	O
to	O
locate	O
relevant	O
role	O
-	O
semantic	O
information	O
in	O
mBERT	O
's	O
layers	O
.	O

The	O
untrained	O
mBERT	O
baseline	O
expectedly	O
underperforms	O
;	O
however	O
,	O
we	O
note	O
good	O
baseline	O
results	O
on	O
surface	O
-	O
level	O
tasks	O
for	O
English	O
,	O
which	O
we	O
attribute	O
to	O
memorizing	O
token	O
identity	O
and	O
position	O
:	O
although	O
the	O
weights	O
are	O
set	O
randomly	O
,	O
the	O
frozen	O
encoder	O
still	O
associates	O
each	O
wordpiece	O
input	O
with	O
a	O
fixed	O
random	O
vector	O
.	O
We	O
have	O
confirmed	O
this	O
assumption	O
by	O
scalar	O
mix	O
analysis	O
of	O
the	O
untrained	O
mBERT	O
baseline	O
:	O
in	O
our	O
experiments	O
the	O
baseline	O
probes	O
for	O
both	O
English	O
and	O
German	O
attended	O
almost	O
exclusively	O
to	O
the	O
first	O
few	O
layers	O
of	O
the	O
encoder	O
,	O
independent	O
of	O
the	O
task	O
.	O
For	O
brevity	O
,	O
here	O
and	O
further	O
we	O
do	O
not	O
examine	O
baseline	O
mixing	O
weights	O
and	O
only	O
report	O
the	O
scores	O
.	O

Our	O
main	O
probing	O
results	O
mirror	O
the	O
findings	O
of	O
Tenney	O
et	O
al	O
.	O
(	O
2019a	O
)	O
about	O
the	O
sequential	O
processing	O
order	O
in	O
BERT	O
.	O
We	O
observe	O
that	O
the	O
layer	O
utilization	O
among	O
tasks	O
(	O
Fig	O
.	O
2	O
)	O
generally	O
aligns	O
for	O
English	O
and	O
German	O
4	O
,	O
although	O
we	O
note	O
that	O
in	O
terms	O
of	O
center	O
-	O
of	O
-	O
gravity	O
mBERT	O
tends	O
to	O
utilize	O
deeper	O
layers	O
for	O
German	O
probes	O
.	O
Basic	O
word	O
-	O
level	O
tasks	O
are	O
indeed	O
processed	O
early	O
by	O
the	O
model	O
,	O
and	O
XNLI	O
probes	O
focus	O
on	O
deeper	O
levels	O
,	O
suggesting	O
that	O
the	O
representation	O
of	O
higher	O
-	O
level	O
semantic	O
phenomena	O
follows	O
the	O
encoding	O
of	O
syntax	O
and	O
predicate	O
semantics	O
.	O

The	O
Effect	O
of	O
Formalism	O

Using	O
separate	O
scalar	O
mixes	O
for	O
source	O
and	O
target	O
tokens	O
allows	O
us	O
to	O
explore	O
the	O
cross	O
-	O
formalism	O
encoding	O
of	O
role	O
semantics	O
by	O
mBERT	O
in	O
detail	O
.	O
For	O
both	O
English	O
and	O
German	O
role	O
labeling	O
,	O
the	O
probe	O
's	O
layer	O
utilization	O
drastically	O
differs	O
for	O
predicate	O
and	O
4	O
Echoing	O
the	O
recent	O
findings	O
on	O
mBERT	O
's	O
multilingual	O
capacity	O
(	O
Pires	O
et	O
al	O
.	O
,	O
2019;Kondratyuk	O
and	O
Straka	O
,	O
2019	O
[	O
6.16	O
]	O
xnli	O
[	O
6.28	O
]	O
en	O
Layer	O
[	O
4.61	O
]	O
[	O
5.2	O
]	O
[	O
5.09	O
]	O
[	O
5.75	O
]	O
[	O
6.01	O
]	O
[	O
5.99	O
]	O
[	O
5.18	O
]	O
[	O
5.24	O
]	O
[	O
5.13	O
]	O
[	O
6.12	O
]	O
[	O
6.06	O
]	O
[	O
5.75	O
]	O
[	O
6.15	O
]	O
de	O
argument	O
tokens	O
.	O
While	O
the	O
argument	O
representation	O
role	O
*	O
tgt	O
mostly	O
focuses	O
on	O
the	O
same	O
layers	O
as	O
the	O
dependency	O
parsing	O
probe	O
,	O
the	O
layer	O
utilization	O
of	O
the	O
predicates	O
role	O
*	O
src	O
is	O
affected	O
by	O
the	O
chosen	O
formalism	O
.	O
In	O
English	O
,	O
PropBank	O
predicate	O
token	O
mixing	O
weights	O
emphasize	O
the	O
same	O
layers	O
as	O
dependency	O
parsing	O
-in	O
line	O
with	O
the	O
previously	O
published	O
results	O
.	O
However	O
,	O
the	O
probes	O
for	O
VerbNet	O
and	O
FrameNet	O
predicates	O
(	O
role.vn	O
src	O
and	O
role.fn	O
src	O
)	O
utilize	O
the	O
layers	O
associated	O
with	O
ttype	O
and	O
lex.unit	O
that	O
contain	O
lexical	O
information	O
.	O
Coupled	O
with	O
the	O
fact	O
that	O
both	O
VerbNet	O
and	O
FrameNet	O
assign	O
semantic	O
roles	O
based	O
on	O
lexical	O
-	O
semantic	O
predicate	O
groupings	O
(	O
frames	O
in	O
FrameNet	O
and	O
verb	O
classes	O
in	O
VerbNet	O
)	O
,	O
this	O
suggests	O
that	O
the	O
lower	O
layers	O
of	O
mBERT	O
implicitly	O
encode	O
predicate	O
sense	O
information	O
;	O
moreover	O
,	O
sense	O
encoding	O
for	O
VerbNet	O
utilizes	O
deeper	O
layers	O
of	O
the	O
model	O
associated	O
with	O
syntax	O
,	O
in	O
line	O
with	O
Verb	O
-	O
Net	O
's	O
predicate	O
classification	O
strategy	O
.	O
This	O
finding	O
confirms	O
that	O
the	O
formalism	O
can	O
indeed	O
have	O
linguistically	O
meaningful	O
effects	O
on	O
probing	O
results	O
.	O

Anchor	O
Tasks	O
in	O
the	O
Pipeline	O

We	O
now	O
use	O
the	O
scalar	O
mixes	O
of	O
the	O
role	O
labeling	O
probes	O
as	O
target	O
tasks	O
,	O
and	O
lower	O
-	O
level	O
probes	O
as	O
anchor	O
tasks	O
to	O
qualitatively	O
explore	O
the	O
differences	O
between	O
how	O
our	O
role	O
probes	O
learn	O
to	O
represent	O
predicates	O
and	O
semantic	O
arguments	O
5	O
(	O
Fig	O
.	O
3	O
)	O
.	O
The	O
results	O
reveal	O
a	O
distinctive	O
pattern	O
that	O
confirms	O
our	O
previous	O
observations	O
:	O
while	O
Verb	O
-	O
Net	O
and	O
FrameNet	O
predicate	O
layer	O
utilization	O
src	O
is	O
similar	O
to	O
the	O
scalar	O
mixes	O
learned	O
for	O
ttype	O
and	O
lex.unit	O
,	O
the	O
learned	O
argument	O
representations	O
tgt	O
and	O
the	O
PropBank	O
predicate	O
attend	O
to	O
the	O
layers	O
associated	O
with	O
dependency	O
relation	O
and	O
POS	O
probes	O
.	O
Aside	O
from	O
the	O
PropBank	O
predicate	O
encoding	O
which	O
we	O
address	O
below	O
,	O
the	O
pattern	O
reproduces	O
for	O
English	O
and	O
German	O
.	O
This	O
aligns	O
with	O
the	O
traditional	O
separation	O
of	O
the	O
semantic	O
role	O
labeling	O
task	O
into	O
predicate	O
disambiguation	O
followed	O
by	O
semantic	O
argument	O
identification	O
and	O
labeling	O
,	O
along	O
with	O
the	O
feature	O
sets	O
employed	O
for	O
these	O
tasks	O
(	O
Björkelund	O
et	O
al	O
.	O
,	O
2009	O
)	O
.	O
Note	O
that	O
the	O
observation	O
about	O
the	O
pipeline	O
-	O
like	O
task	O
processing	O
within	O
the	O
BERT	O
encoders	O
thereby	O
holds	O
,	O
albeit	O
on	O
a	O
sub	O
-	O
task	O
level	O
.	O

Formalism	O
Implementations	O

Both	O
layer	O
and	O
anchor	O
task	O
analysis	O
reveal	O
a	O
prominent	O
discrepancy	O
between	O
English	O
and	O
German	O
role	O
probing	O
results	O
:	O
while	O
the	O
PropBank	O
predicate	O
layer	O
utilization	O
for	O
English	O
mostly	O
relies	O
on	O
syntactic	O
information	O
,	O
German	O
PropBank	O
predicates	O
behave	O
similarly	O
to	O
VerbNet	O
and	O
FrameNet	O
.	O
The	O
lack	O
of	O
systematic	O
cross	O
-	O
lingual	O
differences	O
between	O
layer	O
utilization	O
for	O
other	O
probing	O
tasks	O
6	O
allows	O
us	O
to	O
rule	O
out	O
the	O
effect	O
of	O
purely	O
typological	O
features	O
such	O
as	O
word	O
order	O
and	O
case	O
marking	O
as	O
a	O
likely	O
cause	O
.	O
The	O
difference	O
in	O
the	O
number	O
of	O
role	O
labels	O
for	O
English	O
and	O
German	O
PropBank	O
,	O
however	O
,	O
points	O
at	O
possible	O
qualitative	O
differences	O
in	O
the	O
labeling	O
schemes	O
(	O
Table	O
3	O
)	O
.	O
The	O
data	O
for	O
English	O
stems	O
from	O
the	O
token	O
-	O
level	O
alignment	O
in	O
SemLink	O
that	O
maps	O
the	O
original	O
PropBank	O
roles	O
to	O
Verb	O
-	O
Net	O
and	O
FrameNet	O
.	O
Role	O
annotations	O
for	O
German	O
have	O
a	O
different	O
lineage	O
:	O
they	O
originate	O
from	O
the	O
FrameNet	O
-	O
annotated	O
SALSA	O
corpus	O
(	O
Burchardt	O
et	O
al	O
.	O
,	O
2006	O
)	O
semi	O
-	O
automatically	O
converted	O
to	O
Prop	O
-	O
Bank	O
style	O
for	O
the	O
CoNLL-2009	O
shared	O
task	O
(	O
Hajič	O
et	O
al	O
.	O
,	O
2009	O
)	O
,	O
and	O
enriched	O
with	O
VerbNet	O
labels	O
in	O
SR3de	O
(	O
Mújdricza	O
-	O
Maydt	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
As	O
a	O
result	O
,	O
while	O
English	O
PropBank	O
labels	O
are	O
assigned	O
in	O
a	O
predicate	O
-	O
independent	O
manner	O
,	O
German	O
PropBank	O
,	O
following	O
the	O
same	O
numbered	O
labeling	O
scheme	O
,	O
keeps	O
this	O
scheme	O
consistent	O
within	O
the	O
frame	O
.	O
We	O
assume	O
that	O
this	O
incentivizes	O
the	O
probe	O
to	O
learn	O
semantic	O
verb	O
groupings	O
and	O
reflects	O
in	O
our	O
probing	O
results	O
.	O
The	O
ability	O
of	O
the	O
probe	O
to	O
detect	O
subtle	O
differences	O
between	O
formalism	O
implementations	O
constitutes	O
a	O
new	O
use	O
case	O
for	O
probing	O
,	O
and	O
a	O
promising	O
direction	O
for	O
future	O
studies	O
.	O

Encoding	O
of	O
Proto	O
-	O
Roles	O

We	O
now	O
turn	O
to	O
the	O
probing	O
results	O
for	O
decompositional	O
semantic	O
proto	O
-	O
role	O
labeling	O
tasks	O
.	O
Unlike	O
(	O
Tenney	O
et	O
al	O
.	O
,	O
2019b	O
)	O
who	O
used	O
a	O
multi	O
-	O
label	O
classification	O
probe	O
,	O
we	O
treat	O
SPR	O
properties	O
as	O
separate	O
regression	O
tasks	O
.	O
The	O
results	O
in	O
Table	O
6	O
show	O
that	O
the	O
performance	O
varies	O
by	O
property	O
,	O
with	O
some	O
of	O
the	O
properties	O
attaining	O
reasonably	O
high	O
R	O
2	O
scores	O
despite	O
the	O
simplicity	O
of	O
the	O
probe	O
architecture	O
and	O
the	O
small	O
dataset	O
size	O
.	O
We	O
observe	O
that	O
properties	O
associated	O
with	O
Proto	O
-	O
Agent	O
tend	O
to	O
perform	O
better	O
.	O
The	O
untrained	O
mBERT	O
baseline	O
performs	O
poorly	O
which	O
we	O
attribute	O
to	O
the	O
lack	O
of	O
data	O
and	O
the	O
finegrained	O
semantic	O
nature	O
of	O
the	O
task	O
.	O
Our	O
fine	O
-	O
grained	O
,	O
property	O
-	O
level	O
task	O
design	O
allows	O
for	O
more	O
detailed	O
insights	O
into	O
the	O
layer	O
utilization	O
by	O
the	O
SPR	O
probes	O
(	O
Fig	O
.	O
4	O
)	O
.	O
The	O
results	O
indicate	O
that	O
while	O
the	O
layer	O
utilization	O
on	O
the	O
predicate	O
side	O
(	O
src	O
)	O
shows	O
no	O
clear	O
preference	O
for	O
particular	O
layers	O
(	O
similar	O
to	O
the	O
results	O
obtained	O
by	O
Tenney	O
et	O
al	O
.	O
(	O
2019a	O
)	O
)	O
,	O
some	O
of	O
the	O
proto	O
-	O
role	O
features	O
follow	O
the	O
pattern	O
seen	O
in	O
the	O
categorical	O
role	O
labeling	O
and	O
dependency	O
parsing	O
tasks	O
for	O
the	O
argument	O
tokens	O
tgt	O
.	O
With	O
few	O
exceptions	O
,	O
we	O
observe	O
that	O
the	O
properties	O
displaying	O
that	O
behavior	O
are	O
Proto	O
-	O
Agent	O
properties	O
;	O
moreover	O
,	O
a	O
close	O
examination	O
of	O
the	O
results	O
on	O
syntactic	O
preference	O
by	O
Reisinger	O
et	O
al	O
.	O
(	O
2015	O
,	O
p.	O
483	O
)	O
reveals	O
that	O
these	O
properties	O
are	O
also	O
the	O
ones	O
with	O
strong	O
preference	O
for	O
the	O
subject	O
position	O
,	O
including	O
the	O
outlier	O
case	O
of	O
stationary	O
which	O
in	O
their	O
data	O
behaves	O
like	O
a	O
Proto	O
-	O
Agent	O
property	O
.	O
The	O
correspondence	O
is	O
not	O
strict	O
,	O
and	O
we	O
leave	O
an	O
in	O
-	O
depth	O
investigation	O
of	O
the	O
reasons	O
behind	O
these	O
discrepancies	O
for	O
follow	O
-	O
up	O
work	O
.	O

Conclusion	O

We	O
have	O
demonstrated	O
that	O
the	O
choice	O
of	O
linguistic	O
formalism	O
can	O
have	O
substantial	O
,	O
linguistically	O
meaningful	O
effects	O
on	O
role	O
-	O
semantic	O
probing	O
results	O
.	O
We	O
have	O
shown	O
how	O
probing	O
classifiers	O
can	O
be	O
used	O
to	O
detect	O
discrepancies	O
between	O
formalism	O
implementations	O
,	O
and	O
presented	O
evidence	O
of	O
semantic	O
proto	O
-	O
role	O
encoding	O
in	O
the	O
pre	O
-	O
trained	O
mBERT	O
model	O
.	O
Our	O
refined	O
implementation	O
of	O
the	O
edge	O
probing	O
framework	O
coupled	O
with	O
the	O
anchor	O
task	O
methodology	O
enabled	O
new	O
insights	O
into	O
the	O
processing	O
of	O
predicate	O
-	O
semantic	O
information	O
within	O
mBERT	O
.	O
Our	O
findings	O
suggest	O
that	O
linguistic	O
formalism	O
is	O
an	O
important	O
factor	O
to	O
be	O
accounted	O
for	O
in	O
probing	O
studies	O
.	O
This	O
prompts	O
several	O
recommendations	O
for	O
the	O
follow	O
-	O
up	O
probing	O
studies	O
.	O
First	O
,	O
the	O
formalism	O
and	O
implementation	O
used	O
to	O
prepare	O
the	O
linguistic	O
material	O
underlying	O
a	O
probing	O
study	O
should	O
be	O
always	O
explicitly	O
specified	O
.	O
Second	O
,	O
if	O
possible	O
,	O
results	O
on	O
multiple	O
formalisations	O
of	O
the	O
same	O
task	O
should	O
be	O
reported	O
and	O
validated	O
for	O
several	O
languages	O
.	O
Finally	O
,	O
assembling	O
corpora	O
with	O
parallel	O
cross	O
-	O
formalism	O
annotations	O
would	O
facilitate	O
further	O
research	O
on	O
the	O
effect	O
of	O
formalism	O
in	O
probing	O
.	O

While	O
our	O
work	O
illustrates	O
the	O
impact	O
of	O
formalism	O
using	O
a	O
single	O
task	O
and	O
a	O
single	O
probing	O
framework	O
,	O
the	O
influence	O
of	O
linguistic	O
formalism	O
per	O
se	O
is	O
likely	O
to	O
be	O
present	O
for	O
any	O
probing	O
setup	O
that	O
builds	O
upon	O
linguistic	O
material	O
.	O
An	O
investigation	O
of	O
how	O
,	O
whether	O
,	O
and	O
why	O
formalisms	O
and	O
their	O
implementations	O
affect	O
probing	O
results	O
for	O
tasks	O
beyond	O
role	O
labeling	O
and	O
for	O
frameworks	O
beyond	O
edge	O
probing	O
constitutes	O
an	O
exciting	O
avenue	O
for	O
future	O
research	O
.	O

Acknowledgments	O

This	O
work	O
has	O
been	O
funded	O
by	O
the	O
LOEWE	O
initiative	O
(	O
Hesse	O
,	O
Germany	O
)	O
within	O
the	O
emergenCITY	O
center	O
.	O

Pre	O
-	O
Training	O
Transformers	O
as	O
Energy	O
-	O
Based	O
Cloze	O
Models	O

We	O
introduce	O
Electric	O
,	O
an	O
energy	O
-	O
based	O
cloze	O
model	O
for	O
representation	O
learning	O
over	O
text	O
.	O
Like	O
BERT	O
,	O
it	O
is	O
a	O
conditional	O
generative	O
model	O
of	O
tokens	O
given	O
their	O
contexts	O
.	O
However	O
,	O
Electric	O
does	O
not	O
use	O
masking	O
or	O
output	O
a	O
full	O
distribution	O
over	O
tokens	O
that	O
could	O
occur	O
in	O
a	O
context	O
.	O
Instead	O
,	O
it	O
assigns	O
a	O
scalar	O
energy	O
score	O
to	O
each	O
input	O
token	O
indicating	O
how	O
likely	O
it	O
is	O
given	O
its	O
context	O
.	O
We	O
train	O
Electric	O
using	O
an	O
algorithm	O
based	O
on	O
noise	O
-	O
contrastive	O
estimation	O
and	O
elucidate	O
how	O
this	O
learning	O
objective	O
is	O
closely	O
related	O
to	O
the	O
recently	O
proposed	O
ELECTRA	O
pre	O
-	O
training	O
method	O
.	O
Electric	O
performs	O
well	O
when	O
transferred	O
to	O
downstream	O
tasks	O
and	O
is	O
particularly	O
effective	O
at	O
producing	O
likelihood	O
scores	O
for	O
text	O
:	O
it	O
reranks	O
speech	O
recognition	O
n	O
-	O
best	O
lists	O
better	O
than	O
language	O
models	O
and	O
much	O
faster	O
than	O
masked	O
language	O
models	O
.	O
Furthermore	O
,	O
it	O
offers	O
a	O
clearer	O
and	O
more	O
principled	O
view	O
of	O
what	O
ELECTRA	O
learns	O
during	O
pre	O
-	O
training	O
.	O

Introduction	O

The	O
cloze	O
task	O
(	O
Taylor	O
,	O
1953	O
)	O
of	O
predicting	O
the	O
identity	O
of	O
a	O
token	O
given	O
its	O
surrounding	O
context	O
has	O
proven	O
highly	O
effective	O
for	O
representation	O
learning	O
over	O
text	O
.	O
BERT	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
implements	O
the	O
cloze	O
task	O
by	O
replacing	O
input	O
tokens	O
with	O
[	O
MASK	O
]	O
,	O
but	O
this	O
approach	O
incurs	O
drawbacks	O
in	O
efficiency	O
(	O
only	O
15	O
%	O
of	O
tokens	O
are	O
masked	O
out	O
at	O
a	O
time	O
)	O
and	O
introduces	O
a	O
pre	O
-	O
train	O
/	O
fine	O
-	O
tune	O
mismatch	O
where	O
BERT	O
sees	O
[	O
MASK	O
]	O
tokens	O
in	O
training	O
but	O
not	O
in	O
fine	O
-	O
tuning	O
.	O
ELECTRA	O
(	O
Clark	O
et	O
al	O
.	O
,	O
2020	O
)	O
uses	O
a	O
different	O
pre	O
-	O
training	O
task	O
that	O
alleviates	O
these	O
disadvantages	O
.	O
Instead	O
of	O
masking	O
tokens	O
,	O
ELECTRA	O
replaces	O
some	O
input	O
tokens	O
with	O
fakes	O
sampled	O
from	O
a	O
small	O
generator	O
network	O
.	O
The	O
pre	O
-	O
training	O
task	O
is	O
then	O
to	O
distinguish	O
the	O
original	O
vs.	O
replaced	O
tokens	O
.	O
While	O
on	O
the	O
surface	O
it	O
appears	O
quite	O
different	O
from	O
BERT	O
,	O
in	O
this	O
paper	O
we	O
elucidate	O
a	O
close	O
connection	O
between	O
ELECTRA	O
and	O
cloze	O
modeling	O
.	O
In	O
particular	O
,	O
we	O
develop	O
a	O
new	O
way	O
of	O
implementing	O
the	O
cloze	O
task	O
using	O
an	O
energy	O
-	O
based	O
model	O
(	O
EBM	O
)	O
.	O
Then	O
we	O
show	O
the	O
resulting	O
model	O
,	O
which	O
we	O
call	O
Electric	O
,	O
is	O
closely	O
related	O
to	O
ELECTRA	O
,	O
as	O
well	O
as	O
being	O
useful	O
in	O
its	O
own	O
right	O
for	O
some	O
applications	O
.	O
1	O
EBMs	O
learn	O
an	O
energy	O
function	O
that	O
assigns	O
low	O
energy	O
values	O
to	O
inputs	O
in	O
the	O
data	O
distribution	O
and	O
high	O
energy	O
values	O
to	O
other	O
inputs	O
.	O
They	O
are	O
flexible	O
because	O
they	O
do	O
not	O
have	O
to	O
compute	O
normalized	O
probabilities	O
.	O
For	O
example	O
,	O
Electric	O
does	O
not	O
use	O
masking	O
or	O
an	O
output	O
softmax	O
,	O
instead	O
producing	O
a	O
scalar	O
energy	O
score	O
for	O
each	O
token	O
where	O
a	O
low	O
energy	O
indicates	O
the	O
token	O
is	O
likely	O
given	O
its	O
context	O
.	O
Unlike	O
with	O
BERT	O
,	O
these	O
likelihood	O
scores	O
can	O
be	O
computed	O
simultaneously	O
for	O
all	O
input	O
tokens	O
rather	O
than	O
only	O
for	O
a	O
small	O
masked	O
-	O
out	O
subset	O
.	O
We	O
propose	O
a	O
training	O
algorithm	O
for	O
Electric	O
that	O
efficiently	O
approximates	O
a	O
loss	O
based	O
on	O
noise	O
-	O
contrastive	O
estimation	O
(	O
Gutmann	O
and	O
Hyvärinen	O
,	O
2010	O
)	O
.	O
Then	O
we	O
show	O
that	O
this	O
training	O
algorithm	O
is	O
closely	O
related	O
to	O
ELECTRA	O
;	O
in	O
fact	O
,	O
ELECTRA	O
can	O
be	O
viewed	O
as	O
a	O
variant	O
of	O
Electric	O
using	O
negative	O
sampling	O
instead	O
of	O
noise	O
-	O
contrastive	O
estimation	O
.	O

We	O
evaluate	O
Electric	O
on	O
GLUE	O
and	O
SQuAD	O
(	O
Rajpurkar	O
et	O
al	O
.	O
,	O
2016	O
)	O
,	O
where	O
Electric	O
substantially	O
outperforms	O
BERT	O
but	O
slightly	O
under	O
-	O
performs	O
ELECTRA	O
.	O
However	O
,	O
Electric	O
is	O
particularly	O
useful	O
in	O
its	O
ability	O
to	O
efficiently	O
produce	O
pseudo	O
-	O
likelihood	O
scores	O
(	O
Salazar	O
et	O
al	O
.	O
,	O
2020	O
)	O
for	O
text	O
:	O
Electric	O
is	O
better	O
at	O
re	O
-	O
ranking	O
the	O
outputs	O
of	O
a	O
speech	O
recognition	O
system	O
than	O
GPT-2	O
(	O
Radford	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
is	O
much	O
faster	O
at	O
re	O
-	O
ranking	O
than	O
BERT	O
because	O
it	O
scores	O
all	O
input	O
tokens	O
simultaneously	O
rather	O
than	O
having	O
to	O
be	O
run	O
multiple	O
times	O
with	O
different	O
tokens	O
masked	O
out	O
.	O
In	O
total	O
,	O
investigating	O
Electric	O
leads	O
to	O
a	O
more	O
principled	O
understanding	O
of	O
ELECTRA	O
and	O
our	O
results	O
suggest	O
that	O
EBMs	O
are	O
a	O
promising	O
alternative	O
to	O
the	O
standard	O
generative	O
models	O
currently	O
used	O
for	O
language	O
representation	O
learning	O
.	O

Method	O

BERT	O
and	O
related	O
pre	O
-	O
training	O
methods	O
(	O
Baevski	O
et	O
al	O
.	O
,	O
2019;Lan	O
et	O
al	O
.	O
,	O
2020	O
)	O
train	O
a	O
large	O
neural	O
network	O
to	O
perform	O
the	O
cloze	O
task	O
.	O
These	O
models	O
learn	O
the	O
probability	O
p	O
data	O
(	O
x	O
t	O
|x	O
\t	O
)	O
of	O
a	O
token	O
x	O
t	O
occurring	O
in	O
the	O
surrounding	O
context	O

x	O
\t	O
=	O
[	O
x	O
1	O
,	O
...	O
,	O
x	O
t−1	O
,	O
x	O
t+1	O
,	O
...	O
,	O
x	O
n	O
]	O
.	O

Typically	O
the	O
context	O
is	O
represented	O
as	O
the	O
input	O
sequence	O
with	O
x	O
t	O
replaced	O
by	O
a	O
special	O
[	O
MASK]placeholder	O
token	O
.	O
This	O
masked	O
sequence	O
is	O
encoded	O
into	O
vector	O
representations	O
by	O
a	O
transformer	O
network	O
(	O
Vaswani	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
Then	O
the	O
representation	O
at	O
position	O
t	O
is	O
passed	O
into	O
a	O
softmax	O
layer	O
to	O
produce	O
a	O
distribution	O
over	O
tokens	O
p	O
θ	O
(	O
x	O
t	O
|x	O
\t	O
)	O
for	O
the	O
position	O
.	O

The	O
Electric	O
Model	O

Electric	O
also	O
models	O
p	O
data	O
(	O
x	O
t	O
|x	O
\t	O
)	O
,	O
but	O
does	O
not	O
use	O
masking	O
or	O
a	O
softmax	O
layer	O
.	O
Electric	O
first	O
maps	O
the	O
unmasked	O
input	O
x	O
=	O
[	O
x	O
1	O
,	O
...	O
,	O
x	O
n	O
]	O
into	O
contextualized	O
vector	O
representations	O
h(x	O
)	O
=	O
[	O
h	O
1	O
,	O
...	O
,	O
h	O
n	O
]	O
using	O
a	O
transformer	O
network	O
.	O
The	O
model	O
assigns	O
a	O
given	O
position	O
t	O
an	O
energy	O
score	O
E(x	O
)	O
t	O
=	O
w	O
T	O
h(x	O
)	O
t	O
using	O
a	O
learned	O
weight	O
vector	O
w.	O
The	O
energy	O
function	O
defines	O
a	O
distribution	O
over	O
the	O
possible	O
tokens	O
at	O
position	O
t	O
as	O

p	O
θ	O
(	O
x	O
t	O
|x	O
\t	O
)	O
=	O
exp	O
(	O
−E(x	O
)	O
t	O
)	O
/Z(x	O
\t	O
)	O
=	O
exp	O
(	O
−E(x	O
)	O
t	O
)	O
x	O
∈V	O
exp	O
(	O
−E(REPLACE(x	O
,	O
t	O
,	O
x	O
)	O
)	O
t	O
)	O

where	O
REPLACE(x	O
,	O
t	O
,	O
x	O
)	O
denotes	O
replacing	O
the	O
token	O
at	O
position	O
t	O
with	O
x	O
and	O
V	O
is	O
the	O
vocabulary	O
,	O
in	O
practice	O
usually	O
word	O
pieces	O
(	O
Sennrich	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
Unlike	O
with	O
BERT	O
,	O
which	O
produces	O
the	O
probabilities	O
for	O
all	O
possible	O
tokens	O
x	O
using	O
a	O
softmax	O
layer	O
,	O
a	O
candidate	O
x	O
is	O
passed	O
in	O
as	O
input	O
to	O
the	O
transformer	O
.	O
As	O
a	O
result	O
,	O
computing	O
p	O
θ	O
is	O
prohibitively	O
expensive	O
because	O
the	O
partition	O
function	O
Z	O
θ	O
(	O
x	O
\t	O
)	O
requires	O
running	O
the	O
transformer	O
|V|	O
times	O
;	O
unlike	O
most	O
EBMs	O
,	O
the	O
intractability	O
of	O
Z	O
θ	O
(	O
x	O
\t	O
)	O
is	O
due	O
to	O
the	O
expensive	O
scoring	O
function	O
rather	O
than	O
having	O
a	O
large	O
sample	O
space	O
.	O

As	O
computing	O
the	O
exact	O
likelihood	O
is	O
intractable	O
,	O
training	O
energy	O
-	O
based	O
models	O
such	O
as	O
Electric	O
with	O
standard	O
maximum	O
-	O
likelihood	O
estimation	O
is	O
not	O
possible	O
.	O
Instead	O
,	O
we	O
use	O
(	O
conditional	O
)	O
Noise	O
-	O
Contrastive	O
Estimation	O
(	O
NCE	O
)	O
(	O
Gutmann	O
and	O
Hyvärinen	O
,	O
2010;Ma	O
and	O
Collins	O
,	O
2018	O
)	O
,	O
which	O
provides	O
a	O
way	O
of	O
efficiently	O
training	O
an	O
unnormalized	O
model	O
that	O
does	O
not	O
compute	O
Z	O
θ	O
(	O
x	O
\t	O
)	O
.	O
NCE	O
learns	O
the	O
parameters	O
of	O
a	O
model	O
by	O
defining	O
a	O
binary	O
classification	O
task	O
where	O
samples	O
from	O
the	O
data	O
distribution	O
have	O
to	O
be	O
distinguished	O
from	O
samples	O
generated	O
by	O
a	O
noise	O
distribution	O
q(x	O
t	O
|x	O
\t	O
)	O
.	O
First	O
,	O
we	O
define	O
the	O
un	O
-	O
normalized	O
output	O
p	O
θ	O
(	O
x	O
t	O
|x	O
\t	O
)	O
=	O
exp	O
(	O
−E(x	O
)	O
t	O
)	O

Operationally	O
,	O
NCE	O
can	O
be	O
viewed	O
as	O
follows	O
:	O

•	O
A	O
positive	O
data	O
point	O
is	O
a	O
text	O
sequence	O
x	O
from	O
the	O
data	O
and	O
position	O
in	O
the	O
sequence	O
t.	O

•	O
A	O
negative	O
data	O
point	O
is	O
the	O
same	O
except	O
x	O
t	O
,	O
the	O
token	O
at	O
position	O
t	O
,	O
is	O
replaced	O
with	O
a	O
noise	O
tokenx	O
t	O
sampled	O
from	O
q.	O

•	O
Define	O
a	O
binary	O
classifier	O
D	O
that	O
estimates	O
the	O
probability	O
of	O
a	O
data	O
point	O
being	O
positive	O
as	O

n	O
•p	O
θ	O
(	O
x	O
t	O
|x	O
\t	O
)	O
n	O
•p	O
θ	O
(	O
x	O
t	O
|x	O
\t	O
)	O
+	O
k	O
•	O
q(x	O
t	O
|x	O
\t	O
)	O

•	O
The	O
binary	O
classifier	O
is	O
trained	O
to	O
distinguish	O
positive	O
vs	O
negative	O
data	O
points	O
,	O
with	O
k	O
negatives	O
sampled	O
for	O
every	O
n	O
positive	O
data	O
points	O
.	O

Formally	O
,	O
the	O
NCE	O
loss	O
L(θ	O
)	O
is	O

n	O
•	O
E	O
x	O
,	O
t	O
−	O
log	O
n	O
•p	O
θ	O
(	O
x	O
t	O
|x	O
\t	O
)	O
n	O
•p	O
θ	O
(	O
x	O
t	O
|x	O
\t	O
)	O
+	O
k	O
•	O
q(x	O
t	O
|x	O
\t	O
)	O
+	O
k	O
•	O
E	O
x	O
,	O
t	O
xt∼q	O
−	O
log	O
k	O
•	O
q(x	O
t	O
|x	O
\t	O
)	O
n	O
•p	O
θ	O
(	O
x	O
t	O
|x	O
\t	O
)	O
+	O
k	O
•	O
q(x	O
t	O
|x	O
\t	O
)	O

This	O
loss	O
is	O
minimized	O
whenp	O
θ	O
matches	O
the	O
data	O
distribution	O
p	O
data	O
(	O
Gutmann	O
and	O
Hyvärinen	O
,	O
2010	O
)	O
.	O
A	O
consequence	O
of	O
this	O
property	O
is	O
that	O
the	O
model	O
learns	O
to	O
be	O
self	O
-	O
normalized	O
such	O
that	O
Z	O
θ	O
(	O
x	O
\t	O
)	O
=	O
1	O
.	O

Training	O
Algorithm	O

To	O
minimize	O
the	O
loss	O
,	O
the	O
expectations	O
could	O
be	O
approximated	O
by	O
sampling	O
as	O
shown	O
in	O
Algorithm	O
1	O
.	O
Taking	O
the	O
gradient	O
of	O
this	O
estimated	O
loss	O
produces	O
Algorithm	O
1	O
Naive	O
NCE	O
loss	O
estimation	O
Given	O
:	O
Input	O
sequence	O
x	O
,	O
number	O
of	O
negative	O
samples	O
k	O
,	O
noise	O
distribution	O
q	O
,	O
modelp	O
θ	O
.	O

1	O
.	O
Initialize	O
the	O
loss	O
as	O

n	O
t=1	O
−	O
log	O
n•p	O
θ	O
(	O
xt|x	O
\t	O
)	O
n•p	O
θ	O
(	O
xt|x	O
\t	O
)	O
+	O
k•q(xt|x	O
\t	O
)	O
.	O
2	O
.	O
Sample	O
k	O
negative	O
samples	O
according	O
to	O
t	O
∼	O
unif{1	O
,	O
n},x	O
t	O
∼	O
q(x	O
t	O
|x	O
\t	O
)	O
.	O
3	O
.	O
For	O
each	O
negative	O
sample	O
,	O
add	O
to	O
the	O
loss	O
−	O
log	O
k•q(xt|x	O
\t	O
)	O
n•p	O
θ	O
(	O
xt|x	O
\t	O
)	O
+	O
k•q(xt|x	O
\t	O
)	O
.	O

an	O
unbiased	O
estimate	O
of	O
∇	O
θ	O
L(θ	O
)	O
.	O
However	O
,	O
this	O
algorithm	O
is	O
computationally	O
expensive	O
to	O
run	O
,	O
since	O
it	O
requires	O
k	O
+	O
1	O
forward	O
passes	O
through	O
the	O
transformer	O
to	O
compute	O
thep	O
θ	O
s	O
(	O
once	O
for	O
the	O
positive	O
samples	O
and	O
once	O
for	O
each	O
negative	O
sample	O
)	O
.	O
We	O
propose	O
a	O
much	O
more	O
efficient	O
approach	O
that	O
replaces	O
k	O
input	O
tokens	O
with	O
noise	O
samples	O
simultaneously	O
shown	O
in	O
Algorithm	O
2	O
.	O
It	O
requires	O
just	O

Algorithm	O
2	O
Efficient	O
NCE	O
loss	O
estimation	O

Given	O
:	O
Input	O
sequence	O
x	O
,	O
number	O
of	O
negative	O
samples	O
k	O
,	O
noise	O
distribution	O
q	O
,	O
modelp	O
θ	O
.	O
1	O
.	O
Pick	O
k	O
unique	O
random	O
positions	O
R	O
=	O
{	O
r	O
1	O
,	O
...	O
,	O
r	O
k	O
}	O
where	O
each	O
r	O
i	O
is	O
1	O
≤	O
r	O
i	O
≤	O
n.	O

2	O
.	O
Replace	O
the	O
k	O
random	O
positions	O
with	O
negative	O
samples	O
:	O

x	O
i	O
∼	O
q(x	O
i	O
|x	O
\i	O
)	O
for	O
i	O
∈	O
R	O
,	O
x	O
noised	O
=	O
REPLACE(x	O
,	O
R	O
,	O
X	O
)	O
.	O
3	O
.	O

For	O
each	O
position	O
t	O
=	O
1	O
to	O
n	O
:	O
add	O
to	O
the	O
loss	O
−	O
log	O

k•q(xt|x	O
\t	O
)	O
(	O
n−k)•p	O
θ	O
(	O
xt|x	O
noised	O
\t	O
)	O
+	O
k•q(xt|x	O
\t	O
)	O
if	O
t	O
∈	O
R	O
−	O
log	O
(	O
n−k)•p	O
θ	O
(	O
xt|x	O
noised	O
\t	O
)	O
(	O
n−k)•p	O
θ	O
(	O
xt|x	O
noised	O
\t	O
)	O
+	O
k•q(xt|x	O
\t	O
)	O
otherwise	O

one	O
pass	O
through	O
the	O
transformer	O
for	O
k	O
noise	O
samples	O
and	O
n	O
−	O
k	O
data	O
samples	O
.	O
However	O
,	O
this	O
procedure	O
only	O
truly	O
minimizes	O
L	O
ifp	O
θ	O
(	O
x	O
t	O
|x	O
\t	O
)	O
=	O
p	O
θ	O
(	O
x	O
t	O
|x	O
noised	O
\t	O
)	O
.	O
To	O
apply	O
this	O
efficiency	O
trick	O
we	O
are	O
making	O
the	O
assumption	O
they	O
are	O
approximately	O
equal	O
,	O
which	O
we	O
argue	O
is	O
reasonable	O
because	O
(	O
1	O
)	O
we	O
choose	O
a	O
small	O
k	O
of	O
0.15n	O
and	O
(	O
2	O
)	O
q	O
is	O
trained	O
to	O
be	O
close	O
to	O
the	O
data	O
distribution	O
(	O
see	O
below	O
)	O
.	O
This	O
efficiency	O
trick	O
is	O
analogous	O
to	O
BERT	O
masking	O
out	O
multiple	O
tokens	O
per	O
input	O
sequence	O
.	O

Noise	O
Distribution	O

The	O
noise	O
distribution	O
q	O
comes	O
from	O
a	O
neural	O
network	O
trained	O
to	O
match	O
p	O
data	O
.	O
NCE	O
commonly	O
employs	O
this	O
idea	O
to	O
ensure	O
the	O
classification	O
task	O
is	O
sufficiently	O
challenging	O
for	O
the	O
model	O
(	O
Gutmann	O
and	O
Hyvärinen	O
,	O
2010;Wang	O
and	O
Ou	O
,	O
2018	O
)	O
.	O
In	O
particular	O
,	O
we	O
use	O
a	O
two	O
-	O
tower	O
cloze	O
model	O
as	O
proposed	O
by	O
Baevski	O
et	O
al	O
.	O
(	O
2019	O
)	O
,	O
which	O
is	O
more	O
accurate	O
than	O
a	O
language	O
model	O
because	O
it	O
uses	O
context	O
to	O
both	O
sides	O
of	O
each	O
token	O
.	O
The	O
model	O
runs	O
two	O
transformers	O
T	O
LTR	O
and	O
T	O
RTL	O
over	O
the	O
input	O
sequence	O
.	O
These	O
transformers	O
apply	O
causal	O
masking	O
so	O
one	O
processes	O
the	O
sequence	O
left	O
-	O
to	O
-	O
right	O
and	O
the	O
other	O
operates	O
right	O
-	O
to	O
-	O
left	O
.	O
The	O
model	O
's	O
predictions	O
come	O
from	O
a	O
softmax	O
layer	O
applied	O
to	O
the	O
concatenated	O
states	O
of	O
the	O
two	O
transformers	O
:	O

−	O
→	O
h	O
=	O
T	O
LTR	O
(	O
x	O
)	O
,	O
←	O
−	O
h	O
=	O
T	O
RTL	O
(	O
x	O
)	O
q(x	O
t	O
|x	O
\t	O
)	O
=	O
softmax(W	O
[	O
−	O
→	O
h	O
t−1	O
,	O
←	O
−	O
h	O
t+1	O
]	O
)	O
xt	O

The	O
noise	O
distribution	O
is	O
trained	O
simultaneously	O
with	O
Electric	O
using	O
standard	O
maximum	O
likelihood	O
estimation	O
over	O
the	O
data	O
.	O
The	O
model	O
producing	O
the	O
noise	O
distribution	O
is	O
much	O
smaller	O
than	O
Electric	O
to	O
reduce	O
the	O
computational	O
overhead	O
.	O

Connection	O
to	O
ELECTRA	O

Electric	O
is	O
closely	O
related	O
to	O
the	O
ELECTRA	O
pretraining	O
method	O
.	O
ELECTRA	O
also	O
trains	O
a	O
binary	O
classifier	O
(	O
the	O
"	O
discriminator	O
"	O
)	O
to	O
distinguish	O
data	O
tokens	O
from	O
noise	O
tokens	O
produced	O
by	O
a	O
"	O
generator	O
"	O
network	O
.	O
However	O
,	O
ELECTRA	O
's	O
classifier	O
is	O
simply	O
a	O
sigmoid	O
layer	O
on	O
top	O
of	O
the	O
transformer	O
:	O
it	O
models	O
the	O
probability	O
of	O
a	O
token	O
being	O
negative	O
(	O
i.e.	O
,	O
as	O
replaced	O
by	O
a	O
noise	O
sample	O
)	O
as	O
σ(E(x	O
)	O
t	O
)	O
where	O
σ	O
denotes	O
the	O
sigmoid	O
function	O
.	O
Electric	O
on	O
the	O
other	O
hand	O
models	O
this	O
probability	O
as	O

k	O
•	O
q(x|x	O
\t	O
)	O
n	O
•	O
exp	O
(	O
−E(x	O
)	O
t	O
)	O
+	O
k	O
•	O
q(x|x	O
\t	O
)	O
=	O
σ	O
E(x	O
)	O
t	O
+	O
log	O
k	O
•	O
q(x|x	O
\t	O
)	O
n	O

While	O
ELECTRA	O
learns	O
whether	O
a	O
token	O
is	O
more	O
likely	O
to	O
come	O
from	O
the	O
data	O
distribution	O
p	O
data	O
or	O
noise	O
distribution	O
q	O
,	O
Electric	O
only	O
learns	O
p	O
data	O
because	O
q	O
is	O
passed	O
into	O
the	O
model	O
directly	O
.	O
This	O
difference	O
is	O
analogous	O
to	O
using	O
negative	O
sampling	O
(	O
Mikolov	O
et	O
al	O
.	O
,	O
2013	O
)	O
vs.	O
noise	O
-	O
contrastive	O
estimation	O
(	O
Mnih	O
and	O
Kavukcuoglu	O
,	O
2013	O
)	O
for	O
learning	O
word	O
embeddings	O
.	O
A	O
disadvantage	O
of	O
Electric	O
compared	O
to	O
ELEC	O
-	O
TRA	O
is	O
that	O
it	O
is	O
less	O
flexible	O
in	O
the	O
choice	O
of	O
noise	O
distribution	O
.	O
Since	O
ELECTRA	O
's	O
binary	O
classifier	O
does	O
not	O
need	O
to	O
access	O
q	O
,	O
its	O
q	O
only	O
needs	O
to	O
be	O
defined	O
for	O
negative	O
sample	O
positions	O
in	O
the	O
input	O
sequence	O
.	O
Therefore	O
ELECTRA	O
can	O
use	O
a	O
masked	O
language	O
model	O
rather	O
than	O
a	O
two	O
-	O
tower	O
cloze	O
model	O
for	O
q.	O
An	O
advantage	O
of	O
Electric	O
is	O
that	O
it	O
directly	O
provides	O
(	O
un	O
-	O
normalized	O
)	O
probabilitieŝ	O
p	O
θ	O
for	O
tokens	O
,	O
making	O
it	O
useful	O
for	O
applications	O
such	O
as	O
re	O
-	O
ranking	O
the	O
outputs	O
of	O
text	O
generation	O
systems	O
.	O
The	O
differences	O
between	O
ELECTRA	O
and	O
Electric	O
are	O
summarized	O
below	O
:	O

Model	O
Noise	O
Dist	O
.	O
Binary	O
Classifier	O
Electric	O
Two	O
-	O
Tower	O
Cloze	O
Model	O
σ	O
E(x)t	O
+	O
log	O
k•q(x|x	O
\t	O
)	O
n	O
ELECTRA	O
Masked	O
LM	O
σ(E(x)t	O
)	O

Experiments	O

We	O
train	O
two	O
Electric	O
models	O
the	O
same	O
size	O
as	O
BERT	O
-	O
Base	O
(	O
110	O
M	O
parameters	O
):	O
one	O
on	O
Wikipedia	O
and	O
BooksCorpus	O
(	O
Zhu	O
et	O
al	O
.	O
,	O
2015	O
)	O
for	O
comparison	O
with	O
BERT	O
and	O
one	O
on	O
OpenWebTextCorpus	O
(	O
Gokaslan	O
and	O
Cohen	O
,	O
2019	O
)	O
for	O
comparison	O
2	O
with	O
GPT-2	O
.	O
The	O
noise	O
distribution	O
transformers	O
T	O
LTR	O
and	O
T	O
RTL	O
are	O
1/4	O
the	O
hidden	O
size	O
of	O
Electric	O
.	O
We	O
do	O
no	O
hyperparameter	O
tuning	O
,	O
using	O
the	O
same	O
hyperparameter	O
values	O
as	O
ELECTRA	O
.	O
Further	O
details	O
on	O
training	O
are	O
in	O
the	O
appendix	O
.	O

Transfer	O
to	O
Downstream	O
Tasks	O

We	O
evaluate	O
fine	O
-	O
tuning	O
the	O
Electric	O
model	O
on	O
the	O
GLUE	O
natural	O
language	O
understanding	O
benchmark	O
and	O
the	O
SQuAD	O
2.0	O
question	O
answering	O
dataset	O
(	O
Rajpurkar	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
We	O
report	O
exact	O
-	O
match	O
for	O
SQuAD	O
,	O
average	O
score	O
3	O
over	O
the	O
GLUE	O
tasks	O
4	O
,	O
and	O
accuracy	O
on	O
the	O
multi	O
-	O
genre	O
natural	O
language	O
inference	O
GLUE	O
task	O
.	O
Reported	O
scores	O
are	O
medians	O
over	O
10	O
fine	O
-	O
tuning	O
runs	O
with	O
different	O
random	O
seeds	O
.	O
We	O
use	O
the	O
same	O
finetuning	O
setup	O
and	O
hyperparameters	O
as	O
ELECTRA	O
.	O

Results	O
are	O
shown	O
in	O
Table	O
1	O
.	O
Electric	O
scores	O
better	O
than	O
BERT	O
,	O
showing	O
the	O
energy	O
-	O
based	O
formulation	O
improves	O
cloze	O
model	O
pre	O
-	O
training	O
.	O
However	O
,	O
Electric	O
scores	O
slightly	O
lower	O
than	O
ELECTRA	O
.	O
One	O
possible	O
explanation	O
is	O
that	O
Electric	O
's	O
noise	O
distribution	O
is	O
worse	O
because	O
a	O
two	O
-	O
tower	O
cloze	O
model	O
is	O
less	O
expressive	O
than	O
a	O
masked	O
LM	O
.	O
We	O
tested	O
this	O
hypothesis	O
by	O
training	O
ELECTRA	O
with	O
the	O
same	O
two	O
-	O
tower	O
noise	O
model	O
as	O
Electric	O
.	O
Performance	O
did	O
indeed	O
go	O
down	O
,	O
but	O
it	O
only	O
explained	O
about	O
half	O
the	O
gap	O
.	O
The	O
surprising	O
drop	O
in	O
performance	O
suggests	O
that	O
learning	O
the	O
difference	O
between	O
the	O
data	O
and	O
generations	O
from	O
a	O
low	O
-	O
capacity	O
model	O
leads	O
to	O
better	O
representations	O
than	O
only	O
learning	O
the	O
data	O
distribution	O
,	O
but	O
we	O
believe	O
further	O
research	O
is	O
needed	O
to	O
fully	O
understand	O
the	O
discrepancy	O
.	O

Fast	O
Pseudo	O
-	O
Log	O
-	O
Likelihood	O
Scoring	O

An	O
advantage	O
of	O
Electric	O
over	O
BERT	O
is	O
that	O
it	O
can	O
efficiently	O
produce	O
pseudo	O
-	O
log	O
-	O
likelihood	O
(	O
PLL	O
)	O
scores	O
for	O
text	O
(	O
Wang	O
and	O
Cho	O
,	O
2019	O
)	O
.	O
PLLs	O
for	O
Electric	O
are	O

PLL(x	O
)	O
=	O
n	O
t=1	O
log(p	O
θ	O
(	O
x	O
t	O
|x	O
\t	O
)	O
)	O
=	O
n	O
t=1	O
−E(x	O
)	O
t	O

PLLs	O
can	O
be	O
used	O
to	O
re	O
-	O
rank	O
the	O
outputs	O
of	O
an	O
NMT	O
or	O
ASR	O
system	O
.	O
While	O
historically	O
log	O
-	O
likelihoods	O
from	O
language	O
models	O
have	O
been	O
used	O
for	O
such	O
reranking	O
,	O
recent	O
work	O
has	O
demonstrated	O
that	O
PLLs	O
from	O
masked	O
language	O
models	O
perform	O
better	O
(	O
Shin	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
However	O
,	O
computing	O
PLLs	O
from	O
a	O
masked	O
language	O
model	O
requires	O
n	O
passes	O
of	O
the	O
transformer	O
:	O
once	O
with	O
each	O
token	O
masked	O
out	O
.	O
Salazar	O
et	O
al	O
.	O
(	O
2020	O
)	O
suggest	O
distilling	O
BERT	O
into	O
a	O
model	O
that	O
uses	O
no	O
masking	O
to	O
avoid	O
this	O
cost	O
,	O
but	O
this	O
model	O
considerably	O
under	O
-	O
performed	O
regular	O
LMs	O
in	O
their	O
experiments	O
.	O

Electric	O
can	O
produce	O
PLLs	O
for	O
all	O
input	O
tokens	O
in	O
a	O
single	O
pass	O
like	O
a	O
LM	O
while	O
being	O
bidirectional	O
like	O
a	O
masked	O
LM	O
.	O
We	O
use	O
the	O
PLLs	O
from	O
Electric	O
for	O
re	O
-	O
ranking	O
the	O
100	O
-	O
best	O
hypotheses	O
of	O
a	O
5	O
-	O
layer	O
BLSTMP	O
model	O
from	O
ESPnet	O
(	O
Watanabe	O
et	O
al	O
.	O
,	O
2018	O
)	O
on	O
the	O
960	O
-	O
hour	O
LibriSpeech	O
corpus	O
(	O
Panayotov	O
et	O
al	O
.	O
,	O
2015	O
)	O
following	O
the	O
same	O
experimental	O
setup	O
and	O
using	O
the	O
same	O
n	O
-	O
best	O
lists	O
as	O
Salazar	O
et	O
al	O
.	O
(	O
2020	O
)	O
.	O
Given	O
speech	O
features	O
s	O
and	O
speech	O
recognition	O
model	O
f	O
the	O
re	O
-	O
ranked	O
output	O
is	O
arg	O
max	O

x∈n	O
-	O
best(f	O
,	O
s	O
)	O
f	O
(	O
x|s	O
)	O
+	O
λPLL(x	O
)	O

where	O
n	O
-	O
best(f	O
,	O
s	O
)	O
consists	O
of	O
the	O
top	O
n	O
(	O
we	O
use	O
n	O
=	O
100	O
)	O
predictions	O
from	O
the	O
speech	O
recognition	O
model	O
found	O
with	O
beam	O
search	O
,	O
f	O
(	O
x|s	O
)	O
is	O
the	O
score	O
the	O
speech	O
model	O
assigns	O
the	O
candidate	O
output	O
sequence	O
x.	O
We	O
select	O
the	O
best	O
λ	O
on	O
the	O
dev	O
set	O
out	O
of	O
[	O
0.05	O
,	O
0.1	O
,	O
...	O
,	O
0.95	O
,	O
1.0	O
]	O
,	O
with	O
different	O
λs	O
selected	O
for	O
the	O
"	O
clean	O
"	O
and	O
"	O
other	O
"	O
portions	O
of	O
the	O
data	O
.	O

We	O
compare	O
Electric	O
against	O
GPT-2	O
(	O
Radford	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
BERT	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
and	O
two	O
baseline	O
systems	O
that	O
are	O
bidirectional	O
while	O
only	O
requiring	O
a	O
single	O
transformer	O
pass	O
like	O
Electric	O
.	O
TwoTower	O
is	O
a	O
two	O
-	O
tower	O
cloze	O
model	O
similar	O
to	O
Electric	O
's	O
noise	O
distribution	O
,	O
but	O
of	O
the	O
same	O
size	O
as	O
Electric	O
.	O
ELECTRA	O
-	O
TT	O
is	O
identical	O
to	O
ELECTRA	O
except	O
it	O
uses	O
a	O
two	O
-	O
tower	O
noise	O
distribution	O
rather	O
than	O
a	O
masked	O
language	O
model	O
.	O
5	O
The	O
noise	O
distribution	O
probabilities	O
and	O
binary	O
classifiers	O
scores	O
of	O
ELECTRA	O
can	O
be	O
combined	O
to	O
assign	O
probabilities	O
for	O
tokens	O
as	O
shown	O
in	O
Appendix	O
G	O
of	O
the	O
ELECTRA	O
paper	O
.	O

Results	O
are	O
shown	O
in	O
Table	O
2	O
.	O
Electric	O
scores	O
better	O
than	O
GPT-2	O
when	O
trained	O
on	O
comparable	O
data	O
.	O
While	O
scoring	O
worse	O
than	O
BERT	O
,	O
Electric	O
is	O
much	O
faster	O
to	O
run	O
.	O
It	O
also	O
slightly	O
outperforms	O
ELECTRA	O
-	O
TT	O
,	O
which	O
is	O
consistent	O
with	O
the	O
finding	O
from	O
Labeau	O
and	O
Allauzen	O
(	O
2018	O
)	O
that	O
NCE	O
outperforms	O
negative	O
sampling	O
for	O
training	O
language	O
models	O
.	O
Furthermore	O
,	O
Electric	O
is	O
simpler	O
and	O
faster	O
than	O
ELETRA	O
-	O
TT	O
in	O
that	O
it	O
does	O
not	O
require	O
running	O
the	O
generator	O
to	O
produce	O
PLL	O
scores	O
.	O
TwoTower	O
scores	O
lower	O
than	O
Electric	O
,	O
presumably	O
because	O
it	O
is	O
not	O
a	O
"	O
deeply	O
"	O
bidirectional	O
model	O
and	O
instead	O
just	O
concatenates	O
forward	O
and	O
backward	O
hidden	O
states	O
.	O

Related	O
Work	O

Language	O
modeling	O
(	O
Dai	O
and	O
Le	O
,	O
2015;Radford	O
et	O
al	O
.	O
,	O
2018;Peters	O
et	O
al	O
.	O
,	O
2018	O
)	O
and	O
cloze	O
modeling	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019;Baevski	O
et	O
al	O
.	O
,	O
2019	O
;	O
have	O
proven	O
to	O
be	O
effective	O
pre	O
-	O
training	O
tasks	O
for	O
NLP	O
.	O
Unlike	O
Electric	O
,	O
these	O
methods	O
follow	O
the	O
standard	O
recipe	O
of	O
estimating	O
token	O
probabilities	O
with	O
an	O
output	O
softmax	O
and	O
using	O
maximumlikelihood	O
training	O
.	O

Energy	O
-	O
based	O
models	O
have	O
been	O
widely	O
explored	O
in	O
machine	O
learning	O
(	O
Dayan	O
et	O
al	O
.	O
,	O
1995	O
et	O
al	O
.	O
,	O
2007	O
)	O
.	O
While	O
many	O
training	O
methods	O
involve	O
sampling	O
from	O
the	O
EBM	O
using	O
gradientbased	O
MCMC	O
(	O
Du	O
and	O
Mordatch	O
,	O
2019	O
)	O
or	O
Gibbs	O
sampling	O
(	O
Hinton	O
,	O
2002	O
)	O
,	O
we	O
considered	O
these	O
approaches	O
too	O
slow	O
for	O
pre	O
-	O
training	O
because	O
they	O
require	O
multiple	O
passes	O
through	O
the	O
model	O
per	O
sample	O
.	O
We	O
instead	O
use	O
noise	O
-	O
contrastive	O
estimation	O
(	O
Gutmann	O
and	O
Hyvärinen	O
,	O
2010	O
)	O
,	O
which	O
has	O
widely	O
been	O
used	O
in	O
NLP	O
for	O
learning	O
word	O
vectors	O
(	O
Mnih	O
and	O
Kavukcuoglu	O
,	O
2013	O
)	O
and	O
text	O
generation	O
models	O
(	O
Jean	O
et	O
al	O
.	O
,	O
2014;Józefowicz	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
While	O
EBMs	O
have	O
previously	O
been	O
applied	O
to	O
leftto	O
-	O
right	O
(	O
Wang	O
et	O
al	O
.	O
,	O
2015	O
)	O
or	O
globally	O
normalized	O
(	O
Rosenfeld	O
et	O
al	O
.	O
,	O
2001;Deng	O
et	O
al	O
.	O
,	O
2020	O
)	O
text	O
generation	O
,	O
they	O
have	O
not	O
previously	O
been	O
applied	O
to	O
cloze	O
models	O
or	O
for	O
pre	O
-	O
training	O
NLP	O
models	O
.	O
Several	O
papers	O
have	O
pointed	O
out	O
the	O
connection	O
between	O
EBMs	O
and	O
GANs	O
(	O
Zhao	O
et	O
al	O
.	O
,	O
2016;Finn	O
et	O
al	O
.	O
,	O
2016	O
)	O
,	O
which	O
is	O
similar	O
to	O
the	O
Electric	O
/	O
ELECTRA	O
connection	O
.	O

Conclusion	O

We	O
have	O
developed	O
an	O
energy	O
-	O
based	O
cloze	O
model	O
we	O
call	O
Electric	O
and	O
designed	O
an	O
efficient	O
training	O
algorithm	O
for	O
Electric	O
based	O
on	O
noise	O
-	O
contrastive	O
estimation	O
.	O
Although	O
Electric	O
can	O
be	O
derived	O
solely	O
from	O
the	O
cloze	O
task	O
,	O
the	O
resulting	O
pre	O
-	O
training	O
method	O
is	O
closely	O
related	O
to	O
ELECTRA	O
's	O
GANlike	O
pre	O
-	O
training	O
algorithm	O
.	O
While	O
slightly	O
underperforming	O
ELECTRA	O
on	O
downstream	O
tasks	O
,	O
Electric	O
is	O
useful	O
for	O
its	O
ability	O
to	O
quickly	O
produce	O
pseudo	O
-	O
log	O
-	O
likelihood	O
scores	O
for	O
text	O
.	O
Furthermore	O
,	O
it	O
offers	O
a	O
clearer	O
and	O
more	O
principled	O
view	O
of	O
the	O
ELECTRA	O
objective	O
as	O
a	O
"	O
negative	O
sampling	O
"	O
version	O
of	O
cloze	O
pre	O
-	O
training	O
.	O

as	O
ELECTRA	O
's	O
(	O
Clark	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
which	O
adds	O
some	O
additional	O
ideas	O
from	O
on	O
top	O
of	O
the	O
BERT	O
codebase	O
,	O
such	O
as	O
dynamic	O
masking	O
and	O
removing	O
the	O
next	O
-	O
sentence	O
prediction	O
task	O
.	O
We	O
use	O
the	O
weight	O
sharing	O
trick	O
from	O
ELECTRA	O
,	O
where	O
the	O
transformers	O
producing	O
the	O
proposal	O
distribution	O
and	O
the	O
main	O
transformer	O
share	O
token	O
embeddings	O
.	O
We	O
do	O
not	O
use	O
whole	O
-	O
word	O
or	O
n	O
-	O
gram	O
masking	O
,	O
although	O
we	O
believe	O
it	O
would	O
improve	O
results	O
too	O
.	O
We	O
did	O
no	O
hyperparameter	O
tuning	O
,	O
directly	O
using	O
the	O
hyperparameters	O
from	O
ELECTRA	O
-	O
Base	O
for	O
Electric	O
and	O
our	O
baselines	O
.	O
These	O
hyperparameters	O
are	O
slightly	O
modified	O
from	O
the	O
ones	O
used	O
in	O
BERT	O
;	O
for	O
completeness	O
,	O
we	O
show	O
these	O
values	O
in	O
Table	O
3	O
.	O
The	O
hidden	O
sizes	O
,	O
feed	O
-	O
forward	O
hidden	O
sizes	O
,	O
and	O
number	O
of	O
attention	O
heads	O
of	O
the	O
two	O
transformers	O
T	O
LTR	O
and	O
T	O
RTL	O
used	O
to	O
produce	O
the	O
proposal	O
distribution	O
are	O
1/4	O
the	O
size	O
of	O
Electric	O
.	O
We	O
chose	O
this	O
value	O
because	O
it	O
keeps	O
the	O
compute	O
comparable	O
to	O
ELECTRA	O
;	O
running	O
two	O
1/4	O
-	O
sized	O
transformers	O
takes	O
roughly	O
the	O
same	O
compute	O
as	O
running	O
one	O
1/3sized	O
transformer	O
,	O
which	O
is	O
the	O
size	O
of	O
ELECTRA	O
's	O
generator	O
.	O
To	O
make	O
the	O
compute	O
exactly	O
equal	O
,	O
we	O
train	O
Electric	O
for	O
slightly	O
fewer	O
steps	O
than	O
ELEC	O
-	O
TRA	O
.	O
This	O
same	O
generator	O
architecture	O
was	O
used	O
for	O
ELECTRA	O
-	O
TT	O
.	O
The	O
TwoTower	O
baseline	O
consists	O
of	O
two	O
transformers	O
2/3	O
the	O
size	O
of	O
BERT	O
's	O
,	O
which	O
takes	O
approximately	O
the	O
same	O
compute	O
to	O
run	O
.	O
The	O
Electric	O
models	O
,	O
ELECTRA	O
-	O
Base	O
,	O
and	O
BERT	O
-	O
Base	O
all	O
use	O
the	O
same	O
amount	O
of	O
pre	O
-	O
train	O
compute	O
(	O
e.g.	O
,	O
Electric	O
is	O
trained	O
for	O
fewer	O
steps	O
than	O
BERT	O
due	O
to	O
the	O
extra	O
compute	O
from	O
the	O
proposal	O
distribution	O
)	O
,	O
which	O
equates	O
to	O
approximately	O
three	O
days	O
of	O
training	O
on	O
16	O
TPUv2s	O
.	O

B	O
Fine	O
-	O
Tuning	O
Details	O

We	O
use	O
ELECTRA	O
's	O
top	O
-	O
level	O
classifiers	O
and	O
hyperparameter	O
values	O
for	O
fine	O
-	O
tuning	O
as	O
well	O
.	O
For	O
GLUE	O
tasks	O
,	O
a	O
simple	O
linear	O
classifier	O
is	O
added	O
on	O
top	O
of	O
the	O
pre	O
-	O
trained	O
transformer	O
.	O
For	O
SQuAD	O
,	O
a	O
question	O
answering	O
module	O
similar	O
XLNet	O
's	O
(	O
Yang	O
et	O
al	O
.	O
,	O
2019	O
)	O
is	O
added	O
on	O
top	O
of	O
the	O
transformer	O
,	O
which	O
is	O
slightly	O
more	O
sophisticated	O
than	O
BERT	O
's	O
in	O
that	O
it	O
jointly	O
rather	O
than	O
independently	O
predicts	O
the	O
start	O
and	O
end	O
positions	O
and	O
has	O
an	O
"	O
answerability	O
"	O
classifier	O
added	O
for	O
SQuAD	O
2.0	O
.	O
ELECTRA	O
's	O
hyperparameters	O
are	O
similar	O
to	O
BERT	O
's	O
,	O
with	O
the	O
main	O
difference	O
being	O
the	O
addition	O
of	O
a	O
layer	O
-	O
wise	O
learning	O
rate	O
decay	O
where	O
layers	O
of	O
the	O
network	O
closer	O
to	O
the	O
output	O
have	O
a	O
higher	O
learning	O
rate	O
.	O

Following	O
BERT	O
,	O
we	O
submit	O
the	O
best	O
of	O
10	O
models	O
fine	O
-	O
tuned	O
with	O
different	O
random	O
seeds	O
to	O
the	O
GLUE	O
leaderboard	O
for	O
test	O
set	O
results	O
.	O

C	O
Dataset	O
Details	O

We	O
provide	O
details	O
on	O
the	O
fine	O
-	O
tuning	O
datasets	O
below	O
.	O
All	O
datasets	O
are	O
in	O
English	O
.	O
GLUE	O
data	O
can	O
be	O
downloaded	O
at	O
https://	O
gluebenchmark.com/	O
and	O
SQuAD	O
data	O
can	O
be	O
downloaded	O
at	O
https://rajpurkar	O
.	O
github.io/SQuAD-explorer/.	O

•	O
CoLA	O
:	O
Corpus	O
of	O
Linguistic	O
Acceptability	O
(	O
Warstadt	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
The	O
task	O
is	O
to	O
determine	O
whether	O
a	O
given	O
sentence	O
is	O
grammatical	O
or	O
not	O
.	O
The	O
dataset	O
contains	O
8.5k	O
train	O
examples	O
from	O
books	O
and	O
journal	O
articles	O
on	O
linguistic	O
theory	O
.	O

•	O
SST	O
:	O
Stanford	O
Sentiment	O
Treebank	O
(	O
Socher	O
et	O
al	O
.	O
,	O
2013	O
)	O
.	O
The	O
tasks	O
is	O
to	O
determine	O
if	O
the	O
sentence	O
is	O
positive	O
or	O
negative	O
in	O
sentiment	O
.	O

The	O
dataset	O
contains	O
67k	O
train	O
examples	O
from	O
movie	O
reviews	O
.	O

•	O
MRPC	O
:	O
Microsoft	O
Research	O
Paraphrase	O
Corpus	O
(	O
Dolan	O
and	O
Brockett	O
,	O
2005	O
)	O
.	O
The	O
task	O
is	O
to	O
predict	O
whether	O
two	O
sentences	O
are	O
semantically	O
equivalent	O
or	O
not	O
.	O
The	O
dataset	O
contains	O
3.7k	O
train	O
examples	O
from	O
online	O
news	O
sources	O
.	O

•	O
STS	O
:	O
Semantic	O
Textual	O
Similarity	O
(	O
Cer	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
The	O
tasks	O
is	O
to	O
predict	O
how	O
semantically	O
similar	O
two	O
sentences	O
are	O
on	O
a	O
1	O
-	O
5	O
scale	O
.	O
The	O
dataset	O
contains	O
5.8k	O
train	O
examples	O
drawn	O
from	O
new	O
headlines	O
,	O
video	O
and	O
image	O
captions	O
,	O
and	O
natural	O
language	O
inference	O
data	O
.	O

•	O
QQP	O
:	O
Quora	O
Question	O
Pairs	O
(	O
Iyer	O
et	O
al	O
.	O
,	O
2017	O
)	O
.	O
The	O
task	O
is	O
to	O
determine	O
whether	O
a	O
pair	O
of	O
questions	O
are	O
semantically	O
equivalent	O
.	O
The	O
dataset	O
contains	O
364k	O
train	O
examples	O
from	O
the	O
community	O
question	O
-	O
answering	O
website	O
Quora	O
.	O

•	O
MNLI	O
:	O
Multi	O
-	O
genre	O
Natural	O
Language	O
Inference	O
(	O
Williams	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
Given	O
a	O
premise	O
sentence	O
and	O
a	O
hypothesis	O
sentence	O
,	O
the	O
task	O
is	O
to	O
predict	O
whether	O
the	O
premise	O
entails	O
the	O
hypothesis	O
,	O
contradicts	O
the	O
hypothesis	O
,	O
or	O
neither	O
.	O
The	O
dataset	O
contains	O
393k	O
train	O
examples	O
drawn	O
from	O
ten	O
different	O
sources	O
.	O
using	O
dev	O
-	O
set	O
model	O
selection	O
to	O
choose	O
the	O
test	O
set	O
submission	O
may	O
alleviate	O
the	O
high	O
variance	O
of	O
fine	O
-	O
tuning	O
to	O
some	O
extent	O
,	O
such	O
model	O
selection	O
is	O
still	O
not	O
sufficient	O
for	O
reliable	O
comparisons	O
between	O
methods	O
(	O
Reimers	O
and	O
Gurevych	O
,	O
2018	O
)	O
.	O

Acknowledgements	O

We	O
thank	O
John	O
Hewitt	O
,	O
Yuhao	O
Zhang	O
,	O
Ashwin	O
Paranjape	O
,	O
Sergey	O
Levine	O
,	O
and	O
the	O
anonymous	O
reviewers	O
for	O
their	O
thoughtful	O
comments	O
and	O
suggestions	O
.	O
Kevin	O
is	O
supported	O
by	O
a	O
Google	O
PhD	O
Fellowship	O
.	O

A	O
Pre	O
-	O
Training	O
Details	O

The	O
neural	O
architectures	O
of	O
our	O
models	O
are	O
identical	O
to	O
BERT	O
-	O
Base	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
although	O
we	O
believe	O
incorporating	O
additions	O
such	O
as	O
relative	O
position	O
encodings	O
(	O
Shaw	O
et	O
al	O
.	O
,	O
2018	O
)	O
•	O
QNLI	O
:	O
Question	O
Natural	O
Language	O
Inference	O
;	O
constructed	O
from	O
SQuAD	O
(	O
Rajpurkar	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
The	O
task	O
is	O
to	O
predict	O
whether	O
a	O
context	O
sentence	O
contains	O
the	O
answer	O
to	O
a	O
question	O
sentence	O
.	O
The	O
dataset	O
contains	O
108k	O
train	O
examples	O
from	O
Wikipedia	O
.	O

•	O
RTE	O
:	O
Recognizing	O
Textual	O
Entailment	O
(	O
Giampiccolo	O
et	O
al	O
.	O
,	O
2007	O
)	O
.	O
Given	O
a	O
premise	O
sentence	O
and	O
a	O
hypothesis	O
sentence	O
,	O
the	O
task	O
is	O
to	O
predict	O
whether	O
the	O
premise	O
entails	O
the	O
hypothesis	O
or	O
not	O
.	O
The	O
dataset	O
contains	O
2.5k	O
train	O
examples	O
from	O
a	O
series	O
of	O
annual	O
textual	O
entailment	O
challenges	O
.	O

•	O
SQuAD	O
1.1	O
:	O
Stanford	O
Question	O
Answering	O
Dataset	O
(	O
Rajpurkar	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
Given	O
a	O
context	O
paragraph	O
and	O
a	O
question	O
,	O
the	O
task	O
is	O
to	O
select	O
the	O
span	O
of	O
text	O
in	O
the	O
paragraph	O
answering	O
the	O
question	O
.	O
The	O
dataset	O
contains	O
88k	O
train	O
examples	O
from	O
Wikipedia	O
.	O

•	O
SQuAD	O
2.0	O
:	O
Stanford	O
Question	O
Answering	O
Dataset	O
version	O
2.0	O
(	O
Rajpurkar	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
This	O
task	O
adds	O
addition	O
questions	O
to	O
SQuAD	O
whose	O
answer	O
does	O
not	O
exist	O
in	O
the	O
context	O
;	O
models	O
have	O
to	O
recognize	O
when	O
these	O
questions	O
occur	O
and	O
not	O
return	O
an	O
answer	O
for	O
them	O
.	O

The	O
dataset	O
contains	O
130k	O
train	O
examples	O
,	O

We	O
report	O
Spearman	O
correlation	O
for	O
STS	O
,	O
Matthews	O
correlation	O
coefficient	O
(	O
MCC	O
)	O
for	O
CoLA	O
,	O
exact	O
match	O
for	O
SQuAD	O
,	O
and	O
accuracy	O
for	O
the	O
other	O
tasks	O
.	O
We	O
use	O
the	O
provided	O
evaluation	O
script	O
for	O
SQuAD	O
6	O
,	O
scipy	O
to	O
compute	O
Spearman	O
scores	O
7	O
,	O
and	O
sklearn	O
to	O
compute	O
MCC	O
8	O
.	O
We	O
use	O
the	O
standard	O
train	O
/	O
dev	O
/	O
test	O
splits	O
.	O

D	O
Detailed	O
Results	O

We	O
show	O
detailed	O
results	O
on	O
GLUE	O
and	O
SQuAD	O
in	O
Table	O
4	O
and	O
detailed	O
results	O
on	O
LibriSpeech	O
reranking	O
in	O
Table	O
5	O
.	O
Following	O
BERT	O
,	O
we	O
do	O
not	O
show	O
results	O
on	O
the	O
WNLI	O
GLUE	O
task	O
,	O
as	O
it	O
is	O
difficult	O
to	O
beat	O
even	O
the	O
majority	O
classifier	O
using	O
a	O
standard	O
fine	O
-	O
tuning	O
-	O
as	O
-	O
classifier	O
approach	O
.	O
We	O
show	O
dev	O
rather	O
than	O
test	O
results	O
on	O
GLUE	O
in	O
the	O
main	O
paper	O
because	O
they	O
are	O
more	O
reliable	O
;	O
the	O
performance	O
of	O
fine	O
-	O
tuned	O
models	O
varies	O
substantially	O
based	O
on	O
the	O
random	O
seed	O
(	O
Phang	O
et	O
al	O
.	O
,	O
2018;Clark	O
et	O
al	O
.	O
,	O
2019;Dodge	O
et	O
al	O
.	O
,	O
2020	O
)	O
,	O
but	O
GLUE	O
only	O
supports	O
submitting	O
a	O
single	O
model	O
rather	O
than	O
getting	O
a	O
median	O
score	O
of	O
multiple	O
models	O
.	O
While	O
6	O
https://worksheets	O
.	O
codalab.org/rest/bundles/	O
0x6b567e1cf2e041ec80d7098f031c5c9e/	O
contents	O
/	O
blob/	O
7	O
https://docs.scipy.org/doc/	O
scipy	O
/	O
reference	O
/	O
generated	O
/	O
scipy.stats	O
.	O
spearmanr.html	O

FIND	O
:	O
Human	O
-	O
in	O
-	O
the	O
-	O
Loop	O
Debugging	O
Deep	O
Text	O
Classifiers	O

Since	O
obtaining	O
a	O
perfect	O
training	O
dataset	O
(	O
i.e.	O
,	O
a	O
dataset	O
which	O
is	O
considerably	O
large	O
,	O
unbiased	O
,	O
and	O
well	O
-	O
representative	O
of	O
unseen	O
cases	O
)	O
is	O
hardly	O
possible	O
,	O
many	O
real	O
-	O
world	O
text	O
classifiers	O
are	O
trained	O
on	O
the	O
available	O
,	O
yet	O
imperfect	O
,	O
datasets	O
.	O
These	O
classifiers	O
are	O
thus	O
likely	O
to	O
have	O
undesirable	O
properties	O
.	O
For	O
instance	O
,	O
they	O
may	O
have	O
biases	O
against	O
some	O
sub	O
-	O
populations	O
or	O
may	O
not	O
work	O
effectively	O
in	O
the	O
wild	O
due	O
to	O
overfitting	O
.	O
In	O
this	O
paper	O
,	O
we	O
propose	O
FINDa	O
framework	O
which	O
enables	O
humans	O
to	O
debug	O
deep	O
learning	O
text	O
classifiers	O
by	O
disabling	O
irrelevant	O
hidden	O
features	O
.	O
Experiments	O
show	O
that	O
by	O
using	O
FIND	O
,	O
humans	O
can	O
improve	O
CNN	O
text	O
classifiers	O
which	O
were	O
trained	O
under	O
different	O
types	O
of	O
imperfect	O
datasets	O
(	O
including	O
datasets	O
with	O
biases	O
and	O
datasets	O
with	O
dissimilar	O
traintest	O
distributions	O
)	O
.	O

Introduction	O

Deep	O
learning	O
has	O
become	O
the	O
dominant	O
approach	O
to	O
address	O
most	O
Natural	O
Language	O
Processing	O
(	O
NLP	O
)	O
tasks	O
,	O
including	O
text	O
classification	O
.	O
With	O
sufficient	O
and	O
high	O
-	O
quality	O
training	O
data	O
,	O
deep	O
learning	O
models	O
can	O
perform	O
incredibly	O
well	O
.	O
However	O
,	O
in	O
real	O
-	O
world	O
cases	O
,	O
such	O
ideal	O
datasets	O
are	O
scarce	O
.	O
Often	O
times	O
,	O
the	O
available	O
datasets	O
are	O
small	O
,	O
full	O
of	O
regular	O
but	O
irrelevant	O
words	O
,	O
and	O
contain	O
unintended	O
biases	O
(	O
Wiegand	O
et	O
al	O
.	O
,	O
2019;Gururangan	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
These	O
can	O
lead	O
to	O
suboptimal	O
models	O
with	O
undesirable	O
properties	O
.	O
For	O
example	O
,	O
the	O
models	O
may	O
have	O
biases	O
against	O
some	O
sub	O
-	O
populations	O
or	O
may	O
not	O
work	O
effectively	O
in	O
the	O
wild	O
as	O
they	O
overfit	O
the	O
imperfect	O
training	O
data	O
.	O

To	O
improve	O
the	O
models	O
,	O
previous	O
work	O
has	O
looked	O
into	O
different	O
techniques	O
beyond	O
standard	O
model	O
fitting	O
.	O
If	O
the	O
weaknesses	O
of	O
the	O
training	O
datasets	O
or	O
the	O
models	O
are	O
anticipated	O
,	O
strategies	O
can	O
be	O
tailored	O
to	O
mitigate	O
such	O
weaknesses	O
.	O
For	O
example	O
,	O
augmenting	O
the	O
training	O
data	O
with	O
genderswapped	O
input	O
texts	O
helps	O
reduce	O
gender	O
bias	O
in	O
the	O
models	O
(	O
Park	O
et	O
al	O
.	O
,	O
2018;Zhao	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
Adversarial	O
training	O
can	O
prevent	O
the	O
models	O
from	O
exploiting	O
irrelevant	O
and/or	O
protected	O
features	O
(	O
Jaiswal	O
et	O
al	O
.	O
,	O
2019;Zhang	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
With	O
a	O
limited	O
number	O
of	O
training	O
examples	O
,	O
using	O
human	O
rationales	O
or	O
prior	O
knowledge	O
together	O
with	O
training	O
labels	O
can	O
help	O
the	O
models	O
perform	O
better	O
(	O
Zaidan	O
et	O
al	O
.	O
,	O
2007;Bao	O
et	O
al	O
.	O
,	O
2018;Liu	O
and	O
Avci	O
,	O
2019	O
)	O
.	O

Nonetheless	O
,	O
there	O
are	O
side	O
-	O
effects	O
of	O
suboptimal	O
datasets	O
that	O
can	O
not	O
be	O
predicted	O
and	O
are	O
only	O
found	O
after	O
training	O
thanks	O
to	O
post	O
-	O
hoc	O
error	O
analysis	O
.	O
To	O
rectify	O
such	O
problems	O
,	O
there	O
have	O
been	O
attempts	O
to	O
enable	O
humans	O
to	O
fix	O
the	O
trained	O
models	O
(	O
i.e.	O
,	O
to	O
perform	O
model	O
debugging	O
)	O
(	O
Stumpf	O
et	O
al	O
.	O
,	O
2009;Teso	O
and	O
Kersting	O
,	O
2019	O
)	O
.	O
Since	O
the	O
models	O
are	O
usually	O
too	O
complex	O
to	O
understand	O
,	O
manually	O
modifying	O
the	O
model	O
parameters	O
is	O
not	O
possible	O
.	O
Existing	O
techniques	O
,	O
therefore	O
,	O
allow	O
humans	O
to	O
provide	O
feedback	O
on	O
individual	O
predictions	O
instead	O
.	O
Then	O
,	O
additional	O
training	O
examples	O
are	O
created	O
based	O
on	O
the	O
feedback	O
to	O
retrain	O
the	O
models	O
.	O
However	O
,	O
such	O
local	O
improvements	O
for	O
individual	O
predictions	O
could	O
add	O
up	O
to	O
inferior	O
overall	O
performance	O
(	O
Wu	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Furthermore	O
,	O
these	O
existing	O
techniques	O
allow	O
us	O
to	O
rectify	O
only	O
errors	O
related	O
to	O
examples	O
at	O
hand	O
but	O
provide	O
no	O
way	O
to	O
fix	O
problems	O
kept	O
hidden	O
in	O
the	O
model	O
parameters	O
.	O

In	O
this	O
paper	O
,	O
we	O
propose	O
a	O
framework	O
which	O
allows	O
humans	O
to	O
debug	O
and	O
improve	O
deep	O
text	O
classifiers	O
by	O
disabling	O
hidden	O
features	O
which	O
are	O
irrelevant	O
to	O
the	O
classification	O
task	O
.	O
We	O
name	O
this	O
framework	O
FIND	O
(	O
Feature	O
Investigation	O
aNd	O
Disabling	O
)	O
.	O
FIND	O
exploits	O
an	O
explanation	O
method	O
,	O
namely	O
layer	O
-	O
wise	O
relevance	O
propagation	O
(	O
LRP	O
)	O
(	O
Arras	O
et	O
al	O
.	O
,	O
2016	O
)	O
,	O
to	O
understand	O
the	O
behavior	O
of	O
a	O
classifier	O
when	O
it	O
predicts	O
each	O
training	O
instance	O
.	O

Then	O
it	O
aggregates	O
all	O
the	O
information	O
using	O
word	O
clouds	O
to	O
create	O
a	O
global	O
visual	O
picture	O
of	O
the	O
model	O
.	O
This	O
enables	O
humans	O
to	O
comprehend	O
the	O
features	O
automatically	O
learned	O
by	O
the	O
deep	O
classifier	O
and	O
then	O
decide	O
to	O
disable	O
some	O
features	O
that	O
could	O
undermine	O
the	O
prediction	O
accuracy	O
during	O
testing	O
.	O
The	O
main	O
differences	O
between	O
our	O
work	O
and	O
existing	O
work	O
are	O
:	O
(	O
i	O
)	O
first	O
,	O
FIND	O
leverages	O
human	O
feedback	O
on	O
the	O
model	O
components	O
,	O
not	O
the	O
individual	O
predictions	O
,	O
to	O
perform	O
debugging	O
;	O
(	O
ii	O
)	O
second	O
,	O
FIND	O
targets	O
deep	O
text	O
classifiers	O
which	O
are	O
more	O
convoluted	O
than	O
traditional	O
classifiers	O
used	O
in	O
existing	O
work	O
(	O
such	O
as	O
Naive	O
Bayes	O
classifiers	O
and	O
Support	O
Vector	O
Machines	O
)	O
.	O

We	O
conducted	O
three	O
human	O
experiments	O
(	O
one	O
feasibility	O
study	O
and	O
two	O
debugging	O
experiments	O
)	O
to	O
demonstrate	O
the	O
usefulness	O
of	O
FIND	O
.	O
For	O
all	O
the	O
experiments	O
,	O
we	O
used	O
as	O
classifiers	O
convolutional	O
neural	O
networks	O
(	O
CNNs	O
)	O
(	O
Kim	O
,	O
2014	O
)	O
,	O
which	O
are	O
a	O
popular	O
,	O
well	O
-	O
performing	O
architecture	O
for	O
many	O
text	O
classification	O
tasks	O
including	O
the	O
tasks	O
we	O
experimented	O
with	O
(	O
Gambäck	O
and	O
Sikdar	O
,	O
2017;Johnson	O
and	O
Zhang	O
,	O
2015;Zhang	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
The	O
overall	O
results	O
show	O
that	O
FIND	O
with	O
human	O
-	O
in	O
-	O
the	O
-	O
loop	O
can	O
improve	O
the	O
text	O
classifiers	O
and	O
mitigate	O
the	O
said	O
problems	O
in	O
the	O
datasets	O
.	O
After	O
the	O
experiments	O
,	O
we	O
discuss	O
the	O
generalization	O
of	O
the	O
proposed	O
framework	O
to	O
other	O
tasks	O
and	O
models	O
.	O
Overall	O
,	O
the	O
main	O
contributions	O
of	O
this	O
paper	O
are	O
:	O

•	O
We	O
propose	O
using	O
word	O
clouds	O
as	O
visual	O
explanations	O
of	O
the	O
features	O
learned	O
.	O

•	O
We	O
propose	O
a	O
technique	O
to	O
disable	O
the	O
learned	O
features	O
which	O
are	O
irrelevant	O
or	O
harmful	O
to	O
the	O
classification	O
task	O
so	O
as	O
to	O
improve	O
the	O
classifier	O
.	O
This	O
technique	O
and	O
the	O
word	O
clouds	O
form	O
the	O
human	O
-	O
debugging	O
framework	O
-FIND	O
.	O

•	O
We	O
conduct	O
three	O
human	O
experiments	O
that	O
demonstrate	O
the	O
effectiveness	O
of	O
FIND	O
in	O
different	O
scenarios	O
.	O
The	O
results	O
not	O
only	O
highlight	O
the	O
usefulness	O
of	O
our	O
approach	O
but	O
also	O
reveal	O
interesting	O
behaviors	O
of	O
CNNs	O
for	O
text	O
classification	O
.	O

The	O
rest	O
of	O
this	O
paper	O
is	O
organized	O
as	O
follows	O
.	O
Section	O
2	O
explains	O
related	O
work	O
about	O
analyzing	O
,	O
explaining	O
,	O
and	O
human	O
-	O
debugging	O
text	O
classifiers	O
.	O
Section	O
3	O
proposes	O
FIND	O
,	O
our	O
debugging	O
framework	O
.	O
Section	O
4	O
explains	O
the	O
experimental	O
setup	O
followed	O
by	O
the	O
three	O
human	O
experiments	O
in	O
Section	O
5	O
to	O
7	O
.	O
Finally	O
,	O
Section	O
8	O
discusses	O
generalization	O
of	O
the	O
framework	O
and	O
concludes	O
the	O
paper	O
.	O
Code	O
and	O
datasets	O
of	O
this	O
paper	O
are	O
available	O
at	O
https://github.com/plkumjorn/FIND	O
.	O

Related	O
Work	O

Analyzing	O
deep	O
NLP	O
models	O
-There	O
has	O
been	O
substantial	O
work	O
in	O
gaining	O
better	O
understanding	O
of	O
complex	O
,	O
deep	O
neural	O
NLP	O
models	O
.	O
By	O
visualizing	O
dense	O
hidden	O
vectors	O
,	O
Li	O
et	O
al	O
.	O
(	O
2016	O
)	O
found	O
that	O
some	O
dimensions	O
of	O
the	O
final	O
representation	O
learned	O
by	O
recurrent	O
neural	O
networks	O
capture	O
the	O
effect	O
of	O
intensification	O
and	O
negation	O
in	O
the	O
input	O
text	O
.	O
Karpathy	O
et	O
al	O
.	O
(	O
2015	O
)	O
revealed	O
the	O
existence	O
of	O
interpretable	O
cells	O
in	O
a	O
character	O
-	O
level	O
LSTM	O
model	O
for	O
language	O
modelling	O
.	O
For	O
example	O
,	O
they	O
found	O
a	O
cell	O
acting	O
as	O
a	O
line	O
length	O
counter	O
and	O
cells	O
checking	O
if	O
the	O
current	O
letter	O
is	O
inside	O
a	O
parenthesis	O
or	O
a	O
quote	O
.	O
Jacovi	O
et	O
al	O
.	O
(	O
2018	O
)	O
presented	O
interesting	O
findings	O
about	O
CNNs	O
for	O
text	O
classification	O
including	O
the	O
fact	O
that	O
one	O
convolutional	O
filter	O
may	O
detect	O
more	O
than	O
one	O
n	O
-	O
gram	O
pattern	O
and	O
may	O
also	O
suppress	O
negative	O
n	O
-	O
grams	O
.	O
Many	O
recent	O
papers	O
studied	O
several	O
types	O
of	O
knowledge	O
in	O
BERT	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
,	O
a	O
deep	O
transformer	O
-	O
based	O
model	O
for	O
language	O
understanding	O
,	O
and	O
found	O
that	O
syntactic	O
information	O
is	O
mostly	O
captured	O
in	O
the	O
middle	O
BERT	O
layers	O
while	O
the	O
final	O
BERT	O
layers	O
are	O
the	O
most	O
task	O
-	O
specific	O
(	O
Rogers	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
Inspired	O
by	O
many	O
findings	O
,	O
we	O
make	O
the	O
assumption	O
that	O
each	O
dimension	O
of	O
the	O
final	O
representation	O
(	O
i.e.	O
,	O
the	O
vector	O
before	O
the	O
output	O
layer	O
)	O
captures	O
patterns	O
or	O
qualities	O
in	O
the	O
input	O
which	O
are	O
useful	O
for	O
classification	O
.	O
Therefore	O
,	O
understanding	O
the	O
roles	O
of	O
these	O
dimensions	O
(	O
we	O
refer	O
to	O
them	O
as	O
features	O
)	O
is	O
a	O
prerequisite	O
for	O
effective	O
human	O
-	O
in	O
-	O
the	O
-	O
loop	O
model	O
debugging	O
,	O
and	O
we	O
exploit	O
an	O
explanation	O
method	O
to	O
gain	O
such	O
an	O
understanding	O
.	O
Explaining	O
predictions	O
from	O
text	O
classifiers	O
-Several	O
methods	O
have	O
been	O
devised	O
to	O
generate	O
explanations	O
supporting	O
classifications	O
in	O
many	O
forms	O
,	O
such	O
as	O
natural	O
language	O
texts	O
,	O
rules	O
(	O
Ribeiro	O
et	O
al	O
.	O
,	O
2018	O
)	O
,	O
extracted	O
rationales	O
(	O
Lei	O
et	O
al	O
.	O
,	O
2016	O
)	O
,	O
and	O
attribution	O
scores	O
(	O
Lertvittayakumjorn	O
and	O
Toni	O
,	O
2019	O
)	O
.	O
Some	O
explanation	O
methods	O
,	O
such	O
as	O
LIME	O
(	O
Ribeiro	O
et	O
al	O
.	O
,	O
2016	O
)	O
and	O
SHAP	O
(	O
Lundberg	O
and	O
Lee	O
,	O
2017	O
)	O
,	O
are	O
model	O
-	O
agnostic	O
and	O
do	O
not	O
require	O
access	O
to	O
model	O
parameters	O
.	O
Other	O
methods	O
access	O
the	O
model	O
architectures	O
and	O
parameters	O
to	O
generate	O
the	O
explanations	O
,	O
such	O
as	O
DeepLIFT	O
(	O
Shrikumar	O
et	O
al	O
.	O
,	O
2017	O
)	O
and	O
LRP	O
(	O
layer	O
-	O
wise	O
relevance	O
propagation	O
)	O
(	O
Bach	O
et	O
al	O
.	O
,	O
2015;Arras	O
et	O
al	O
.	O
,	O
2016	O
)	O
.	O
In	O
this	O
work	O
,	O
we	O
use	O
LRP	O
to	O
explain	O
not	O
the	O
predictions	O
but	O
the	O
learned	O
features	O
so	O
as	O
to	O
expose	O
the	O
model	O
behavior	O
to	O
humans	O
and	O
enable	O
informed	O
model	O
debugging	O
.	O

Debugging	O
text	O
classifiers	O
using	O
human	O
feedback	O
-Early	O
work	O
in	O
this	O
area	O
comes	O
from	O
the	O
human	O
-	O
computer	O
interaction	O
community	O
.	O
Stumpf	O
et	O
al	O
.	O
(	O
2009	O
)	O
studied	O
the	O
types	O
of	O
feedback	O
humans	O
usually	O
give	O
in	O
response	O
to	O
machine	O
-	O
generated	O
predictions	O
and	O
explanations	O
.	O
Also	O
,	O
some	O
of	O
the	O
feedback	O
collected	O
(	O
i.e.	O
,	O
important	O
words	O
of	O
each	O
category	O
)	O
was	O
used	O
to	O
improve	O
the	O
classifier	O
via	O
a	O
user	O
co	O
-	O
training	O
approach	O
.	O
Kulesza	O
et	O
al	O
.	O
(	O
2015	O
)	O
presented	O
an	O
explanatory	O
debugging	O
approach	O
in	O
which	O
the	O
system	O
explains	O
to	O
users	O
how	O
it	O
made	O
each	O
prediction	O
,	O
and	O
the	O
users	O
then	O
rectify	O
the	O
model	O
by	O
adding	O
/	O
removing	O
words	O
from	O
the	O
explanation	O
and	O
adjusting	O
important	O
weights	O
.	O
Even	O
without	O
explanations	O
shown	O
,	O
an	O
active	O
learning	O
framework	O
proposed	O
by	O
Settles	O
(	O
2011	O
)	O
asks	O
humans	O
to	O
iteratively	O
label	O
some	O
chosen	O
features	O
(	O
i.e.	O
,	O
words	O
)	O
and	O
adjusts	O
the	O
model	O
parameters	O
that	O
correspond	O
to	O
the	O
features	O
.	O
However	O
,	O
these	O
early	O
works	O
target	O
simpler	O
machine	O
learning	O
classifiers	O
(	O
e.g.	O
,	O
Naive	O
Bayes	O
classifiers	O
with	O
bag	O
-	O
of	O
-	O
words	O
)	O
and	O
it	O
is	O
not	O
clear	O
how	O
to	O
apply	O
the	O
proposed	O
approaches	O
to	O
deep	O
text	O
classifiers	O
.	O

Recently	O
,	O
there	O
have	O
been	O
new	O
attempts	O
to	O
use	O
explanations	O
and	O
human	O
feedback	O
to	O
debug	O
classifiers	O
in	O
general	O
.	O
Some	O
of	O
them	O
were	O
tested	O
on	O
traditional	O
text	O
classifiers	O
.	O
For	O
instance	O
,	O
Ribeiro	O
et	O
al	O
.	O
(	O
2016	O
)	O
showed	O
a	O
set	O
of	O
LIME	O
explanations	O
for	O
individual	O
SVM	O
predictions	O
to	O
humans	O
and	O
asked	O
them	O
to	O
remove	O
irrelevant	O
words	O
from	O
the	O
training	O
data	O
in	O
subsequent	O
training	O
.	O
The	O
process	O
was	O
run	O
for	O
three	O
rounds	O
to	O
iteratively	O
improve	O
the	O
classifiers	O
.	O
Teso	O
and	O
Kersting	O
(	O
2019	O
)	O
proposed	O
CAIPI	O
,	O
which	O
is	O
an	O
explanatory	O
interactive	O
learning	O
framework	O
.	O
At	O
each	O
iteration	O
,	O
it	O
selects	O
an	O
unlabelled	O
example	O
to	O
predict	O
and	O
explain	O
to	O
users	O
using	O
LIME	O
,	O
and	O
the	O
users	O
respond	O
by	O
removing	O
irrelevant	O
features	O
from	O
the	O
explanation	O
.	O
CAIPI	O
then	O
uses	O
this	O
feedback	O
to	O
generate	O
augmented	O
data	O
and	O
retrain	O
the	O
model	O
.	O
While	O
these	O
recent	O
works	O
use	O
feedback	O
on	O
lowlevel	O
features	O
(	O
input	O
words	O
)	O
and	O
individual	O
predictions	O
,	O
our	O
framework	O
(	O
FIND	O
)	O
uses	O
feedback	O
on	O
the	O
learned	O
features	O
with	O
respect	O
to	O
the	O
big	O
picture	O
of	O
the	O
model	O
.	O
This	O
helps	O
us	O
avoid	O
local	O
decision	O
pitfalls	O
which	O
usually	O
occur	O
in	O
interactive	O
machine	O
learning	O
(	O
Wu	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Overall	O
,	O
what	O
makes	O
our	O
contribution	O
different	O
from	O
existing	O
work	O
is	O
that	O
(	O
i	O
)	O
we	O
collect	O
the	O
feedback	O
on	O
the	O
model	O
,	O
not	O
the	O
individual	O
predictions	O
,	O
and	O
(	O
ii	O
)	O
we	O
target	O
deep	O
text	O
classifiers	O
which	O
are	O
more	O
complex	O
than	O
the	O
models	O
used	O
in	O
previous	O
work	O
.	O

FIND	O
:	O
Debugging	O
Text	O
Classifiers	O

Motivation	O

Generally	O
,	O
deep	O
text	O
classifiers	O
can	O
be	O
divided	O
into	O
two	O
parts	O
.	O
The	O
first	O
part	O
performs	O
feature	O
extraction	O
,	O
transforming	O
an	O
input	O
text	O
into	O
a	O
dense	O
vector	O
(	O
i.e.	O
,	O
a	O
feature	O
vector	O
)	O
which	O
represents	O
the	O
input	O
.	O
There	O
are	O
several	O
alternatives	O
to	O
implement	O
this	O
part	O
such	O
as	O
using	O
convolutional	O
layers	O
,	O
recurrent	O
layers	O
,	O
and	O
transformer	O
layers	O
.	O
The	O
second	O
part	O
performs	O
classification	O
passing	O
the	O
feature	O
vector	O
through	O
a	O
dense	O
layer	O
with	O
softmax	O
activation	O
to	O
get	O
predicted	O
probability	O
of	O
the	O
classes	O
.	O
These	O
deep	O
classifiers	O
are	O
not	O
transparent	O
,	O
as	O
humans	O
can	O
not	O
interpret	O
the	O
meaning	O
of	O
either	O
the	O
intermediate	O
vectors	O
or	O
the	O
model	O
parameters	O
used	O
for	O
feature	O
extraction	O
.	O
This	O
prevents	O
humans	O
from	O
applying	O
their	O
knowledge	O
to	O
modify	O
or	O
debug	O
the	O
classifiers	O
.	O

In	O
contrast	O
,	O
if	O
we	O
understand	O
which	O
patterns	O
or	O
qualities	O
of	O
the	O
input	O
are	O
captured	O
in	O
each	O
feature	O
,	O
we	O
can	O
comprehend	O
the	O
overall	O
reasoning	O
mechanism	O
of	O
the	O
model	O
as	O
the	O
dense	O
layer	O
in	O
the	O
classification	O
part	O
then	O
becomes	O
interpretable	O
.	O
In	O
this	O
paper	O
,	O
we	O
make	O
this	O
possible	O
using	O
LRP	O
.	O
By	O
understanding	O
the	O
model	O
,	O
humans	O
can	O
check	O
whether	O
the	O
input	O
patterns	O
detected	O
by	O
each	O
feature	O
are	O
relevant	O
for	O
classification	O
.	O
Also	O
,	O
the	O
features	O
should	O
be	O
used	O
by	O
the	O
subsequent	O
dense	O
layer	O
to	O
support	O
the	O
right	O
classes	O
.	O
If	O
these	O
are	O
not	O
the	O
case	O
,	O
debugging	O
can	O
be	O
done	O
by	O
disabling	O
the	O
features	O
which	O
may	O
be	O
harmful	O
if	O
they	O
exist	O
in	O
the	O
model	O
.	O
Figure	O
1	O
shows	O
the	O
overview	O
of	O
our	O
debugging	O
framework	O
,	O
FIND	O
.	O

Notation	O

Let	O
us	O
consider	O
a	O
text	O
classification	O
task	O
with	O
|C|	O
classes	O
where	O
C	O
is	O
the	O
set	O
of	O
all	O
classes	O
and	O
let	O
V	O
be	O
a	O
set	O
of	O
unique	O
words	O
in	O
the	O
corpus	O
(	O
the	O
vocabulary	O
)	O
.	O

A	O
training	O
dataset	O
D	O
=	O
{	O
(	O
x	O
1	O
,	O
y	O
1	O
)	O
,	O
.	O
.	O
.	O
,	O
(	O
x	O
N	O
,	O
y	O
N	O
)	O
}	O
is	O
given	O
,	O
where	O
x	O
i	O
is	O
the	O
i	O
-	O
th	O
document	O
containing	O
a	O
sequence	O
of	O
L	O
words	O
,	O
[	O
x	O
i1	O
,	O
x	O
i2	O
,	O
...	O
,	O
x	O
iL	O
]	O
,	O
and	O
y	O
i	O
∈	O
C	O
is	O
the	O
class	O
label	O
of	O

Understanding	O
the	O
Model	O

To	O
understand	O
how	O
the	O
model	O
M	O
works	O
,	O
we	O
analyze	O
the	O
patterns	O
or	O
characteristics	O
of	O
the	O
input	O
that	O
activate	O
each	O
feature	O
f	O
i	O
.	O
Specifically	O
,	O
using	O
LRP	O
1	O
,	O
for	O
each	O
f	O
i	O
of	O
an	O
example	O
x	O
j	O
in	O
the	O
training	O
dataset	O
,	O
we	O
calculate	O
a	O
relevance	O
vector	O
r	O
ij	O
∈	O
R	O
L	O
showing	O
the	O
relevance	O
scores	O
(	O
the	O
contributions	O
)	O
of	O
each	O
word	O
in	O
x	O
j	O
for	O
the	O
value	O
of	O
f	O
i	O
.	O
After	O
doing	O
this	O
for	O
all	O
d	O
features	O
of	O
all	O
training	O
examples	O
,	O
we	O
can	O
produce	O
word	O
clouds	O
to	O
help	O
the	O
users	O
better	O
understand	O
the	O
model	O
M	O
.	O
Word	O
clouds	O
-For	O
each	O
feature	O
f	O
i	O
,	O
we	O
create	O
(	O
one	O
or	O
more	O
)	O
word	O
clouds	O
to	O
visualize	O
the	O
patterns	O
in	O
the	O
input	O
texts	O
which	O
highly	O
activate	O
f	O
i	O
.	O
This	O
can	O
be	O
done	O
by	O
analyzing	O
r	O
ij	O
for	O
all	O
x	O
j	O
in	O
the	O
training	O
data	O
and	O
displaying	O
,	O
in	O
the	O
word	O
clouds	O
,	O
words	O
or	O
n	O
-	O
grams	O
which	O
get	O
high	O
relevance	O
scores	O
.	O
Note	O
that	O
different	O
model	O
architectures	O
may	O
have	O
different	O
ways	O
to	O
generate	O
the	O
word	O
clouds	O
so	O
as	O
to	O
effectively	O
reveal	O
the	O
behavior	O
of	O
the	O
features	O
.	O

For	O
CNNs	O
,	O
the	O
classifiers	O
we	O
experiment	O
with	O
in	O
this	O
paper	O
,	O
each	O
feature	O
has	O
one	O
word	O
cloud	O
containing	O
the	O
n	O
-	O
grams	O
,	O
from	O
the	O
training	O
examples	O
,	O
which	O
were	O
selected	O
by	O
the	O
max	O
-	O
pooling	O
of	O
the	O
CNNs	O
.	O
For	O
instance	O
,	O
Figure	O
2	O
,	O
corresponding	O
to	O
a	O
feature	O
of	O
filter	O
size	O
2	O
,	O
shows	O
bi	O
-	O
grams	O
(	O
e.g.	O
,	O
"	O
love	O
love	O
"	O
,	O
"	O
love	O
my	O
"	O
,	O
"	O
loves	O
his	O
"	O
,	O
etc	O
.	O
)	O
whose	O
font	O
size	O
corresponds	O
to	O
the	O
feature	O
values	O
of	O
the	O
bi	O
-	O
grams	O
.	O
This	O
is	O
similar	O
to	O
how	O
previous	O
works	O
analyze	O
CNN	O
features	O
(	O
Jacovi	O
et	O
al	O
.	O
,	O
2018;Lertvittayakumjorn	O
and	O
Toni	O
,	O
2019	O
)	O
,	O
and	O
it	O
is	O
equivalent	O
to	O
back	O
-	O
propagating	O
the	O
feature	O
values	O
to	O
the	O
input	O
using	O
LRP	O
and	O
cropping	O
the	O
consecutive	O
input	O
words	O
with	O
non	O
-	O
zero	O
LRP	O
scores	O
to	O
show	O
in	O
the	O
word	O
clouds	O
.	O

Disabling	O
Features	O

As	O
explained	O
earlier	O
,	O
we	O
want	O
to	O
know	O
whether	O
the	O
learned	O
features	O
are	O
valid	O
and	O
relevant	O
to	O
the	O
classification	O
task	O
and	O
whether	O
or	O
not	O
they	O
get	O
appropriate	O
weights	O
from	O
the	O
next	O
layer	O
.	O
This	O
is	O
possible	O
by	O
letting	O
humans	O
consider	O
the	O
word	O
cloud(s	O
)	O
of	O
each	O
feature	O
and	O
tell	O
us	O
which	O
class	O
the	O
feature	O
is	O
relevant	O
to	O
.	O
A	O
word	O
cloud	O
receiving	O
human	O
answers	O
that	O
are	O
different	O
from	O
the	O
class	O
it	O
should	O
support	O
(	O
as	O
indicated	O
by	O
W	O
)	O
exhibits	O
a	O
flaw	O
in	O
the	O
model	O
.	O
For	O
example	O
,	O
if	O
the	O
word	O
cloud	O
in	O
Figure	O
2	O
represents	O
the	O
feature	O
f	O
i	O
in	O
a	O
sentiment	O
analysis	O
task	O
but	O
the	O
i	O
th	O
column	O
of	O
W	O
implies	O
that	O
f	O
i	O
supports	O
the	O
negative	O
sentiment	O
class	O
,	O
we	O
know	O
the	O
model	O
is	O
not	O
correct	O
here	O
.	O
If	O
this	O
word	O
cloud	O
appears	O
in	O
a	O
product	O
categorization	O
task	O
,	O
this	O
is	O
also	O
problematic	O
because	O
the	O
phrases	O
in	O
the	O
word	O
cloud	O
are	O
not	O
discriminative	O
of	O
any	O
product	O
category	O
.	O
Hence	O
,	O
we	O
provide	O
options	O
for	O
the	O
users	O
to	O
disable	O
the	O
features	O
which	O
correspond	O
to	O
any	O
problematic	O
word	O
clouds	O
so	O
that	O
the	O
features	O
do	O
not	O
play	O
a	O
role	O
in	O
the	O
classification	O
.	O
To	O
enable	O
this	O
to	O
happen	O
,	O
we	O
modify	O
M	O
c	O
to	O
be	O
M	O
c	O
where	O
p	O
=	O
M	O
c	O
(	O
f	O
)	O
=	O
softmax((W	O
Q)f	O
+	O
b	O
)	O
and	O
Q	O
∈	O
R	O
|C|×d	O
is	O
a	O
masking	O
matrix	O
with	O
being	O
an	O
element	O
-	O
wise	O
multiplication	O
operator	O
.	O
Initially	O
,	O
all	O
elements	O
in	O
Q	O
are	O
ones	O
which	O
enable	O
all	O
the	O
connections	O
between	O
the	O
features	O
and	O
the	O
output	O
.	O
To	O
disable	O
feature	O
f	O
i	O
,	O
we	O
set	O
the	O
i	O
th	O
column	O
of	O
Q	O
to	O
be	O
a	O
zero	O
vector	O
.	O
After	O
disabling	O
features	O
,	O
we	O
then	O
freeze	O
the	O
parameters	O
of	O
M	O
f	O
and	O
fine	O
-	O
tune	O
the	O
parameters	O
of	O
M	O
c	O
(	O
except	O
the	O
masking	O
matrix	O
Q	O
)	O
with	O
the	O
original	O
training	O
dataset	O
D	O
in	O
the	O
final	O
step	O
.	O

Experimental	O
Setup	O

All	O
datasets	O
and	O
their	O
splits	O
used	O
in	O
the	O
experiments	O
are	O
listed	O
in	O
Table	O
1	O
.	O
We	O
will	O
explain	O
each	O
of	O
them	O
in	O
the	O
following	O
sections	O
.	O
For	O
each	O
classification	O
task	O
,	O
we	O
ran	O
and	O
improved	O
three	O
models	O
,	O
using	O
different	O
random	O
seeds	O
,	O
independently	O
of	O
one	O
another	O
,	O
and	O
the	O
reported	O
results	O
are	O
the	O
average	O
of	O
the	O
three	O
runs	O
.	O
Regarding	O
the	O
models	O
,	O
we	O
used	O
1D	O
CNNs	O
with	O
the	O
same	O
structures	O
for	O
all	O
the	O
tasks	O
and	O
datasets	O
.	O
The	O
convolution	O
layer	O
had	O
three	O
filter	O
sizes	O
[	O
2	O
,	O
3	O
,	O
4	O
]	O
with	O
10	O
filters	O
for	O
each	O
size	O
(	O
i.e.	O
,	O
d	O
=	O
10	O
×	O
3	O
=	O
30	O
)	O
.	O
All	O
the	O
activation	O
functions	O
were	O
ReLU	O
except	O
the	O
softmax	O
at	O
the	O
output	O
layer	O
.	O
The	O
input	O
documents	O
were	O
padded	O
or	O
trimmed	O
to	O
have	O
150	O
words	O
(	O
L	O
=	O
150	O
)	O
.	O
We	O
used	O
pre	O
-	O
trained	O
300	O
-	O
dim	O
GloVe	O
vectors	O
(	O
Pennington	O
et	O
al	O
.	O
,	O
2014	O
)	O
as	O
non	O
-	O
trainable	O
weights	O
in	O
the	O
embedding	O
layers	O
.	O
All	O
the	O
models	O
were	O
implemented	O
using	O
Keras	O
and	O
trained	O
with	O
Adam	O
optimizer	O
.	O
We	O
used	O
iNNvestigate	O
(	O
Alber	O
et	O
al	O
.	O
,	O
2018	O
)	O
to	O
run	O
LRP	O
on	O
CNN	O
features	O
.	O
In	O
particular	O
,	O
we	O
used	O
the	O
LRP	O
-	O
propagation	O
rule	O
to	O
stabilize	O
the	O
relevance	O
scores	O
(	O
=	O
10	O
−7	O
)	O
.	O
Finally	O
,	O
we	O
used	O
Amazon	O
Mechanical	O
Turk	O
(	O
MTurk	O
)	O
to	O
collect	O
crowdsourced	O
responses	O
for	O
selecting	O
features	O
to	O
disable	O
.	O
Each	O
question	O
was	O
answered	O
by	O
ten	O
workers	O
and	O
the	O
answers	O
were	O
aggregated	O
using	O
majority	O
votes	O
or	O
average	O
scores	O
depending	O
on	O
the	O
question	O
type	O
(	O
as	O
explained	O
next	O
)	O
.	O

Exp	O
1	O
:	O
Feasibility	O
Study	O

In	O
this	O
feasibility	O
study	O
,	O
we	O
assessed	O
the	O
effectiveness	O
of	O
word	O
clouds	O
as	O
visual	O
explanations	O
to	O
reveal	O
the	O
behavior	O
of	O
CNN	O
features	O
.	O
We	O
trained	O
CNN	O
models	O
using	O
small	O
training	O
datasets	O
and	O
evaluated	O
the	O
quality	O
of	O
CNN	O
features	O
based	O
on	O
responses	O
from	O
MTurk	O
workers	O
to	O
the	O
feature	O
word	O
clouds	O
.	O

Then	O
we	O
disabled	O
features	O
based	O
on	O
their	O
average	O
quality	O
scores	O
.	O
The	O
assumption	O
was	O
:	O
if	O
the	O
scores	O
of	O
the	O
disabled	O
features	O
correlated	O
with	O
the	O
drop	O
in	O
the	O
model	O
predictive	O
performance	O
,	O
it	O
meant	O
that	O
humans	O
could	O
understand	O
and	O
accurately	O
assess	O
CNN	O
features	O
using	O
word	O
clouds	O
.	O
We	O
used	O
small	O
training	O
datasets	O
so	O
that	O
the	O
trained	O
CNNs	O
had	O
features	O
with	O
different	O
levels	O
of	O
quality	O
.	O
Some	O
features	O
detected	O
useful	O
patterns	O
,	O
while	O
others	O
overfitted	O
the	O
training	O
data	O
.	O

Datasets	O

We	O
used	O
subsets	O
of	O
two	O
datasets	O
:	O
(	O
1	O
)	O
Yelp	O
-predicting	O
sentiments	O
of	O
restaurant	O
reviews	O
(	O
positive	O
or	O
negative	O
)	O
and	O
(	O
2	O
)	O
Amazon	O
Products	O
-classifying	O
product	O
reviews	O
into	O
one	O
of	O
four	O
categories	O
(	O
Clothing	O
Shoes	O
and	O
Jewelry	O
,	O
Digital	O
Music	O
,	O
Office	O
Products	O
,	O
or	O
Toys	O
and	O
Games	O
)	O
(	O
He	O
and	O
McAuley	O
,	O
2016	O
)	O
.	O
We	O
sampled	O
500	O
and	O
100	O
examples	O
to	O
be	O
the	O
training	O
data	O
for	O
Yelp	O
and	O
Amazon	O
Products	O
,	O
respectively	O
.	O

Human	O
Feedback	O
Collection	O
and	O
Usage	O

We	O
used	O
human	O
responses	O
on	O
MTurk	O
to	O
assign	O
ranks	O
to	O
features	O
.	O
As	O
each	O
classifier	O
had	O
30	O
original	O
features	O
(	O
d	O
=	O
30	O
)	O
,	O
we	O
divided	O
them	O
into	O
three	O
ranks	O
(	O
A	O
,	O
B	O
,	O
and	O
C	O
)	O
each	O
of	O
which	O
with	O
10	O
features	O
.	O
We	O
expected	O
that	O
features	O
in	O
rank	O
A	O
are	O
most	O
relevant	O
and	O
useful	O
for	O
the	O
prediction	O
task	O
,	O
and	O
features	O
in	O
rank	O
C	O
least	O
relevant	O
,	O
potentially	O
undermining	O
the	O
performance	O
of	O
the	O
model	O
.	O
To	O
make	O
the	O
annotation	O
more	O
accessible	O
to	O
lay	O
users	O
,	O
we	O
designed	O
the	O
questions	O
to	O
ask	O
whether	O
a	O
given	O
word	O
cloud	O
is	O
(	O
mostly	O
or	O
partially	O
)	O
relevant	O
to	O
one	O
of	O
the	O
classes	O
or	O
not	O
,	O
as	O
shown	O
in	O
Figure	O
3	O
.	O
If	O
the	O
answer	O
matches	O
how	O
the	O
model	O
really	O
uses	O
this	O
feature	O
(	O
as	O
indicated	O
by	O
W	O
)	O
,	O
the	O
feature	O
gets	O
a	O
positive	O
score	O
from	O
this	O
human	O
response	O
.	O
For	O
example	O
,	O
if	O
the	O
CNN	O
feature	O
of	O
the	O
word	O
cloud	O
in	O
Figure	O
3	O
is	O
used	O
by	O
the	O
model	O
for	O
the	O
negative	O
sentiment	O
class	O
,	O
the	O
scores	O
of	O
the	O
five	O
options	O
in	O
the	O
figure	O
are	O
-2	O
,	O
-1	O
,	O
0	O
,	O
1	O
,	O
2	O
,	O
respectively	O
.	O
We	O
collected	O
ten	O
responses	O
for	O
each	O
question	O
and	O
used	O
the	O
average	O
score	O
to	O
sort	O
the	O
features	O
descendingly	O
.	O
After	O
sorting	O
,	O
the	O
1	O
st	O
-10	O
th	O
features	O
,	O
11	O
th	O
-20	O
th	O
features	O
,	O
and	O
21	O
st	O
-30	O
th	O
features	O
are	O
considered	O
as	O
rank	O
A	O
,	O
B	O
,	O
and	O
C	O
,	O
respectively	O
.	O
3	O
To	O
show	O
the	O
effects	O
of	O
feature	O
disabling	O
,	O
we	O
compared	O
the	O
original	O
model	O
M	O
with	O
the	O
modified	O
model	O
M	O
with	O
features	O
in	O
rank	O
X	O
disabled	O
where	O
X	O
∈	O
{	O
A	O
,	O
B	O
,	O
C	O
,	O
A	O
and	O
B	O
,	O
A	O
and	O
C	O
,	O
B	O
and	O
C	O
}	O
.	O

Results	O
and	O
Discussions	O

Figure	O
4	O
shows	O
the	O
distribution	O
of	O
average	O
feature	O
scores	O
from	O
one	O
of	O
the	O
three	O
CNN	O
instances	O
for	O
the	O
Yelp	O
dataset	O
.	O
Examples	O
of	O
the	O
word	O
clouds	O
from	O
each	O
rank	O
are	O
displayed	O
in	O
Figure	O
5	O
.	O
We	O
can	O
clearly	O
see	O
dissimilar	O
qualities	O
of	O
the	O
three	O
features	O
.	O
Some	O
participants	O
answered	O
that	O
the	O
rank	O
B	O
feature	O
in	O
Figure	O
5	O
was	O
relevant	O
to	O
the	O
positive	O
class	O
(	O
probably	O
due	O
to	O
the	O
word	O
'	O
delicious	O
'	O
)	O
,	O
and	O
the	O
weights	O
of	O
this	O
feature	O
in	O
W	O
agreed	O
(	O
Positive	O
:	O
Negative	O
=	O
0.137:-0.135	O
)	O
.	O
Interestingly	O
,	O
the	O
rank	O
C	O
feature	O
in	O
Figure	O
5	O
got	O
a	O
negative	O
score	O
because	O
some	O
participants	O
believed	O
that	O
this	O
word	O
cloud	O
was	O
relevant	O
to	O
the	O
positive	O
class	O
,	O
but	O
actually	O
the	O
model	O
used	O
this	O
feature	O
as	O
evidence	O
for	O
the	O
negative	O
class	O
(	O
Positive	O
:	O
Negative	O
=	O
0.209:0.385	O
)	O
.	O

Considering	O
all	O
the	O
three	O
runs	O
,	O
Figure	O
6	O
(	O
top	O
)	O
shows	O
the	O
average	O
macro	O
F1	O
score	O
of	O
the	O
original	O
model	O
(	O
the	O
blue	O
line	O
)	O
and	O
of	O
each	O
modified	O
model	O
.	O
The	O
order	O
of	O
the	O
performance	O
drops	O
is	O
AB	O
>	O
A	O
>	O
AC	O
>	O
BC	O
>	O
B	O
>	O
Original	O
>	O
C.	O
This	O
makes	O
sense	O
because	O
disabling	O
important	O
features	O
(	O
rank	O
A	O
and/or	O
B	O
)	O
caused	O
larger	O
performance	O
drops	O
,	O
and	O
the	O
overall	O
results	O
are	O
consistent	O
with	O
the	O
average	O
fea-	O
ture	O
scores	O
given	O
by	O
the	O
participants	O
(	O
as	O
in	O
Figure	O
4	O
)	O
.	O
It	O
confirms	O
that	O
using	O
word	O
clouds	O
is	O
an	O
effective	O
way	O
to	O
assess	O
CNN	O
features	O
.	O
Also	O
,	O
it	O
is	O
worth	O
noting	O
that	O
the	O
macro	O
F1	O
of	O
the	O
model	O
slightly	O
increased	O
when	O
we	O
disabled	O
the	O
low	O
-	O
quality	O
features	O
(	O
rank	O
C	O
)	O
.	O
This	O
shows	O
that	O
humans	O
can	O
improve	O
the	O
model	O
by	O
disabling	O
irrelevant	O
features	O
.	O

The	O
CNNs	O
for	O
the	O
Amazon	O
Products	O
dataset	O
also	O
behaved	O
in	O
a	O
similar	O
way	O
(	O
Figure	O
6	O
-bottom	O
)	O
,	O
except	O
that	O
disabling	O
rank	O
C	O
features	O
slightly	O
undermined	O
,	O
not	O
increased	O
,	O
performance	O
.	O
This	O
implies	O
that	O
even	O
the	O
rank	O
C	O
features	O
contain	O
a	O
certain	O
amount	O
of	O
useful	O
knowledge	O
for	O
this	O
classifier	O
.	O
4	O

6	O
Exp	O
2	O
:	O
Training	O
Data	O
with	O
Biases	O

Given	O
a	O
biased	O
training	O
dataset	O
,	O
a	O
text	O
classifier	O
may	O
absorb	O
the	O
biases	O
and	O
produce	O
biased	O
predictions	O
against	O
some	O
sub	O
-	O
populations	O
.	O
We	O
hypothesize	O
that	O
if	O
the	O
biases	O
are	O
captured	O
by	O
some	O
of	O
the	O
learned	O
features	O
,	O
we	O
can	O
apply	O
FIND	O
to	O
disable	O
such	O
features	O
and	O
reduce	O
the	O
model	O
biases	O
.	O

Datasets	O
and	O
Metrics	O

We	O
focus	O
on	O
reducing	O
gender	O
bias	O
of	O
CNN	O
models	O
trained	O
on	O
two	O
datasets	O
-Biosbias	O
(	O
De	O
-	O
Arteaga	O
et	O
al	O
.	O
,	O
2019	O
)	O
and	O
Waseem	O
(	O
Waseem	O
and	O
Hovy	O
,	O
2016	O
)	O
.	O
For	O
Biosbias	O
,	O
the	O
task	O
is	O
predicting	O
the	O
occupation	O
of	O
a	O
given	O
bio	O
paragraph	O
,	O
i.e.	O
,	O
whether	O
the	O
person	O
is	O
'	O
a	O
surgeon	O
'	O
(	O
class	O
0	O
)	O
or	O
'	O
a	O
nurse	O
'	O
(	O
class	O
1	O
)	O
.	O
Due	O
to	O
the	O
gender	O
imbalance	O
in	O
each	O
occupation	O
,	O
a	O
classifier	O
usually	O
exploits	O
gender	O
information	O
when	O
making	O
predictions	O
.	O
As	O
a	O
result	O
,	O
bios	O
of	O
female	O
surgeons	O
and	O
male	O
nurses	O
are	O
often	O
misclassified	O
.	O
For	O
Waseem	O
,	O
the	O
task	O
is	O
abusive	O
language	O
detection	O
-assessing	O
if	O
a	O
given	O
text	O
is	O
abusive	O
(	O
class	O
1	O
)	O
or	O
not	O
abusive	O
(	O
class	O
0	O
)	O
.	O
Previous	O
work	O
found	O
that	O
this	O
dataset	O
contains	O
a	O
strong	O
negative	O
bias	O
against	O
females	O
(	O
Park	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O
In	O
other	O
words	O
,	O
texts	O
related	O
to	O
females	O
are	O
usually	O
classified	O
as	O
abusive	O
although	O
the	O
texts	O
themselves	O
are	O
not	O
abusive	O
at	O
all	O
.	O
Also	O
,	O
we	O
tested	O
the	O
models	O
,	O
trained	O
on	O
the	O
Waseem	O
dataset	O
,	O
using	O
another	O
abusive	O
language	O
detection	O
dataset	O
,	O
Wikitoxic	O
(	O
Thain	O
et	O
al	O
.	O
,	O
2017	O
)	O
,	O
to	O
assess	O
generalizability	O
of	O
the	O
models	O
.	O
To	O
quantify	O
gender	O
biases	O
,	O
we	O
adopted	O
two	O
metrics	O
-false	O
positive	O
equality	O
difference	O
(	O
FPED	O
)	O
and	O
false	O
negative	O
equality	O
difference	O
(	O
FNED	O
)	O
(	O
Dixon	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O

The	O
lower	O
these	O
metrics	O
are	O
,	O
the	O
less	O
biases	O
the	O
model	O
has	O
.	O
4	O
We	O
also	O
conducted	O
the	O
same	O
experiments	O
here	O
with	O
bidirectional	O
LSTM	O
networks	O
(	O
BiLSTMs	O
)	O
which	O
required	O
a	O
different	O
way	O
to	O
generate	O
the	O
word	O
clouds	O
(	O
see	O
Appendix	O
C	O
)	O
.	O
The	O
results	O
on	O
BiLSTMs	O
,	O
however	O
,	O
are	O
not	O
as	O
promising	O
as	O
on	O
CNNs	O
.	O
This	O
might	O
be	O
because	O
the	O
way	O
we	O
created	O
word	O
clouds	O
for	O
each	O
BiLSTM	O
feature	O
was	O
not	O
an	O
accurate	O
way	O
to	O
reveal	O
its	O
behavior	O
.	O
Unlike	O
for	O
CNNs	O
,	O
understanding	O
recurrent	O
neural	O
network	O
features	O
for	O
text	O
classification	O
is	O
still	O
an	O
open	O
problem	O
.	O

Human	O
Feedback	O
Collection	O
and	O
Usage	O

Unlike	O
the	O
interface	O
in	O
Figure	O
3	O
,	O
for	O
each	O
word	O
cloud	O
,	O
we	O
asked	O
the	O
participants	O
to	O
select	O
the	O
relevant	O
class	O
from	O
three	O
options	O
(	O
Biosbias	O
:	O
surgeon	O
,	O
nurse	O
,	O
it	O
could	O
be	O
either	O
/	O
Waseem	O
:	O
abusive	O
,	O
nonabusive	O
,	O
it	O
could	O
be	O
either	O
)	O
.	O
The	O
feature	O
will	O
be	O
disabled	O
if	O
the	O
majority	O
vote	O
does	O
not	O
select	O
the	O
class	O
suggested	O
by	O
the	O
weight	O
matrix	O
W.	O
To	O
ensure	O
that	O
the	O
participants	O
do	O
not	O
use	O
their	O
biases	O
while	O
answering	O
our	O
questions	O
,	O
we	O
firmly	O
mentioned	O
in	O
the	O
instructions	O
that	O
gender	O
-	O
related	O
terms	O
should	O
not	O
be	O
used	O
as	O
an	O
indicator	O
for	O
one	O
or	O
the	O
other	O
class	O
.	O

Results	O
and	O
Discussions	O

The	O
results	O
of	O
this	O
experiment	O
are	O
displayed	O
in	O
Figure	O
7	O
.	O
For	O
Biosbias	O
,	O
on	O
average	O
,	O
the	O
participants	O
'	O
responses	O
suggested	O
us	O
to	O
disable	O
11.33	O
out	O
of	O
30	O
CNN	O
features	O
.	O
By	O
doing	O
so	O
,	O
the	O
FPED	O
of	O
the	O
models	O
decreased	O
from	O
0.250	O
to	O
0.163	O
,	O
and	O
the	O
FNED	O
decreased	O
from	O
0.338	O
to	O
0.149	O
.	O
After	O
investigating	O
the	O
word	O
clouds	O
of	O
the	O
CNN	O
features	O
,	O
we	O
found	O
that	O
some	O
of	O
them	O
detected	O
patterns	O
containing	O
both	O
gender	O
-	O
related	O
terms	O
and	O
occupation	O
-	O
related	O
terms	O
such	O
as	O
"	O
his	O
surgical	O
expertise	O
"	O
and	O
"	O
she	O
supervises	O
nursing	O
students	O
"	O
.	O
Most	O
of	O
the	O
MTurk	O
participants	O
answered	O
that	O
these	O
word	O
clouds	O
were	O
relevant	O
to	O
the	O
occupations	O
,	O
and	O
thus	O
the	O
corresponding	O
features	O
were	O
not	O
disabled	O
.	O
However	O
,	O
we	O
believe	O
that	O
these	O
features	O
might	O
contain	O
gender	O
biases	O
.	O
So	O
,	O
we	O
asked	O
one	O
annotator	O
to	O
consider	O
all	O
the	O
word	O
clouds	O
again	O
and	O
disable	O
every	O
feature	O
for	O
which	O
the	O
prominent	O
n	O
-	O
gram	O
patterns	O
contained	O
any	O
genderrelated	O
terms	O
,	O
no	O
matter	O
whether	O
the	O
patterns	O
detect	O
occupation	O
-	O
related	O
terms	O
.	O
With	O
this	O
new	O
disabling	O
policy	O
,	O
12	O
out	O
of	O
30	O
features	O
were	O
disabled	O
on	O
average	O
,	O
and	O
the	O
model	O
biases	O
further	O
decreased	O
,	O
as	O
shown	O
in	O
Figure	O
7	O
(	O
Debugged	O
(	O
One	O
)	O
)	O
.	O
The	O
sideeffect	O
of	O
disabling	O
33	O
%	O
of	O
all	O
the	O
features	O
here	O
was	O
only	O
a	O
slight	O
drop	O
in	O
the	O
macro	O
F1	O
from	O
0.950	O
to	O
0.933	O
.	O
Hence	O
,	O
our	O
framework	O
was	O
successful	O
in	O
reducing	O
gender	O
biases	O
without	O
severe	O
negative	O
effects	O
in	O
classification	O
performance	O
.	O

Concerning	O
the	O
abusive	O
language	O
detection	O
task	O
,	O
on	O
average	O
,	O
the	O
MTurk	O
participants	O
'	O
responses	O
suggested	O
us	O
to	O
disable	O
12	O
out	O
of	O
30	O
CNN	O
features	O
.	O
Unlike	O
Biosbias	O
,	O
disabling	O
features	O
based	O
on	O
MTurk	O
responses	O
unexpectedly	O
increased	O
the	O
gender	O
bias	O
for	O
both	O
Waseem	O
and	O
Wikitoxic	O
datasets	O
.	O
However	O
,	O
we	O
found	O
one	O
similar	O
finding	O
to	O
Biosbias	O
,	O
that	O
many	O
of	O
the	O
CNN	O
features	O
captured	O
n	O
-	O
grams	O
which	O
were	O
both	O
abusive	O
and	O
related	O
to	O
a	O
gender	O
such	O
as	O
'	O
these	O
girls	O
are	O
terrible	O
'	O
and	O
'	O
of	O
raping	O
slave	O
girls	O
'	O
,	O
and	O
these	O
features	O
were	O
not	O
yet	O
disabled	O
.	O
So	O
,	O
we	O
asked	O
one	O
annotator	O
to	O
disable	O
the	O
features	O
using	O
the	O
new	O
"	O
brutal	O
"	O
policy	O
-disabling	O
all	O
which	O
involved	O
gender	O
words	O
even	O
though	O
some	O
of	O
them	O
also	O
detected	O
abusive	O
words	O
.	O
By	O
disabling	O
18	O
out	O
of	O
30	O
features	O
on	O
average	O
,	O
the	O
gender	O
biases	O
were	O
reduced	O
for	O
both	O
datasets	O
(	O
except	O
FPED	O
on	O
Wikitoxic	O
which	O
stayed	O
close	O
to	O
the	O
original	O
value	O
)	O
.	O
Another	O
consequence	O
was	O
that	O
we	O
sacrificed	O
4	O
%	O
and	O
1	O
%	O
macro	O
F1	O
on	O
the	O
Waseem	O
and	O
Wikitoxic	O
datasets	O
,	O
respectively	O
.	O
This	O
finding	O
is	O
consistent	O
with	O
(	O
Park	O
et	O
al	O
.	O
,	O
2018	O
)	O
that	O
reducing	O
the	O
bias	O
and	O
maintaining	O
the	O
classification	O
performance	O
at	O
the	O
same	O
time	O
is	O
very	O
challenging	O
.	O

Exp	O
3	O
:	O
Dataset	O
Shift	O

Dataset	O
shift	O
is	O
a	O
problem	O
where	O
the	O
joint	O
distribution	O
of	O
inputs	O
and	O
outputs	O
differs	O
between	O
training	O
and	O
test	O
stage	O
(	O
Quionero	O
-	O
Candela	O
et	O
al	O
.	O
,	O
2009	O
)	O
.	O
Many	O
classifiers	O
perform	O
poorly	O
under	O
dataset	O
shift	O
because	O
some	O
of	O
the	O
learned	O
features	O
are	O
inapplicable	O
(	O
or	O
sometimes	O
even	O
harmful	O
)	O
to	O
classify	O
test	O
documents	O
.	O
We	O
hypothesize	O
that	O
FIND	O
is	O
useful	O
for	O
investigating	O
the	O
learned	O
features	O
and	O
disabling	O
the	O
overfitting	O
ones	O
to	O
increase	O
the	O
generalizability	O
of	O
the	O
model	O
.	O

Datasets	O

We	O
considered	O
two	O
tasks	O
in	O
this	O
experiment	O
.	O
The	O
first	O
task	O
aims	O
to	O
classify	O
"	O
Christianity	O
"	O
vs	O
"	O
Atheism	O
"	O
documents	O
from	O
the	O
20	O
Newsgroups	O
dataset	O
5	O
.	O
This	O
dataset	O
is	O
special	O
because	O
it	O
contains	O
a	O
lot	O
of	O
artifacts	O
-tokens	O
(	O
e.g.	O
,	O
person	O
names	O
,	O
punctuation	O
marks	O
)	O
which	O
are	O
not	O
relevant	O
,	O
but	O
strongly	O
co	O
-	O
occur	O
with	O
one	O
of	O
the	O
classes	O
.	O
For	O
evaluation	O
,	O
we	O
used	O
the	O
Religion	O
dataset	O
by	O
Ribeiro	O
et	O
al	O
.	O
(	O
2016	O
)	O
,	O
containing	O
"	O
Christianity	O
"	O
and	O
"	O
Atheism	O
"	O
web	O
pages	O
,	O
as	O
a	O
target	O
dataset	O
.	O
The	O
second	O
task	O
is	O
sentiment	O
analysis	O
.	O
We	O
used	O
,	O
as	O
a	O
training	O
dataset	O
,	O
Amazon	O
Clothes	O
,	O
with	O
reviews	O
of	O
clothing	O
,	O
shoes	O
,	O
and	O
jewelry	O
products	O
(	O
He	O
and	O
McAuley	O
,	O
2016	O
)	O
,	O
and	O
as	O
test	O
sets	O
three	O
out	O
-	O
of	O
-	O
distribution	O
datasets	O
-Amazon	O
Music	O
(	O
He	O
and	O
McAuley	O
,	O
2016	O
)	O
,	O
Amazon	O
Mixed	O
,	O
and	O
the	O
Yelp	O
dataset	O
(	O
which	O
was	O
used	O
in	O
Experiment	O
1	O
)	O
.	O
Amazon	O
Music	O
contains	O
only	O
reviews	O
from	O
the	O
"	O
Digital	O
Music	O
"	O
product	O
category	O
which	O
was	O
found	O
to	O
have	O
an	O
extreme	O
distribution	O
shift	O
from	O
the	O
clothes	O
category	O
(	O
Hendrycks	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
Amazon	O
Mixed	O
compiles	O
the	O
reviews	O
from	O
various	O
kinds	O
of	O
products	O
,	O
while	O
Yelp	O
focuses	O
on	O
restaurant	O
reviews	O
.	O

Human	O
Feedback	O
Collection	O
and	O
Usage	O

We	O
collected	O
responses	O
from	O
MTurk	O
workers	O
using	O
the	O
same	O
user	O
interfaces	O
as	O
in	O
Experiment	O
2	O
.	O
Simply	O
put	O
,	O
we	O
asked	O
the	O
workers	O
to	O
select	O
a	O
class	O
which	O
was	O
relevant	O
to	O
a	O
given	O
word	O
cloud	O
and	O
checked	O
if	O
the	O
majority	O
vote	O
agreed	O
with	O
the	O
weights	O
in	O
W.	O

Results	O
and	O
Discussions	O

For	O
the	O
first	O
task	O
,	O
on	O
average	O
,	O
14.33	O
out	O
of	O
30	O
features	O
were	O
disabled	O
and	O
the	O
macro	O
F1	O
scores	O
of	O
the	O
20Newsgroups	O
before	O
and	O
after	O
debugging	O
are	O
0.853	O
and	O
0.828	O
,	O
respectively	O
.	O
The	O
same	O
metrics	O
of	O
the	O
Religion	O
dataset	O
are	O
0.731	O
and	O
0.799	O
.	O
This	O
shows	O
that	O
disabling	O
irrelevant	O
features	O
mildly	O
undermined	O
the	O
predictive	O
performance	O
on	O
the	O
indistribution	O
dataset	O
,	O
but	O
clearly	O
enhanced	O
the	O
performance	O
on	O
the	O
out	O
-	O
of	O
-	O
distribution	O
dataset	O
(	O
see	O
Figure	O
8	O
,	O
left	O
)	O
.	O
This	O
is	O
especially	O
evident	O
for	O
the	O
Atheism	O
class	O
for	O
which	O
the	O
F1	O
score	O
increased	O
around	O
15	O
%	O
absolute	O
.	O
We	O
noticed	O
from	O
the	O
word	O
clouds	O
that	O
many	O
prominent	O
words	O
for	O
the	O
Atheism	O
class	O
learned	O
by	O
the	O
models	O
are	O
person	O
names	O
(	O
e.g.	O
,	O
Keith	O
,	O
Gregg	O
,	O
Schneider	O
)	O
and	O
these	O
are	O
not	O
applicable	O
to	O
the	O
Religion	O
dataset	O
.	O
Forcing	O
the	O
models	O
to	O
use	O
only	O
relevant	O
features	O
(	O
detecting	O
terms	O
like	O
'	O
atheists	O
'	O
and	O
'	O
science	O
'	O
)	O
,	O
therefore	O
,	O
increased	O
the	O
macro	O
F1	O
on	O
the	O
Religion	O
dataset	O
.	O

Unlike	O
20Newsgroups	O
,	O
Amazon	O
Clothes	O
does	O
not	O
seem	O
to	O
have	O
obvious	O
artifacts	O
.	O
Still	O
,	O
the	O
re	O
-	O
sponses	O
from	O
crowd	O
workers	O
suggested	O
that	O
we	O
disable	O
6	O
features	O
.	O
The	O
disabled	O
features	O
were	O
correlated	O
to	O
,	O
but	O
not	O
the	O
reason	O
for	O
,	O
the	O
associated	O
class	O
.	O
For	O
instance	O
,	O
one	O
of	O
the	O
disabled	O
features	O
was	O
highly	O
activated	O
by	O
the	O
pattern	O
"	O
my	O
....	O
year	O
old	O
"	O
which	O
often	O
appeared	O
in	O
positive	O
reviews	O
such	O
as	O
"	O
my	O
3	O
year	O
old	O
son	O
loves	O
this	O
.	O
"	O
.	O
However	O
,	O
these	O
correlated	O
features	O
are	O
not	O
very	O
useful	O
for	O
the	O
three	O
outof	O
-	O
distribution	O
datasets	O
(	O
Music	O
,	O
Mixed	O
,	O
and	O
Yelp	O
)	O
.	O
Disabling	O
them	O
made	O
the	O
model	O
focus	O
more	O
on	O
the	O
right	O
evidence	O
and	O
increased	O
the	O
average	O
macro	O
F1	O
for	O
the	O
three	O
datasets	O
,	O
as	O
shown	O
in	O
Figure	O
8	O
(	O
right	O
)	O
.	O
Nonetheless	O
,	O
the	O
performance	O
improvement	O
here	O
was	O
not	O
as	O
apparent	O
as	O
in	O
the	O
previous	O
task	O
because	O
,	O
even	O
without	O
feature	O
disabling	O
,	O
the	O
majority	O
of	O
the	O
features	O
are	O
relevant	O
to	O
the	O
task	O
and	O
can	O
lead	O
the	O
model	O
to	O
the	O
correct	O
predictions	O
in	O
most	O
cases	O
.	O
6	O

Discussion	O
and	O
Conclusions	O

We	O
proposed	O
FIND	O
,	O
a	O
framework	O
which	O
enables	O
humans	O
to	O
debug	O
deep	O
text	O
classifiers	O
by	O
disabling	O
irrelevant	O
or	O
harmful	O
features	O
.	O
Using	O
the	O
proposed	O
framework	O
on	O
CNN	O
text	O
classifiers	O
,	O
we	O
found	O
that	O
(	O
i	O
)	O
word	O
clouds	O
generated	O
by	O
running	O
LRP	O
on	O
the	O
training	O
data	O
accurately	O
revealed	O
the	O
behaviors	O
of	O
CNN	O
features	O
,	O
(	O
ii	O
)	O
some	O
of	O
the	O
learned	O
features	O
might	O
be	O
more	O
useful	O
to	O
the	O
task	O
than	O
the	O
others	O
and	O
(	O
iii	O
)	O
disabling	O
the	O
irrelevant	O
or	O
harmful	O
features	O
could	O
improve	O
the	O
model	O
predictive	O
performance	O
and	O
reduce	O
unintended	O
biases	O
in	O
the	O
model	O
.	O

Generalization	O
to	O
Other	O
Models	O

In	O
order	O
to	O
generalize	O
the	O
framework	O
beyond	O
CNNs	O
,	O
there	O
are	O
two	O
questions	O
to	O
consider	O
.	O
First	O
,	O
what	O
is	O
an	O
effective	O
way	O
to	O
understand	O
each	O
feature	O
?	O
We	O
exemplified	O
this	O
with	O
two	O
word	O
clouds	O
representing	O
each	O
BiLSTM	O
feature	O
in	O
Appendix	O
C	O
,	O
and	O
we	O
plan	O
to	O
experiment	O
with	O
advanced	O
visualizations	O
such	O
as	O
LSTMVis	O
(	O
Strobelt	O
et	O
al	O
.	O
,	O
2018	O
)	O
in	O
the	O
future	O
.	O
Second	O
,	O
can	O
we	O
make	O
the	O
model	O
features	O
more	O
interpretable	O
?	O
For	O
example	O
,	O
using	O
ReLU	O
as	O
activation	O
functions	O
in	O
LSTM	O
cells	O
(	O
instead	O
of	O
tanh	O
)	O
renders	O
the	O
features	O
non	O
-	O
negative	O
.	O
So	O
,	O
they	O
can	O
be	O
summarized	O
using	O
one	O
word	O
cloud	O
which	O
is	O
more	O
practical	O
for	O
debugging	O
.	O

In	O
general	O
,	O
the	O
principle	O
of	O
FIND	O
is	O
understanding	O
the	O
features	O
and	O
then	O
disabling	O
the	O
irrelevant	O
ones	O
.	O
The	O
process	O
makes	O
visualizations	O
and	O
interpretability	O
more	O
actionable	O
.	O
Over	O
the	O
past	O
few	O
years	O
,	O
we	O
have	O
seen	O
rapid	O
growth	O
of	O
scientific	O
research	O
in	O
both	O
topics	O
(	O
visualizations	O
and	O
interpretability	O
)	O
aiming	O
to	O
understand	O
many	O
emerging	O
advanced	O
models	O
including	O
the	O
popular	O
transformer	O
-	O
based	O
models	O
(	O
Jo	O
and	O
Myaeng	O
,	O
2020;Voita	O
et	O
al	O
.	O
,	O
2019;Hoover	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O
We	O
believe	O
that	O
our	O
work	O
will	O
inspire	O
other	O
researchers	O
to	O
foster	O
advances	O
in	O
both	O
topics	O
towards	O
the	O
more	O
tangible	O
goal	O
of	O
model	O
debugging	O
.	O

Generalization	O
to	O
Other	O
Tasks	O

FIND	O
is	O
suitable	O
for	O
any	O
text	O
classification	O
tasks	O
where	O
a	O
model	O
might	O
learn	O
irrelevant	O
or	O
harmful	O
features	O
during	O
training	O
.	O
It	O
is	O
also	O
convenient	O
to	O
use	O
since	O
only	O
the	O
trained	O
model	O
and	O
the	O
training	O
data	O
are	O
required	O
as	O
input	O
.	O
Moreover	O
,	O
it	O
can	O
address	O
many	O
problems	O
simultaneously	O
such	O
as	O
removing	O
religious	O
and	O
racial	O
bias	O
together	O
with	O
gender	O
bias	O
even	O
if	O
we	O
might	O
not	O
be	O
aware	O
of	O
such	O
problems	O
before	O
using	O
FIND	O
.	O
In	O
general	O
cases	O
,	O
FIND	O
is	O
at	O
least	O
useful	O
for	O
model	O
verification	O
.	O

For	O
future	O
work	O
,	O
it	O
would	O
be	O
interesting	O
to	O
extend	O
FIND	O
to	O
other	O
NLP	O
tasks	O
,	O
e.g.	O
,	O
question	O
answering	O
and	O
natural	O
language	O
inference	O
.	O
This	O
will	O
require	O
some	O
modifications	O
to	O
understand	O
how	O
the	O
features	O
capture	O
relationships	O
between	O
two	O
input	O
texts	O
.	O

Limitations	O

Nevertheless	O
,	O
FIND	O
has	O
some	O
limitations	O
.	O
First	O
,	O
the	O
word	O
clouds	O
may	O
reveal	O
sensitive	O
contents	O
in	O
the	O
training	O
data	O
to	O
human	O
debuggers	O
.	O
Second	O
,	O
the	O
more	O
hidden	O
features	O
the	O
model	O
has	O
,	O
the	O
more	O
human	O
effort	O
FIND	O
needs	O
for	O
debugging	O
.	O
For	O
instance	O
,	O
BERT	O
-	O
base	O
(	O
Devlin	O
et	O
al	O
.	O
,	O
2019	O
)	O
has	O
768	O
features	O
(	O
before	O
the	O
final	O
dense	O
layer	O
)	O
which	O
require	O
lots	O
of	O
human	O
effort	O
to	O
perform	O
investigation	O
.	O
In	O
this	O
case	O
,	O
it	O
would	O
be	O
more	O
efficient	O
to	O
use	O
FIND	O
to	O
disable	O
attention	O
heads	O
rather	O
than	O
individual	O
features	O
(	O
Voita	O
et	O
al	O
.	O
,	O
2019	O
)	O
.	O
Third	O
,	O
it	O
is	O
possible	O
that	O
one	O
feature	O
detects	O
several	O
patterns	O
(	O
Jacovi	O
et	O
al	O
.	O
,	O
2018	O
)	O
and	O
it	O
will	O
be	O
difficult	O
to	O
disable	O
the	O
feature	O
if	O
some	O
of	O
the	O
detected	O
patterns	O
are	O
useful	O
while	O
the	O
others	O
are	O
harmful	O
.	O
Hence	O
,	O
FIND	O
would	O
be	O
more	O
effective	O
when	O
used	O
together	O
with	O
disentangled	O
text	O
representations	O
(	O
Cheng	O
et	O
al	O
.	O
,	O
2020	O
)	O
.	O

A	O
Layer	O
-	O
wise	O
Relevance	O
Propagation	O

Layer	O
-	O
wise	O
Relevance	O
Propagation	O
(	O
LRP	O
)	O
is	O
a	O
technique	O
for	O
explaining	O
predictions	O
of	O
neural	O
networks	O
in	O
terms	O
of	O
importance	O
scores	O
of	O
input	O
features	O
(	O
Bach	O
et	O
al	O
.	O
,	O
2015	O
)	O
.	O
Originally	O
,	O
it	O
was	O
devised	O
to	O
explain	O
predictions	O
of	O
image	O
classifiers	O
by	O
creating	O
a	O
heatmap	O
on	O
the	O
input	O
image	O
highlighting	O
pixels	O
that	O
are	O
important	O
for	O
the	O
classification	O
.	O
Then	O
Arras	O
et	O
al	O
.	O
(	O
2016	O
)	O
and	O
Arras	O
et	O
al	O
.	O
(	O
2017	O
)	O
extended	O
LRP	O
to	O
work	O
on	O
CNNs	O
and	O
RNNs	O
for	O
text	O
classification	O
,	O
respectively	O
.	O

Consider	O
a	O
neuron	O
k	O
whose	O
value	O
is	O
computed	O
using	O
n	O
neurons	O
in	O
the	O
previous	O
layer	O
,	O

x	O
k	O
=	O
g	O
(	O
n	O
j=1	O
x	O
j	O
w	O
jk	O
+	O
b	O
k	O
)	O

where	O
x	O
k	O
is	O
the	O
value	O
of	O
the	O
neuron	O
k	O
,	O
g	O
is	O
a	O
nonlinear	O
activation	O
function	O
,	O
w	O
jk	O
and	O
b	O
k	O
are	O
weights	O
and	O
bias	O
in	O
the	O
network	O
,	O
respectively	O
.	O
We	O
can	O
see	O
that	O
the	O
contribution	O
of	O
a	O
single	O
node	O
j	O
to	O
the	O
value	O
of	O
the	O
node	O
k	O
is	O

z	O
jk	O
=	O
x	O
j	O
w	O
jk	O
+	O
b	O
k	O
n	O

assuming	O
that	O
the	O
bias	O
term	O
b	O
k	O
is	O
distributed	O
equally	O
to	O
the	O
n	O
neurons	O
.	O
LRP	O
works	O
by	O
propagating	O
the	O
activation	O
of	O
a	O
neuron	O
of	O
interest	O
back	O
through	O
the	O
previous	O
layers	O
in	O
the	O
network	O
proportionally	O
.	O
We	O
call	O
the	O
value	O
each	O
neuron	O
receives	O
a	O
relevance	O
score	O
(	O
R	O
)	O
of	O
the	O
neuron	O
.	O
To	O
back	O
propagate	O
,	O
if	O
the	O
relevance	O
score	O
of	O
the	O
neuron	O
k	O
is	O
R	O
k	O
,	O
the	O
relevance	O
score	O
that	O
the	O
neuron	O
j	O
receives	O
from	O
the	O
neuron	O

k	O
is	O
R	O
j←k	O
=	O
z	O
jk	O
n	O
j	O
=	O
1	O
z	O
j	O
k	O
R	O
k	O

To	O
make	O
the	O
relevance	O
propagation	O
more	O
stable	O
,	O
we	O
add	O
a	O
small	O
positive	O
number	O
(	O
as	O
a	O
stabilizer	O
)	O
to	O
the	O
denominator	O
of	O
the	O
propagation	O
rule	O
:	O

R	O
j←k	O
=	O
z	O
jk	O
+	O
n	O
j	O
=	O
1	O
z	O
j	O
k	O
R	O
k	O

We	O
used	O
this	O
propagation	O
rule	O
,	O
so	O
called	O
LRP-	O
,	O
in	O
the	O
experiments	O
of	O
this	O
paper	O
.	O
For	O
more	O
details	O
about	O
LRP	O
propagation	O
rules	O
,	O
please	O
see	O
Montavon	O
et	O
al	O
.	O
(	O
2019	O
)	O
.	O

To	O
explain	O
a	O
prediction	O
of	O
a	O
CNN	O
text	O
classifier	O
,	O
we	O
propagate	O
an	O
activation	O
value	O
of	O
the	O
output	O
node	O
back	O
to	O
the	O
word	O
embedding	O
matrix	O
.	O
After	O
that	O
,	O
the	O
relevance	O
score	O
of	O
an	O
input	O
word	O
equals	O
the	O
sum	O
of	O
relevance	O
scores	O
each	O
dimension	O
of	O
its	O
word	O
vector	O
receives	O
.	O
However	O
,	O
in	O
this	O
paper	O
,	O
we	O
want	O
to	O
analyze	O
the	O
hidden	O
features	O
rather	O
than	O
the	O
output	O
,	O
so	O
we	O
start	O
back	O
propagating	O
from	O
the	O
hidden	O
features	O
instead	O
to	O
capture	O
patterns	O
of	O
input	O
words	O
which	O
highly	O
activate	O
the	O
features	O
.	O

B	O
Multiclass	O
Classification	O

As	O
shown	O
in	O
Figure	O
9	O
,	O
we	O
used	O
a	O
slightly	O
different	O
user	O
interface	O
in	O
Experiment	O
1	O
for	O
the	O
Amazon	O
Products	O
dataset	O
which	O
is	O
a	O
multiclass	O
classification	O
task	O
.	O
In	O
this	O
setting	O
,	O
we	O
did	O
not	O
provide	O
the	O
options	O
for	O
mostly	O
and	O
partly	O
relevant	O
;	O
otherwise	O
,	O
there	O
would	O
have	O
been	O
nine	O
options	O
per	O
question	O
which	O
are	O
too	O
many	O
for	O
the	O
participants	O
to	O
answer	O
accurately	O
.	O
With	O
the	O
user	O
interface	O
in	O
Figure	O
9	O
,	O
we	O
gave	O
a	O
score	O
to	O
the	O
feature	O
f	O
i	O
based	O
on	O
the	O
participant	O
answer	O
.	O
To	O
explain	O
,	O
we	O
re	O
-	O
scaled	O
values	O
in	O
the	O
i	O
th	O
column	O
of	O
W	O
to	O
be	O
in	O
the	O
range	O
[	O
0,1	O
]	O
using	O
min	O
-	O
max	O
normalization	O
and	O
gave	O
the	O
normalized	O
value	O
of	O
the	O
chosen	O
class	O
as	O
a	O
score	O
to	O
the	O
feature	O
f	O
i	O
.	O
If	O
the	O
participant	O
selects	O
None	O
,	O
this	O
feature	O
gets	O
a	O
zero	O
score	O
.	O
The	O
distribution	O
of	O
the	O
average	O
feature	O
scores	O
for	O
this	O
task	O
(	O
one	O
CNN	O
)	O
is	O
displayed	O
in	O
Figure	O
10	O
.	O

C	O
Bidirectional	O
LSTM	O
networks	O

To	O
understand	O
BiLSTM	O
features	O
,	O
we	O
created	O
two	O
word	O
clouds	O
for	O
each	O
feature	O
.	O
The	O
first	O
word	O
cloud	O
contains	O
top	O
three	O
words	O
which	O
gain	O
the	O
highest	O
positive	O
relevance	O
scores	O
from	O
each	O
training	O
example	O
,	O
while	O
the	O
second	O
word	O
cloud	O
does	O
the	O
same	O
but	O
for	O
the	O
top	O
three	O
words	O
which	O
gain	O
the	O
lowest	O
negative	O
relevance	O
scores	O
(	O
see	O
Figure	O
11	O
)	O
.	O

Furthermore	O
,	O
we	O
also	O
conducted	O
Experiment	O
1	O
for	O
BiLSTMs	O
.	O
Each	O
direction	O
of	O
the	O
recurrent	O
layer	O
had	O
15	O
hidden	O
units	O
and	O
the	O
feature	O
vector	O
was	O
obtained	O
by	O
taking	O
element	O
-	O
wise	O
max	O
of	O
all	O
the	O
hidden	O
states	O
(	O
i.e.	O
,	O
d	O
=	O
15	O
×	O
2	O
=	O
30	O
)	O
.	O
We	O
adapted	O
the	O
code	O
of	O
(	O
Arras	O
et	O
al	O
.	O
,	O
2017	O
)	O
to	O
run	O
LRP	O
on	O
BiLSTMs	O
.	O
Regarding	O
human	O
feedback	O
collection	O
,	O
we	O
collected	O
feedback	O
from	O
Amazon	O
Mechanical	O
Turk	O
workers	O
by	O
splitting	O
the	O
pair	O
of	O
word	O
clouds	O
into	O
two	O
and	O
asking	O
the	O
question	O
about	O
the	O
relevant	O
class	O
independently	O
of	O
each	O
other	O
.	O
The	O
answer	O
of	O
the	O
positive	O
relevance	O
word	O
cloud	O
should	O
be	O
consistent	O
with	O
the	O
weight	O
matrix	O
W	O
,	O
while	O
the	O
answer	O
of	O
the	O
negative	O
relevance	O
word	O
cloud	O
should	O
be	O
the	O
opposite	O
of	O
the	O
weight	O
matrix	O
W.	O
The	O
score	O
of	O
a	O
BiLSTM	O
feature	O
is	O
the	O
sum	O
of	O
its	O
scores	O
from	O
the	O
positive	O
word	O
cloud	O
and	O
the	O
negative	O
word	O
cloud	O
.	O

The	O
results	O
of	O
the	O
extra	O
BiLSTM	O
experiments	O
are	O
shown	O
in	O
Table	O
4	O
and	O
5	O
.	O
Table	O
4	O
shows	O
unexpected	O
results	O
after	O
disabling	O
features	O
.	O
For	O
instance	O
,	O
disabling	O
rank	O
B	O
features	O
caused	O
a	O
larger	O
performance	O
drop	O
than	O
removing	O
rank	O
A	O
features	O
.	O
This	O
suggests	O
that	O
how	O
we	O
created	O
word	O
clouds	O
for	O
each	O
BiLSTM	O
feature	O
(	O
i.e.	O
,	O
displaying	O
top	O
three	O
words	O
with	O
the	O
highest	O
positive	O
and	O
lowest	O
negative	O
rel-	O
evance	O
)	O
might	O
not	O
be	O
an	O
accurate	O
way	O
to	O
explain	O
the	O
feature	O
.	O
Nevertheless	O
,	O
another	O
observation	O
from	O
Table	O
4	O
is	O
that	O
even	O
when	O
we	O
disabled	O
two	O
-	O
third	O
of	O
the	O
BiLSTM	O
features	O
,	O
the	O
maximum	O
macro	O
F1	O
drop	O
was	O
less	O
than	O
5	O
%	O
.	O
This	O
suggests	O
that	O
there	O
is	O
a	O
lot	O
of	O
redundant	O
information	O
in	O
the	O
features	O
of	O
the	O
BiLSTMs	O
.	O

D	O
Metrics	O
for	O
Biases	O

In	O
this	O
paper	O
,	O
we	O
used	O
two	O
metrics	O
to	O
quantify	O
biases	O
in	O
the	O
models	O
-False	O
positive	O
equality	O
difference	O
(	O
FPED	O
)	O
and	O
False	O
negative	O
equality	O
difference	O
(	O
FNED	O
)	O
-with	O
the	O
following	O
definitions	O
(	O
Dixon	O
et	O
al	O
.	O
,	O
2018	O
)	O
.	O

F	O
P	O
ED	O
=	O
t∈T	O
|F	O
P	O
R	O
−	O
F	O
P	O
R	O
t	O
|	O
F	O
N	O
ED	O
=	O
t∈T	O
|F	O
N	O
R	O
−	O
F	O
N	O
R	O
t	O
|	O

where	O
T	O
is	O
a	O
set	O
of	O
all	O
sub	O
-	O
populations	O
we	O
consider	O
(	O
i.e.	O
,	O
T	O
=	O
{	O
male	O
,	O
female	O
}	O
)	O
.	O
FPR	O
and	O
FNR	O
stand	O
for	O
false	O
positive	O
rate	O
and	O
false	O
negative	O
rate	O
,	O
respectively	O
.	O
The	O
subscript	O
t	O
means	O
that	O
we	O
calculate	O
the	O
metrics	O
using	O
data	O
examples	O
mentioning	O
the	O
sub	O
-	O
population	O
t	O
only	O
.	O
We	O
used	O
the	O
following	O
keywords	O
to	O
identify	O
examples	O
which	O
are	O
related	O
to	O
or	O
mentioning	O
the	O
sub	O
-	O
populations	O
.	O
Male	O
gender	O
terms	O
:	O

"	O
male	O
"	O
,	O
"	O
males	O
"	O
,	O
"	O
boy	O
"	O
,	O
"	O
boys	O
"	O
,	O
"	O
man	O
"	O
,	O
"	O
men	O
"	O
,	O
"	O
gentleman	O
"	O
,	O
"	O
gentlemen	O
"	O
,	O
"	O
he	O
"	O
,	O
"	O
him	O
"	O
,	O
"	O
his	O
"	O
,	O
"	O
himself	O
"	O
,	O
"	O
brother	O
"	O
,	O
"	O
son	O
"	O
,	O
"	O
husband	O
"	O
,	O
"	O
boyfriend	O
"	O
,	O
"	O
father	O
"	O
,	O
"	O
uncle	O
"	O
,	O
"	O
dad	O
"	O
Female	O
gender	O
terms	O
:	O

"	O
female	O
"	O
,	O
"	O
females	O
"	O
,	O
"	O
girl	O
"	O
,	O
"	O
girls	O
"	O
,	O
"	O
woman	O
"	O
,	O
"	O
women	O
"	O
,	O
"	O
lady	O
"	O
,	O
"	O
ladies	O
"	O
,	O
"	O
she	O
"	O
,	O
"	O
her	O
"	O
,	O
"	O
herself	O
"	O
,	O
"	O
sister	O
"	O
,	O
"	O
daughter	O
"	O
,	O
"	O
wife	O
"	O
,	O
"	O
girlfriend	O
"	O
,	O
"	O
mother	O
"	O
,	O
"	O
aunt	O
"	O
,	O
"	O
mom	O
"	O
.	O
All	O
the	O
bios	O
are	O
from	O
Common	O
Crawl	O
August	O
2018	O
Index	O
.	O

•	O
Waseem	O
:	O
The	O
authors	O
of	O
(	O
Waseem	O
and	O
Hovy	O
,	O
2016	O
)	O
kindly	O
provided	O
the	O
dataset	O
to	O
us	O
by	O
email	O
.	O
We	O
considered	O
"	O
racism	O
"	O
and	O
"	O
sexism	O
"	O
examples	O
as	O
"	O
Abusive	O
"	O
and	O
"	O
neither	O
"	O
examples	O
as	O
"	O
Non	O
-	O
abusive	O
"	O
.	O

•	O
Wikitoxic	O
:	O
The	O
dataset	O
can	O
be	O
downloaded	O
here	O
10	O
.	O
We	O
used	O
only	O
examples	O
which	O
were	O
given	O
the	O
same	O
label	O
by	O
all	O
the	O
annotators	O
.	O

•	O
20Newsgroups	O
:	O
We	O
downloaded	O
the	O
standard	O
splits	O
of	O
the	O
dataset	O
using	O
scikit	O
-	O
learn	O
11	O
.	O
The	O
header	O
and	O
the	O
footer	O
of	O
each	O
text	O
were	O
removed	O
.	O

F	O
Full	O
Experimental	O
Results	O

Model	O
:	O
CNNs	O

Test	O
dataset	O
:	O
Yelp	O
Negative	O
F1	O

Positive	O
F1	O
Accuracy	O
Macro	O
F1	O
Original	O
0.767	O
±	O
0.02	O
0.800	O
±	O
0.00	O
0.785	O
±	O
0.01	O
0.789	O
±	O
0.01	O
Disabling	O
(	O
MTurk	O
)	O
0.786	O
±	O
0.00	O
0.804	O
±	O
0.00	O
0.795	O
±	O
0.00	O
0.796	O
±	O
0.00	O

Acknowledgments	O

We	O
would	O
like	O
to	O
thank	O
Nontawat	O
Charoenphakdee	O
and	O
anonymous	O
reviewers	O
for	O
helpful	O
comments	O
.	O
Also	O
,	O
the	O
first	O
author	O
wishes	O
to	O
thank	O
the	O
support	O
from	O
Anandamahidol	O
Foundation	O
,	O
Thailand	O
.	O

